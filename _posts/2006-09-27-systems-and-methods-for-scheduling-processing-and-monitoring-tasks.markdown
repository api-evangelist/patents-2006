---

title: Systems and methods for scheduling, processing, and monitoring tasks
abstract: A computer-implemented method for performing a process is provided. The method comprises: (a) receiving a request to perform a process, the process comprising a plurality of tasks and at least a scheduler rule; (b) receiving a plurality of checkpoints associated with the process, each checkpoint comprising checkpoint state data and at least a respective checkpoint rule governing execution of the process; (c) determining a first task of the plurality of tasks to be scheduled into a priority queue, in accordance with the scheduler rule; (d) determining the first checkpoint of the plurality of checkpoints that is to be the first checkpoint used in processing the first task, in accordance with the scheduler rule; (e) creating the checkpoint state data for the first checkpoint; (f) saving the checkpoint state data for the first checkpoint; (g) processing the first task in accordance with the checkpoint rule associated with the first checkpoint; (h) determining the next task in the plurality of tasks to perform, based on the checkpoint rule associated with the first checkpoint; (i) updating the saved checkpoint data for the first checkpoint with the data and state associated with the first task; and (j) repeating steps (c) through (i) for each subsequent task and checkpoint, in accordance with the respective scheduler and checkpoint rules, until a predetermined condition has been reached.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07669081&OS=07669081&RS=07669081
owner: Raytheon Company
number: 07669081
owner_city: Waltham
owner_country: US
publication_date: 20060927
---
This invention was made with Government support under Contract N00024 04 c 2301 with the Department of the Navy. The Government has certain rights in this invention.

Embodiments of the invention generally relate to computer hardware and software and more particularly the invention relates to systems and methods that enable task scheduling processing and monitoring especially as part of a scalable and configurable architecture.

The processing unit of a computer system e.g. a Central Processing Unit CPU or microprocessor interprets and executes instructions to accomplish processes or tasks that can process data within the system or control some device or application. Some computer systems provide multiple processors to perform different tasks or groups of tasks and other computer systems might instead provide a single processor that is responsible for performing all of the required tasks. With either a single processor system or a multi processor system when the system is running multiple tasks or multiple applications at the same time some type of scheduling becomes necessary.

An operating system running on a computer system can include some type of task scheduler process routine algorithm or procedure. The task scheduler determines priority or is generally responsible for determining the priority of each task and selects and schedules tasks for performance. Task Schedulers divide up a total amount of available processing cycles or processor time available on the processing unit between the applications and or various tasks that must be performed sometimes referred to as time slicing . Many different task scheduling techniques and or algorithms have been employed. A few examples include load control scheduling priority based scheduling First In First Out FIFO scheduling rate monotonic scheduling and round robin scheduling.

In some environments the computer system and its operation e.g. the computer hardware and software are custom and application specific. Consider for example military applications such as the U.S. Navy. Throughout the Navy s fleet computer hardware and software systems have long tended to be unique to particular ships or classes of ships. Even on a single ship there can be multiple independent computer systems dedicated to specific functions such as operating the radar and sonar navigating the ship gathering intelligence firing guns and missiles controlling shipboard power systems tracking spare parts inventories and training the crew.

Such all unique computer systems are examples of so called closed architectural designs also referred to as stovepiped designs . That is such closed architectural systems usually operate independently in parallel and incompatibly with each other. Such systems frequently cannot communicate freely with other computers in any capacity for example as hosts peers or clients unless those other computers are of the same type running the same software operating systems and applications. Thus designing building maintaining and above all using multiple closed architecture computer systems can be very expensive time consuming and labor intensive. In addition multiple systems may necessitate multiple teams of system operators and support technicians multiple spare parts inventories multiple installations and multiple support infrastructures.

To help overcome the limitations of the closed architectural designs some organizations including the Navy are migrating to more efficient and cost effective approaches to computing. One efficient and cost effective approach being considered is using so called open architecture OA systems which have long been employed in many non military industries. OA systems are designed to be integrated and interoperable with each other and can have published specifications which let lets third parties develop add on hardware or software for a computer or device that is part of the OA system. In many instances a single OA system and its users can more effectively handle the heavy workloads that formerly required a variety of different systems and many more personnel. To achieve a high level of inter operability and openness in an OA system the OA system uses common communications standards and protocols paired with affordable widely available Commercial off the Shelf COTS hardware and software. One example of a widely adopted OA system in commercial use is the Internet technology that sustains both the public World Wide Web and similar private secure corporate intranets.

The U.S. Navy s first large scale OA system implementation is the so called Total Ship Computing Environment TSCE which comprises a single computer network infrastructure that supports various layers of interoperable application software programs. Raytheon Corporation of Waltham Mass. developed the TSCE for use with a specific Navy vessel the next generation DD X multi mission destroyer. DD X is a family of ships including the DD X multi mission destroyer that will be the U.S. Navy s first ship of the next generation surface combatants . It is expected that the TSCE design will find application in many military and non military applications in addition to the DD X program.

TSCE consists of an application software layer such as a DD X tactical application software layer running on top of the Total Ship Computing Environment Infrastructure TSCEI or TSCE I . The TSCEI includes several layers comprising hardware operating system middleware and infrastructure services. The TSCE software environment is a service based architecture where each element of the software environment infrastructure and applications is treated as a service provider to the system. At the lowest level a service equates to a single software object that resides in the TSCE. TSCE software services populate all of the hardware resources that make up the TSCE physical environment. For example an application can reside in a ship s data center shore site or a remote access device such as a PDA. The location of the device or its type makes no difference as long as the device provides the necessary computing resources.

One advantage of the TSCE is that a user e.g. the U.S. Navy can move away from the closed systems and closed software previously developed at great expense for particular applications. Many closed systems especially those in use in the military include special purpose variants of many functions that could individually be genericized and made into reusable patterns or components. By using TSCE instead of closed software systems the user e.g. U.S. Navy can achieve faster deployment times easier upgrading of deployed systems and lower life cycle costs. Advantageously the TSCE is constructed to be flexible and extensible to meet all current and future U.S. Navy missions encompassing command control communications and computers intelligence surveillance and reconnaissance C4 ISR and combat systems. The TSCE also extends ashore to support DD X maintenance logistics training and other deployment functions

Services are deployed to the TSCE locate each other through lookup and discovery mechanisms and are assimilated into the software environment as peers in the service community. Because TSCE is open services can join and leave the TSCE as the mission operational requirements of the system change. More importantly the system has the ability to move services dynamically when a failure or casualty occurs yielding the maximum system reliability scalability and availability in a dynamic changing computing environment. The DD X open standards based approach to the TSCE detaches applications from hardware and software eradicates rigid weapon sensor pairings and eliminates the need for independently managed tactical software programs.

Controlling the operation of a computer system and computer applications running on the computer system also involves issues such as prioritizing tasks monitoring tasks providing a fail over strategy should the computer system or application encounter a problem saving the state of the computer system and or an application if the computer system and or application must be stopped and recovering the computer system and or application after the program has been stopped.

One way to save the state of a computer system is by creating a snapshot or restore point that stores the state of a running computer system in a predetermined repository such as a file or hard disk. Restore points can be established in various ways including upon user initiation periodically triggered by an external event etc. When a restore point is used if the computer system later fails the computer system can be restored to a previous restore point by using information from the snapshot e.g. a recovery file to recreate the computer systems state at the time the restore point was made. The computer system can then resume execution from the restore point. It can be advantageous if restore points also are established and used for applications running on a computer system but known recovery systems don t provide the ability to save the state of an application or a high level process at user developer defined points.

To handle scheduling various types of operating systems have various types of schedulers. For example the UNIX operating system provides a scheduling feature called cron . Cron handles simple job scheduling at the operating system level in the form of an ability to start a Unix command at a specific time based upon sufficient date and time matching criteria. For example if a user wants to tell a system to perform a backup every night at midnight the user can use the cron feature. The Unix chron scheduler is not able to connect the execution of a first job with the results of a second job and cron cannot start jobs that aren t time dependent. Thus a developer can t use Unix cron to run a job based on a non time dependent condition such as when an error occurs or when a system resource becomes available nor can a developer tell the cron scheduler conditional ways that job flow can change. Job scheduling on mainframe computers is also done at the operating system level but can provide more features than the Unix Scheduler including the ability to trigger running a job using some types of non time based criteria such as if a certain system activity occurs e.g. a database is shut down . However there are few if any schedulers that provide a scheduling capability at the application level.

In one aspect the invention provides a software architectural framework that supports the processing of tasks including application level tasks via multiple priority queues. The framework allows a user developer to break down a logical thread of processing into smaller parts that are modeled as processor functions that allow for an elevated amount of software reusability where the processor function is responsible for some common functionality.

The state of a logical thread is modeled as a task that is passed between processor functions. When a processor function accepts a Task the processor function uses data within the task as necessary and stores the output data in the task. This output data in turn becomes the input data for the next processor function. Selecting the next processor function is supported through the use of developer provided rules also referred to herein as strategy patterns . Each rule encapsulates the decision making necessary for selecting the next processor function. A task scheduler gets directed by these rules to select the next processor.

Through the use of these rules the integrity of the original logical thread of processing is maintained. Tasks are consequently placed in a priority queue as they wait to be sent to the next selected processor function. Before a task is placed on a queue it is saved to persistent storage using primary keys known only to the task scheduler. This step allows for the recovery of the task data placed on the queues. Each priority queue and processor function is allocated its own thread. A task processor manages the priority queue processor function and thread. In the case where an immediate mission high priority message task is received in at least one embodiment all task processors halt their threads. The immediate task is allowed to go through its needed processor functions. Once the immediate task has completed going through all its processor functions the task processors resume their normal dispatching of tasks from the priority queues.

In one aspect the invention provides a computer implemented method for performing a process the method comprising 

 a receiving a request to perform a process the process comprising a plurality of tasks and at least a scheduler rule 

 b receiving a plurality of checkpoints associated with the process each checkpoint comprising checkpoint state data and at least a respective checkpoint rule governing execution of the process 

 c determining a first task of the plurality of tasks to be scheduled into a priority queue in accordance with the scheduler rule 

 d determining the first checkpoint of the plurality of checkpoints that is to be the first checkpoint used in processing the first task in accordance with the scheduler rule 

 g processing the first task in accordance with the checkpoint rule associated with the first checkpoint 

 h determining the next task in the plurality of tasks to perform based on the checkpoint rule associated with the first checkpoint 

 i updating the saved checkpoint data for the first checkpoint with the data and state associated with the first task and

 j repeating steps c through i for each subsequent task and checkpoint in accordance with the respective scheduler and checkpoint rules until a predetermined condition has been reached.

The predetermined condition can comprise determining that the process has finished checking a rule to determine whether the process has finished and or receiving an instruction to process the tasks in a specific order e.g. where the specific order deviates from the order specified in at least one of the scheduler and checkpoint rules. The predetermined condition also can comprise receiving a second request to perform a process where the second request has a higher priority than the first request determining that a task has not been scheduled properly determining that a task has not been processed correctly determining that a task is unhealthy and or receiving an instruction to pause or stop the performing of the process.

In one embodiment the method further comprises the steps of k retrieving a stored checkpoint associated with the task that did not process correctly l recovering the failed task using the retrieved checkpoint and m repeating steps d through j . Also the method can further comprise polling during at least one of steps a through j to determine whether processing of a task occurred correctly.

In one embodiment each checkpoint is allocated a respective thread and a priority queue and the method further comprises polling each thread to determine whether the thread is healthy. The method can further comprise reporting when a task has been processed and optionally determining how long it takes for a given task to be performed.

A notification can be sent providing information regarding the progress made in performing the process and or if a task is unhealthy. If a task is unhealthy the method can further include performing at least one of the following actions i restarting the task ii ending the task and iii moving processing to a different task

In another aspect the invention provides a method for processing a logical thread comprising the steps of 

 b modeling the state of the logical thread as a first task that is passed between processor functions the first task comprising first task data and a first task state 

 e selecting a first processor function for processing the first task in accordance with a first rule 

 f receiving the first task at a first processor function and using the first task data to perform a first process on the task 

 i selecting a second processor function for processing the first task in accordance with a second rule and

 j receiving the first task at the second processor function wherein the second processor function uses the output data from the first process if necessary as the input data to the second process.

Task data that is used across processor functions can be tracked. The tracked task data can be removed when all processor functions are complete. The modeling can further comprise modeling the state of the logical thread as a second task that is passed between processor functions the second task comprising first task data and a first task state and further comprising the steps of adding the second task to the queue of tasks persisting the second task in a third checkpoint and selecting the next task to be processed by the processor functions in accordance with a predetermined priority.

In still another aspect the invention provides a computerized system for executing a process the system comprising means for receiving requests to execute a business process and for providing responses to the requests means for processing incoming requests in accordance with a predetermined priority method means for saving data relating to the state of processing of the incoming request at one or more checkpoints and means for recovering data from a checkpoint to restore the business process.

The invention can further comprise means for checking the health of the business process means for pausing the business process to permit a higher priority activity to occur and or means for changing the way the business process executes.

The drawings are not necessarily to scale emphasis instead generally being placed upon illustrating the principles of the invention.

Before discussing the details of the invention a preliminary discussion is provided giving an overview of the type of computing environment in which at least some embodiments of the invention are realized. Systems and methods in accordance with the invention can be implemented using any type of general purpose computer system including but not limited to a personal computer PC laptop computer server workstation personal digital assistant PDA mobile communications device interconnected group of general purpose computers and the like running any one of a variety of operating systems. An example of a general purpose computer system usable with at least one embodiment of the present invention is illustrated in .

Referring briefly to the general purpose computer system includes a central processor associated memory for storing programs and or data an input output controller a network interface a display device one or more input devices a fixed or hard disk drive unit a floppy disk drive unit a tape drive unit and a data bus coupling these components to allow communication therebetween.

The central processor can be any type of microprocessor such as a PENTIUM processor made by Intel of Santa Clara Calif. The display device can be any type of display such as a liquid crystal display LCD cathode ray tube display CRT light emitting diode LED and the like capable of displaying in whole or in part the outputs generated in accordance with the systems and methods of the invention. The input device can be any type of device capable of providing the inputs described herein such as keyboards numeric keypads touch screens pointing devices switches styluses and light pens. The network interface can be any type of a device card adapter or connector that provides the computer system with network access to a computer or other device such as a printer. In one embodiment of the present invention the network interface enables the computer system to connect to a computer network such as the Internet.

Those skilled in the art will appreciate that computer systems embodying the present invention need not include every element shown in and that equivalents to each of the elements are intended to be included within the spirit and scope of the invention. For example the computer system need not include the tape drive and may include other types of drives such as compact disk read only memory CD ROM drives. CD ROM drives can for example be used to store some or all of the databases described herein.

In at least one embodiment of the invention one or more computer programs define the operational capabilities of the computer system . These programs can be loaded into the computer system in many ways such as via the hard disk drive the floppy disk drive the tape drive or the network interface . Alternatively the programs can reside in a permanent memory portion e.g. a read only memory ROM chip of the main memory . In another embodiment the computer system can include specially designed dedicated hard wired electronic circuits that perform all functions described herein without the need for instructions or methods from computer programs.

In at least one embodiment of the present invention the computer system is networked to other devices such as in a client server or peer to peer system. The computer system can for example be a client system a server system or a peer system. In one embodiment the invention is implemented at the server side and receives and responds to requests from a client such as a reader application running on a user computer.

The client can be any entity such as a the computer system or specific components thereof e.g. terminal personal computer mainframe computer workstation hand held device electronic book personal digital assistant peripheral etc. or a software program running on a computer directly or indirectly connected or connectable in any known or later developed manner to any type of computer network such as the Internet. For example a representative client is a personal computer that is x86 PowerPC.RTM PENTIUM based or RISC based that includes an operating system such as IBM.RTM UNIX HP UX LINUX OS 2.RTM. or MICROSOFT WINDOWS made by Microsoft Corporation of Redmond Wash. and that includes a Web browser such as MICROSOFT INTERNET EXPLORER NETSCAPE NAVIGATOR made by Netscape Corporation Mountain View Calif. having a Java Virtual Machine JVM and support for application plug ins or helper applications. A client may also be a notebook computer a handheld computing device e.g. a PDA an Internet appliance a telephone an electronic reader device or any other such device connectable to the computer network.

The server can be any entity such as the computer system a computer platform an adjunct to a computer or platform or any component thereof such as a program that can respond to requests from a client. Of course a client can be broadly construed to mean one who requests or gets the file and server can be broadly construed to be the entity that sends or forwards the file. The server also may include a display supporting a graphical user interface GUI for management and administration and an Application Programming Interface API that provides extensions to enable application developers to extend and or customize the core functionality thereof through software programs including Common Gateway Interface CGI programs plug ins servlets active server pages server side include SSI functions and the like.

In addition software embodying the present invention in one embodiment resides in an application or other program running on the computer system . In at least one embodiment the present invention is embodied in a computer readable program medium usable with the general purpose computer system . In at least one embodiment the present invention is embodied in a data structure stored on a computer or a computer readable program medium. In addition in one embodiment the present invention is embodied in a transmission medium such as one or more carrier wave signals transmitted between the computer system and another entity such as another computer system a server a wireless network etc. The present invention also in an embodiment is embodied in an application programming interface API or a user interface. In addition the present invention in one embodiment is embodied in a data structure.

Having described examples of computing environments illustrative embodiments of the invention will now be described. Note that in the following description the framework and system described herein is illustratively shown as being in communication with the aforementioned TSCE I environment by way of example only. Those of skill in the art will recognize that this example and area of use e.g. U.S. Navy is in no way limiting. The TSCE I environment is but one application of the invention. At least some embodiments of the invention described herein have applicability and utility in virtually any type of environment capable of using reusable design patterns and states task scheduling systems and monitoring systems.

The following provides a detailed explanation of the functions and operations of several embodiments of the invention.

The environment in which the scheduler operates is in one embodiment a layered architecture having two layers of abstraction the scheduler and a software configuration item SCI layer which includes the SCI business logic component and the SCI itself . The scheduler serves as a central communications point with the TSCE I and other external applications and provides de coupling of the task scheduler from external interactions and external dependencies. The SCI specific business logic provides the logic e.g. rules that govern the execution of the tasks for the specific business application function being provided to the scheduler such as the SCI . The scheduler includes a task queue a processor function a persistence module a recovery mechanism and a task scheduler . Each of these is explained further below.

The initialization module provides the model for sequencing the events during each SCI phase i.e. the time period that an SCO is using the scheduler including events such as booting starting and termination. The health module monitors the health of SCI components running on the scheduler . The Task Scheduler reports a periodic health to the health module . The recovery mechanism restores the last known safe state of an SCI by restoring an SCI related tasks running on the scheduler to a last known good state. The Task Scheduler monitors the threads of the Processor Functions PF if one does not check in with its health in a developer configured amount of time the thread can be restarted. Optionally the SCI can be reported as unhealthy or the offending task can be removed so all other tasks within the Processor Functions Task Queue can be processed. The persistence module stores state data and other relevant data at predetermined times such as when a processor function checkpoint described further herein is completed when a task begins ends pauses resumes or is restarted and or at other times defined by user or developer such as through one or more rules described further herein.

The scheduler is in operable communication with the TSCE I . The Task Scheduler allows the scheduler to interrupt a thread and or recover a thread.

Advantageously the scheduler provides Application Program Interfaces API s that are implemented by the developer. This allows for a significant amount of reusable code. For example in one embodiment a software configuration item SCI is implemented using the SCI Specific Business logic in cooperation with the scheduler as described further herein an extensible markup language .XML file to configure the Scheduler and as few as four small classes totaling about 50 source lines of code SLOC .

Referring to the scheduler provides task schedulers persistence task processing and task queue processor function also referred to herein as checkpoint functionality although the actual business processing to accomplish these functions is specific within an SCI and a recovery mechanism . The task scheduler module which is explained in greater detail further in connection with provides functions including restoring state prioritizing messages enabling tasks to hold process information monitoring thread health and providing persistence via persistence module . The task factory module creates the tasks and its operation is explained further.

The SCI Specific Business logic provides a scheduler that it is in communications with one or more rules that govern the way a set of tasks will execute as well as one or more tasks to be executed. At least some of these rules are used by the common business component described above.

The Task Scheduler provides interfaces that can be implemented so each component may assess its own health independently. The health module receives health information from the Task Scheduler or any other source or component that an application developer opts to use. For example when a task is received and takes an unusually long time to process then the health could be reported as degraded by the Task Scheduler . Generally the health module does not necessarily know how each SCI assesses its health information. In addition the persistence module does not provide the health module with its health information rather health of the persistence module is taken care of in the scheduler . In addition health of the common business component is assessed indirectly by the Task Scheduler .

In a message is received from TSCE I . The message is turned into a task through the task factory and submitted to the task scheduler . The task scheduler looks at the associated rule and adds the task to a queue e.g. task queue . The processor function has a thread attached to it that processes the task queue . Tasks are scheduled based on priority. The processor function removes the next task and calls into the SCI business logic . There are interfaces not shown but understood by those of skill in the art that the SCI Business logic implements so that the processor function knows what to call. Once the SCI Business logic is done processing the task it inserts any data it wants to save into a task data map see . The processor function gets the task returned to it with the task data map and persists the state of the SCI . After persisting the processor function checks the rules and adds the task to the next processor function task queue . The next processor function repeats the same behavior.

If an SCI fails the task scheduler automatically goes to the recovery mechanism described further herein and recovers all tasks looks at each task s rule and puts the task on the appropriate task queues for processing. This is done whenever an SCI is started to recover or pick up where processing left off.

Referring now to the diagram of task scheduler activity flow shows processing occurring over four zones a health zone a scheduling zone an application zone and a recovery persistence zone . The health zone includes a health monitor . Each is described further herein. The scheduling zone includes a scheduler and a plurality of processor function priority queues A B C each of which has a priority attribute the task scheduler uses a queue thread in each processor function. The application zone includes checkpoints A B and C. The recovery persistence zone includes persistent storage . The persistent storage is used as part of the process where data is checkpointed at the beginning of a processor function and between processor functions see threads and 

Each of the above steps along with the operations shown in is described further below in connection with the flowcharts of .

Referring to and at a high level the task scheduler operates on an input or message it receives e.g. a method invocation or a publish subscribe request and ultimately produces a corresponding output or response message. For example in the scheduler receives an external message thread such as via TSCE I . The message is translated into a task through the task factory and a resultant task is passed to the scheduler thread . The message can for example be from the SCI business logic of another SCI requesting that a process be performed the process consisting of one or more tasks to be executed. The SCI business logic thus creates the task s and the scheduler schedules executes and monitors them.

In one embodiment the scheduler is implemented using a manager thread which adds entries to the appropriate checkpoint priority queue processor function priority queue A also referred to herein as a task queue A . After the checkpoint thread is finished processing the processor function advances the state of the task a task is an object that contains state and relevant data that has been altered or created during checkpoint processing to the next checkpoint processor function and adds the task to the appropriate checkpoint processor function task queue . The task in the example of is processed where a process exists to process information and or data. The process could for example be a process used by an SCI .

The processing done in an SCI can be logically broken up into parts or tasks as shown in and in the latter of which is a checkpoint structure diagram showing the checkpoint structure used with the tasking queue operation diagram of . The SCI provides a first task for the process and adds the task thread to the tasking queue A. A task can carry data between checkpoints which are described below and a task is recoverable. Before processing starts the state of the data is saved to persistent storage thread . Note that although persistent storage is illustrated in the embodiment as being separate from the scheduler in at least one embodiment the scheduler also can be implemented to include the persistent storage as well. Advantageously however the persistent storage is implemented in a manner such that it is separate from the scheduler doing the processing of tasks to help ensure that the persistent storage is able to provide task recovery should there be a problem with the task processing.

Part of the tasking queue A s functionality includes segregating business processing i.e. processes tasks that it receives from the SCI business logic to logical services states. Logical Services are also referred to herein as checkpoints and each process can be divided into checkpoints e.g. checkpoints A B and D of . Each checkpoint effectively has intelligence because the checkpoint includes and is associated with one or more rules that tell how the checkpoint is to proceed. is a checkpoint and thread flow diagram A for the tasking queue operation diagram of and is a rule strategy pattern diagram for checkpoint flow for the tasking queue operation diagram of . Examples of checkpoints include checkpoints A B C of checkpoints A B C and D in and B or checkpoints A through D of . After each task has been completed a checkpoint exists and checkpoints can have a queue of tasks that are operated on see e.g. . Checkpoints are threads that also provide status information in addition each checkpoint also has its own rule associated with it and the SCI working with the scheduler can have a number of threads running concurrently. There can be as many or as few checkpoints as needed. Note also that a checkpoint can be associated with more than one task and can be reused by more than one task or even the same task . See e.g. which shows that checkpoint A is associated with five different tasks and also which shows checkpoint A being revisited.

Each checkpoint contains its own thread. There can be multiple threads running at once after the thread has finished processing the task it is persisted checkpointed and the rule is interrogated to determine which task queue to add the task to. A given checkpoint does a defined set of processing i.e. the checkpoint runs the task and the example checkpoints of are linked together via one or more predetermined rules or strategy patterns to process inputs. For example in checkpoint A links to checkpoint B via first process task thread . Further a given checkpoint can be associated with a first rule or set of rules while being used by a first SCI and with a second rule or set of rules when the same checkpoint is being used by a second SCI .

The rule linking checkpoints together is preferably predetermined such as being provided in the SCI business logic by a developer or user. In at least one embodiment even if the rule is predetermined the rule operates as if it were dynamic and or data condition driven. This allows checkpoints to be revisited and or bypassed skipped based on whether a predetermined condition exists such as if data has a certain value . For example consider the possible rules that are applicable to the checkpoint flow shown in which links checkpoints A B C and D together. An illustrative example of a possible rule strategy pattern for is as follows 

 3 If first predetermined condition exists e.g. data has a certain value certain system conditions are present etc. after tasks associated with checkpoint B are complete process tasks associated with checkpoint C 

 4 If second predetermined exists after tasks associated with Checkpoint B are complete process tasks associated with Checkpoint D i.e. bypass Checkpoint C 

 5 Else i.e. if neither first nor second condition exists after tasks associated with checkpoint B are complete process tasks associated with checkpoint A and repeat from Checkpoint A onward 

With the rule strategy pattern example of checkpoints can be revisited and or skipped. As those of skill in the art will appreciate the rule strategy pattern represented by steps 1 7 above is but one of many possible rules applicable to the example checkpoint flow of and is but one rule strategy pattern that is possible for the embodiments of the invention.

As another example referring to a first developer can create a state and processor function associated with checkpoint B and apply them using a first set of rules then a second developer can re use this state and processing functions of the state associated with checkpoint B that the first developer created in a new state associated with checkpoint D but the second developer applies them to checkpoint D using a second different set of rules. This can be done without problems i.e. without the second developer s actions affecting the first and vice versa because each checkpoint is a separate thread that can fix itself.

Referring again to A and B at the end of each checkpoint i.e. after the associated task processing is complete the state of data has an opportunity to persist if necessary. For example in after the processing associated with checkpoint A is complete threads checkpoint data is saved to persistent storage thread before processing begins at checkpoint B B and the checkpoint B can return an entry to the tasking queue B. Similar persisting occurs at the other checkpoints. In the example of the state of the data is saved before processing starts and again at the end of each checkpoint . Persisting the relevant data and state helps allow for a fail over mechanism. If an SCI or any of its processes or threads is terminated or fails for some reason the state and relevant data have been saved. If a fail over is necessary at start up after the fail over the SCI can retrieve the state and relevant data and repopulate the queues.

Once the processing has completed e.g. after checkpoint D in the state data also referred to as the keys to the data can be deleted removed thread or archived. The keys to the data are passed along in the outgoing message thread . In addition once the processing has completed for a given checkpoint the rule is queried and the task is added to the next checkpoint queue

In at least some embodiments of the invention various events and or conditions can interrupt and or stop a process that is running. For example if a process receives a terminate message e.g. from the TSCE I or from the SCI then task scheduler module stops processing of the queues. The entries that are currently being processed are allowed to move to their next checkpoint and when all threads have reported to the task scheduler the task scheduler sends a message to TSCE I that it is ready and able for an orderly shutdown.

In one embodiment of the invention a priority scheme is implemented to give high priority messages have their own special path thread in the queuing mechanism. When a high priority message is received at the scheduler the high priority message given a state and an entry is added to the priority queue. All threads are notified that a high priority entry has been received and all queues stop processing lower priority entries until the high priority entries have been processed. The low priority entries that were in process are allowed to finish to the next checkpoint and then the threads are kept waiting until the high priority entry has finished processing. Once the high priority entry has finished processing the task scheduler is alerted and all the lower priority entries are allowed to resume processing. The threads that were interrupted are not preempted rather these threads are merely stopped in an orderly fashion until the high priorities have been processed.

The Scheduler as described above provides several additional advantages for at least some embodiments of the invention. Using a Scheduler facilitates development of checkpoints by individual developers and or sites enabling the scheduler to maintain flexibility. Use of a Scheduler also makes software development especially application SCI development simpler because all a developer needs to be concerned with is meeting the application SCI s functionality requirements not the processing recovery backup or fail over associated with the execution of the application SCI . The Scheduler s use of checkpoints helps provide a fail over mechanism and enables the scheduler to be extensible e.g. checkpoints can be added and re used to fulfill new requirements . The Scheduler also allows thread control provides persistence for business logic and mitigates risks associated with synchronization of data structures and or resources.

Referring briefly to and in the queue A the highest priority task is popped i.e. released for processing and consumed i.e. executed see block in and thread in . The rule is checked block so that the next processor function PF can be retrieved thread in . Before beginning processing of the next processor function the data is persisted i.e. the checkpoint data in this case at checkpoint B is updated block in and thread in . The checkpoint data provides a TaskDataMap for persistent data used across processor functions. This data is stored at the beginning of the task request and at the end of each subsequent processor function and checkpoint data is removed at the end of the last processor function. Because the checkpoint data is stored in persistent storage it can be used to restore a task and or put the task back into the appropriate queue should there be a need to recover the data and or the application running the data.

At checkpoint B the thread pushes down to point to the next highest processor function in the queue block . Then the processes are repeated blocks of until the rule determines that the task has finished block . When the task is finished the checkpoint data is removed block in and thread in and the task is ended.

In at least some embodiments of the invention a user can control the checkpointing functions after processor functions have been executed. For example a user can choose to skip the step of persisting the current checkpoint data and choose to recover instead from the last saved checkpoint. This can be useful in instances where a user has determined that some or all of the current processing has problems and or errors or if a user wants to terminate a possibly malfunctioning thread.

Unlike conventional printing queue tasks however with the invention it is possible to recover failed tasks more easily permit other tasks to go ahead even if one has failed or has not executed correctly and monitor thread task and checkpoint health and notifications of problems more generic and applicable to many different systems and configurations versus the very specific printer queue processing that can occur with certain specific types of printers.

Referring again to the processing for this flowchart takes place in the health zone and the scheduling zone of . The health monitor is started block and it polls the scheduler for health information block . If the scheduler tells the health monitor that it has a problem i.e. is not healthy block then the health monitor reports that the component currently being polled in this case the scheduler is unhealthy block and the health monitor continues polling. The health monitor continues polling because the TaskScheduler may be able to recover from the problem. If the TaskScheduler reports a problem as serious as a catastrophic error the health monitor stops polling and reports a problem that causes the SCI to be shutdown and the recovery mechanism gets activated as a slave SCI take over from the master SCI.

If the polling of the scheduler shows that it is healthy then the health monitor polls the first checkpoint i.e. checkpoint A block . If the first checkpoint is unhealthy block then the health monitor reports that the component currently being polled in this case checkpoint A is unhealthy block and the health monitor stops polling. Similar polling and notifications occur for checkpoints B and C. The task scheduler reports a rollup of all thread health. If a single thread is unhealthy the task scheduler reports a minor error and tries to recover the thread. If unsuccessful in recovering the thread it can shutdown the offending thread and start a new one.

Should the health monitor processing of find that the scheduler or one of the checkpoints is not healthy recovery is possible. is a recovery activity flow chart for the Task Scheduler of . Recovery processing takes place in the recovery persistence zone the application zone and the scheduling zone of . Referring to the application that is being recovered is restarted block . In one embodiment a failed task will necessitate a failed thread which necessitates a failed SCI but this is not necessarily true for all embodiments of the invention. For example in one embodiment the task scheduler could recover a failed task and ultimately shutdown a failed thread and re start it with the failed task. In another embodiment if a task fails 3 times then the scheduler could log a problem to the user and start the next task on the queue. Of course these are only illustrative examples and other modes of recovery are possible. Tasks associated with the failed application are recovered from persistent storage block . If the tasks cannot be recovered block then recovery processing ends which could mean for example that recovery has failed or even that the process has just started and there are not yet any tasks to recover. If the tasks are recovered then they are scheduled block and the task flow proceeds in the same manner described previously for other scheduled tasks.

Referring to in block if the poll of the scheduler for health block finds that the scheduler is not healthy then processing proceeds in accordance with one or more predetermined rules. For simplification of explanation in the example of it is assumed that the logic governing the operation of the scheduler and each checkpoint is the same and is as follows 

If the healthy poll result blocks comes back with the answer No for unhealthy first determine whether the rule for the scheduler and or the checkpoint wants an attempt at restart to be made block . If the answer is Yes then processing proceeds to the recovery flow chart of . If the answer is No then processing proceeds to the query block . In query block a determination is made as to whether the rule for the scheduler and or the checkpoint wants the process to end be shut down. If the answer at query block is Yes then a graceful shutdown occurs such as with saving states files where appropriate as is known to those of skill in the art block and processing proceeds to block to see what to do next. If the answer at query block is a No that is the process should not be shut down then processing moves to query block .

At query block a determination is made as to whether the rule for the scheduler and or the checkpoint wants an attempt to be made to begin processing at another checkpoint. If the answer at block is Yes then the state of the unhealthy process is saved the processing begins resumes at a different checkpoint block and the polling for health resumes block . If the answer at block is No then the given scheduler checkpoint is reported as unhealthy block in the same manner as done in .

An illustrative example of an embodiment of the invention utilizing the above tasking queue design is now described. This embodiment includes illustrative examples of class diagrams and sequence diagrams for operations associated with the above described tasking queue checkpoints rules threads etc. Of course those of skill in the art will appreciate that the particular class and sequence diagrams provided herein including the names used and order listed are proved by way of example and are not limiting.

In this example a class called TaskScheduler is used to implement the tasking queue of . together form a TaskScheduler class diagram for the system and scheduler of in accordance with one embodiment of the invention. The TaskScheduler class diagram is a high level class diagram showing the interdependency of objects and interfaces.

Advantageously in one embodiment the design of the TaskScheduler utilizes services provided by a Systems of Systems Common Operating Environment SOSCOE . SOSCOE is a system used by the U.S. military that delivers a reusable set of software components that platform integrators and application developers use as the foundational building blocks of their software code. SOSCOE helps battlefield systems communicate and interact with other systems such as the U.S. Army s Future Combat Systems FCS equipped Unit of Action UA .

The Database SOSCOE service is used for persisting Checkpoint state data. This data is used for recovery failover. Every Checkpoint s state data is persisted before the previous thread s control is relinquished which helps to make the scheduler more deterministic. Once the last Checkpoint s execution is finished the state data is removed.

The Pub Sub SOSCOE service is used as an external stimulus. Any message can be passed through this framework for processing so long as a TaskProcessor has been implemented to handle that data entity. Pub Sub is a standard way for incoming messages to be received and sent.

The Event SOSCOE mechanism can be used to send messages for processing into the TaskScheduling framework notify a manager entity that a particular TaskProcessor has completed been entered or has an issue etc.

Of course as those of skill in the art will appreciate use of SOSCOE services and mechanisms is not required for any embodiments of the invention. The embodiments of the invention that include use of outside services can be used with reusable software components or services provided by any entity independent of whether the entity is a military based entity.

Referring again to the TaskScheduler is a class that is responsible for the scheduling and creation of checkpoints. When a message is given e.g. received at scheduler for processing it is the TaskScheduler that ensures that the message data is forwarded to the correct checkpoint and that higher priority messages are handled appropriately. An important purpose of the TaskScheduler is to link several so called atomic tasks together to perform a larger operation. These atomic tasks referred to herein as TaskProcessors can be derived from a large task broken at functional locations and linked together with specific rules which are referred to herein as RuleProcessors. By doing this a system e.g. scheduler of can have several tasks use some of the same TaskProcessors but link to others possibly in differing order simply by configuring the RuleProcessors accordingly. These rules define the order and which TaskProcessors are visited during the execution of a complete task.

The TaskProcessor is a functional business logic component. This class is responsible for managing an isolated portion of business logic used in processing the given data. A particular task data element may require multiple actions to be taken each of which can be done in isolation and are data independent. Each of these actions can be modeled as TaskProcessors with a RuleProcessor specifying what the next action to take based on the data present. Particular implementations of the Task Processor are user dependent.

The Checkpoint also referred to herein as a processor function is a container for a TaskProcessor and provides it the framework needed to integrate into the scheduling system. In addition the Checkpoint provides the means for task threading queuing persisting and recovery.

A RuleProcessor dictates which TaskProcessor is necessary to continue the processing of the given data. The determination can be static non dynamic and or based on state data. Particular implementations of the RuleProcessor are user dependent. The Rule Processor encapsulates the configurability of the scheduling framework. The rules are provided by the SCI business logic .

The RuleProcessor and TaskProcessor described further herein provide flexibility to the TaskScheduler framework. A RuleProcessor can dictate the direction of processing flow order of TaskProcessors by data state as shown in which includes a TaskScheduler State Diagram B. In each checkpoint A A is a container for a respective TaskProcessor that performs specific business tasks on the data presented them while RuleProcessors the links between the TaskProcessors dictate which path to take based on the current state of the given data. Each TaskProcessor has its own corresponding RuleProcessor to determine what business logic component to use next in processing. For example by utilizing RuleProcessors the same four TaskProcessors can be used for many different messages and contexts. As illustrated in each TaskProcessor represented in by the Tasks performs tasks on a separate queue and separate thread. This allows tasks to be processed independently and concurrently.

In a further embodiment of the invention the TaskProcessors are dynamically swapped and or loaded. Different task processors can be loaded or swapped based on a predetermined usage algorithm. For example if several TaskProcessors have not been used within a predetermined time period e.g. 10 minutes the TaskProcessors are removed until their use becomes necessary to free heap space. Another use algorithm example is to lazy load also referred to as on demand load one or more Task Processors i.e. defer the loading of one or more TaskProcessors until they are needed or access to them is requested .

First the client the GenericService in this diagram invokes the constructor of the TaskSchedulerImpl step thereby instantiating the TaskMap step . which maintains the association of Task to Id within the manager and the TaskScheduler step . . After creating and populating an array of TaskProcessors step the client hands those TaskProcessors to the TaskScheduler associated with the TaskManager via the initialize method steps through .. . The start method for the TaskScheduler is invoked upon each Checkpoint step . and the TaskProcessor array is passed through. This creates the list of Checkpoints to be managed one created for each TaskProcessor step .. . Upon doing so the start method of each Checkpoint is called step .. . This will result in data recovery for each Checkpoint setting each Checkpoint to the state they were in prior to the last shutdown step ... . After all of the Checkpoints have completed recovery the TaskScheduler is able to receive client Messages.

Referring to the TaskScheduler begins processing the Task by requesting the ID of the first Checkpoint used in processing of the given Task from its member RuleProcessor if one is not provided steps through . . After retrieving this Checkpoint the state data for this Checkpoint is persisted steps . and .. . This is done for recovery purposes. If the message is dropped before being persisted it is the client s responsibility to ensure the re delivery of the message. However after a successful delivery the TaskScheduler must ensure the message is successfully and correctly processed. After the state data is persisted the thread of control is relinquished back to the client and further processing will be managed by the threads owned by the TaskScheduler.

After the state data is persisted the Message of interest is placed on the queue of the current Checkpoint step . . Subsequent processing within that Checkpoint will be done on that thread thereby allowing for concurrent processing of Messages. The state data named TaskData is handed off to the current Checkpoint s TaskProcessor step which controls the business logic used in processing this Task. Upon the TaskProcessor s completion the RuleProcessor for the current Checkpoint is requested step . The RuleProcessor is queried for the next Checkpoint needed to complete the processing of this task step . The RuleProcessor returns the ID of the next Checkpoint step . that Checkpoint ID is set in the Task for facilitating recovery and Task scheduling step . The next Checkpoint is retrieved from the TaskScheduler step and the new state data for the next Checkpoint is persisted which also places the current Task on the next Checkpoint s processing queue. The above process continues e.g. steps until there is not another Checkpoint needed for processing. When all Checkpoints required for processing the current Task have been visited the state data associated with this Task is deleted from the persistent storage step .

In one embodiment of the invention to track the progress of a task specific messages are published during the lifecycle of that task. This is similar to the way the health monitor polls and then provides a notification as described further herein. Those messages are captured and interpreted by a tracking service. The publishing of messages is done in one or more ways in the various embodiments of the invention 

One benefit of the system and scheduler of and as further described herein is that the task can be broken in as many or few TaskProcessor units as necessary. Other benefits of at least some embodiments of the invention include 

 a Request Queuing Multi Threading which allows the client to post a non blocking request of service.

 b Request Pause Stop which allows Clients to pause or stop a particular ServiceRequest without affecting the other requests being serviced by the scheduler.

 c TaskProcessor Independence where each TaskProcessor has visibility to its necessary business logic components. Those functional blocks know how to process a particular data set thus facilitating the interchanging of processors to accomplish several different tasks.

 d User Contributed TaskProcessors and RuleProcessors which allow the user to implement specific rule logic this framework has scalability. In addition this framework is designed to be generic enough to be used in varying environments.

 d Persistence and Recovery where the Checkpoint manages state persistence before handing the ServiceRequest to the next Checkpoint ensuring recovery to the current Checkpoint. In addition to managing persistence the Checkpoint recovers its previous state during initialization.

As seen in the above figures the TaskScheduler has a procedure to handle the pausing resuming and stopping of a ServiceRequest described above. Certain services may require that specific actions take place before a request be paused stopped or resumed. In at least some embodiments of the invention the requirement that specific actions take place before a request is paused stopped or resumed is handled in one of the two following ways.

In accordance with one embodiment of the invention another approach to the RuleProcessor utilization described above involves associating a rule to each type of ServiceRequest handled by each service. This rule dictates the order of TaskProcessors to complete the request synonymously to the RuleProcessor but is tailored to that request rather than having a RuleProcessor tailored to a TaskProcessor. This implements the rule and is equally configurable as the other embodiments but enables the system and scheduler of to be more static than dynamic data driven.

In accordance with another embodiment of the invention to minimize the thread overhead utilization for example possible operating system OS threading issues with 300 services concurrently running each with one or more threads provisions are added that allow processing to be accomplished on the client thread. This is a configurable item dependent on the service and required capabilities. The services that employ this feature only require a single Checkpoint no state persistence and the business logic needed to service a request is minimal. This option and embodiment requires that the need for pausing and shedding of a ServiceRequest be unnecessary for those services.

Using the task scheduler as described herein provides a number of benefits for the software development process including providing a framework for prioritizing processing tasks enabling application teams to divide up large application processing functions and design concurrently helping to free up application developers to focus on business logic by relying on the Task Scheduler for persistence data recovery threads and thread health and providing a common consistent code for handling fail over needs

As the above description provides at least some embodiments of the invention establish a task scheduling monitoring approach that accommodates a scalable and configurable architecture provide a fault recovery strategy and has provision to allow for decision engine usage. Reuse of the design patterns as provided in some of the embodiments of the invention provides a more reliable implementation and improves value to the customer.

The systems and methods of the invention can be adapted to run on a variety of standard COTS computer hardware available from commercial suppliers. It is transportable between systems with minimal modification and is expandable to keep place with evolving business and customer requirements. Because at least some embodiments of the invention provides systems and methods for monitoring thread health and correcting itself the invention is very useful at the application level for many different applications especially web service applications e.g. electronic commerce applications .

As those skilled in the art will recognize the invention described herein can be modified to accommodate and or comply with any many different technologies and standards. In addition variations modifications and other implementations of what is described herein can occur to those of ordinary skill in the art without departing from the spirit and the scope of the invention as claimed. Further virtually any aspect of the embodiments of the invention described herein can be implemented using software hardware or in a combination of hardware and software.

It should be understood that in the Figures of this application in some instances a plurality of system elements or method steps may be shown as illustrative of a particular system element and a single system element or method step may be shown as illustrative of a plurality of a particular systems elements or method steps. It should be understood that showing a plurality of a particular element or step is not intended to imply that a system or method implemented in accordance with the invention must comprise more than one of that element or step nor is it intended by illustrating a single element or step that the invention is limited to embodiments having only a single one of that respective elements or steps. In addition the total number of elements or steps shown for a particular system element or method is not intended to be limiting those skilled in the art will recognize that the number of a particular system element or method steps can in some instances be selected to accommodate the particular user needs.

It should also be appreciated that the flow diagrams and flow charts provided herein do not depict the syntax of any particular programming language although in some instances methods from the Java programming language have been provided by way of example . Rather the flow diagrams and flow charts illustrate the functional information one of ordinary skill in the art requires to fabricate circuits or to generate computer software to perform the processing required of the particular apparatus. It should be noted that many routine program elements such as initialization of loops and variables and the use of temporary variables are not shown. It will be appreciated by those of ordinary skill in the art that unless otherwise indicated herein the particular sequence of steps described is illustrative only and can be varied without departing from the spirit and scope of the invention.

Further in describing the embodiments of the invention illustrated in the figures specific terminology is used for the sake of clarity. However the invention is not limited to the specific terms so selected and each specific term at least includes all technical and functional equivalents that operate in a similar manner to accomplish a similar purpose.

Although the invention has been described and pictured in a preferred form with a certain degree of particularity it is understood that the present disclosure of the preferred form has been made only by way of example and that numerous changes in the details of construction and combination and arrangement of parts may be made without departing from the spirit and scope of the invention as hereinafter claimed.

