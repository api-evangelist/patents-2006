---

title: Communicating arbitrary data in a concurrent computing environment
abstract: A communication protocol is provided for processes to send and receive arbitrary data in a concurrent computing environment. The communication protocol enables a process to send or receive arbitrary data without a user or programmer specifying the attributes of the arbitrary data. The communication protocol automatically determines the attributes of the arbitrary data, for example, the type and/or size of the data and sends information on the attributes of the data to a process to which the data is to be sent. Based on the information on the attributes of the data, the receiving process can allocate appropriate memory space for the data to be received.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08745254&OS=08745254&RS=08745254
owner: The MathWorks, Inc.
number: 08745254
owner_city: Natick
owner_country: US
publication_date: 20061113
---
A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

A technical computing environment provides mathematical and graphical tools for mathematical computation data analysis visualization and algorithm development. MATLAB from The MathWorks Inc. of Natick Mass. is one example of technical computing environments. MATLAB computing environment integrates numerical analysis matrix computation signal processing and graphics in an easy to use environment where problems and solutions are expressed in familiar mathematical notation without traditional programming. A technical computing environment can be used to solve complex engineering and scientific problems by developing mathematical models that simulate the problem.

A technical computing environment may allow scientists and engineers to interactively perform complex analysis and modeling in their familiar workstation environment. At times users may want to use more than one computational unit executing a technical computing environment. Multiple computational units may be used to increase the computing power to decrease computational time to balance computing loads or for other reasons as determined by one of skill in the art.

Applications that are traditionally used as desktop applications may need to be modified to be able to utilize the computing power of concurrent computing. The term concurrent computing can refer to parallel and or distributed computing that is it encompasses computing performed simultaneously or nearly simultaneously as well as computing performed on different computing units regardless of the timing of the computation.

A computation unit may be any unit capable of carrying out processing. Computation units may be but are not limited to separate processors cores on a single processor hardware computing units software computing units software threads portable devices biological computing units quantum computing units etc. 

An exemplary embodiment provides a computing environment in which a large computational job can be performed concurrently by multiple processes. This concurrent computing environment may include a client that creates the job. The job may include one or more tasks. The client may send the job or tasks to the multiple processes for the concurrent execution of the job. In the embodiment the processes may establish communication channels with other processes so that the processes can collaborate to execute the job. The processes execute the job and may return execution results to the client directly or indirectly via an intermediary agent such as a job manager.

The exemplary embodiment provides a communication protocol for processes to send and receive arbitrary data in a concurrent computing environment. The communication protocol enables the processes to send or receive arbitrary data without a user or programmer specifying the attributes of the arbitrary data. In the embodiment the communication protocol automatically identifies the attributes of the arbitrary data for example the type and or size of the data and sends information on the attributes of the data to a process to which the data is to be sent. Based on the information on the attributes of the data the receiving process can allocate appropriate memory space for the data to be received.

In an exemplary communication protocol of the embodiment a header message can be sent and received first with a fixed size and then payload messages can be sent and received. The header message may include information on the attributes of data to be sent and received such as information on how to interpret the remainder of the header message and how many payload messages are needed to follow and how to interpret the payload messages. When the data is small enough to fit in the header message the data can be sent within the header message. The receiving process knows from the header message information how large the payload messages will be and can allocate memory space for the payload messages accordingly.

In the exemplary embodiment the communication protocol may allow the processes to perform error detection user interrupt detection and or deadlock detection while retaining the underlying speed of the communication. When an error user interrupt request or deadlock occurs and hence it is not possible to send and or receive a message the communication protocol may enable the processes to cancel the communication. The communication protocol may also enable the processes to clear the partially sent message.

In one aspect a method and a medium holding instructions executable in a computing device are provided for communicating data between processes in a concurrent computing environment. The attributes of data to be sent from a first process to a second process are determined. A header message is sent to the second process for providing information on the attributes of the data the second process.

In another aspect a method and a medium holding instructions executable in a computing device are provided for communicating data between processes in a concurrent computing environment. A header message is received that includes information on the attributes of data to be received from a first process. Memory space is allocated for the data based on the information on the attributes of the data.

In another aspect a system is provided for communicating data between processes in a concurrent computing environment. The system includes a first process for identifying attributes of data to be sent. The first process sends a header message for providing information on the attributes of data. The system also includes a second process for receiving the header message and for allocating memory space for the data based on the information on the attributes of the data in the header message.

An exemplary embodiment provides a communication protocol for computation units to send and receive arbitrary data between applications in a concurrent computing environment.

In one embodiment of the invention a computation unit may need to have its local copy of the application or at least a part of the application. Between different instances of the application or different applications there may need to be a way to communicate and pass messages and data so that two or more computing units can collaborate with each other.

In an alternative embodiment of the invention the application data or executable code may be loaded onto a computing unit prior to execution of the code.

Message passing is a form of communication used in concurrent computing in order to facilitate communication between two or more computing units. The applications execution on the computing units may be different instances of the same application or they may be different versions of the same or similar application or they may be entirely different applications and or their execution instances.

Communication is accomplished by the sending of messages from one computing unit to another computing unit. Various messages may include function invocation signals data packets a combination of any of the above etc. One example of a message passing protocol that establishes a communication channel between computing units is Message Passing Interface MPI . MPI is a message passing library specification defining a collection of subroutines and arguments used for communication among nodes running a parallel program on a distributed memory system. Message passing protocols are not limited to MPI and alternative embodiments of the invention may employ different protocols.

In standard message passing programming a user or programmer is expected to specify how large the data the processes are sending and receiving is so that the processes can allocate memory space for storing the data. However some programming languages or environments such as MATLAB control the memory allocation directly and do not allow a user to control the memory allocation. In MATLAB memory allocation is not controlled by the user and hence it is difficult for the user to know how much memory is being allocated and used for the data type. Therefore it is desired to provide new communication protocols for sending and receiving an arbitrary data type in a concurrent computing environment.

A communication protocol may enable computing units to send or receive arbitrary data without a user or programmer specifying the attributes of the arbitrary data for example the size and or type of the data. In an exemplary embodiment the protocol specifies a fixed maximum size for a header message. In the exemplary embodiment the communication protocol automatically identifies the attributes of the arbitrary data and sends a header message with the attributes of the data to the computing units to which the data is to be sent. Based on the information on the attributes of the data in the header message the receiving unit can allocate appropriate memory space for one or more payload messages to be received.

In the exemplary embodiment the communication protocol may allow the computing units to perform error detection user interrupt detection and or deadlock detection while retaining the underlying speed of the communication. For example when a header message indicates that a payload message follows but a payload message doe not follow it means that an error occurs. When an error user interrupt request or deadlock occurs so that it is not possible to send and or receive a message the communication protocol enables the processes to cancel the communication. The communication protocol may also enable the processes to clean the partially sent message.

The exemplary embodiment provides an environment that enables a user to execute one or more computational jobs concurrently using multiple computing units. A job may include activities or tasks that are processed and or managed collectively. The job may be a batch processing job or interactive processing job. A task may define a technical computing command such as a MATLAB command to be executed and the number of arguments and any input data to the arguments. In the exemplary embodiment the concurrent computing system may include a client for creating the job. The client may be a user or a software application setting out the computing tasks. One or more clients may be used to control concurrent processing units executing computing tasks. A client may be a stand alone application an application of the same type as executing on one or more of the processing units a client running in a web interface a client embedded in scientific hardware an application running on a portable device etc. The client may send the job to one or more computing units for the execution of the job. The computing units execute the job and return the execution results to the client. The computing units may establish communication channels with other computing units so that the computing units can collaborate to execute the job. In an exemplary embodiment the job may be executed in batch processing or interactive processing. As such the exemplary embodiment executes the job using a concurrent computing system.

The exemplary embodiment will be described for illustrative purposes relative to a MATLAB based technical computing environment. Although the exemplary embodiment will be described relative to a MATLAB based application one of ordinary skill in the art will appreciate that the present invention may be applied to distributing the processing of technical computing tasks with other technical computing environments such as technical computing environments using software products of LabVIEW or MATRIXx from National Instruments Inc. or Mathematica from Wolfram Research Inc. or Mathcad of Mathsoft Engineering Education Inc. or Maple from Maplesoft a division of Waterloo Maple Inc. Comsol from Comsol AB of Sweden GNU Octave.

The memory may include a computer system memory or random access memory RAM such as DRAM SRAM EDO RAM etc. The memory may include other types of memory as well or combinations thereof. A human user may interact with the computing device through a visual display device such as a computer monitor which may include a graphical user interface GUI . The computing device may include other I O devices such a keyboard and a pointing device for example a mouse for receiving input from a user. Optionally the keyboard and the pointing device may be connected to the visual display device . The computing device may include other suitable conventional I O peripherals. Moreover the computing device may be any computer system such as a workstation desktop computer server laptop handheld computer or other form of computing or telecommunications device that is capable of communication and that has sufficient processor power and memory capacity to perform the operations described herein.

Additionally the computing device may include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. 802.11 T1 T3 56 kb X.25 broadband connections e.g. ISDN Frame Relay ATM wireless connections high speed interconnects e.g. InfiniBand gigabit Ethernet Myrinet or some combination of any or all of the above. The network interface may include a built in network adapter network interface card PCMCIA network card card bus network adapter wireless network adapter USB network adapter modem or any other device suitable for interfacing the computing device to any type of network capable of communication and performing the operations described herein.

The computing device may further include a storage device such as a hard drive or CD ROM for storing an operating system OS and for storing application software programs such as the MATLAB based concurrent computing application or environment . The MATLAB based concurrent computing application or environment may run on any operating system such as any of the versions of the Microsoft Windows operating systems the different releases of the Unix and Linux operating systems any version of the MacOS for Macintosh computers any embedded operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices or any other operating system capable of running on the computing device and performing the operations described herein. Furthermore the operating system and the MATLAB based concurrent computing application or environment can be run from a bootable CD such as for example KNOPPIX a bootable CD for GNU Linux.

The concurrent computing application may include communication protocols that enable the concurrent computing application or environment to communicate with other computing applications or processes in a concurrent computing system. The communication protocols may use message passing primitives for the concurrent computing application to establish communication channels with other computing processes or applications in the concurrent computing system. Message passing systems may permit programs with separate address spaces to synchronize with one another and move data from the address space of one process to that of another by sending and receiving messages. The message passing primitives may be provided as a shared library such as DLL files on Windows and .so files on UNIX. The shared library enables the application to dynamically open and close communication channels. The communication protocols will be described below in more detail with reference to .

The computing application may include a concurrent computing client application or concurrent computing client running on a client computer and a concurrent computing application or concurrent computing unit running on a workstation . The concurrent computing client may be in communication through the network communication channel on the network with one some or all of the concurrent computing units . The concurrent computing units can be hosted on the same workstation or a single concurrent computing unit can have a dedicated workstation . Alternatively one or more of the concurrent computing units can be hosted on the client .

The concurrent computing client can be a technical computing software application that provides a technical computing and graphical modeling environment for generating block diagram models and to define mathematical algorithms for simulating models. The concurrent computing client can be a MATLAB based client which may include all or a portion of the functionality provided by the standalone desktop application of MATLAB . Additionally the concurrent computing client can be any of the software programs available in the MATLAB product family. Furthermore the concurrent computing client can be a custom software program or other software that accesses MATLAB functionality via an interface such as an application programming interface or by other means. One ordinarily skilled in the art will appreciate the various combinations of client types that may access the functionality of the system.

With an application programming interface and or programming language of the concurrent computing client functions can be defined representing a technical computing task to be executed by either a technical computing environment local to the client computer or remote on the computing unit . The local technical computing environment may be part of the concurrent computing client or a concurrent computing unit running on the client computer . The programming language includes mechanisms to define tasks to be distributed to a technical computing environment and to communicate the tasks to the concurrent computing units on the workstations or alternatively on the client . Also the application programming interface and programming language of the client includes mechanisms to receive a result from the execution of technical computing of the task from another technical computing environment. Furthermore the client may provide a user interface that enables a user to specify the size of the collaboration of the concurrent computing units for the execution of the job or tasks. The user interface may also enable a user to specify a concurrent computing unit to be added to the collaboration or to be removed from the collaboration.

The concurrent computing unit of the system can be a technical computing software application that provides a technical computing environment for performing technical computing of tasks such as those tasks defined or created by the concurrent computing client . The concurrent computing unit can be a MATLAB based computing application module service software component or a session which includes support for technical computing of functions defined in the programming language of MATLAB . A session is an instance of a running concurrent computing unit by which a concurrent computing client can connect and access its functionality. The concurrent computing unit can include all the functionality and software components of the concurrent computing client or it can just include those software components it may need to perform technical computing of tasks it receives for execution. The concurrent computing unit may be configured to and capable of running any of the modules libraries or software components of the MATLAB product family. As such the concurrent computing unit may have all or a portion of the software components of MATLAB installed on the workstation or alternatively accessible on another system in the network . The concurrent computing unit is capable of performing technical computing of the task as if the concurrent computing client was performing the technical computing in its own technical computing environment. The concurrent computing unit also has mechanisms to return a result generated by the technical computing of the task to the concurrent computing client .

A server may be coupled to the network . The server may include a job manager . The job manager can provide control of delegating tasks and obtaining results in the concurrent computing system . The job manager may provide an interface for managing a group of tasks collectively as a single unit called a job and on behalf of a concurrent computing client submitting those tasks making. up the job and obtaining the results of each of the tasks until the job is completed. This eases the programming and integration burden on the concurrent computing client . For multiple task submissions from the concurrent computing client the job manager can manage and handle the delegations of the tasks to the concurrent computing units and hold the results of the tasks on behalf of the concurrent computing client for retrieval after the completion of technical computing of all the tasks.

Although the exemplary embodiment is discussed above in terms of the MATLAB based concurrent computing application across the computing devices of a client server and workstation any other system and or deployment architecture that combines and or distributes one or more of the concurrent computing client job manager and concurrent computing units across any other computing devices and operating systems available in the network may be used. Alternatively all or some of the software components of the MATLAB based concurrent computing application can run on a single computing device such as the client server or the workstation .

In the exemplary embodiment the arrays may be dynamically typed. In a dynamically typed language such as MATLAB types are assigned to each data value in memory at runtime rather than assigning a type to a static syntactic entity in the program source code. MATLAB controls the memory allocation directly and does not allow a user to control the memory allocation. When a user assigns data type a numeric string or structure array for example to a variable MATLAB allocates a block of memory and stores data in the block at runtime. The exemplary embodiment enables the process of dynamically typed languages to communicate with other processes using message passing primitives that require a user to specify for example the size of the data to be sent. Those of ordinary skill in the art however appreciate that although the exemplary embodiment is described relative to MATLAB and MPI other programming language processes and communication interfaces may be used.

Referring back to depending upon the attributes of the data to be sent step the computing unit may perform separate functions calls for different communication protocols. In the exemplary embodiment the computing unit may perform three different functional calls such as SendScalar SendNumericArray and SendSerializedData. If the data is a scalar the computing unit may perform SendScalar step which is described below with reference to . If the data is a numeric array a character array or a logical array the computing unit may perform SendNumericArray step which is described below with reference to . If the data is a cell array or a structure array the computing unit may perform SendSerializedData step which is described below with reference to . Those of ordinary skill in the art will appreciate that the branch algorithm is illustrative and other implementations are possible for the communication protocols in different embodiments. For example the data can be sent using a generalized communication protocol SendSerializedData in the embodiment regardless of the types of the data. Exemplary code for the branch algorithm is provided as follows.

In the exemplary code described above the fourth line sets the first element of a header message to indicate that the data is a scalar type. From the first element of the header message the receiver can expect that it will receive a scalar type of data. The fifth line packs the scalar type data into the header message. The sixth line sends the header message and returns MPI status.

In the exemplary code described above the fourth line sets the first element of a header message to indicate that the data is a numeric array. From the first element of the header message the receiver can expect that it will receive a numeric array type of data. The fifth line sets the second element of the header message to specify the number of dimensions of the array data. The sixth line copies the number of elements per dimension into the header message. The seventh and eighth lines send the header message and payload messages respectively 

In the exemplary code described above the fifth line sets the first element of a header message to indicate that the data is serialized data. From the first element of the header message the receiver can expect that it will receive serialized data. The function in the sixth line converts any arbitrary MATLAB data type into a sequence of bytes. The seventh line sets the second element of the header message to specify the length of the serialized data. The eighth and ninth lines send the header message and one or more payload message. The tenth line frees the memory space allocated for the serialized data.

In the exemplary code described above the second line assigns 100 integer elements for a header message which may be determined by the constraints of protocols as a programmer defined when writing the send and receive portions of the protocol. In the fifth line a computing unit may receive a header message using an MPI primitive such as MPI Recv. The first element of the header message indicates the type of data to be received. From the seventh line the communication protocol performs separate routines for receiving the data depending on the first element of the header message.

In the exemplary code described above the third line copies the payload value directly from the header message. The fourth line returns the payload value copied from the from the header message.

In the exemplary code the third line allocates memory space for the data to be received. Since the first element of the header message indicates that the data is a numeric array the memory space can be allocated based on the number of dimensions and the number of elements per dimension. The number of dimensions can be obtained from the second element of the header message and the number of elements per dimension can be obtained from the third element and thereafter. In the fourth line one or more payload messages are received and stored in the allocated memory space.

In the exemplary code the length of serialized data to be received can be obtained from the second element of the header message the second line . The third line allocates memory space for the serialized data to be received based on the length of the serialized data. In the fifth line the serialized data is received via one or more payload messages and stored in the allocated memory space. The function in the seventh line de serializes the received data.

The embodiment described above uses blocking message passing routines such as MPI Send and MPI Receive. Blocking routines return only after the data buffer in the sending task is free for reuse or block until the requested data is available in the data buffer in the receiving task. Some other embodiments may use a synchronous send to implement the blocking send. In the synchronous blocking communication a send computing unit may send a message and block until the data buffer in the sending task is free for reuse and the receiving unit has started to receive the message.

The computing unit may then perform error detection user interrupt detection and or deadlock detection while the data is being sent or received step . The user may request for example by pressing CTRL C that the program is interrupted. When the request is detected the process may cancel the communication request. In an embodiment a checkpoint called barrier synchronization point is used to check for any communication mismatch in a concurrent computing program. The barrier synchronization point can be placed anywhere in a concurrent computing program as desired. Once a node has reached the barrier synchronization point the node suspends execution and becomes idle to wait for other nodes to reach the barrier synchronization point as well. No node can leave the barrier synchronization point until all nodes have entered the barrier synchronization point. If a node attempts to initiate communication with another node that has already entered the barrier synchronization point an error is raised immediately. Once all the nodes have reached the barrier synchronization point any message in the send receive buffer is flushed before resuming to normal execution to ensure that any communication mismatch before the barrier synchronization point does not continue past the barrier synchronization point. Each message to be flushed represents a communication mismatch and a warning or an error can be issued. Exemplary code for a communication with error detection deadlock detection of user interrupt detection is provided as follows.

The exemplary code described above checks whether a communication is completed or one of deadlock communication error or user interrupt e.g. CTRL C occurs during the communication. The fifth to seventh lines check for communication error deadlock or user interrupt. If communication error deadlock or user interrupt is detected the process cancels the communication request at the eighth line. If communication error deadlock and user interrupt is not detected the process sets the done flag to 1 when the communication is complete eleventh line .

To perform the error detection deadlock detection or user interrupt detection during a communication MPI Send and MPI Recv described above may be replaced by errDetectingSend and errDetectingReceive which are described below with exemplary code.

Both methods described above initiate asynchronous communications and wait for a process to complete using pollForCompletion which is also described above.

The exemplary code described below shows how a partially transmitted message is flushed. The following method flushingReceive may be called repeatedly in a loop until it is determined that no further messages are available to be flushed.

The communication error or deadlock is typically detected during sending of a payload message the header has already been sent or during receiving of a payload message i.e. during the period where the expected sender has not yet started sending a payload message . If there is at least a header message to be received the fifth line receives the header message. The six line checks if there is a payload present to receive. If there is an error detected there may be no payload messages. If there is no error detected the process continues to receive payload messages. Each process can send at most one mismatched header message before a flush is performed.

Alternatively instead of barrier synchronization points regions can be used to implement the exemplary embodiment. Nodes that use the region based implementation do not suspend execution when they are leaving one region and entering another. In one embodiment each message is packaged with information that identifies the region that the sending node is in so that the receiving node can determine if such message can be successfully received without error. The receiving node checks if the region information in the message is compatible with the region that the receiving node is currently in and an error is raised if there is an incompatibility between the regions. In another embodiment a sending node queries the region that the receiving node is in and compares the region of the receiving node with the region that the sending node is currently in. If the receiving node is in a compatible region with the sending node then a message is sent from the receiving node to the sending node. However if the receiving node is in an incompatible region with the sending node then a communication mismatch is detected. In yet another embodiment a message is sent by a sending node without information on the region that the sending node is in and the receiving node queries the region that the sending node is in before the receiving node successfully receives the message. If the region of the receiving node is compatible with the region of the sending node then the receiving node successfully receives the message. If the region of the receiving node is incompatible with the region of the sending node then a communication mismatch is detected.

The error detection user interrupt detection and deadlock detection are described in more detail in co pending U.S. patent application Ser. No. 11 488 432 filed Jul. 17 2006 and entitled RECOVERABLE ERROR DETECTION FOR CONCURRENT COMPUTING PROGRAMS. The content of the application is incorporated herein by reference in its entirety.

When an error user interrupt request or deadlock occurs or when it is not possible to send and or receive data anymore the communication protocols may enable the computing unit to cancel the pending communication . The communication protocols may also enable the computing unit to clean memory space allocated for the partially sent message step .

Many alterations and modifications may be made by those having ordinary skill in the art without departing from the spirit and scope of the invention. Therefore it must be expressly understood that the illustrated embodiments have been shown only for the purposes of example and should not be taken as limiting the invention which is defined by the following claims. These claims are to be read as including what they set forth literally and also those equivalent elements which are insubstantially different even though not identical in other respects to what is shown and described in the above illustrations.

