---

title: System and method for generating distributed information systems
abstract: An architecture for developing a distributed information system comprises a service definition tool for generating service protocols as a service definition. Each service protocol includes a plurality of messages. The messages include incoming messages and outgoing messages. Each message carries a plurality of data fields. A component development tool generates a first and second plurality of components that implement and consume services. Each component in the first plurality of components represents a physical entity in the distributed information system. Each component in the second plurality of components represents a logical entity in the distributed information system. A system development tool generates a plurality of component instances based on the first and second plurality of components. An engine software program runs on each of a plurality of networked nodes. The engine software program provides a programmable run-time environment for hosting the plurality of component instances and supporting communication between component instances.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08225272&OS=08225272&RS=08225272
owner: Savigent Software, Inc.
number: 08225272
owner_city: Minnetonka
owner_country: US
publication_date: 20061030
---
This application is a division of U.S. application Ser. No. 09 638 491 entitled SYSTEM AND METHOD FOR GENERATING DISTRIBUTED INFORMATION SYSTEMS filed on Aug. 15 2000 which claims the benefit of Provisional Application No. 60 149 507 entitled SYSTEM AND METHOD FOR GENERATING DISTRIBUTED INTELLIGENCE SYSTEMS which was filed Aug. 17 1999.

Developers of distributed information systems are faced with daunting complexities. The traditional approach to system design and development requires a monumental task of understanding constantly changing requirements while designing and implementing the system as a whole. The requirements for the system are collected and interpreted by software developers who are not the domain experts. At the same time people who have an intimate knowledge of the system requirements are not the software engineers.

Difficulty in communication between developers and domain experts results in multiple iterations of a system design and multiple patches and changes to the delivered product. Such a system when completed becomes a legacy island in the enterprise that is impossible to change extend or integrate into the global information infrastructure.

Prior art solutions have tried to solve this major problem by introducing new languages targeted to capture requirements for the system design such as the graphical Use Cases language of UML. These new languages add an extra level of complexity and require a high level of commitment from both groups involved in the design and development process. The biggest problem with this approach is that the design model is not present in the system delivered to the customer. An end user gets a system that consists of files modules and executables but not of accounts machines units etc. From the end users standpoint all of the time that went into the requirements capturing and modeling was wasted because the system does not represent their real world entities that they interact with but some foreign entities forced on them by the system implementation.

This prior art approach does not help developers simplify the design and implementation of the system. Developers have to deal with the details of a target deployed environment communication and hardware. An object orientated approach to the system implementation while helping in the design process leaves them with monolithic applications once compiled.

This application orientation makes prior art approaches much more difficult to use in the environments where requirements are constantly changing and system complexities are increasing. Even component specifications that have been introduced did not address the distributed nature of the systems nor did they help to solve the complexities of the development process and were a mere extension of the client server model of the past.

Monolithic applications have no way to interact with other applications deployed in the enterprise. A special integration infrastructure has to be used to build an integration layer to pull it all together. This integration is an afterthought solution that is an application by itself and has all the problems noted above.

With traditionally developed information systems decision making is centralized even though the information sources are distributed throughout the enterprise. Generally information is transferred to a central point where it is processed. In physically distributed enterprises with either large buildings or worldwide operations it is very difficult to transfer large amounts of information to a central point. Often the solution is to install multiple copies of an application each in an area of the enterprise. This results in unconnected islands with little or no synchronization between areas.

Most prior art applications were not designed for real time behavior. With the exception of real time control systems most applications were designed to run periodically perhaps a few times a day or once a week to update inventory send orders to the suppliers or process production data for the last day or week. This limitation prevents businesses from immediately reacting to the needs of customers or reacting to problems with internal operations. There is a need to have all applications including supply chain management e commerce and plant floor operations to react in real time as an integrated enterprise.

An architecture for developing a distributed information system comprises a service definition tool for generating service protocols as a service definition. Each service protocol includes a plurality of messages. The messages include incoming messages and outgoing messages. Each message carries a plurality of data fields. A component development tool generates a first and a second plurality of components that implement and consume services. Each component in the first plurality of components represents a physical entity in the distributed information system. Each component in the second plurality of components represents a logical entity in the distributed information system. A system development tool generates a plurality of component instances based on the first and second plurality of components. An engine software program runs on each of a plurality of networked nodes. An engine software program provides a programmable run time environment for hosting the plurality of component instances and supporting communication between component instances.

The architecture presented by this invention uses components as building blocks for distributed information systems. By placing components as the centerpiece of the design and development process this invention improves on the prior use of components as application parts that are glued together by application code. This invention makes another step toward generalization of components by defining them as service providers and consumers. A service represents an operation or activity that is continuous and internal to the component. Because implementation of the service is internal to the component external entities do not have direct access to the service. External entities can interact with the service by sending messages to and receiving messages from the service implementation component . Services are defined by protocols collections of incoming and outgoing messages. Another way to describe service protocols is to treat incoming messages as function calls implemented by the service and outgoing messages as events raised by the service. Service providers are responsible for implementing handlers for incoming messages as defined by the service protocol. Service consumers are responsible for implementing handlers for outgoing messages as defined by the protocol. Any consumer can use any provider if they implement the same protocol. This allows components to be modeled as collections of provided and consumed services. For example a product routing component can implement routing service functionality and consume equipment service functionality of components representing factory floor equipment. Components can provide or consume any number of services. This adds flexibility to components and allows a system approach to development.

This example depicts a protocol for the service Mixing Station that has two incoming messages Start and Stop where the Start message carries the parameter Duration of the type long . It also has one outgoing message Status with three parameters Elapsed Time of the type long Level of the type double and Error Code of the locally defined type Errors that can be one of the following values None Empty Motor Failed or Cycle Completed .

Service protocols are different from interfaces as defined by DCE Distributed Computing Environment RPC Remote Procedure Call COM Component Object Model DCOM Distributed COM CORBA Common Object Request Broker Architecture and Java RMI Remote Method Invocation . Service protocols according to the present invention assume an asynchronous bidirectional communication model unlike the synchronous unidirectional RPC based model of the above mentioned specifications. This invention s approach frees components from being dependent on the knowledge of a peer component but more importantly components are not dependent on the presence of a peer at all. These prior art specifications are based on an assumption of one component being a client of the other component. represents the interaction of prior art components and where activity can occur only when the two components and interact. Component has no knowledge of the capabilities of component component is a server and component is a client. Communication between components and is unidirectional as represented by arrow . Communication is initiated with an RPC call. Activity exists only in the context of the RPC call from component to component . In other words component has to get a reference to the peer component or to the proxy of the peer by creating it or by some other means. This prior art approach also implies that one component cannot work without other components present online. That is any activity within a system can occur only when components interact. In a distributed multi node system this requirement is impossible to satisfy without going into extreme hardware and network solutions that are expensive proprietary and cannot be cost effectively deployed on a large scale. This also limits what can be modeled using this approach. Most real world objects operate on a continuous basis concurrently not just during function calls which forces developers to emulate concurrence in their components when developing for existing specifications.

An effect of this inventive approach is simplification of system design. Because each component is a stand alone entity it can be designed implemented and tested stand alone. This greatly simplifies testing and debugging of the system because there is no additional glue code to test and debug. It also promotes a common domain specific terminology use within a system. For example a control solution many use components such as sensors pumps and valves where a MES Manufacturing Execution System solution may use BOM Bill of Materials inventory and work cell components. Collaboration between developers and domain experts is simplified because of this and there is no need for yet another language to use.

In the real world entities modeled by components are parts of a hierarchical structure where components on the different levels are dependent on other components in the hierarchy. The old approach for modeling this decomposition where the whole system is modeled and then components are built as parts of the whole produces non portable and inflexible solutions. This is a top to bottom approach. This invention reverses this approach by modeling from bottom up. This makes a lot of sense because bottom level components are more generic than components on the higher levels of a hierarchy. For example in an industrial control system components such as sensors valves motors etc. are generic where components directly related to that process implemented are specific to the process. In a MES system generic components are inventory item work cell final product etc. and non generic components are process manager production sequencer and BOM. shows an example of a system model built from components A I collectively referred to as components connected by links A I collectively referred to as links . By building libraries of generic components new systems can be created with minimal new development efforts and improved reliability by defining components and linking them together with links .

Users building solutions as defined by this invention do not deal with applications any more they work with the system as a whole. This is again in contrast to the prior art solutions where distributed systems are built of multiple applications. Tools targeting domain experts users reinforce and promote this approach to system development. Because there is not a monolithic application anywhere in the system but a hierarchy of components system tools can represent a user with the picture of the system as it was originally modeled. This preservation of design representation simplifies deployment and management of a completed system as well as communication between developers and users of the system. It also allows a continuous approach to the system implementation where new functionality and features are added while preserving and extending existing functionality and maintaining a model up to date.

All information about system is stored in the System Repository . System Repository includes service protocol definitions components component instance data links node deployment information etc. System Repository is populated using system tools and is transparent to the user or developer. This information is not required for any of the run time activities within the system. It can be treated as a centralized redundant directory and can be recreated from information stored on nodes .

This invention presents a new architecture for creating and managing distributed information systems shown on . System development starts with the modeling phase that involves developers A B collectively referred to as developers and domain experts users A C collectively referred to as domain experts users .

New Services are defined by means of Service Protocols using the Service Definition Tool . Developers and domain experts contribute to this phase of development. Developed service protocols are stored in the Service Protocol Repository A which is part of the System Repository . The Service Protocol Repository is a catalog of all defined service protocols in the system. Service protocols may be exported from and imported into the Service Protocol Repository. Service protocols can be re used from system to system.

Developers in collaboration with domain experts create new Components that implement services based on newly defined and or existing service protocols . Developers use the Component Development Tool to build components and to store them in Component Repository B. A given component may implement unlimited numbers of services both as a consumer and as a provider. Each implemented service protocol is exposed as a Service Access Port such as service access ports and shown in . The component developer may define Configuration Attributes. Attributes are used to configure individual instances of a component . Component developers use attributes to alter component functionality at run time based on the values supplied. Component Repository B is a catalog of all components defined in the system. As with service protocols components can be shared between multiple systems.

Domain experts users utilize the System Development Tool to define system behavior by creating and configuring attributes are configured instances of components A B collectively referred to as component instances . The System Development Tool stores all configuration information in the Model Repository C. When created each instance is given a meaningful unique name usually reflecting its system location and or functionality. Component instances are connected through Links definitions of the communication channel. A link can be created between two Service Access Ports if they represent two ends of the same Service Protocol e.g. if the first port represents a service provider and the second port represents a complementary inverse version of the same service protocol service consumer. Each port may be connected to any number of complementary ports on any number of component instances including the parent component instance itself.

The System Development Tool can be used to modify configuration data for component instances . If a component instance is deployed these changes are sent to the node s run time environment which in turn notifies the component instance of the changes and provides new configuration to the instance . If a deployed instance is deleted from the Model Repository C it would be removed from the node and all related data would be deleted from the Local System Repository . All active links connected to the deleted instance would be shutdown and the run time software would dent any request of connection addressed to this instance . Deleting an instance on one end of a link automatically deletes the link itself. These changes are propagated to the nodes where affected component instances were deployed.

New links maybe created at any time using the System Development Tool . If a link is created between two deployed component instances the link information is sent to the nodes involved and stored in both nodes Local System Repository . Run time software then creates a logical connection and starts passing messages to and from the instance s port. Establishing a link is anode s local operation and is not involved in any communication with the rest of the system. This ensures that system components such as nodes and system repository can go on and off line without affecting overall system functionality. Note that this is only true if the off line node is not hosting any component instances whose presence is required for normal system operation. Creating redundant component instances and links and distributing them across multiple nodes can solve this problem but this relates to the particular system design and is outside of the scope of this invention.

Although the present invention has been described with reference to preferred embodiments workers skilled in the art will recognize that changes maybe made in form and detail without departing from the spirit and the scope of the invention.

