---

title: Load distribution in storage area networks
abstract: A load balancing method and system for identifying an input/output (I/O) network path from a set off I/O network paths is provided by the invention. The set off I/O network paths connect a host system via a network to a storage subsystem. The host system comprises at least one host bus adapter (HBA) and the storage subsystem comprises at least one I/O device and the network comprises at least one network device. Each of the HBA, the I/O device and the network device comprise at least one I/O port. For each I/O port of each HBA, an HBA port limit is determined. Additionally the set of I/O network paths which connect the I/O port of each of the HBA via the I/O ports of the network device to the I/O port of the I/O device is identified. Then a fabric utilization limit is determined for each I/O network path and a HBA port utilization is determined for each I/O port of the at least one HBA. All network paths are discarded for which the HBA port utilization is greater than the HBA port limit. For each of the remaining paths a network path distance is determined. All I/O network paths for which the network path distance is greater than the path distance limit are discarded. Then for each of the remaining paths a fabric utilization is determined. All I/O network paths for which the fabric utilization is greater than the fabric utilization limit are discarded and the I/O network path is determined from the remaining network paths.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07743198&OS=07743198&RS=07743198
owner: International Business Machines Corporation
number: 07743198
owner_city: Armonk
owner_country: US
publication_date: 20060713
---
The invention relates to storage area networks in general and in particular to the dynamical distribution of input output workload within a storage area network.

In modern IT systems servers and tape drives are connected via a storage area network e.g. Fibre Channel SAN iSCSI SAN . In addition to that the IEEE 1244 Standard for Removable Media Management defines the architecture and the protocols to share tape drives efficiently across heterogeneous server and application boundaries. To simplify configuration and access control IEEE 1244 organizes drives in drive groups. Two applications can share IEEE 1244 managed drives if both applications are authorized to access the drives of a common drive group.

In theory tape management systems like IEEE 1244 allow to share tape drives very flexibly between several applications but in practice this sharing is limited by bandwidth considerations. Due to bandwidth limitations of the host I O bus e.g. PCI bus and of the I O ports of the server e.g. Fibre Channel port iSCSI port an I O port can only utilize a certain number of drives efficiently. If the number of drives utilized by an I O port is above a certain threshold the performance will suffer.

This number is often referred to as drive limit of an I O port. Furthermore in heterogeneous environments different I O ports may have different drive limits. For instance a 2 Gbit Fibre Channel port can utilize more drives at full drive speed than a 1 Gbit Fibre Channel port or 1 Gbit iSCSI port. The term drive is not limited to tape drive it can be any other I O device such as disk optical random access memory holographic or nano technology device.

Prior art uses the following methods and systems to assure that in a drive sharing environment the number of drives which are concurrently used by an I O port does not exceed its drive limit.

There is therefore a need for a method and system which facilitates the dynamical distribution of I O workload distribution among removable media devices attached via multiple host bus adapters.

In accordance with the present invention there is provided a load balancing method for identifying an input output I O network path from a set off I O network paths. Each path of the set off I O network paths connects a host system via a network to a storage subsystem. The host system comprises at least one host bus adapter HBA . The storage subsystem comprises at least one I O device and the network comprises at least one network device. Each of the HBA the I O device and the network device comprise at least one I O port. For each of the at least one I O port of the at least one HBA the HBA port limit is determined. The set of the I O network paths which connect the at least one I O port of each of the at least one HBA via the I O ports of the at least one network device to the at least one I O port of each of the at least one I O device is then determined. Then a fabric utilization limit is determined for each I O network path and a HBA port utilization is determined for each of the at least one I O port of the at least one HBA. All network paths are discarded for which the HBA port utilization is greater than the HBA port limit. For each of the remaining paths a network path distance is determined. All network paths for which the network path distance is greater than the path distance limit are discarded. Then for each of the remaining paths a fabric utilization is determined. All paths for which the fabric utilization is greater than the fabric utilization limit are discarded and the I O network path is determined from the remaining network paths.

The present invention is particularly advantageous as it dynamically determines a network path from an HBA to an I O device by taking into account the parameters HBA port utilization path distance and fabric utilization. These parameters are checked against the parameters HBA port limit path distance limit and fabric utilization limit respectively. In this way the best network path is identified out of all eligible network paths.

In accordance with an embodiment of the invention the HBA port limit is determined for each of the at least one I O port of each of the at least one HBA by the number of I O devices that can be served by the I O port of the HBA in parallel. This is particularly advantageous because the number of I O devices that can be served by an I O port of a HBA in parallel is usually specified. The specification can for example be provided by the system administrator or can be read out from the corresponding I O port by the load balancing system in accordance with the invention. The specification defines the bandwidth one I O port of a HBA can provide and is directly related by the number of I O devices which can receive I O from said HBA I O port. The bandwidth essentially defines the number of I O operations per second which can be performed by one HBA I O port and is usually measured in megabyte per second MB s .

In accordance with an embodiment of the invention the HBA port limit is determined for each of the at least one I O port of each of the at least one HBA by the maximum number of bits per second which can be processed by the I O port of the HBA. It is particularly advantageous to use the number of bits per second that can be processes an I O port as the HBA port limit because this value can be determined dynamically by the load balancing system.

In accordance with an embodiment of the invention the HBA port utilization of an I O port of an HBA is determined by the workload or bandwidth which is assigned to the I O port of the HBA. This is particularly advantageous because the workload can be determined dynamically by the load balancing system by sending an inquiry command to the HBA.

In accordance with an embodiment of the invention the HBA port utilization is determined by use of a drive weight. The drive weight is assigned to an I O device and the drive weight denotes to the workload of the I O device.

In accordance with an embodiment of the invention the HBA port utilization is determined by use of drive weight which denotes the workload of an I O device and which is adjusted by a compression ration whereby the compression ratio is obtained from the I O device.

The present invention is particularly advantageous as it enables to take the HBA port limit of the at least one I O port of the at least one host bus adapter into account and discards all paths for which the HBA port utilization is greater than the HBA port limit. Notice that each I O port of each HBA has its own specific HBA port limit. This ensures that only an optimum number of drives are utilized by the I O ports of the HBAs. This contributes to an overall improvement of the aggregated bandwidth of the whole I O device infrastructure.

In accordance with an embodiment of the invention the network path distance for each remaining network path is determined by summing the latency of all interconnects comprised in the I O network path and adding the number of I O ports comprised in the I O network path.

In accordance with an embodiment of the invention the fabric utilization is determined by summing the data rates passing through the I O ports of the at least one network device comprised in a network path. A network path through a network device comprises generally at least two ports one input port and one output port.

In an embodiment of the invention the fabric utilization of a network path is determined by the ratio of the number of active I O ports comprised in the network path to the total number of I O ports comprised in the network path.

The use of the fabric utilization for the determination of a network path is particularly advantages as the workload of all components comprised in a network path is taken into account. Selecting paths with the lowest fabric utilization offers best utilization of all active resources. Moreover the current invention is particularly advantageous as it takes the fabric utilization limit of a network path into account and checks if the magnitude of the fabric utilization is below the fabric utilization limit. This ensures that the maximum bandwidth of the I O device infrastructure is never exceeded.

In accordance with an embodiment of the invention the best I O network path is the remaining network path for which a function taking into account the HBA port utilization the network path distance and the fabric utilization yields the lowest functional value. The three parameters HBA utilization network path distance and fabric utilization are assigned to all paths from which the best path is selected. The function is for example specified by the system administrator. The use of a function for the determination of the best path has the advantage that it enables a system administrator to weight the three parameters equally or differently.

In another aspect the invention relates to a computer program product which comprises computer executable instruction in order to perform the method.

In another aspect the invention relates to a load balancing system for identifying an I O network path from a set of I O network paths the set of I O network paths connecting a host system via a network to a storage subsystem.

The network comprises network components and which are typical network devices such as for example switches routers and hubs within a storage network for example Fibre Channel iSCSI . Each network device comprises I O ports and .

The storage subsystem comprises I O devices and . The I O devices are typically removable media devices such as tape disk holographic nano technology or optical I O devices. Each I O device and comprises one or more I O ports and respectively.

An I O network path connects an I O port of a HBA via the I O ports of one or more network devices to the I O port of an I O device by use of interconnects. For example network path connects the I O port of HBA by use of an interconnect to I O port of the network device and connects another I O port of the network device to the I O port of I O device . It should be noted that a HBA may comprise more than one I O ports. Up to four I O ports are typical. Moreover a network device comprises in practice two or more I O ports and an I O device can also comprise more than one I O port.

A path comprises one or more interconnects. An interconnect can be any device by which data is transported from one I O port to another I O port. Examples for interconnects are Fibre Channel cables Ethernet cables or WAN interconnects like CWDM DWDM ATM Sonet SDH or TCP IP. An interconnect might also be provided by a wireless connection. For example the host system and the storage subsystem might be interconnected by a wireless local area network whereby data is transmitted by optical signals from one I O port to another I O port and whereby the optical signals have for example frequencies in the infrared frequency range.

If an optical cable is employed as an interconnect or if a wireless interconnection is used the interconnect itself can comprise several channels which differ in the signal frequency. Thus an interconnect can provide several paths whereby each path is characterized by the channel or correspondingly by the optical frequency used for the transfer of data.

A network path might also comprise more than one network component. For example in the I O network path an interconnect connects I O port to I O port then an interconnect connects I O port to I O port and additionally an interconnect connects the I O port to I O port of the I O device .

A network path might also comprise no network component. The I O port of an I O device can be directly connected with an I O port of a HBA by an interconnect. The network path consists than of said interconnect.

Application accesses the I O devices and by use of the host system . The host system more particular the application contacts the load balancing system comprised in the media management system via the agent and an appropriate communication method such as TCPIP. The load balancing system determines a network path from the set of network paths by which application can read or write data to the I O devices . The application might contact the load balancing system as a result of a data access request such as a mount read or write command. Various embodiments of the method employed to identify the I O network path from the set of network paths are described below.

The load balancing system uses the agent to determine some parameters of the network and the storage subsystem which are stored on the volatile memory device . Alternatively they can be stored on the non volatile memory device . The host system employs one or more device drivers in order to access the I O devices and .

The system in accordance with the invention is however by no means restricted to this embodiment. For example the media management system which comprises the load balancing system might be comprised in the host system or in the storage subsystem . The media management system might for example be implemented into the host system in form of a library manager which is built in to an application. The media management system might for example be implemented into the storage subsystem in form of an advanced library manager for a tape library. However the advantage of an external media management system is that it can be used simultaneously by several host systems which are connected to different network and storage subsystems or to the same network and storage subsystems.

The set of network paths consists of all paths that connect I O ports or of the HBA or via the network to the I O devices and of the storage subsystem . For example the I O network path is embodied by the interconnect leading from I O port of HBA to I O port of network device plus the interconnect from I O port of network device leading to I O port of network device plus the interconnect leading from I O port of network device to the I O port of I O device .

In accordance with an embodiment of the invention the load balancing system determines besides other parameters specified below the following parameters which are stored on the volatile memory device or non volatile memory device HBA port limit HBA port utilization network path distance path distance limit fabric utilization limit fabric utilization a compression ratio and a drive weight . A detailed description how these parameters are determined will be given below.

The load balancing method is executed by the microprocessor in response to the reception of a data access request from application . Examples for data requests include the mount request for a cartridge a connection establishing from a SCSI source to a SCSI target in a storage network and the creation of a new zone in a storage network.

The process flows then to decision checkpoint . If at this point no eligible paths are left P then the process ends with step . Step indicates that at this point in time no eligible paths are available. The action performed in or as a result of step depends on the environment. For instance in a removable media management system the respective mount request could either be blocked which means that the mount request is added to mount request queue or be rejected. In another embodiment a storage network capacity planning module could deny a respective zoning or access request. In yet another embodiment step can loop back to step the starting point of this flowchart in order to retry the path finding. In yet another embodiment an on demand module can be invoked which dynamically provides additional infrastructure in order to add more paths to the set of paths P.

If there are eligible paths at checkpoint which satisfy the access request P then the process continues with step . Step builds the set H of all I O ports h of host bus adapters where h is starting point of at least one I O network path p element P p P Furthermore in step the HBA port utilization uis determined for each host bus adapter I O port h element of H under the assumption that the access request is scheduled. Alternate embodiments for the calculation of the HBA port utilization are detailed later.

Then the process flows to step . Step compares the HBA port utilization uof each HBA port h H with the HBA port limit land discards all paths p with HBA port utilization u HBA port limit l. In one embodiment the HBA port limit lis determined dynamically after process has been triggered by an application. This determination is based on the parameters of the network components in network and I O device characteristics in a storage system which are scanned and inquired by the processor of the media management system. For example the load balancing system inquiries all components associated with a network path and determines the maximum data rate possible in a path. This maximum data rate is than equivalent to the HBA port limit. In another embodiment the HBA port limit lis configured by the user for each HBA port. The parameter HBA port limit lis further explained later. The result of step is the set of network paths Pwhere P p Pwith h is starting point of p AND new HBA port utilization u HBA port limit l .

If no eligible candidates are determined in step P the process flows to step indicating that no eligible path has been found.

Otherwise the process flows to step where the network path distance Nof all remaining paths p Pis determined. The network path distance Nfor a path p Pis the physical distance between two ports or the length of the interconnects. The network path distance Nfor a path p Pcan be determined automatically by the microprocessor of the media management system for example by sending test packages on the network and measuring the turn around times. The turn around time is proportional to the distance said package has to travel on the network. In an alternate embodiment the network path distance Nis user configurable which means that the user configures the distance for any given path in the network. The parameter network path distance is further explained later.

The next step discards all paths p Pfor which the network path distance Nof I O network path p is larger than the path distance limit l. In one embodiment of the invention the path distance limit lis determined dynamically by the load balancing system in accordance with the invention after process has been triggered by an application. This determination is based on the parameters of the network components connecting the host system and storage subsystem which are scanned and inquired. In another embodiment the path distance limit is configured by the user for each interconnect. The parameter path distance limit lis further explained later. The result of step is the set of Pwhere P P Pwith network path distance Nof I O network path p path distance limit lof I O network path p . The processing stops here with step if no eligible candidates are left P .

Step calculates the fabric utilization of all remaining paths p element P. The fabric utilization Ffor a path p Pis defined by the workload a fabric F including the path p has to manage. The fabric utilization Ffor a path p Pcan be determined automatically by the microprocessor of the media management system for example by sending inquiries to the network components of the fabric F inquiring the number of I Os per second. This number is then accumulated across all network components relating to the path p in fabric F. The parameter fabric utilization is further explained later.

Next step discards all paths p element Pwith fabric utilization of path p is larger than fabric utilization limit lof I O network path p. In one embodiment of the invention the fabric utilization limit lis determined dynamically by the load balancing system in accordance with the invention after process has been triggered by an application. This determination is based on the parameters of the network components in network connecting the host system and storage subsystem which are scanned and inquired. In another embodiment the fabric utilization limit is configured by the user. The parameter fabric utilization limit lis further explained later.

The result of step is the set Pwhere P p Pwith new fabric utilization of path p fabric utilization limit of path p . If no eligible candidates are left in P P the process flows to step indicating no eligible path has been found. Otherwise all paths p Pdo not exceed the bandwidth and are therefore potential candidates for the best path and the process flows to step . Thus the remaining steps of the processing do not discard additional paths but they determine the optimal path.

Step introduces a function f which weights the three parameters HBA port utilization u fabric utilization p and distance p. In one embodiment the function f is a weighted sum f u p p a u b p c p where a b and c are constant values specified for example by the system administrator.

Finally in step the I O network path pfor which the function f given above yields the lowest functional value p min f u p p of all p Pis selected. The processing ends with step which returns the determined network path as the best path featuring the best performance.

In an embodiment of the invention only the steps to and either step or step are carried out. As mentioned above the result of step is the set of network paths Pwhere P p Pwith h is starting point of p AND new HBA port utilization u HBA port limit . If P then the process continues with step where one network path from the set Pis selected for example by selecting the first network path from the list P or by selecting randomly the network path from the set P. If P then the process continues with step .

According to this invention each I O network path p element Pis characterized by three parameters a HBA port utilization b network path distance and c fabric utilization which are used to determine the best path . These parameters are explained below.

HBA port utilization u It keeps track how much workload is currently assigned to an I O port of a HBA and is expressed in megabyte per second MB s . Its value is zero if currently no drive is used at this HBA port. If one or more drives are scheduled for use at an HBA port then this value is set to the sum of a drive weight of the respective drives.

The drive weight is an additional parameter which denotes how much I O resources an I O device consumes. It is expressed by an I O rate in megabyte per second MB s . This parameter can be obtained automatically by sending an inquiry command to the drive instructing the drive to report which data rate can be achieved. The inquiry command is for example a SCSI INQUIRY command which inquiries a drive for its characteristics where one parameter usually denotes the drive bandwidth. The drive bandwidth denotes for example the data rate which an I O device can handle and is usually expressed in megabytes per second. In an alternate embodiment the parameter drive weight can be configured by the user. In yet another embodiment the drive weight is dynamically adjusted based on the I O device operations by the media management system in accordance with the invention. An I O device usually keeps statistics about the data rates which were processed in a foregoing operation. This statistics can be inquired by the media management system. An example for the inquiry command is the SCSI LOG SENSE command. Based on this information the media management system can dynamically update the drive weight by calculating the average I O rate across multiple mounts.

In one embodiment the drive weight parameter is adjusted by the compression ratio when the drive weight relates to uncompressed data. Compression is usually done at the I O device level at a certain ratio and influences the I O rate of an I O device. In this embodiment the drive weight parameter is multiplied with the compression ratio before it is added to HBA port utilization and compared with the HBA port limit. In one embodiment the compression ratio parameter is inquired by the media management from the I O device. The media management system calculates a compression ratio average and stores it in the volatile memory device. The inquiry command is a SCSI 3 LOG SENSE command. In another embodiment the compression ratio is configured by the user.

The method for updating the HBA port utilization is quite simple. It starts when no I O device is used via that port with the value zero. If as a result of the process in a I O device is scheduled for an HBA port mount request then the value of the HBA port utilization is increased by the drive weight parameter which might be adjusted by the compression ratio of the I O device. The HBA port utilization is than stored in the media management system. If a drive is de scheduled from a HBA port un mount request then the value of the HBA port utilization is decreased by drive weight.

Network Path Distance N The network path distance is primarily presented by length of the I O network path which is the sum of the physical length of the interconnects comprised in the I O network path. The preferred embodiment is to include the number of I O ports involved in the I O network path. The reason for this is that each port represents some level of overhead which influences the data rate and should therefore be taken into consideration. The network path distance is measured in a length entity such as meters m according to the preferred embodiment. In an alternate embodiment this parameter is expressed in the turn around time of a data package on this path measured in a time unity such as milliseconds ms . In order to determine the length of a given network path the load balancing process either send packages across the path and measure the turn around time similar to a ping command according to the TCPIP protocol. The turn around time is stored as the network path distance parameter in the memory device of the media management system. In an alternate embodiment the path distance is configured by the user and expressed in meters.

Fabric utilization F describes the utilization of the fabric in which the path p resided. A fabric consists of a number of switches or network components. A network component or switch consists of a number of I O ports. The fabric utilization for path p is calculated by the sum of the I O rate of the I O ports within the path. Therefore not the entire fabric is considered but only the components in the I O network path between one HBA and one I O device. This parameter is expressed by a data rate such as megabyte per second describing the comprised data rate of ports pertaining the path p within the fabric. The load balancing system determines the data rate of the ports pertaining to a path through appropriate commands. For example SAN switch components according to prior art provide an application programming interface API for an outbound connection which the load balancing system can use to inquiry the data rate of a I O port. In an alternate embodiment fabric utilization for a path p is determined by the ratio of the number of active ports in the fabric to the total numbers of ports in the fabric. The activity of ports is inquired by the load balancing system through for example the API provided by SAN components. This parameter is determined as part of step of process in . Since the fabric utilization changes dynamically it can alternatively determined in the background.

By utilizing this parameter the load balancing method and system in accordance with the invention take the workload of all components of the path into account which connect a HBA port and the I O device. Selecting paths with the lowest fabric utilization offers equal utilization of all resources.

The process described in also includes limits or thresholds for these parameters allowing to exclude certain paths such as a HBA Port Limit b Network path distance limit and c Fabric utilization limit. These limits are compared to one of three parameters outlined above in steps and and further explained below.

HBA Port Limit l The HBA port limit is a new metadata attribute for each port of an HBA. In one embodiment the HBA port limit represents just a number of drives which this port may serve in parallel. In another embodiment the HBA port limit represents the maximum throughput e.g. 100 Gbits which the port can handle. In another embodiment where the interconnect is an optical cable or a wireless connection which comprise several channels whereby data is transferred on each channel by use of a different optical frequency the HBA port limit can also be the number of channels that can be handled by the HBA port.

Path Distance Limit l describes the maximum allowed distance of a path and is compared against the path distance. The path distance limit is a constant value configured by the user.

Fabric utilization limit l describes the maximum allowed utilization of a fabric and is compared against the fabric utilization. The fabric utilization limit is configured by the user.

The process is executed by the load balancing system in response to a data access request from application . An alternative embodiment is that this process is executed in time of less utilization of the host system .

The process starts at and flows to where the set of all paths is determined. Each I O network path describes the route from the I O ports or of the host bus adapters or of the host system via the network to the at least one I O port of I O device and . For example the I O network path includes I O port of HBA the interconnect leading from I O port to I O port the network device the interconnect leading from I O port to I O port the network device and the interconnect leading from I O port to I O port of I O device .

In step it is checked if there are any network paths. If there is no network path the flow continues with step and stops whereby no path is determined. If there is at least one network path the flow continues with step . In step the HBA port utilization of each I O port or of each host bus adapter or is determined. Step determines the I O port or with the lowest utilization. In step the HBA port utilization of the HBA port and is compared and the HBA port with lowest utilization is selected. If there is only one I O network path with a minimum HBA port utilization the process continues with step discussed later.

Otherwise if there is more than one I O network path with a minimum utilization the process continues with step where the distance between the host bus adapter ports and the I O ports and of the drives is determined for the I O network paths which have the same minimum utilization.

In step the minimum network path distance is determined among the I O network paths considered in step . In step the decision is made if the number of paths with the minimum distance is greater than one. If the answer is NO i.e. only one path the process continues with step discussed later. If there is more than one I O network path with a minimum distance the process flows to step where the fabric utilization is determined for all paths with the minimum network path distance. In step the minimum fabric utilization for the I O network paths is determined.

The process flows then to step where the determination is made whether there is more than one I O network path with minimum fabric utilization. If the answer is NO only one path the process flows to step . Step receives from step step or step exactly one I O network path. This I O network path is identified as the best path in step . Step flows to the end .

If the decision in step is that there is more than one network path with the minimum fabric utilization then the process flows to step where the so called first network path is selected. In an embodiment of the invention all network paths determined in step are stored in a list. The so called first network path is then the I O network path which is the first element of the list. An alternative embodiment of the invention is to select the last I O network path in the list. Step flows to the end point.

In an embodiment of the invention only steps to and either step or step are carried out. If the number of paths determined in step is larger than one then one path is selected for example randomly and the method exits in step with the best path .

