---

title: System and method of analyzing web content
abstract: A system and method are provided for identifying inappropriate content in websites on a network. Unrecognized uniform resource locators (URLs) or other web content are accessed by workstations and are identified as possibly having malicious content. The URLs or web content may be preprocessed within a gateway server module or some other software module to collect additional information related to the URLs. The URLs may be scanned for known attack signatures, and if any are found, they may be tagged as candidate URLs in need of further analysis by a classification module.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08020206&OS=08020206&RS=08020206
owner: Websense, Inc.
number: 08020206
owner_city: San Diego
owner_country: US
publication_date: 20060710
---
This Application is related to U.S. patent application Ser. No. 11 484 335 filed on even date which is hereby incorporated by reference in its entirety.

This application relates to data and application security. In particular this application discloses systems methods of collecting and mining data to determine whether the data includes malicious content.

Traditionally computer viruses and other malicious content were most often provided to client computers by insertion of an infected diskette or some other physical media into the computer. As the use of e mail and the Internet increased e mail attachments became a prevalent method for distributing virus code to computers. To infect the computer with these types of viruses having malicious content some affirmative action was typically required by the user such as opening an infected file attachment or downloading an infected file from a web site and launching it on their computer. Over time antivirus software makers developed increasingly effective programs designed to scan files and disinfect them before they had the opportunity to infect client computers. Thus computer hackers were forced to create more clever and innovative ways to infect computers with their malicious code.

In today s increasingly networked digital world distributed applications are being developed to provide more and more functionality to users in an open collaborative networking environment. While these applications are more powerful and sophisticated their increased functionality requires that network servers interact with client computers in a more integrated manner. For example where previous web applications primarily served HTML content to client browsers and received data back from the client via HTTP post commands many new web applications are configured to send various forms of content to the client computer which cause applications to be launched within the enhanced features of newer web browsers. For example many web based applications now utilize Active X controls which must be downloaded to the client computer so they may be effectively utilized. Java applets VBScript and JavaScript commands also have the capability of modifying client computer files in certain instances.

The convenience that has arrived with these increases in functionality has not come without cost. Newer web applications and content are significantly more powerful than previous application environments. As a result they also provide opportunities for malicious code to be downloaded to client computers. In addition as the complexity of the operating system and web browsing applications increase it becomes more difficult to identify security vulnerabilities which may allow hackers to transfer malicious code to client computers. Although browser and operating system vendors generally issue software updates to remedy these vulnerabilities many users have not configured their computers to download these updates. Thus hackers have begun to write malicious code and applications which utilize these vulnerabilities to download themselves to users machines without relying on any particular activity of the user such as launching an infected file. One example of such an attack is the use of malicious code embedded into an active content object on a website. If the malicious code has been configured to exploit a vulnerability in the web browser a user may be infected or harmed by the malicious code as a result of a mere visit to that page as the content in the page will be executed on the user s computer.

An attempt to address the problem of malicious code embedded in content is to utilize heightened security settings on the web browser. However in many corporate environments intranet or extranet applications are configured to send executable content to client computers. Setting browser settings to a high security level tends to impede or obstruct the effective use of these types of safe applications. Another attempt to address the issue is to block all executable content using a network firewall application. This brute force approach also is ineffective in many environments because selective access to certain types of content is necessary for software to correctly function.

What is needed is a system and method that allows for the detection of malicious web content without compromising user functionality. Further what is needed is a system that can detect executable content and quickly identify and categorize its behavior and provide protection from the malicious content to a high volume of client computers with minimum delay.

The system method and devices of the present invention each have several aspects no single one of which is solely responsible for its desirable attributes. Without limiting the scope of this invention several of its features will now be discussed briefly.

In one embodiment a computer implemented method of identifying inappropriate content in web content is provided. The method includes receiving a request for a web content. The requested web content is compared to data in a database. If the requested content is not in the database it is sent to a collection module which collects data related to the requested content. Based on the collected data a candidate status for the URL is determined.

In another embodiment a system for identifying candidate URLs from a set of uncategorized URLs is provided. The system may include a URL database configured to store the uncategorized URLs and a collection system configured to collect information about the uncategorized URLs including data related to the uncategorized URLs. The collection system may include a data mining module configured to identify uncategorized URLs having a characteristic indicative of targeted content.

In yet another embodiment a computer implemented method of collecting data about URLs is provided. The method includes providing a data mining module with a configuration plug in. The data mining module may have a plurality of dispatchers configured to operate independently of each other. The data mining module receives URL data for analysis and separates the URL data into work units of URL strings. The method further provides for determining whether one of the plurality of dispatchers is available for receiving a work unit and sending the URL to one of the dispatchers if it is available.

In yet another embodiment a system for collecting data about URLs is provided. The system may include a database for storing information about URLs. The system may also include a pool of dispatchers which include asynchronous system processes each configured to receive URL data input and perform actions on the data. The system may also include a driver module configured to monitor the pool of dispatchers for available dispatchers and send part of the URL data input to the available dispatchers.

In still another embodiment a system for identifying candidate URLs from a set of uncategorized URLs include means for storing the uncategorized URLs means for collecting information related to the uncategorized URLs and means for identifying the uncategorized URLs having a characteristic indicative of targeted content.

Certain embodiments provide for systems and method of identifying and categorizing web content including potentially executable web content and malicious content that is found at locations identified by Uniform Resource Locators URLs . As used herein potentially executable web content generally refers to any type of content that includes instructions that are executed by a web browser or web client computer. Potentially executable web content may include for example applets executable code embedded in HTML or other hypertext documents including script languages such as JavaScript or VBScript executable code embedded in other documents such as Microsoft Word macros or stylesheets. Potentially executable web content may also refer to documents that execute code in another location such as another web page another computer or on the web browser computer itself. For example a HTML web page that includes an OBJECT element and thus can cause execution of ActiveX or other executable components may generally be considered potentially executable web content regardless of the location of the executable components. Malicious content may refer to content that is not executable but which is calculated to exploit a vulnerability on a client computer. However potentially executable web content may also be malicious content. For example image files have been used to exploit vulnerabilities in certain operating systems when those images are processed for display. Moreover malicious web content may also refer to interactive content such as phishing schemes in which a HTML form or other web content is designed to appear to be provided by another typically trusted web site such as a bank in order to deceive the user into providing credentials or other sensitive information to an unauthorized party.

Each of the workstations may be in electrical communication with a gateway server module . The gateway server module may reside at the edge of the network so that traffic sent to and from the Internet may pass through it on its way into or out of the network . The gateway server module may take the form of a software module that is installed on a server that stands as a gateway to a wider area network than the network to which the workstations are directly attached. Also connected to the Internet is a database management module . The database management module also may be a software module or one or more hardware appliances which resides on one or more computing devices. The database management module may reside on a machine that includes some sort of network connecting hardware such as a network interface card which allows the database management module to send and receive data and information to and from the Internet .

Referring now to a more detailed view of the workstation is presented. The workstation may include a workstation module . The workstation module may take the form of software installed to run on the operating system of the workstation . Alternatively the workstation module could be an application running on another machine that is launched remotely by the workstation .

The workstation module may include various components. The workstation module may include an inventory of a local active content module which records all web content stored on the workstation . For example the local content inventory module may periodically inventory all local content. The inventoried data may be uploaded to the gateway server module for comparison to the categorized URL content database . The local content inventory module may determine whether new content is being introduced to the workstation by comparison to the inventoried local content .

The workstation module also may include an upload download module and a URL request module . The upload download module may be used to send and receive data from the network through the gateway server module and to the Internet . The URL request module receives a URL input from either a user or some system process and may send a request via the gateway server module to retrieve the file and or content associated with that URL. Typically the functions of each of the upload download module and the URL request module may be performed by a software applications such as web browsers with Internet Explorer Mozilla Firefox Opera Safari being examples of browsing software well known in the art. Alternatively the functions of the modules may be divided among different software applications. For example an FTP application may perform the functions of the upload download module while a web browser my perform URL requests. Other types of software may also perform the functions of the upload download module . Although these types of software are generally not desirable on a workstation software such as Spyware or Trojan Horses may make requests to send and receive data from the Internet.

The workstation module may be in communication with the gateway server module . The gateway server module may be used to analyze incoming and outgoing web traffic and to make various determinations about the impact the traffic may have on the workstations . Referring now to an example of the gateway server module is provided. The gateway server module is in two way communication with the workstation . It may receive file uploads and downloads and URL requests from the workstation module . The gateway server module is also in two way communication with the Internet . Thus requests originating within the workstations of the network may be required to pass through the gateway server module as they proceed to the Internet. In some embodiments the gateway server module may be integrated with some firewall hardware or software that protects the network from unauthorized intrusions from the Internet . In other embodiments the gateway server module may be a standalone hardware appliance or even a software module installed on a separate gateway server residing at the network gateway to the Internet .

As discussed above the gateway server module may receive URL requests and upload download data from the workstation by way of the workstation module . The gateway server module may include various components that perform various functions based on the data received.

One feature included in the gateway server module is a categorized URL database . The URL database may be used to store information about URLs including data that is associated with the URLs. The categorized URL database may be a relational database or it may be stored in some other form such as a flat file an object oriented database and may be accessed via an application programming interface API or some database management software DBMS . The URL database may generally be used to help determine whether URL requests sent by the URL request module will be permitted to be completed. In one embodiment the URLs stored in the URL database are categorized.

The gateway server module may also include a policy module . The policy module may used to implement network policies regarding how certain content will be handled by the gateway server module or by a firewall or some other security software installed within the network . In one embodiment the policy module may be configured to provide the system guidance on how to handle URL requests for categorized URLs. For example the gateway server module may be configured to disallow URL requests that are categorized as being Malicious or Spyware. In other embodiments the policy module may be used to determine how to handle URL requests that have not been categorized. In one embodiment the system may be configured to block all requests for URLs that are not in the categorized URL database . The policy module may also be configured to allow certain requests of uncategorized URLs based on the user making the request or the time at which the request is made. This allows the system to avoid having a one size fits all configuration when such as configuration would not meet the business needs of the organization running the gateway server module .

The gateway server module may include a collection module . The collection module may be a software program routine or process that is used to collect data about URLs. In one embodiment when a request for a particular URL is received from the URL request module the collection module may be configured to visit the URL and download the page data to the gateway server module for analysis by components of the gateway server module . The downloaded data may also be sent via the Internet for delivery to the database management module as will be discussed in further detail below .

In some embodiments the gateway server module may also include a logging database . The logging database may perform various functions. For example it may store records of certain types of occurrences within the network . In one embodiment the logging database may be configured to record each event in which an uncategorized URL is requested by a workstation . In some embodiments the logging database may also be configured to record the frequency with which a particular uncategorized URL is requested. This information may be useful in determining whether an uncategorized URL should be of particular importance or priority and should be categorized by the database management module ahead of earlier received data. In some embodiments uncategorized URLs may be stored separately in an uncategorized URL database .

For example some spyware may be written to request data from a particular URL. If many workstations within the network are infected with the spyware repeated requests to a particular URL may provide an indication that some anomaly is present within the network. The logging database may also be configured to record requests of categorized URL data. In some embodiments categorizing requests of categorized URLs may be helpful in determining whether a particular URL has been mischaracterized.

Referring now to an example of the logging database is discussed. The logging database includes four columns of data. The first column No. Page Requests is indicative of the number of times a particular URL has been requested by users within the network . The second column URL records the particular URL string that is being logged in the logging database . Thus when a URL is sent to the logging database the database may first be searched to determine whether the URL string is already in it. If not then the URL string may be added to the database. In some embodiments the collection module may be configured to visit the requested URL and gather data about the URL. The collection module may retrieve the page source of the requested URL and scan it for certain keywords that may indicate a type of content. For example if the page source includes javascript then the page may be identified as having JavaScript. While such content is not inherently dangerous a web page with JavaScript may have a greater chance of including malicious content designed to exploit how a browser application handles JavaScript function calls. In some embodiments this data may be stored in the logging database in JavaScript column . The logging database may also receive similar information from pages that include Active X content and store that content within Active X column . In other embodiments other types of content may be detected and stored for java applets VBScript and the like.

Referring again to the gateway server module may further include an administrative interface module or admin module. The admin module may be used to allow network administrators or other technical personnel within an organization to configure various features of the gateway server module . In certain embodiments the admin module allows the network administrator or some other network management type to configure the policy module .

Referring now to an example of a URL access policy database is provided. The URL access policy database may be used by the policy module to implement policies for accessing web based content by workstations within the network . In the embodiment shown the URL access policy database includes a table with four columns. The first column is a user column . The User column includes data about the users that are subject the policy defined in a given row of the table. The next column Category lists the category of content to which the policy defined by that row is applicable. The third column Always Block represents the behavior or policy that is implemented by the system when the user and category of requested content match the user and category as defined in that particular row. In one embodiment the Always Block field may be a Boolean type field in which the data may be set to either true or false. Thus in the first row shown in the data table the policy module is configured to always block requests for malicious content by user asmith. 

As noted above the policy module may also be configured to implement policies based on different times. In the embodiment provided in the fourth column Allowed Times provides this functionality. The second row of data provides an example of how time policies are implemented. The user is set to bnguyen and the category is gambling. The policy is not configured to always block gambling content for bnguyen as indicated by the field being left blank. However the time during which these URL requests are permitted is limited to from 6 PM to 8 AM. Thus adopting these types of policies allows network administrators to provide a certain degree of flexibility to workstations and users but to do so in a way that network traffic is not compromised during typical working hours.

Referring now to the table of uncategorized URLs is provided described earlier in connection with . This table may be populated by URL requests from the workstation which request URLs that are not present in the categorized URL table . As will be described in greater detail below the gateway server module may be configured to query the categorized URL database to determine whether a requested URL should be blocked. If the requested URL is in the categorized database the policy module may determine whether to allow the request to proceed to the internet . If the requested URL is not found in the categorized URL database however it may be added to the list of uncategorized URLs so that it may be sent to the database management module via the Internet and later analyzed and categorized and downloaded into the database of categorized URLs .

In one embodiment the database management module may include an upload download module . The upload download module may be a software or hardware component that allows the database management module to send and receive data from the Internet to any number of locations. In one embodiment the upload download module is configured to send newly categorized URLs to gateway server modules on the Internet for addition to their local URL databases .

The database management module may also include a URL content database . The URL content database may take the form of a data warehouse which stores URL strings and information about URLs that have been collected by the collection system . The URL content database may be a relational database that is indexed to provide quick and effective searches for data. In certain embodiments the URL database may be a data warehousing application which spans numerous physical hardware components and storage media. The URL database may include data such as URL strings the content associated with those strings information about how the content was gathered e.g. by a honey client by a customer submission etc. and possibly the date in which the URL was written into the URL content database .

The database management module may further include a training system . The training system may be a software hardware module which is used to define properties and definitions that may be used to categorize web based content. The database management module may further provide a scoring classification system which utilizes the definitions and properties created by the training system to provide a score or classification e.g. a categorization to web content so that the categorization may be delivered via the upload download module to gateway server modules .

With reference now to a more detailed view of the collection system is provided. The collection system may include a collection module which is coupled either directly or indirectly to a data mining module . The collection module may be used by the database management module to collect data for the URL content database about URLs that have not been categorized. The collection module may also be used to collect URLs for additional analysis by other system components. The collection module may be associated with one or more collection sources from which it may collect data about URLs. Collection sources may take various forms. In some embodiments the collection sources may include active and passive honeypots and honey clients data analysis of logging databases stored on gateway server module to identify applications URLs and protocols for collection. The collection sources may also be webcrawling applications that search the Internet for particular keywords or search phrases within page content. The collection sources may also include URLs and IP addresses data mined from a DNS database to identify domains that are associated with known malicious IP addresses. In some embodiments URLs for categorization may be collected by receiving malicious code and malicious URL samples from other organizations who share this information. In yet other embodiments URLs may be collected via e mail modules configured to receive tips from the public at large much in the way that criminals are identified through criminal tip hotlines.

Referring now to a more detailed view of the collection module is provided. The collection module may include various subcomponents that allow it to effectively utilize each of the collection sources described above. The collection module may include a search phrase data module and a expression data module . The search phrase data module collects and provides search phrases that may be relevant to identifying inappropriate content. The expression data module may include various types of expressions such as regular expressions operands or some other expression. The search phrase data module and the expression data module each may include updatable record sets that may be used to define the search parameters for the web crawling collection source . The collection module may also include a priority module . The priority module may take the form of a software process running within the collection system or it may run as a separate process. The priority module may be used to prioritize the data collected by the collection module in order to have more potentially dangerous or suspect URLs or data receive close inspection prior to the likely harmless URLs. In one embodiment the priority module may assign priority based on the collection source from which the URL is received. For example if a URL is received from a customer report it may be designated with a higher priority. Similarly if the URL is received from a web crawler accessing a domain or IP address or subnet known to host malicious content in the past the URL may receive a high priority. Similarly a potentially dangerous website identified by a honey client discussed in further detail below may also receive a high priority. The collection module may also include a data selection module which may work with the priority module to determine whether identified URLs should be tagged as candidate URLs for categorization. In one embodiment the data selection URL may provide a user interface for receiving search parameters to further refine the prioritized data by searching for data based on priority and content.

As indicated above the collection module may also include a data download module . The data download module may be configured to identify URLs to visit and to download data and content from the visited URLs. The data download module may work in conjunction with various subsystems in the collection module to retrieve data for the URL content database . One such subsystem is the webcrawler module . The webcrawler module may be a software application configured to access websites on the Internet by accessing web pages and following hyperlinks that are included in those pages. The webcrawler module may be configured with several concurrent processes that allow the module to simultaneously crawl many websites and report the visited URLs back to the URL content database as will be discussed in further detail below. The collection module may also include a honey client module . The honey client module is a software process configured to mimic the behavior of a web browser to visit websites in such a manner that is inviting to malicious code stored within the visited pages. The honey client module may visit the web sites and track the behavior of the websites and download the content back to the URL content database for further analysis.

The download module may also include a third party supplier module which is configured to receive URLs and associated content from third parties. For example the third party module may be configured to provide a website which may be accessed by the general public. The module may be configured to receive an input URL string which may then be entered into the URL content database . In some embodiments the third party module may also be configured to receive e mails from private or public mailing lists and to identify any URL data embedded within the e mails for storage in the URL content database .

The download module may also include a gateway server access module . The gateway server access module is a software component or program that may be configured to regularly access the logging database on the gateway server module to download upload all of the newly uncategorized web content identified by the logging database .

Referring back to the collection system may also include a data mining module . The data mining module may be used to obtain additional data about URLs stored in the URL content database . In many instances the information supplied by the collection sources to the collection module and URL content database is limited to nothing more than a URL string. Thus in order for the system to effectively categorize the content within that URL more data may be necessary. For example the actual page content may need to be examined in order to determine whether there is dangerous content embedded within the URL. The data mining module is used to collect this additional necessary data about the URLs and will be discussed in further detail below.

In one embodiment each control server may control passive honey miners . The control servers may extract or receive URLs from the URL content database which need additional information in order to be fully analyzed or categorized. The control servers provide the URLs to the miners which in turn review the URLs and store the collected data. When a passive miner is finished with a particular URL it may request another URL from its control server . In some embodiments the miners may be configured to follow links on the URL content so that in addition to visiting URLs specified by the control server the miners may visit content that it linked to those URLs. In some embodiments the miners may be configured to mine to a specified depth with respect to each original URL. For example the miners may be configured to mine down through four layers of web content before requesting new URL data from the control server .

In other embodiments the control servers may be configured to control active honey miners . In contrast to the passive honey miners which only visit web sites and store the content presented on the sites the active honey miners may be configured to visit URLs and run or execute the content identified on the sites. In some embodiments the active honey miners include web browsing software that is configured to visit websites and access content on the websites via the browser software. The control server or the honey miners themselves may be configured to monitor the characteristics of the honey miners as they execute the content on the websites they visit. In one embodiment the control server will record the URLs that are visited by the honey miners as a result of executing an application or content on the websites visited. Thus active honey miners may provide a way to more accurately track system behavior and discover previously unidentified exploits. Because the active honey miners expose themselves to the dangers of executable content in some embodiments the active honey miners may be located within a sandbox environment which provides a tightly controlled set of resources for guest programs to run in in order to protect the other computers from damage that could be inflicted by malicious content. In some embodiments the sandbox may take the form of a virtual machine emulating an operating system. In other embodiments the sandbox may take the form of actual systems that are isolated from the network. Anomalous behavior may be detected by tracking in real time changes made to the file system on the sandbox machine. In some embodiments the code executed by the active honey miners may cause the machine on which they are running to become inoperable due to malicious code embedded in the webpage content. In order to address this issue the control server may control a replacement miner which may step in to complete the work of a honey miner which is damaged during the mining process.

Referring now to an example of a set of URL related data that has been collected by the collection system is provided. Although a particular example of collected data is provided one of skill in the art will appreciate that other data might be collected in addition to the data provided in this example. Included in the collected data is an IP address for the URL. The IP address may be used to identify websites that are hosting multiple domains of questionable content under the same IP address or on the same server. Thus if a URL having malicious content is identified as coming from a particular IP address the rest of the data in the URL content database may be mined for other URLs having the same IP address in order to select them and more carefully analyze them. The collected URL data may also include a URL as indicated by the second column in . In instances where the data is collected using a mining process such as the honey client process described above the URL may often include various pages from the same web domains as the miners may have been configured to crawl through the links in the websites. The collected data may also include the page content for a particular URL. Because the content of a URL may be in the form of graphics text applications and or other content in some embodiments the database storing this URL data may be configured to store the page content as a binary large object blob or application objects in the data record. However as some web pages contain text exclusively the page content may be stored as text as well. In some embodiments the collection routine may be configured to determine whether the URL contains executable content. In these instances the resultant data set of collected data may include an indication of whether the URL has executable content within its page code. This information may be later used in selecting data from the URL content database has candidate data for analysis.

As discussed above in connection with in some embodiments the gateway server module may be configured to control access to certain URLs based on data stored in the categorized URL database . is a flowchart describing an embodiment in which the gateway server module handles a request from a workstation .

At block the workstation requests a URL from the Internet . This request is intercepted at the Internet gateway and forwarded to the gateway server module at block . At block the categorized URL database is queried to determine if the requested URL is stored in the database . If the requested URL is found as a record in the database the process moves on to block where it analyzes the URL record to determine whether the category of the URL is one that should be blocked for the workstation user. If the category is blocked the process skips to block and the request is blocked. If the category is not blocked however the request is allowed at block .

If the requested URL is not found as a record in the categorized URL database at block the system proceeds to block . At block the system determines how to handle the uncategorized content. In some embodiments the system may utilize the policy module to make this determination. If the gateway server module is configured to block requests for uncategorized content the process moves to block and the request is blocked. If on the other hand the module is configured to allow these types of uncategorized requests the process moves to block where the request is allowed to proceed to the Internet .

In some embodiments the request of URL data may result in new records being added to the logging database . These records may be later transferred to the database management module for further analysis. Referring now to another flowchart describing a process by which the gateway server module may handle a URL request is provided. At block the gateway server module receives a request for a URL. As noted above this request may come from a workstation . At block the URL is then compared against the categorized URL database and the system determines at block whether the requested URL is in the categorized URL database.

If the URL is already in the categorized URL database the process skips to block . If the requested URL is not found in the categorized URL database however the process moves to block where the URL is inserted into the uncategorized URL database . In some embodiments the logging database and the uncategorized URL database may be the same database. After inserting the URL into the database the method proceeds to block . At block the policy database is checked for instructions on how to handle the received URL. Once the policy module has been checked the logging database is updated to record that the URL has been requested at block . After updating the logging database if the workstation is permitted to access the URL by the policy database the process moves to block and the URL request is sent to the Internet . If however the policy database does not allow the request the process skips to block and the request is blocked.

In some embodiments the gateway server module may perform collection to lessen the burden on the collecting system of the database management module . provides an example of a system in which the gateway server collection module is used to collect data about an uncategorized URL. At block the gateway server module receives a request for a URL. Next at block the requested URL is compared against the categorized URL database. If the system determines that the requested URL is in the URL database at block the process moves to block where the request is either forwarded to the Internet or blocked depending on how the URL is categorized.

If the requested URL is not in the categorized URL database the process moves to block where the URL is sent to the gateway collection module . Next at block the collection module collects URL data about the requested URL. In some embodiments this data may be stored in the uncategorized URL database . Alternatively this data may simply be forwarded to the database management module via the Internet . Once the data has been collected and stored the process moves to block where the URL request is either allowed or blocked based on the policies indicated in the policy module .

As discussed previously uncategorized URL data may be sent from the gateway server module to the database management module for further analysis so that the URL may be categorized and added to the categorized URL database . However because the volume of uncategorized data is so large at times it may not be possible to categorized all of the received data without compromising accuracy. As a result in some instances it may be desirable to identify candidate URLs within the uncategorized data that are most likely to present a threat to workstations and networks .

In another embodiment the system may utilize the honey client system in conjunction with the data mining system to collect URLs to be added to the candidate URL list for classification. illustrates an example of a process for collecting this data. At block the honey client control server is launched. The control server then launches one or more honey miners at block . Next at block the honey miners visit the next URL provided to them by the control servers and parse the page source of that URL to determine if there is active content in the URL at block . If no active content is found in the page the process skips to block . If however active content is found the process moves to block where the URL is added to the candidate URL list.

Next at block the miner determines whether the current URL contains hyperlinks or forms. If no hyperlinks or forms are found the process loops back to block where the miner receives another URL from the control server for analysis. If however the URL contains hyperlinks or forms the method proceeds to block where it then determines whether the URL includes hidden links or forms. Because many malicious websites wish to avoid detection by mining software such as the honey clients systems they include hidden hyperlinks that are not visible when browsed by a human. Thus the website can detect a miner by hiding these links as bait. One technique used to hide the links is to make them the same color as the background of the web page. If the miner follows the links then the website is alerted to its presence.

In the method provided in the miner is configured to detect these hidden links. If no hidden links are present the process skips to block and the miner continues by following the non hidden links that are in the URL content. If however any hidden links are present at block the URL and its hidden links are added to the classification list and passed over at block . Once the hidden links have been processed i.e. added to the classification list the method then proceeds to block where the non hidden links are followed.

In some embodiments URL data is added to the URL content database without all of the necessary data for full analysis by the scoring classification system . For example sometimes the only data received about a URL from a collection source is the URL string itself. Thus it may become necessary to collect additional data about URLs in order properly analyze them. Referring now to a process is shown describing how the system may handle candidate URLs according to one embodiment. At block data from a collection source is added to the URL content database . As discussed previously the URL content database may be a data warehouse. Next at block the system looks at the URL data and determines whether there is missing content that is necessary for analysis. In some configurations if the content of the URL is not in the data warehouse the system determines that more data is needed and sends the URL to the data mining module for supplementation at block . The data mining module then may take the data received and collect additional data. If no content is missing the URL is immediately sent to the scoring classification module for further analysis at block .

As discussed above one of the challenges to collecting and analyzing Internet data to determine whether it includes harmful active content is the sheer volume of data that must be collected and analyzed. In yet another embodiment the data mining module may be used to address these issues by collecting large volumes of relevant data utilize system resources effectively and efficiently. Referring now to a more detailed block diagram of the data mining system is provided. The data mining system may take the form of a software module that runs a plurality of asynchronous processes to achieve maximum efficiency and output. The data mining system may include a plug in module which receives configuration parameters which provide instruction on how inputted data should be handled. In one embodiment the instructions received by the plug in module may take the form of an HTTP protocol plug in that provide parameters for the data mining system to receive URL data and analyze and supplement the data based on various HTTP related instructions implemented by the data mining system on the URL data. In another embodiment the plug in may be geared toward mining some other protocol such as FTP NNTP or some other data form.

The data mining system which may also be used to implement passive honey clients may also include a pool of dispatchers . The dispatchers are individual asynchronous processing entities that receive task assignments based on the data input for analysis into the data mining system and the configuration data received by the plug in module . The pool is a collection of the dispatchers that is controlled by a driver . The driver is a managing mechanism for the pool. The driver may be configured to monitor the activity of the dispatchers in the pool to determine when to send additional data into the pool for mining and analysis. In one embodiment the driver may be configured to send new data units into the pool whenever any dispatchers are idle. In one embodiment the driver may be utilized as a control server for managing honey client miners as described above in connection with . The pool may deliver the data unit to the idle dispatcher . The dispatcher reads the plug in configuration and performs actions in accordance with plug in .

In one embodiment the plug in module may receive an HTTP plug in. The HTTP plug in may be configured to receive input data in the form of URL strings about which the data mining system will obtain addition information such as the page content for the URL HTTP messages returned by the URL when accessed such as 4xx file not found or 5xx server error . The plug in may further specify a webcrawling mode in which the dispatches in addition to collecting page content also add URL links within the URL content to the URL data set to be analyzed.

As used herein database refers to any collection of stored data stored on a medium accessible by a computer. For example a database may refer to flat data files or to a structured data file. Moreover it is to be recognized that the various illustrative databases described in connection with the embodiments disclosed herein may be implemented as databases that combine aspects of the various illustrative databases or the illustrative databases may be divided into multiple databases. For example one or more of the various illustrative databases may be embodied as tables in one or more relational databases. Embodiments may be implemented in relational databases including SQL databases object oriented databases object relational databases flat files or any other suitable data storage system.

The various illustrative logical blocks modules and circuits described in connection with the embodiments disclosed herein may be implemented or performed with a general purpose processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor but in the alternative the processor may be any conventional processor controller microcontroller or state machine. A processor may also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The steps of a method or algorithm described in connection with the embodiments disclosed herein may be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module may reside in RAM memory flash memory ROM memory EPROM memory EEPROM memory registers hard disk a removable disk a CD ROM or any other form of storage medium known in the art. An exemplary storage medium is coupled to the processor such the processor can read information from and write information to the storage medium. In the alternative the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a user terminal. In the alternative the processor and the storage medium may reside as discrete components in a user terminal. It will be understood by those of skill in the art that numerous and various modifications can be made without departing from the spirit of the present invention. Therefore it should be clearly understood that the forms of the invention are illustrative only and are not intended to limit the scope of the invention.

