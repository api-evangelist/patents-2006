---

title: Distributed physics based training system and methods
abstract: A distributed simulation system is composed of simulator stations linked over a network that each renders real-time video imagery for its user from scene data stored in its data storage. The simulation stations are each connected with a physics farm that manages the virtual objects in the shared virtual environment based on their physical attribute data using physics engines, including an engine at each simulation station. The physics engines of the physics farm are assigned virtual objects so as to reduce the effects of latency, to ensure fair fight requirements of the system, and, where the simulation is of a vehicle, to accurately model the ownship of the user at the station. A synchronizer system is also provided that allows for action of simulated entities relying on localized closed loop controls to cause the entities to meet specific goal points at specified system time points.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08645112&OS=08645112&RS=08645112
owner: L-3 Communications Corporation
number: 08645112
owner_city: New York
owner_country: US
publication_date: 20061128
---
This application claims the priority of U.S. provisional application Ser. No. 60 740 579 filed Nov. 28 2005 which is herein incorporated by reference in its entirety.

This invention relates to the field of simulators and more particularly to the field of simulator systems for multiple users for training in military exercises or military vehicle operations especially such systems for users that are geographically distributed relative to each other and connected by communications links such as a network or the Internet.

It is known in the prior art to provide simulation systems for users distributed geographically relative to each other potentially thousands of miles apart with communications between the various users being transmitted over a network such as the Internet. In these systems each user normally has a simulation station where the user can see on a screen a head mounted display or other display device that user s view of a shared virtual environment based on his virtual position in it. The displayed scene is video prepared by an image generator at the simulation station that renders serial frames of video using changing scene data that defines the visible objects in the simulated environment in real time. The user also can interact with and affect the virtual environment as with simulated cockpit controls in an aircraft simulator simulated weapons systems or other interface mechanisms known in the art and his interactions that change the scenery can be seen by him and all the other users.

In the armed forces Distributed Interactive Simulations DIS are recognized as being essential for training system acquisition and test and evaluation. DIS may also be employed in non military simulation applications such as e.g. simulations for air traffic control airplane crash traffic land use environmental natural disaster videogames networked multiplayer video games and the like. Within the U.S. Department of Defense key components of DIS include high fidelity computer simulated individual entities tanks trucks aircraft etc. interactions among entities hosted on different computers through network messages and support for Human In Loop HIL interactions.

Using DIS it is possible to create large scale virtual representations of real operational environments that are inexpensive enough to be used repeatedly. Accordingly a set of DIS protocols were promulgated by the IEEE in 1995 and became the basis for much of the current generation of networked simulations.

Modular Semi Automated Forces ModSAF is an example of the implementation and use of the DIS protocol in the armed forces for cost effective training. ModSAF generally runs using a collection of workstations communicating over a network typically a LAN. Each workstation is responsible for simulating a predetermined number of entities or simulated objects. These computer generated Semi Automated Forces SAF are intended to mimic realistically the behaviors of opposing forces or support forces within an exercise. The entity and environment models employed are typically quite detailed and the individual simulators can interact by exchanging data using a messaging protocol the basic unit of which is referred to as a Protocol Data Units PDUs . PDUs are used in ModSAF to describe the state of individual entities weapons firing detonations environmental phenomena command and control orders etc.

In standard ModSAF the PDUs are sent as UDP datagrams which is an unreliable message delivery mechanism and therefore each entity state PDU typically contains a complete summary of the vehicle s current state. PDUs are transmitted retransmitted at frequent regular heartbeat intervals to compensate for dropped data packets. In using such a system assurance that each simulator receives and responds to all PDUs from all other simulators is extremely difficult if not impossible as the number of simulators and simulated entities increases due to the avalanche of communication network traffic that results from dynamically moving entities continually updating their state. Human In Loop HIL entities tend to complicate matters even further given their interactive and inherently unpredictable behavior.

A primary problem encountered in such distributed systems is that of latency meaning communications delay between the transmission from a remote site of data affecting the scene and the reception and display of that data at a user s station. Latency depends on distance and the quality of the communications links and can commonly be 200 milliseconds a fifth of a second or more. The consequence of latency in multi user situations is that the actions of a remote user do not affect the scene viewed by the local user immediately and this can result in inconsistencies in the views seen by the users in the distributed system.

To try to reduce some of the effects of latency prior art systems have used a kinematics approach in which when information relating to position and movement of a virtual object is received it is checked for a time stamp indicative of when precisely in system time the data was produced. The movement of the affected object is then simply linearly projected or extrapolated to an estimate of its current position based on its position and velocity defined by the most recent data available together with a t of the time stamp from the current time indicating the age of the data in system time terms.

Linear projections of this type do not accurately extrapolate the real position of objects under a number of circumstances and in addition to the positional errors associated with a pure linear projection of the location of the object it is also possible that behavior of the object will be unrealistic if it is projected to a point that it could not reach in reality such as for example when the position of a moving person or vehicle is extrapolated to the other side of a solid wall making it appear that the person or vehicle actually went through the wall.

Furthermore especially in military simulation based training discrepancies between various users views of the simulated world can compromise principles of training notably fair fight requirements. Fair Fight is a term that means no combatant has an unfair advantage over another due to differences in each participant s representation of the world. Differences in the viewed scenery of the participants can afford such an advantage to one user or another.

In addition simulators for vehicles especially aircraft are usually modeled to run scripts when certain events occur to the user s ownship such as when damage is done to the vehicle in combat. As an example in a helicopter simulation if a blade of the helicopter is shot at and it breaks off the simulator normally initiates a damaged vehicle script that is usually limited to a single type of damage scenario and does not provide the realism of allowing a wide variety of effects for the various types of damage that may be done to the aircraft. These limitations reduce realism and also lessen to a degree the training value of the simulation.

It is accordingly an object of the invention to provide systems and methods that avoids the drawbacks of the prior art.

In one aspect of the invention this is achieved by a simulation station for use in a simulation system having a plurality of users each associated with a respective simulation station. The simulation station comprises a link to a communication network to which all simulation stations are linked and computer accessible data storage storing scene data. The scene data includes object data defining a plurality of virtual objects in a virtual environment. The object data includes for each of the objects location data defining a location of the object in the virtual environment and data defining characteristics of the virtual object affecting its appearance. An image generator periodically renders from the scene data a frame of video imagery corresponding to a view of the virtual environment from a position associated with the user of the simulation station so that the user is provided with a real time view of the virtual environment. A display receives the video imagery and displays the imagery so as to be viewable by the associated user. A physics engine manages the virtual objects in the scene data by determining physics data for a subset of the virtual objects in the scene based on data defining physical attributes of the objects and the locations thereof and receiving via the link physics data regarding other of the virtual objects in the scene data. The physics engine influences the scene data so that the location data of the virtual objects as defined in the scene data complies with physical rules governing based at least in part on the physical attribute data the movement of the object in the virtual environment.

According to another aspect of the invention a system is provided for giving a shared simulated environment to a plurality of users each having a respective user location in said simulated environment. The system comprises a plurality of simulator stations each associated with a respective user and linked over a network so as to communicate with each other. The simulator stations each include a data storage system storing scene data thereon and a computerized image generator generating real time video as a stream of images each rendered based on the scene data corresponding to a respective point in time. The video is displayed to one of the users associated with the simulator station using a display communicating with the image generator. The scene data includes object data defining a position and physical attributes of virtual objects in the shared simulated environment. A physics farm is connected with the simulator stations and it interfaces with the scene data of each of the simulator stations and controls position data of virtual objects of the scene data based on the defined physical attributes of the virtual objects and on physical rules that cause the virtual objects to emulate real movement of objects having corresponding real physical attributes. The physics farm comprises a plurality of physics engines operatively connected with the network so as to communicate with each other each having at least one of the physics engines at its location and a physics manager assigning each of the virtual objects in the shared simulated environment to one of the physics engines. Each of the physics engines determines if any of the virtual objects assigned thereto are in a physical conflict with any other objects in the simulated environment. Responsive to such a determination each physics engine attempts to resolve the conflict of the objects locally without reference to the other physics engines. If not resolved locally by the physics engine the conflict outcome for the virtual objects in the conflict is determined by the physics engines assigned the virtual objects involved and the conflict outcome is communicated by transmitting a packet of data identifying the virtual object involved and including conflict data corresponding to the conflict over the network from which packet of data the position or positions of the virtual objects involved after the conflict can be determined.

According to a further aspect of the invention a method for providing an interactive simulation of an environment to a plurality of users comprises providing each of the users with a respective simulator station having a display displaying to the associated user video rendered by a computerized image generator from scene data stored in a computer accessible data storage system. An input signal indicative of an interactive command from the user for influencing the simulated environment is received from one of the users at the respective simulator station. Data from the input signal defining the interactive command is derived as a force applied to one or more virtual objects in the simulated environment. Physics processing of the force or torque on the object or objects is performed using a distributed physics farm comprising a plurality of physics engines. At least one of the physics engines is operatively associated with the respective simulator station. Physics notification data on the object and a system time thereof is published to all of the physics engines in the physics farm. The physics notification data is received at a second of the physics engines operatively associated with another of the simulation stations. Physics processing of the notification data of the object is performed at the second of the physics engines. The second physics engine computes a position of the object based on the physics notification data and a difference between the system time thereof and a current system time. The second physics engine accesses locally data defining the positions of other objects in the simulated environment and the determination of the computed position includes a conflict check that incorporates into the computation any conflict with other objects in the simulated environment. The scene data at the associated simulation station is modified such that the scene data reflects an updated position of the object conforming to the computed position. The scene data is rendered to produce imagery showing the object at the computed position and the imagery is displayed to the user of the second simulation station.

According to another aspect of the invention a simulation system comprises a physics farm communications layer comprising a communications backbone and a physics farm layer. The physics farm layer has a plurality of distributed physics engines each communicatively linked to the physics farm communications layer so as to transmit data to the other physics engines and to receive data therefrom. Each physics engine stores physical attribute and location data for all of objects in a virtual environment. A physics farm management system selects the physics engine that performs physics processing for each object in the virtual environment and a physics based simulation API communicates with the physics farm management system to allow access thereto by applications. A physics based simulation application layer comprising at least two distributed simulation stations provides interactive simulation to respective users including displaying to the respective user imagery rendered from scene data stored at the simulation system. The scene data is modified by the physics farm layer to reflect interaction of the users with the objects in the virtual environment.

According to still a further aspect of the invention a method of providing distributed simulation of a plurality of vehicles comprises providing a plurality of simulation stations each having simulated controls for a respective vehicle being simulated a display a storage medium storing scene data defining positions of virtual objects in a virtual environment and a physics engine. The physics engine stores physics data for objects in the virtual environment and the objects include an ownship set of objects configured to correspond to the vehicles being simulated. Physics processing of the ownship set of objects for the simulation station is performed using the physics engine of each simulation station and the resulting physics data is transmitted to the other simulation station or stations. The physics data is received at the other simulation station or stations and the scene data thereof is modified based on the physics data so that the other user or users can see the other station s ownship if appropriate to said user s point of view. The physics data for each ownship is used to control the simulated behavior of the ownship of said simulation station.

It is also an object of the invention to provide a simulation system comprising a plurality of computerized simulation stations connected with each other via a network. Each simulation station has a respective computer accessible data storage storing a respective version of scene data corresponding to a virtual environment a respective computerized image generator generating serial frames each of which is a rendered view for a respective point of view in the virtual environment defined by the respective version of the scene data stored and a display device displaying said frames. The system further comprises a simulation computer system determining behavior of a virtual client entity in the virtual environment and transmitting client movement data via the network to the simulation stations. This client movement data corresponds to the determined behavior and it defines at least one location in the virtual environment to which the client entity is to move as well as time constraint data indicative of a point in time by which the entity is to move to the location. Each simulation station has a synchronizer that receives the client movement data and based thereon causes the virtual object of the client entity in the scene data of the simulation station to be modified so as to reflect movement of the client entity to the location by the point in time by which the entity is to move to the location.

Also according to the invention a method is described that provides an interactive simulation of a virtual environment to a user at a simulator station. The method comprises storing physics data on a computer accessible memory coupled with a physics engine. The physics data defines physics parameters of a plurality of virtual objects in a virtual scene and includes position data reflecting respective positions of the virtual objects in the virtual scene. The physics engine is passed data identifying at least one of the virtual objects and defining a value of force or torque the physics engine modifies the physics data in the memory so that the position data of the virtual object in the memory reflects a modified position that corresponds to a result in the virtual environment of the force or torque acting on the virtual object pursuant to physics rules of said physics engine. The modified position data is obtained and stored said so as to be accessible to a computerized viewer. An image is rendered corresponding to a view of the virtual scene using the computerized viewer and the view includes a view of at least a portion of the virtual object in the modified position.

According to another aspect of the invention a system is provided for providing distributed simulations to one or more users. The system comprises a first computer system linked for communication over a network and having a data storage device storing data and a display. The data storage device stores data defining a virtual scene having a number of virtual objects therein each having a respective visual appearance position and orientation defined by the data the computer system includes a viewer generating real time imagery from the data and displaying the imagery on the display the imagery corresponding to a rendered view at the time the image was rendered of the virtual scene as defined by the data. A second computer system has a data storage device the data storage device storing data defining the same virtual scene with the same virtual objects as defined by the data on the first computer system. The second computer system executes a program determining movement of a controlled virtual object in the virtual scene. The second computer system further has a master synchronizer transmitting over the network route data for the controlled virtual object indicative of a point in the virtual scene and a future point in time by which the controlled virtual object is directed to reach the point. The first computer system has a slave synchronizer receiving the route data and responsive thereto causes the data stored therewith to be modified so that in the data stored at the first computer system the controlled virtual object moves to the point in the virtual scene by the point in time.

Other objects and advantages of the invention will become apparent from this specification and the scope of the invention will be set out in the claims.

As best shown in a simulation system according to a preferred embodiment of the invention has a number of simulation stations each linked to a network either a LAN or the Internet. Instructor station is also linked to the network as is an auxiliary client computer system the operation of which will be discussed below.

Each simulation station is a computerized system that supports an interactive involvement of a respective user. The simulator stations each include a display device of some sort ranging from a projection sphere to a head mounted display. The simulation stations also include an interactive device that allows a user to input data to the simulator and where a vehicle is being simulated this usually takes the form of a simulated cockpit or driver s seat that inputs data but is also controlled by the simulator computer system to afford realism to the simulation as with functioning gauges and indicators on the control panel of the vehicle. The simulator includes a computer system that manages the operation of the interaction with the user as is well known in the art.

In addition the simulator station includes a computerized image generator that accesses scene data stored on a data storage system . The scene data stored includes data defining effectively every visible virtual object in a virtual world or environment in which the simulation takes place. This scene data includes all information needed to determine the appearance of the objects in the virtual world including the location shape size orientation color texture and any other visible characteristics that the object may have. Image generator generates video imagery from the scene data by rendering views of the scene data for the point of view of the user from the user s virtual location in the virtual world.

The scene data of course can change as objects move in the virtual world although at start up of the system all simulator stations have the same scene data in their mass data storage because they all are in the same world.

Simulator stations also have a physics engine component that communicates with the network or Internet . This physics engine component includes at its heart one or more physics engines which are preferably physics processor units PPUs which are dedicated hardware devices with supporting circuitry that can process large amounts of data defining physical parameters of virtual objects in a simulated three dimensional environment world and determine interactions for those objects expressed as forces accelerations position velocity and various constraints on an objects movement due to contacts with other objects in the simulated world.

Particularly preferred for use in the physics engines are those based on the physics processors sold under the names PhysX or NovodeX by a company named Ageia having a place of business at 82 Pioneer Way Suite 118 Mountain View Calif. 94041. Other dedicated hardware physics processor systems may also be used advantageously with the invention. At present the computational power of any software system is so far below that of the dedicated hardware physics engines which can process on the order of thousands of times more objects that a software system in terms of present technology at least would have at best a very limited utility.

The physics engine component also includes a memory system preferably a RAM memory that stores physics environment data defining the physical attributes of the virtual objects in the virtual environment including a detailed model of the ownship vehicle in a vehicle simulator expressed as an assembly of constituent virtual parts. Each object or entity has physical attribute data and location data stored in this memory including data indicating the geometry of the entity its mass its center of gravity its inertia its orientation its density and any joints or contacts that may connect it with any other objects. The physical attributes are used by the physics engine to determine movement of the virtual objects based on physical rules of the physics engine which emulate the physical laws of the real world.

The physics engine component preferably includes a physics manager as well which controls which physics engine does the physics calculations for any specific object. For example the objects making up the ownship of the simulator are normally assigned to the physics engine of that simulator because changes in the physical data are especially important to that particular simulator and latency in reporting movement in those parts is very undesirable.

Objects in the virtual world that are near the virtual position of the user in the simulation system such as a building next to which a helicopter simulated by the simulation station is landing are also preferably processed at the simulator station physics engine because their closeness makes latency and the resulting inaccuracies in display more undesirable. On the other hand objects making up a distant building that has little if any effect on the user s view are appropriately processed in a different physics engine because latency does not have a significant negative effect on the user s view. One exception to this is that if a weapon subsystem is being simulated a distant object is processed by the local physics engine if the object is being targeted as the object though distant is critical to the user s view.

The collection of all of the physics engines connected with the network and their managers is referred to as a physics farm as it is a distributed system the parts of which cooperate to share the physics data and computational workload for the simulation.

In operation each physics engine only acts in response to a force applied to an object for which it is responsible. When that happens if the object is subjected to enough force to cause it to move the physics engine will calculate its movement and change the local scene data accordingly. It will also broadcast over the network to all other simulator stations or physics engines in the system a message indicating the amount location and time of the force applied to the object. Those other stations will then receive the message and update their own copy of the world s physics data by applying the physical rules to this data message with other local processing as will be discussed below to compensate for latency in the transmission.

If the force moves the object so that it contacts another object then the physics engine resolves the collision to determine where the two objects wind up when it is over. In addition a slightly different collision message of data is sent out identifying the two objects that collided. The other physics engine that is responsible for the other object contacted also will issue a collision report. The scene data is updated by each physics engine to reflect the end position of the two objects pursuant to the physics engine rules.

Referring again to in addition to the simulation stations additional physics engines can be provided in a computerized system also connected with the network. These physics engines can assist in computation for the simulation stations but can also provide for physics processing of other objects moved in the virtual world by something other than the users such as by applications that access the physics engines through physics based simulation API . Examples of such applications are computerized processes that provide an environmental influence such as a hurricane force wind which produces force on a number of objects and intelligent behavior or SAF modeling which provides for movements of computer controlled forces that operate essentially on their own independently of the users or in reaction to events in the simulation for example as enemy forces support forces or something else in the simulation.

Administrator or instructor IOS stations is a computer system that can access any physics data in the system to set up a desired training scenario as will be discussed below in greater detail.

The physics farm communications layer is used to communicate and exchange data between the participating physics engines all of which are linked via the communications backbone network to receive and transmit data to and from the other physics engines in the system.

The physics farm layer enables a physics based simulation to be performed in a distributed environment. The physics farm manager dynamically assigns objects in the simulated environment to one of the physics engines for physics processing as discussed elsewhere herein. The physics based simulator API interfaces the physics farm data with the other software applications components of the simulation system.

The physics based simulation application layer is comprised of the one or more applications or simulation components entities participating in the distributed physics based simulation e.g. typical components entities might include one or more helicopter aircraft or ground vehicle simulation stations computer models that control ground or life form behaviors managing environment objects occulting or line of sight results SAF behaviors or similar modeled functionalities executed on connected computer systems that influence the virtual world of the simulation.

The physics based simulation training layer enables the introduction of training artifacts typically employed in a training environment into a physics based simulation. The physics based simulation training layer is desirable but not strictly necessary to an operating distributed simulation system and is an alternate embodiment for systems where closely supervised or very flexible training is desired. In another embodiment the physics based simulation training layer is replaced with a layer that performs the specific system wide administrative functions required by the particular purpose of the system such as in a multiplayer video game environment layer can process overall management of player accounts statistics etc.

The physics farm communications layer provides the communications backbone for the physics based simulations contemplated by the present invention. Physics based simulations introduce actions and reactions that can be highly sensitive to time and latency issues that have not been adequately addressed by previous approaches using Distributed Interactive Simulation DIS protocol or High Level Architecture HLA based systems.

In one aspect of the invention timing and latency issues are reduced or eliminated by determining the resulting positions velocities and accelerations when two objects collide using the physics engines instead of using the applications themselves to represent the colliding objects as in traditional simulations.

One approach used by current distributed simulation training systems is to incorporate threshold techniques to minimize network traffic i.e. applications responsible for their own objects won t send data reflecting current positions velocities and accelerations until some predetermined position orientation or time delta has exceeded a specified threshold.

Such threshold techniques disadvantageously require the local or receiving application simulation to extrapolate position and orientation over time i.e. in the period of time that new data has not yet been received from the remote application simulation. The result of implementing such threshold techniques is that the same object may be in a different position and or orientation in one simulator than it is in another participating simulation. The physics based outcome of a collision may produce different results in different distributed participating simulations. Because time and latency may also present issues in the physics based simulations creating potential inconsistencies new methods employed by certain preferred embodiments of the present invention are used to resolve conflicts and maintain consistency.

In one aspect of the invention latency is minimized and communications bandwidth is maximized using the physics farm communications layer . Preferably the physics farm communications backbone is a high bandwidth network that is highly optimized to the protocols used by participating physics engines. In one preferred embodiment data is packaged prioritized and shared between physics engines in order to provide realistic and consistent results. According to another aspect of the invention the physics farm layer is used to obtain realistic and consistent results.

The physics farm layer is a collection of capabilities sub layers including preferably the physics farm application programming interface API layer the physics farm management layer and the physics engines referred to interchangeably throughout as the physics farm participating in a physics based simulation. The individual physics engines managed by the physics farm management application are preferably treated as a pooled resource where some physics engines may be loosely coupled and others may be tightly coupled i.e. embedded within a simulation application .

The capabilities of the physics farm layer are preferably distributed with data exchanged via the physics farm communications layer or backbone. The physics engines are preferably instances of the physics algorithms used to model the physics environment deployed in either dedicated hardware e.g. physics processor unit or PPU or one or more software routines. Physics based objects i.e. objects for which physics based computations are required to allow the object to interact within the distributed simulation are registered or instantiated with the responsible physics engine. Physics based results are then preferably produced based on the objects attributes such as position velocity mass dimensions and the like.

Physics farm management is responsible for coordinating and managing the activity between participating physics engines. According to one aspect the physics farm management layer preferably arbitrates manages coordinates which physics engine will be responsible for modeling a specific object or request. The physics farm management layer preferably balances network computational load s and resolves conflicts in order to maintain consistency throughout the distributed simulation.

The physics farm management capabilities preferably reside with each instance of a physics engine whether loosely or tightly coupled and will use the physics farm communication backbone to exchange or share data. Preferably each simulation application employs logic allowing the simulation applications to access the physics farm capabilities using the physics farm API to make requests for services to be performed or to implement callback routines to receive results or updates to the distributed simulation state.

Advantageously the physics farm API provides applications with an interface to the physics engines as well as the physics based simulation environment. In addition the physics farm API hides the details and nuances involved with distributing and balancing the load across the participating and distributed physics engines.

In accordance with yet another aspect of the invention the physics based simulation application layer implements the simulation application logic. Preferably the logical architecture is designed such that any application logic can reside in the physics based simulation application layer illustrates some representative simulation applications . Preferably those simulation applications requiring or desiring physics based simulation use the physics farm API to create delete modify and obtain results of actions to be performed by specified objects. Actions can include instruction to move to specific location instructions to apply a force or acceleration and the like. Similarly actions can include instructions to trigger a model to perform an abstract operation such as to detonate or explode injecting an impulse force into the physics based simulation. Preferably any combination or sequence of actions can be utilized.

Where instructor involvement in the training is provided the physics based simulation training layer can be employed to allow the introduction of training artifacts into the physics based simulation training environment. This layer may be referred to interchangeably herein as the Next Generation Training NGT infrastructure. Preferably NGT supports a distributed training environment based on commercial web based technologies such as e.g. XML Java Web Services and the like.

The physics based simulation training layer may include components for instructor operator services IOS brief debrief exercise and resource management capabilities or the like. The functions of the IOS can include exercise planning objectives performance measures initialization monitoring controlling the progression After Action Review AAR of the exercise etc. For example the brief de brief capabilities may be utilized by the IOS to brief the training audience prior to the start of an exercise and de brief the training audience on the outcome of the exercise.

In a particularly preferred embodiment the IOS is an instructor station with a data entry interface and a display. From the IOS station an instructor can access physics based attributes of objects to initialize or modify the attributes of one or more aspects objects of the physics model during the exercise. Advantageously using a physics based approach in accordance with one aspect of the invention provides a more flexible and simpler approach to insertion of malfunctions and control of the distributed simulation. For example an instructor can access through the IOS station the physical attributes a support for an engine of a vehicle to cause it to break creating a custom designed training scenario.

Simulation applications can generally have two connections one connection to the physics farm through the physics farm communications backbone and another connection to the NGT infrastructure . The connection to the NGT infrastructure can be achieved by using an application bridge where the purpose of the bridge would be to preferably translate application specific representations data structures to a common NGT representation data structure.

Additionally gateways are employed to convert between disparate protocols and data structures e.g. DIS to HLA NGT to DIS to accommodate distributed simulations that may include legacy systems networks. Also the incorporation of commercial game engines is shown these engines having embedded i.e. tightly coupled physics engines into the distributed physics based simulation.

In the game engine server component is connected to the physics farm communications backbone and the individual game clients are connected to the game engine server most present day multiplayer gaming systems employ a client server network architecture . As discussed in more detail below the physics farm communications backbone is preferably optimized for physics based requests and callbacks facilitating communication of physics model state data between physics engines. Additionally one or more physics engines in the physics farm can be assigned responsibility of performing physics based computing processing for applications lacking their own physics engine.

The computer architecture of the simulation stations is schematically illustrated in . shows the physics networking and entity management approach employed in a preferred embodiment of the present invention. The physics engine utilized in computing the remote entity s state can either be a locally embedded tightly integrated physics engine or a loosely coupled physics engine that is allocated to the physics farm and managed by the physics farm manager. In two simulation applications e.g. simulation stations participate in a distributed interactive simulation by communicating across the physics communication backbone . The physics communications backbone is used to communicate or share physics based state data e.g. forces accelerations orientations collisions position etc. between physics based simulation applications . This backbone may be a communications protocol system using the network that allows communications between the physics engines.

In the preferred embodiment host processors system clocks are synchronized using e.g. the standard network time protocol NTP and time stamped physics based state data is preferably communicated over the physics communications backbone for each physics based entity.

Each simulation application preferably includes a local physics farm API interface and a physics manager . In certain simulation applications the physics engine may be embedded as depicted in the simulation applications . However as shown in and discussed in greater detail below the simulation application may include only a physics farm API and physics manager. In such an application without an embedded physics engine the application can use the physics farm to interact with the physics based environment. Specifically the physics manager can request and be allocated the services of one or more of the physics engines in the physics farm. In light of the fact that the physics engine may or may not be embedded the physics farm API is preferably configured to encapsulate both the physics manager and the physics engine since the physics manager should be capable of intercepting local changes to forces when they are applied.

As depicted in the illustrative example of the local physics manager e.g. notifies the remote physics manager e.g. of any new modified removed or deleted entities and vice versa. If a collision event is generated by the physics engine the physics manager uses the collision event as an indicator that corrective action may be required. If a collision event occurs for the local entity the local physics manager preferably sends only those new forces resulting from the collision event. Upon receipt of a collision indicator the receiving physics manager s preferably apply any needed corrections for the notifying remote entity. Through use of the physics based approach illustrated in extrapolation by dead reckoning is no longer necessary since the physics engine s are continuously applying forces acting upon remote entities.

The problems of dead reckoning extrapolation which has been used in past distributed systems to try to compensate for latency in the network are explained in . In the current approach of military simulations employing DIS protocols is illustrated. The participating simulation depicts a high fidelity dedicated simulator e.g. helicopter and includes a rendering engine and an engine to incorporate remote entities . Another participating simulation depicts an SAF application embodying a behaviors engine a vehicle dynamics engine and an engine to incorporate remote entities . The SAF application is a program that that models a vehicle or other entity such as a military unit that moves on its own. Each participating simulation etc. publishes or communicates its entity i.e. virtual object state e.g. position orientation linear velocity linear acceleration angular velocity etc. across the DIS network .

Each participating simulation etc. locally computes the position and orientation of the entity states of remote participating simulations until the next entity state update from the remote entity is received. The remote entity s state is computed locally using the remote entity engine by performing linear extrapolation known in the art as dead reckoning .

The basic idea underlying the use of dead reckoning algorithms is that rather than each and every entity sending frequent state updates each entity s remote entity engine estimates the location of the remote entities based on their last reported entity states. A dead reckoning algorithm is typically specified for each entity and each entity publishes its entire entity state only when its actual state differs from that predicted by the dead reckoning algorithm by some delta i.e. a threshold value is exceeded. As a result participating simulations render imagery displayed to their respective users based on the dead reckoned remote data for remote entities while using actual data for controlling ownship SAF vehicle dynamics . Moreover the SAF vehicle dynamics used in present day military simulations employ simplified kinematics models.

As can be seen in the use of dead reckoning algorithms i.e. linear extrapolation can result in inconsistencies between local and remote entities in representing the state of the simulation. This results from the fact that the actual position of a remote entity is typically not linear. As best shown in another problem is encountered in the dead reckoning method. Simply put the linear dead reckoning extrapolation can extrapolate the object to a location that it could not reach in reality such as the far side of a wall or other barrier.

The physics based approach according to the present invention does not use dead reckoning algorithms but instead specifies that each simulation application locally compute the entity state of physics based remote entities using a physics engine. The physics information for the moving object is received by the physics engine of the relevant simulator station and the movement of the object under the effect of the defined forces is projected taking into account the possible obstruction caused by other objects in the scene. This prevents any extrapolation through another object. The physics engine will determine the interaction of the objects and process the collision as an event but the object will not be extrapolated to an impossible location.

Physics based modeling readily provides for the detection of and the computation of resulting forces due to collision events. Since as discussed above dead reckoning is not used by the physics based approach of the present invention but instead simulation applications locally compute the state of each remote physics based entity collision events can be readily detected. Accordingly any resulting changes in the remote entity s physical state may also be readily computed.

Nonetheless collision events handled by the preferred physics based approach may also suffer from latency issues associated with network communications of physics based data.

As can be seen in at the point in time when the entity s actual state is received by the remote host the remote host would have already altered the state i.e. location of the remote entity based on its own physics based computations and potentially a few frames would have been generated during this latency lag period resulting in the object s position being calculated at point . The remote host then projects out in time some increment to compute the necessary corrections that must be applied in order to converge the remotely computed state of the entity with the entity s actual state. This corrective path illustrated in the graph is smoothed and timed so as to prevent corrective jerking of objects in the simulation.

Collision events in accordance with one aspect of the invention are preferably dealt with according to the following approach. Within the local simulation application based on the contact point of a force on a given entity e.g. box features etc. the constraint forces are computed and sent to the remote simulator s . Using the constraint forces transmitted by the local simulation application accelerations velocities and position can be computed within the remote simulators physics engine s . Preferably forces are only sent when they exceed a certain predetermined threshold value. For example if we assume that in a simulation for example there is an IED explosion that is an instantaneous impulse then the force is broadcast to all other simulators only one time. Advantageously this approach does not require the transmission of continuous updates reflecting position velocities and accelerations. Further complex extrapolation or dead reckoning computations are not needed.

As shown first at step contact points are determined using surface normals. Next in step the constraint forces are computed based on the determined contact points. Then at accelerations velocities and position are integrated to obtain a result in terms of current position of the object. The physics engine continuously carries out this computation at each time step for each physics based entity registered with the engine and the scene data of the object in the associated simulation station is updated based on the calculated position of the object.

1. For an entity i.e. virtual object hosted by simulation application i.e. an instance of a participating physics engine owning the entity simulation a collision is detected by the physics engine and reported to the local physics manager . Typical information reported includes e.g. entity ID colliding entity ID entity with which collision occurred collision position and collision time.

2. The physics engine also reports the same information to the local physics farm API which in turn passes the information along to the local simulation application for updating the local scene data to reflect the end location of the virtual object or entity.

3. The local physics manager broadcasts over the physics farm communications backbone information related to the collision event including e.g. entity ID colliding entity ID collision time and the new forces computed by the local physics engine as a result of the collision.

4. The remote physics manager s receives this information and uses the information to synchronize and de conflict the results broadcast by the simulation application responsible for the entity which was the subject of the collision with its own results that it has been computing simultaneously on its own physics engine.

5. The physics manager transmits the entity s position and other state data to the physics farm API of its simulator station to be passed on for incorporation into the scene data stored therein

When an object or entity ids created the event is broadcast over the physics farm backbone with a data packet containing the entity ID the entity type defining geometries and other physical attributes of the entity the time of creation in system time the initial position of the entity and the initial forces on the entity defined in the six degrees of freedom discussed above.

When a force is applied to an object sufficient to cause it to move above a threshold limit an applied force data record or packet is transmitted containing the entity ID receiving the force the time of the force and data defining the force in six degrees of freedom.

When a collision occurs a collision data or data packet is transmitted to the other physics engines over the physics farm backbone. The collision data includes the entity ID of the entity hitting another object the entity ID of the other object that is hit the time in system time the location of the collision and the forces resulting from the collision.

1. For an entity hosted by the local simulation application i.e. an instance of a participating physics engine owning the entity simulation the simulation application communicates to the local physics farm API a request to create an entity providing information such as e.g. kind of entity entity ID initial time initial position and initial forces.

2. The physics farm API in turn then communicates a request to the local physics engine to load the corresponding physics model with the given entity attributes position and forces and notify the local physics manager of the creation of the entity and its corresponding creation data.

3. The local physics manager broadcasts the creation of the entity and its associated creation data across the physics farm communications backbone .

4. The remote physics manager s receives the notification of the creation of the new entity on simulation application .

5. The remote physics manager s proceeds to instantiate the entity within its local physics engine i.e. instruct its own physics engine to load the physics model data for the new entity.

6. The remote physics engine then notifies the remote physics farm API of the creation of the new entity.

7. The remote physics farm API in turn notifies the remote simulation application of the creation of the entity.

1. The local simulation application communicates to the local physics farm API the request to apply a set of forces to an existing entity owned by that simulation application typical information included in the request might include e.g. entity ID and set of forces to be applied.

2. The local physics farm API then instructs the local physics engine to apply the forces and at the same time notifies the local physics manager of the request to apply the new set of forces.

3. The local physics manager in turn broadcasts the application of the new set of forces to the entity across the physics farm communications backbone .

4. The remote physics manager s receives the broadcast and communicates the information to the remote physics engine so that simulation of that remote entity can now be carried out using the new set of forces.

In the physics based system of the present invention frequent entity state updates and consequent frequent extrapolation by dead reckoning are not required. illustrates this with a side by side comparison of the current approach used in military DIS based simulations with the approach according to a preferred embodiment of the present invention. The left side of the diagram of depicts the local host activities and the right side depicts the remote host activities. In the upper half of the diagram depicts the current military DIS approach and in the lower portion depicts the approach according to a preferred embodiment of the present invention.

As can be seen from in the current military DIS approach the local host updates the actual position velocities and accelerations for a locally owned entity fairly frequently and then performs dead reckoning of the local entity to check for any excursions beyond the predefined threshold value. Only when the local dead reckoning computations exceed the predefined threshold value s does the local host broadcast an update across the DIS network. Updates are also broadcast upon the occurrence of a collision event. Therefore in the absence of entity updates the remote host continues to compute the entity s state based on the dead reckoning algorithms and needs to execute correction routines when an entity update is received i.e. when the local owning host determines that the dead reckoning computations no longer accurately represent the entity s state based on some predefined threshold tolerance value.

In contrast in the physics based approach of the present invention the local host does not perform any dead reckoning threshold computations and only updates the entity s state when forces have changed or when a collision event is detected. Similarly the remote host does not perform any dead reckoning extrapolation of the local entity s state since it has the same physics model of the entity loaded and is simulating its behavior based on the same set of applied forces and collision events.

Modeling of the ownship for vehicle simulator stations has in the past usually used scripts triggered by events or the instructor and these provide limited scenarios for training. According to the preferred embodiment of the invention however the simulation station has a detailed physics based model made up of the entities that together form the user s ownship. As such the physics engine at the simulation station is preferably used to perform physics processing on the constituent parts of the vehicle being simulated. The result is that the physics engine provides a realistic and very flexible simulation of the dynamic operation of the vehicle. Component parts may be damaged by other entities in the virtual world or influenced by an IOS command entered for training purposes in which case the physics engine causes the vehicle in simulation to perform or fail similarly to the real vehicle with a similar type of damage.

The simulation based on physics processing of the virtual entity model of the ownship may also be used to supply simulated data to the simulator cockpit or control panel such as in an aircraft providing data defining an artificial horizon or altimeter gauge.

In addition the physics engine of the simulation station generates force or collision data reports in the processing of the ownship constituent entities or virtual objects. That physics data is published as events on the physics farm backbone to the other physics engines which use the force or collision data to update their associated copy of the world physics data which includes the constituent entities that make up the ownship of each simulator station in the system. As a result not only is the physics data for the ownship components used for simulating operation at the associated simulator station but it is also used to render the views that other users on the system have of the vehicle. Because these views correspond exactly except for any latency issues with the exact operational simulation of the vehicle reality of the scene is enhanced as well.

In a dedicated high fidelity simulator representation e.g. a helicopter flight simulator is participating in a distributed physics based simulation with a more traditional SAF application. The simulator includes its own rendering engine a physics farm API a physics manager and an embedded physics engine . A simplified representation of an SAF application is also depicted.

The SAF application includes an SAF physics API a physics farm API and a physics manager . A simplified representation of an intelligent behaviors application is also shown having an artificial intelligence AI physics API physics farm API and a physics manager .

In generic form any simulation application can be adapted to work with the physics based network not only simply participating but also using the physics based processing to govern the behavior of entities hosted by its own simulation. For example a physics farm application component can include an SAF physics manager application an intelligent behaviors physics manager application an environment manager application or vehicle physics manager application.

In order to effectively participate communicate and utilize physics farm resources the physics farm application component application includes a physics farm API a physics manager and a physics engine . Alternatively the physics farm application component does not include its own embedded physics engine not shown but instead uses a physics engine in the physics farm either a tightly or loosely coupled physics engine available as a pooled resource. Another component includes a physics manager application for managing the resources of the physics farm. The physics manager application includes a physics farm API to communicate and manage the physics farm components.

One possible data format for the physics resource request might include request type database requirements entity count etc. The physics manager application would then communicate over the physics farm communications backbone to the newly participating physics manager the results of the physics resource request i.e. assign resources . For example in assigning resources the physics manager application might assign provide the newly participating physics manager an ID database multicast address etc. Similarly when the physics manager departs or ceases participation the physics manager application would release the resources previously assigned. A database would preferably include scene data including e.g. models entity attributes etc.

The physics manager application preferably includes scene manager capabilities for maintaining attributes and states of participating physics managers . The participating physics manager then communicates with the physics engine either assigned from the pooled resources or embedded and provide it with relevant information regarding the simulation which it just joined e.g. provide the physics engine with the relevant scene data and model s to load. The physics engine could load more than a single scene. Scenes could appear as interacting scenes or they could be independent scenes wherein objects in one scene do not interact with objects in another scene.

In one embodiment the physics manager application could manage resources as depicted in which illustrates a physics manager application communicating with physics farm components over the physics farm communications backbone . Each physics farm resource available for allocation i.e. a physics farm component would include a physics manager and a physics engine . In the embodiment of the physics manager application preferably creates multicast groups and assigns participating physics managers to one or more multicast groups preferably multicast group assignments are implemented so as to optimize network efficiency and or to improve simulation performance.

Also in the embodiment shown in the simulation world is divided into areas where each area represents a portion of the simulation database loaded into a physics engine. The areas could be assigned by the physics manager application to the physics farm resources based on any one of a number of factors. Preferably areas are assigned to physics farm resources so as to optimize computational and network performance of the distributed simulation. The areas preferably overlap with adjoining areas of the simulation world so as to support effectively handing off responsibility for simulation entities as they transition from one area under the ownership of a particular physics engine to another area under the ownership of a separate physics engine.

The physics manager application receives the registration requests over the communications backbone and issues acknowledgements to the requesting physics managers confirming registration. Once registered the physics farm API can issue a request to the physics manager to initialize the environment and the physics manager in turn broadcasts the request over the communications backbone to the physics manager application . The physics manager application then allocates the necessary resources to accommodate the request broadcasting the allocated resources e.g. ID capabilities etc. over the communications backbone to the requesting physics manager . Utilization of the allocated resource can then proceed.

According to another aspect of the invention the errors differences inconsistencies conflicts etc. that can exist among the individual participating simulation applications are further reduced or eliminated by avoiding coordinate conversions in the computations that are most sensitive to slight variations.

As shown in the current approach using the DIS protocols network requires that all traffic across the network utilize the Geocentric Coordinates GCC . As a result each simulator application despite the coordinate system being used locally in the local simulator application must be converted to GCC when broadcast across the network. The receiving simulator applications then have to convert from GCC into whatever local coordinate system that particular receiving simulator application was using for its computations. This is required even if the receiving simulator application was using the same coordinate system as the remote sending simulator application.

As can be seen by the different positions of the rendered entities in each of the simulators in errors in position can result in inconsistent detection or results of collisions. Similarly differences in line of sight LOS may exist due to inconsistencies in the different scene data which impacts fair fight because as an example entity has a LOS on entity in simulator but in simulator entity does not have a LOS on entity .

According to one embodiment of the present invention conversions are eliminated between physics engine managers as they would each be operating in the same global coordinate system. The only point at which conversion to a simulator s local coordinate system might be required is when communicating between the physics engine and the associated simulator no conversion is required when a physics engine manager communicates across the physics farm communications backbone with the rest of the physics engines. In such an embodiment physics engines and physics managers are operating in a common coordinate system thereby eliminating errors due to conversion in the physical representations of entities in local and remote simulators. More specifically only rendering in the local simulator can be affected by conversion errors while the physics calculations which are inherently more sensitive to differences due for example to the effects of slight errors on collisions or lines of sight do not experience this issue because all of the physics engines use the same coordinate system.

In the prior art SAF entities are used to fill in the battle space with friendly neutral and opposing forces. SAF forces in prior art systems are generally controlled as simple kinematical models primarily to reduce computational loads. As a result the SAF entities of the prior art are not influenced by physics based forces and the result is that the SAP entities lack realism. According to the invention however an SAF application relies on the physics farm to allow for additional functionality of SAF entities as for example to allow for the SAF forces to influence and be affected by physics based events.

The physics backbone is linked with SAF computer system which supports thereon an SAF application. Using the current military approach employing the standard DIS protocols SAF behaviors are bundled with vehicle dynamics where the vehicle dynamics are based upon kinematics new positions computed for each frame and the SAF behaviors are based upon defined echelon hierarchy and standard military doctrine.

The SAF application is divided into two separate applications the SAF Physics Manager Application the native application and a separate SAF behaviors application . Each application has a respective interface with the physics farm via entity management APIs and and Physics Farm APIs and . These APIs communicate with a respective physics manager and for each SAF application. The physics manager integrates the SAF requests from the SAF applications with a physics engine and provides feedback to the SAF physics manager application or the SAF behaviors application.

The requests of the SAF applications result in creation or movement of physics based entities in the virtual world and those entities can affect users or the simulated environment based on the physics based interaction of entities discussed above e.g. SAF forces may be able to shoot to put weight on objects and cause them to fall or to engage in any kind of activity that produces force on the entities in the virtual world. In addition the SAF entities can be the recipients of forces that affect them and that alter their conduct based on their strategic rules.

According to the preferred embodiment behaviors are separated from vehicle dynamics requiring position data feedback to the SAF behaviors application only when the SAF directed request is complete the request is interrupted or a collision occurs. As can be seen the proposed entity management protocol and entity management API permit the SAF behaviors to be separated from vehicle modeling. Additionally the entity management protocol provides mechanisms for SAF behaviors to direct the movement of physics based vehicle models. The SAF physics manager is configured to integrate SAF requests from the SAF application with the physics engine and for providing feedback callback routines.

The data flow of the physics interface with the SAF application is schematically illustrated in . A simple message protocol is used as the interface between the physics engine interface and SAP application and the messages are transmitted via multicast socket.

During the creation of SAF entities the SAF application sends out data indicative of the initial position orientation and entity type to the physics engine interface for those entities that will be modeled in the physics engine. Based on the entity data received the physics engine interface then creates a physics model in the physics engine for each SAF entity so that it begins to exist in the simulated environment.

The SAF application periodically sends an update to the physics engine interface to update the physics models of the SAF entities.

When the physics models of the SAF entities interact with other objects in the virtual environment creating a collision in the physics engine any position orientation and velocity changes to the physics models of the SAF entity involved is sent back to the SAF application which updates its corresponding entity based on the updated position orientation and velocity.

Behavior of the SAF entities in the simulated environment follows the behavior of the corresponding entity defined in the SAF application and processed therein. Complex SAF behaviors resulting in realistic interactions with the physics based simulation are made possible by this interface.

The demonstrator provided higher fidelity models increased quantities of vehicles and new dynamic cultural features. In addition to the inclusion of vehicle models dynamic cultural features were incorporated into the simulation by loading cultural feature models into the physics engine. This allowed for interactions between the cultural features and vehicles in the simulation. For example using the physics based approach a vehicle was now able to push a barrel out of the way with both the barrel and the vehicle responding in a realistic manner to the forces generated by the interaction.

The key components in the example shown in included a physics engine a Semi Automated Forces SAF application supported in an Aviation Combined Arms Tactical Trainer AVCATT a dynamic environmental model for cultural features intelligent behaviors and an NGT bridge .

The physics engine used in the demonstrator of was a commercially available software product that provides a software development kit SDK and algorithms for modeling a physics based virtual world. Objects in the physics engine can be created attributed and registered with the physics engine. The physics engine s algorithms can either be implemented in software or hardware via a PPU.

The legacy based AVCATT SAF application was adapted to work in the physics based proof of concept demonstrator by first removing the existing dynamic models from the behaviors that direct the movement of the vehicles. In particular the SAF helicopter and wheeled vehicle models were replaced with helicopter and wheeled vehicle models developed using the physics engine SDK and registered executed on the physics engine .

As adapted the SAF behavioral commands e.g. move directed to the vehicle dynamics are sent to the dynamic models hosted on the physics engine and the results or progress are is sent back to the SAF behavioral logic to continue reasoning in accordance with the behavioral artificial intelligence implemented in the SAF application . In accordance with a preferred embodiment of the present invention the SAF application sent the physics engine the type of model to be created e.g. helicopter wheeled vehicle etc. along with its required attributes such as mass inertias dimensions etc.

Once the model is instantiated and registered with the physics engine the SAF application directs the physics based model behavior e.g. directs it to move . Preferably position updates are periodically sent from the physics engine to the SAF application . In order to enable the SAF application to direct requests and receive results from the physics engine hosting the physics based objects entities e.g. helicopter wheeled based vehicle etc. the demonstrator utilized communications protocols message formats and APIs developed to process SAF application requests and communicate results in accordance with a preferred embodiment of the present invention the details of which or discussed in greater detail below.

In addition to the physics based dynamic models i.e. helicopter wheel based vehicle etc. that are directed by the SAF application cultural feature objects e.g. dynamic buildings can be created and registered on the physics engine by the dynamic environmental model . Advantageously the cultural feature objects e.g. barrels crates boxes barricades and the like can be seamlessly integrated into the environment and will interact with other physics based objects such as helicopters ground vehicles life forms etc. The dynamic buildings may be assembled from objects that interact with the physics environment individually and can break apart based on forces being applied as opposed to scripted events. The forces can be generated by explosive detonations impacts from other dynamic objects etc.

Life form behaviors have traditionally consisted of virtual representations of people participating in a simulation. The intelligent behaviors component can model life forms using a physics based approach so that the life forms may be treated like other dynamic objects such as air or ground vehicles. In accordance with a preferred embodiment of the present invention feedback mechanism would be required to communicate requests and to receive results of the effects of forces from the physics engine that computes the physics based interactions operations.

In order to interface the physics engine with other more traditional simulations based on the DIS protocols an NGT bridge as discussed above was employed. The NGT bridge enabled entities modeled by simulations external to the physics engine application to be incorporated injected into the physics based environment these external simulations are preferably injected as kinematics objects since their motion behavior is governed by external forces. Accordingly according to a preferred embodiment of the present invention entities natively modeled by the physics engine would be distributed to the external simulations using the DIS protocols.

The system as described so far provides some substantial advantages. However three potential problems should be addressed when using physics coprocessors to simulate objects in a distributed environment. One is the problem of network latency. A second problem arises from the fact that multiple physics engines that have been provided with identical initial conditions will over time inevitably provide solutions that diverge from each other. The third potential issue is that objects in the physics environment will interact with other objects in the virtual environment and may move in a manner not intended by the controlling simulation. For example a computer controlled vehicle may be influenced or damaged by a collision created by latency and move in an erratic unintended path in certain of the simulations affected by that latency.

These problems can be addressed using periodic positional updates that allow the various simulator systems to synch up and match their respective versions of the scene data of the virtual world. Although this is workable the periodic positional updates consume network bandwidth and computer processing resources in proportion to the number of simulated objects. This bandwidth demand makes it increasingly difficult to perform distributed simulation exercises that include thousands of objects which means that it is less practical to attempt exercises with the tens of thousands of objects desired for certain virtual environments such as dense urban scenarios.

Referring to a system of master and slave synchronizers or controllers is provided that may be used with the physics based system of the invention to enhance the synchronization of the system of the invention with less of a bandwidth load. This system implements an approach to distributing simulated objects across networks simulations that reduces the impact of network latency and also allows for a much larger number of objects in the virtual environment without a concomitant consumption of network bandwidth and computational resources. The system also preferably relies on physics coprocessors and or the physics farm discussed above for the associated control of objects simulated in the virtual environment of the simulation as will be described below.

The system comprises a plurality of simulation stations which are simulation systems similar to systems as discussed above with respect to . The system also includes one or more client entity or object simulation computer systems which are computer systems such as SAF controlling computer systems discussed above. The simulation stations and simulation computer systems are connected via a network which is preferably the network of the system of e.g. the Internet or a WAN. Only two simulation stations and one simulation computer system are shown in for illustration purposes but the system preferably encompasses a substantial number of each type of station or to support a number of trainees and also a relatively large number of computer controlled client objects to enhance realism of the simulation.

The simulation computer systems are systems that control the behavior of client objects in the virtual world of the simulation particularly SAF entities such as enemy forces vehicles or weapon systems the simulation of which is discussed above and illustrated in e.g. . Essentially each simulation computer system is a computer system with a connection or access to a data storage device storing a respective version of the simulation scene data. A behavior software application runs on the computer system and determines based at least in part on the scene data the behavior of the client objects e.g. SAFs or intelligent entities assigned to that system .

Generally the behavior is movement of the simulated client entity or object but may include any sort of self actuated or reactive behavior as discussed above and is well known in the simulation art. For example the behavior can include behaviors such as e.g. a device exploding usually expressed as extremely high speed movement of the discrete parts of the exploding object .

Within the behaviors appropriate to the client object the behavior is calculated by the behavior application software so as to yield behavior data defining the behavior. Because the behavior data is usually data defining an intended projected path or movement of the client object the behavior data for most objects simulated especially vehicles or simulated humans constitutes client route data.

In the preferred embodiment the client route data includes at least a desired speed one or more route points defining the route that the client object is to pass through in the movement a desired ETA at the end of a route and an append flag.

The route points are preferably two or three dimensionally expressed points in a client coordinate system. Where the client object is one that moves along the ground in the virtual simulation such as a vehicle an animal or a walking person the coordinates can be two dimensional because the client object moves in two dimensions with the vertical movement of the client controlled by the height of the terrain it is situated on. Where the client object is one that is able to initiate its own movement in three dimensions such as a submarine a fish a helicopter or a bird then the route is expressed in three dimensionally defined points.

The ETA is expressed using a system wide time clock system such as the system wide network time protocol NTP . From the standpoint of the master synchronizer the ETA defines a future point in time by which the client object should reach the point at the end of the defined route. In addition data defining an ETA for intermediate points along the defined route may also be provided in the client route data.

The append flag is a flag of data that is set to indicate whether the route being requested is to be appended to the existing route for the client object or if the new route is intended to simply replace the current route for the client object.

The behavior or client route data from the behavior application passes or is otherwise communicated to master synchronizer or controller application software which preferably also runs on simulation computer system . The master synchronizer receives the behavior data and based thereon handles the creation of the virtual components of the simulated client object within the physics engines as well as the low level control and synchronization of the object within the distributed environment.

Each client object simulated within the physics environment has one and only one master synchronizer that communicates with the application that is simulating the client object. Client behavior application provides behavior or client route data to the associated master synchronizer . Distributed control and synchronization of the client entity or object over the system is then accomplished using synchronizers in a master slave relationship as shown in .

The synchronizer route data for a client object is derived from the behavior or client route data received by the master synchronizer and is configured for distribution over the network. Generally the synchronizer route data typically includes data defining a goal and a start time. The data defining the goal may be a destination point or it may be data that defines a route and a desired speed that the client object is to proceed along the route or it may be another combination of data defining some time dependent locations and or orientations for the client object. For example the synchronizer route data may contain data defining a route and an ETA at an endpoint of the route i.e. a point in time that is at least a short time in the future from the standpoint of the master synchronizer at which it is desired that the client object reach the endpoint of the route.

The synchronizer route data according to the preferred embodiment also includes an append flag indicating on or off whether the route transmitted is to be appended to the currently in place route or if it should replace the current route.

Where the goal is defined using one or more route points the points are preferably are defined in two or three dimensions depending on whether the object is capable of flight or simply surface movement and are preferably x y z or x y points in the internal coordinate system of the physics environment data accessed by the physics engines. In addition duplicate points and small route segments in the behavior data both of which represent unnecessarily transmitted data are removed.

While there is one and only one master synchronizer for each client object in the virtual world of the simulation the master synchronizer spawns in each simulator station computer system to which the simulated entity or client object is relevant creation of a respective slave synchronizer for that station s physics environment. As a result for each client object relevant to the simulator station there is a respective instance of the slave synchronizer program that controls the client object. Master synchronizer transmits synchronizer behavior or route data for the associated client object over the network to slave synchronizers at the various distributed simulation stations .

At each simulation station the slave synchronizer receives the synchronization route data and interacts with the physics engine of that station to cause the client object to follow the directed route in the stored physics based environment so that in the associated simulator system the client object meets the goal or goals specified by the synchronization route data within the specified time or time dependent constraints. The slave synchronizer is preferably a software program running on the computer system of the simulation station and one copy of the program runs on each simulation station in which the client object is relevant to the local simulation. The physics engines of the simulation stations are preferably connected as parts of the physics backbone discussed above exchanging physics data over the system as discussed above with physics management software running on the simulation system assigning the responsibility for physics of the objects as has been set out previously herein.

The local slave synchronizer program receives the synchronizer data as input from a link to the network and controls movement of the client object in the local physics environment simulation by passing or transmitting to the physics engine physics data reflecting appropriate forces to be applied to the client object or to its component virtual objects e.g. the drive wheels of a vehicle or the parts of an exploding device that will cause the client object to move to reach the goal at the appropriate time. The physics engine in turn calculates the solution of the physical forces introduced that reflects the consequences under the internally define physical laws of the physics engine of the forces from the slave synchronizer and any other synchronizers in the station meaning changes in location or orientation or velocity of one or more objects in the virtual scene. The physics engine modifies the physics data stored therewith and aspects of the physics data i.e. the new locations of objects in the virtual scene are passed or moved to be incorporated in the scene data stored at the station similarly to the procedure described above. The image generator accesses the scene data or data derived renders imagery from the scene data which is then displayed to the user at the simulation station at whatever display device is associated with the station . In addition the slave synchronizer accesses the scene data to determine the updated location of the client object after the physics data transmitted to the physics engine is implemented in the virtual environment as will be expanded upon below.

A key aspect of the synchronizer system is that the local slave synchronizer has direct access to the client object as it is modeled within the local physics environment and can therefore provide tightly coupled high frequency control of the physical model used at the simulation station . Due to this local control the simulating application does not need to attempt to provide this high frequency control across the network.

Master synchronizer in this illustration is part of a server without an image generator or viewer. However the master synchronizer may be on a system such as stations that has a physics engine and image generator. In that case the master synchronizer transmits force data to the physics engine which calculates the effect of the force data on objects in the scene according to its internal physical rules resulting in a modification of its internal physics data defining the world. The changes to the physics data of the physics engine are transmitted to the local computer system of the station and the scene data used to generate the imagery on the simulator display is updated and the local image generator displays the modified virtual world based on the physics data.

In addition as will be expanded on below the client computer system that is running the slave synchronizer is configured to under the appropriate conditions to load appropriate software and become the host computer that runs the master synchronizer for a virtual object.

The behavior applications of the system determine the timing and route of movement for the associated client object according to the type of object it is.

Generally there are two classes of simulated client objects and associated synchronizer algorithms that are the basis of most synchronizer implementations 1 simulated objects that exhibit behavior and 2 simulated objects that do not exhibit behavior. Examples of objects that exhibit behavior are vehicles and personnel. These objects generally conduct themselves with a purpose and toward the achievement of a goal. Examples of objects that do not exhibit behavior are buildings or shipping crates. Objects such as those tend to remain in their initial state unless acted upon by some external force.

Synchronizers for objects that exhibit behavior implement algorithms with two characteristics. First a deterministic algorithm defines the immediate goal of the object behavior. Second a closed loop control algorithm that understands the nature of the physical model drives it toward the immediate goal. This provides the advantage that once the goals relevant time parameters for the goal and a start time have been communicated between master and slave synchronizers no further network communication is necessary for the objects to achieve their goals and to remain in synchronization. Network latency ceases to be an issue because the deterministic goals allow the objects to move without constant control over a latency affected communications link.

The closed loop control solves the possible issue of divergent physics engine solutions at different simulation stations that could result if left to run under open loop control. The closed loop control also addresses the possibility that an object in the local physics environment may not follow the path that the controlling simulation intended. The closed loop control quickly corrects any perturbation from the intended path due to interactions with other objects within the local physics environment.

Generally expressed the slave synchronizer operates according to a closed loop to cause the client object to achieve the goal at the correct time. In the closed loop the slayer synchronizer receives the route data and derives from that data a current set of physics data for the client object configured to cause the client object to advance toward the goal and that data is passed to the physics engine which implements the physics data for the client object in the virtual physics environment data according to the physics rules resulting in change of the scene data. The scene data is also accessed by the slave synchronizer which calculates a new set of physics data based on the updated position of the client object in the scene data and on the most recent route data that has been received from the master synchronizer and new physics data is derived for the client object to cause it to reach the currently specified goal at the currently specified time. This new physics data is passed to the physics engine and the scene data is again updated. The cycle is completed within the duty cycle for the image generator in refreshing the rendered video images displayed to the user at the simulation station e.g. 1 Hz and is preferably substantially faster.

The slave synchronizer at station performs a process in which a determination is made whether there is a conflict in the physics based environment preventing or delaying the client object moving according to the desired synchronizer route data and where there is such a conflict the synchronizer adjusts its physics data for the client object to compensate for the obstruction or delay to try to cause the client object to reach the goal point at the appropriate time.

According to the preferred embodiment at each cycle of the slave synchronizer a calculation derives the appropriate point in the virtual world where the client object should be if proceeding along the identified route at the prescribed rate and with the directed starting time. This is compared with the current actual virtual location of the object according to the scene data. The difference is used to compute appropriate physics data that is configured to cause the client object to accelerate or decelerate if it is moving too fast for the rate and to get the client object on to the route if it has gone off the prescribed route.

Operation of the synchronizer system of the preferred embodiment is illustrated by an example shown in .

At time t the local slave synchronizer determines that the client vehicle has been delayed and has not yet reached point B as directed by the synchronization data. The local slave synchronizer therefore acts on the physics engine of the station to accelerate the client vehicle i.e. increasing the forces moving the vehicle forward or increasing torque on the drive wheels of the vehicle after tso that the vehicle can make up for the delay.

At time t the vehicle in the example is not yet at point C where it should be so further acceleration up to an appropriate limit for the simulated vehicle is applied to the vehicle . At time t however the vehicle being simulated has not yet within the physics rules constraints of the physics eng been able to reach the scheduled point D. The slave synchronizer applies further acceleration as permitted by the simulated vehicle constraints stored therein and gets the rate of the vehicle above the appointed rate so that the vehicle reaches the endpoint of the route E at the proper point in time t. As a result of these accelerations the vehicle proceeds at a higher rate along the route segments CD and DE than originally scheduled by the synchronization data illustrated in .

Where the client object is a vehicle the slave synchronizer applies the control loop and method diagrammatically expressed in to control its movement. This illustration is expressed in analog format but the preferred embodiment implements to the logic of the diagram using software recorded on a computer accessible data storage medium and operating on a digital computer at the simulation station which computer may share in other activities e.g. providing the communication link of the physics engine with the physics backbone or the local portion of physics management of the physics farm.

In this specific vehicle application the slave synchronizer receives or calculates for a route two values the distance from the next goal point e.g. as in the appropriate point on the route for the current time indicated at line and the rate at which the vehicle is to proceed to reach that endpoint at the point in time prescribed by the behavior application indicated at line . The distance to goal is then scaled by control gain or constant calculation Kto yield a data value scaled to the data value of the desired speed which is actually a distance value for a unit of time such as the duty cycle. These two values are compared at comparator to yield a difference value i.e. a speed value indicative of the rate needed to reach the goal point at the appropriate time. This speed value is further scaled by control gain or constant calculation Kto yield a commanded speed . This commanded speed is compared by comparator with the current vehicle speed line to yield after control gain or constant calculation K a difference value corresponding to a commanded acceleration . Commanded acceleration is compared with current vehicle acceleration at comparator to yield a data value that is integrated in step to produce a data value indicating drive wheel torque to be applied to the drive wheel or wheels of the vehicle which are physically modeled in the physics environment data as independent parts of the vehicle. The drive wheel torque data value is processed by a physics drive wheel model which is configured to determine the specific data values to be defined for application via the physics engine to the physics of the client vehicle i.e. the vehicle speed and the vehicle acceleration . These data values are then implemented in the physics engine so that the client vehicle accelerates or decelerates to reach the indicated goal point at the correct time. The data values are also looped back and the desired acceleration is re calculated for the next cycle of the loop.

To keep the vehicle on the defined route of the synchronization data or on a revised route created by the slave synchronizer to avoid an obstacle on the route the steering direction of the client vehicle is also controlled in the slave synchronizer by a closed loop. illustrates the operation of this aspect of the slave synchronizer which is also implemented in the preferred embodiment in software recorded on a computer accessible data storage medium and running on a digital computer system.

In the process disclosed data defining the route segment heading meaning data defining the direction that the client vehicle is to follow according to the route defined by the associated behavior application is combined with a data value derived from a control gain of a determination of the distance of the client vehicle perpendicularly from the route by comparator to yield a data value corresponding to a desired heading for the vehicle to follow the route. This desired heading is compared with the current vehicle heading at comparator to yield the raw steering command . This data value is limited to a permitted range of steering directions to yield a data value corresponding to a final steering command which is processed by a physics steering model . The physics steering model generates a vehicle heading data value which is implemented in the physics engine. The implementation may correspond as illustrated to turning the independently modeled steering wheels of the client vehicle with resulting movement of the vehicle being guided thereby according to the laws of the physics environment. The heading is also looped back and the desired heading is re calculated yielding a new steering command for the next cycle of the loop.

Analogous control loop processes i.e. speed and direction can be used to control movement of virtually any client entity in the virtual environment of the simulation.

Life forms such as human beings are modeled in the physics world as a column supported on a wheel for purposes of movement. The column is configured as always vertical so there is no balance involved in the movement of the life form. The scene data associated with the life form however is a more realistic detailed image of the person or animal that reflects its position as defined by the physics environments data but has the other visible attributes of the life form e.g. head legs arms clothing fur etc. The speed of movement of the life form is controlled as above for a wheeled vehicle with the drive wheel being the wheel of the physics model. The direction of movement of the life form is controlled by applying rotational speed and acceleration about the vertical axis.

The method illustrated in preferably implemented in software as discussed above uses a joystick input for the life form as when an instructor controls a SAF movement in the virtual world. The joystick input is passed through control gain Kto yield a desired angular velocity which is compared with the actual angular velocity value of the life form from the last command to the physics engine to yield a difference value that is passed through control gain K to yield the desired angular acceleration . This desired angular acceleration is compared with the actual angular acceleration value of the life form from the last command to the physics engine and is integrated to yield a value representing body torque to be applied to the life form model column. This body torque value is used by a physics life form model to yield an angular velocity value and an angular acceleration value which are sent to the physics engine and implemented in the scene data. These values are also returned and used for comparison as actual values and .

Where the control of the life form is by a software application running on a simulation computer system and not by human input as by a joystick a similar process of control loop is employed but where a desired angular rotation and velocity are calculated by the slave synchronizer using the synchronizer route data. A comparison of the desired heading and the desired rate are made as with the vehicle above and are implemented similarly to keep the life form on route and on schedule per the synchronizer route data.

Human input controlling entities in the physics based environment is normally accomplished by input from an instructor station equipped with an input such as a joystick and a display showing the virtual environment to the instructor. Instructor control of virtual entities is not limited to SAF entities or life forms. The instructor can assume control of any virtual entity in simulation where that entity is capable of movement. Furthermore the compute system local to the instructor will become the system that supports and hosts the master synchronizer for the object until the instructor relinquishes control.

A simple example of one of the potential problems that can be encountered with the physics engine system e.g. differing physics based conflicts among the distributed simulation systems is illustrated in .

Referring to the exemplary virtual world includes two objects a SAP vehicle that according to its associated behavior application is instructed to proceed immediately to point A and a virtual object that is being propelled by some force to move to point B. In the example here shown both of these movements are to occur in roughly the same time window in the overall system simulation. However if the instructions to objects and are delayed differently at different simulation stations due to a latency then the results may be divergent.

As best seen in according to this illustration in a system without the synchronization here described at station the vehicle in station leaves at t while the block starts moving at t reaching an obstructing or blocking position at t 1 . The vehicle meets the block at t 3 well after the block has arrived and is prevented by the physics rules from proceeding to point A as directed because of a conflict with the block

On the other hand at station the latency delays block but not vehicle . Vehicle starts out on its route at t but at station due to latency block does not start to move until t 1 only reaching its position blocking the route at t 2 . By that time of t 2 however the vehicle has already passed the location of the obstruction and proceeds to point A without obstruction as directed.

As a result the scene data defining the two virtual worlds of station and station reflect two divergent solutions one in which the vehicle gets to A and the other in which the vehicle is obstructed by the block and never reaches point A.

Where the master slave synchronizer system is applied to the systems of the illustration in this problem of divergent solutions is avoided. The master synchronizer for the vehicle transmits synchronizer data to the slave synchronizers at stations and that directs the vehicle to proceed to point A and that includes data defining a start time tfor the movement defining the route by coordinates of at least point A defining a rate of travel along the route certain rate so that vehicle arrives at point A by a certain point in time e.g. t x and optionally defining the specific desired ETA t x at point A.

At station the slave synchronizer transmits or passes physics data for the vehicle to the physics engine at that station that causes the physics engine to move the vehicle or its constituent virtual parts in the physics environment data at an appropriate rate and reach A at the appropriate time. Due to the latency delay in the start of the movement of block by the time that the block arrives at an obstructing position the vehicle has already passed the obstructed part of the route to A. The vehicle proceeds to point A by t x at the specified rate along the route. Because there is no conflict with the block the movement is essentially the same as the movement of the vehicle at station in .

At station in contrast due to latency in the communication of the desired vehicle movement the vehicle starts moving but due to the absence of latency for the block at station the block arrives quickly enough to block the route of the vehicle to A resulting in the conflict as illustrated in . This is implemented in the scene data and rendered by the image generator and the user at station sees the contact of the vehicle with the obstruction on his simulator display if it is part of his appropriate view of the virtual world.

In the next cycle of the local slave synchronizer of station the local slave synchronizer compares the obstructed position of the vehicle against the block to the position in which the vehicle is scheduled to be in based on the start time and the rate data values from the synchronizer data on the other side of the obstruction . Based on the determination that the vehicle is delayed the closed loop control of the synchronizer transmits physics data to the physics engine to move faster. This will result in an increase of force from the vehicle pushing in the physics environment on the obstruction

If the vehicle is able to generate enough force pursuant to its model in the local synchronizer it will eventually push the block out of the way. The result of the pushing is resolved by the physics of the conflict e.g. by how heavy the virtual object is supposed to be in the simulation. Ultimately there are three possible outcomes the block is pushed out of the way there is a deflection of the vehicle from the route or the vehicle is obstructed.

Where the block is simply pushed out of the way to the extent that the block has delayed the vehicle the vehicle will push the block out of the route and then accelerate to reach the goal point A by the prescribed time.

Where the block is partially pushed out of the way but the vehicle is deflected from the route a similar result will follow the steering control loop of the synchronizer will guide the vehicle back to the route and the vehicle will accelerate to the goal point A to get there in time.

In either of these two cases the physics farm will subsequently resolve the position of the blocks and and of the block in any other simulation stations across the system to conform to a single position in the virtual physics environment and the virtual world defined by the scene data by a positional update over the entire simulation system. As a result after a short period the solutions of stations and will not be divergent if the vehicle can push the block out of the way in its route.

In contrast where the vehicle is obstructed and unable to push through the block a different remedial action is taken by the synchronizer to ensure that the vehicle arrives at the goal point at the appropriate time. The inability of the vehicle as modeled to generate enough force to move the obstruction out of the way will result in a delay that will continue for a period of time with the vehicle effectively obstructed by the block . The synchronizer in this situation determines that a delay has been created that is not remedied by acceleration of the client object.

The determination of obstruction may be made in a number of ways. For one when the client object should be moving but its rate of movement is zero or below a predetermined threshold value for a single cycle or for a time period that is longer than a predetermined time period or a threshold number of cycles of the synchronizer loop it is concluded that the client object is obstructed. Alternatively the conflict may be determined based purely on the contact event and an analysis thereof.

In a further alternate embodiment the determination of obstruction may be accomplished by extrapolating the route of the vehicle ahead by one two or more duty cycles of the slave synchronizer and noting if there is any obstruction thereof in the physics engine without permitting the scene data to be modified until the actual intended movement is determined.

Whatever the way the conflict is detected responsive to the determination of the obstruction of the route synchronizer takes remedial action to ensure that the vehicle reaches point A in time.

One possible type of remedial action is accomplished by the synchronizer by causing the client object to move in reverse for a short period e.g. a duty cycle of the synchronizer to disengage from the obstruction and then extrapolating a new path of movement for the vehicle that circumvents the obstruction. This new path identified by reference character allows for the vehicle to proceed to point A circumventing the blockage of the originally intended path and then rejoins the original route after the obstruction as illustrated at . The new path is determined based on the scene data defining the object that obstructed the route and simply extending a route around the object that meets the original route on the other side of the obstructing object by any route planning program known to those of skill in the art.

A similar action may be taken where the obstruction is detected by projection of the client object route without moving the client object in reverse to disengage from the obstruction. This is done by the slave synchronizer itself as opposed to determining a conflict using the physics engine. The slave synchronizer accesses data stored at its client system that defines the locations of objects in the virtual environment e.g. the local physics data or object state data and determines if any obstructions are in the path of the client object. Responsive to a determination of the presence of an obstruction on the route a new route is prepared that avoids the obstruction and allows the client object to reach its goal point in time. The route is prepared using any of a number of route making algorithms as are well known in the art.

As another alternative or as a second option where an unobstructed alternate route such as that of cannot be found by the slave synchronizer the synchronizer may direct the physics engine to suspend the physical rules that create the obstructing conflict. As a result the obstructing effect of the intervening object e.g. block disappears which allows the vehicle to proceed to point A as if there were no block of the route. This is illustrated in . Vehicle simply proceeds to point A without regard to the presence of block . In the image generator output which is based on scene data derived frame by frame from the physics data including the position of the vehicle the result will appear to violate the laws of physics somewhat in that the vehicle goes straight through the obstruction but this brief appearance of unrealistic imagery is preferable to the greater problem of diverging virtual environments. This suspension of the physics rules may be applied only when certain prerequisite conditions apply e.g. that a conflict exists and also that there is no route that can be calculated around the conflict in compliance with the physics rules of the physical objects in the local version of the virtual physical environment.

The suspension of the physical rules is preferably accomplished by the slave synchronizer interacting with the physics engine to make the physics engine act as the obstructing object was not there but with the restriction that this temporary disappearance of the obstructing object from the physics environment data does not affect the its consequent presence in the simulation imagery generated at the simulation station.

For objects that do not exhibit behavior the closed loop control aspect of the synchronizer system is ordinarily not necessary but is still available. In such an application of the synchronizer system to a non behaving object is moved due e.g. to the application of a force from the physics environment each physics engine of the physics farm independently solves for the motion of the non behaving object. When the non behaving object has come to rest or has achieved some intermediate position if the master slave synchronizer system will cause the slave synchronizer to synchronize the state of the object across the network with a single positional update from the master synchronizer for the non behaving object to each of its slave synchronizers .

The details of the architecture of the system of the preferred embodiment employing the above described synchronizer system is illustrated in et seq.

As best seen in the system comprises client side applications and server side applications each connected a physics based environment generator PBEG infrastructure which is distributed over the system using a physics communications backbone similar to the network discussed above. The client side applications include the simulators of the system the image generators associated with simulator stations environment applications applications controlling intelligent behaviors as well as distributed interactive simulations connected via a network bridge all of which interact with the PBEG infrastructure providing data to it and or receiving data from it.

The server side applications behavior applications debris simulations and threat simulators are supported on one or more servers connected with the PBEG infrastructure and these also communicate with the PBEG infrastructure. In addition a PBEG manager application is connected with the PBEG infrastructure and provides for management of the PBEG infrastructure. The PBEG manager applications embrace a number of modules performing system wide functions to manage the distributed physics based environment such as load balancing exercise control failure recovery object or synchronizer state etc.

The various applications are supported on a number of distributed client computer systems each of which supports a part of the PBEG infrastructure and are connected via a network i.e. the physics communications backbone network. Generally the PBEG infrastructure comprises at least at each client computer system associated with it a memory resident data storage that stores data representing the version local to that computer system of a physics based definition of the shared virtual environment that is updated as described herein.

The client system further has a set of synchronizers that are software programs running on the client system . One is a master synchronizer SAF Sync that transmits route data for the SAF client being simulated. Also included are synchronizers SIM Sync and SIM Sync which are slave synchronizers that receive and implement in the object state data position prediction data from the simulator stations. The position prediction data is data indicating movement of the ownships of the vehicles simulated by the simulation stations and . The data is derived from the movements of the ownships as defined by master synchronizers SIM Sync in station and SIM Sync in station . The movement of the ownship is generally controlled by the trainee at the simulator and supportive software and the data reflects this man in loop input as well as any physical consequences on the associated ownship in the PBE.

The simulator stations each have respective controlling software and that runs the simulator station to provide realistic interaction with the human user and also to receive input from the human user as from simulated cockpit controls. The simulator stations each also have a respective viewer or image generator IG and that renders a view of the three dimensional world defined by the respective stored object state data and of the PBEG infrastructure. The viewers are rendering programs that render images as serial frames of appropriate views from the point of view in the PBE of the respective simulator station which frames are serially displayed as video at a rate of approximately 60 Hz to provide realistic imagery in the simulator.

In the preferred embodiment the viewer renders its imagery based on scene data stored on a computer accessible data storage device which scene data contains data for each object that defines its location orientation appearance e.g. color texture etc. and any other data needed to generate an image of the object. The scene data is kept absolutely up to date by constantly i.e. at least once every frame cycle 60 Hz in the preferred embodiment querying the PBEG infrastructure and deriving information regarding the location orientation and other conditions of the objects therein and updating the scene data accordingly. This information is stored in the object state list data which generally is a list of every object in the PBEG environment or scene with that physics data that is relevant to its representation in the image generator meaning its location orientation and condition e.g. exploding or dead which will also affect its appearance in the rendering. The viewer at the simulator station communicates directly with the PBEG infrastructure independently of the other simulator control applications and and can be considered as illustrated in as a separate application connected with the PBEG infrastructure.

Referring to the operation of the system is illustrated by layers of functionality. The application level may include one of three possible types of application that makes an object in the PBEG environment move a SAF application that causes one or more vehicles or life forms to move a man in loop simulator in which a human interacts with controls and causes the objects that make up the ownship of the simulation to move in corresponding ways in the PBEG environment responsive thereto and environment manager applications which inject and manage physics based culture features e.g. barrels boxes etc. as well as activation of intelligent behaviors such as the movement of life forms or a crowd of civilians and generally move objects based on instructor input or any of a number of other automatic or scheduled events that cause movement of objects in the PBEG environment.

These applications each interact with the PBEG infrastructure using a respective master controller. There are three types of master synchronizers SAF controllers man in loop controllers and environmental controllers. SAF controllers transmit route data to slave SAF controllers across the physics communications backbone network as has been discussed previously. Man in loop controllers transmit force data to slave man in loop controllers across the physics communications backbone network which translates the simulator application output to cause the ownship client objects in the various PBEG environment versions to move as directed by the simulator application. The environment controllers transmit data to slave environment controllers over the physics backbone that represents forces and also collision data and positional update data which is derived and applied generally as discussed above with respect to the first embodiments of the invention i.e. by moving objects and resolving conflicts locally and updating the positions of the client objects which are then moved locally by their slave controllers to the proper location which is uniform over the entire distributed system.

The synchronizers both master and slave are essentially the same program module loaded as a plug in. As illustrated in the client system that is assigned to be the master synchronizer system has a physics manager . The physics manager is a software application that manages the local version of the PBEG object state data. The physics manager communicates with synchronizer plug in manager . Plug in manager when a client object assigned to it is instantiated accesses an object type controller plug in mapping file is accessed which contains data that causes the plug in manager to load the correct type of synchronizer SAF man in loop or environmental which is a plug in that fits any client object of the specified type. Once the correct type of synchronizer plug in is loaded it accesses a physical object configuration file that contains data identifying a parametric data file and a PhysX object description file that provides the synchronizer with physics based data that causes the plug in to properly manage the physics operation of the object such as the steering and acceleration of a vehicle.

Each plug in then begins acting as a master synchronizer and communicates with the local physics engine which in the illustrated embodiment comprises a physics API that communicates with the synchronizers and with a physics processor API plug in that links the physics API with the physics processor i.e. the hardware physics engine of the client system .

The physics backbone of the PBEG infrastructure connects with another client system and when the objects are instantiated the physics manager application of that system activates controller i.e. slave synchronizer plug in manager which loads an appropriate slave synchronizer plug in based on the object type controller plug in mapping file for the type of client object that is to be controlled. The slave synchronizer plug in then accesses the physical object configuration file and through that file the parametric data file and PhysX object description file which provide the slave synchronizer plug in with data that is used to configure the plug in to control the type of client object. The slave synchronizer plug ins communicate with the local physics engine which in the illustrated embodiment comprises a physics API that communicates with the synchronizers and with a physics processor API plug in that links the physics API with the physics processor i.e. the hardware physics engine of the client system .

Subsequent to the initial loading the master synchronizer continues to transmit the data appropriate to the type of object controlled e.g. for a SAF route data for a man in loop object force data etc. which is received by the slave synchronizer and used via the local physics engine to modify the local PBEG environment data stored in the local memory at the client system in a manner described above.

Referring to the context of a client system is shown schematically. The client system comprises at least one of a simulator application a viewer an environment application or a SAF application optionally connected with a DIS network linking the client system with an external entity manager using military standard protocols. The external entity manager sends and receives entity data to and from applications that are not physics based applications most notably DIS and HLA.

The SAF application is often a traditional military computer generated force modeling application that has been modified or enhanced as necessary to allow it to define modeled forces that can be introduced into the PBEG environment. These types of SAF applications also involves some additional packages preferably these being a SAF Physics API a SAF Physics Object Manager a SAF API a SAF manager and an artificial intelligence engine for modeling intelligent behaviors of SAF entities all of which cooperate to provide for a class of computer generated models to be injected into and managed in the PBEG environment.

All of these modules preferably link directly to the PBEG infrastructure of the client system indicated at or indirectly to the PBEG infrastructure via physics application API which interfaces to the PBEG infrastructure . The PBEG infrastructure part of each computer system is similar in each system server or simulator station in the distributed simulation system. It should also be understood that not all of the illustrated applications are used in every system. A simulator station for example may have only the simulator application and the viewer in addition to the PBEG infrastructure . On the other hand in a server system with no operator for example only the SAF application and SAF modules are used with the PBEG infrastructure .

As best seen in the PBEG infrastructure part of each system preferably comprises a physics environment API . The physics environment API provides the application interface to the PBEG infrastructure allows the applications accessing the PBEG infrastructure therethrough to create remove apply forces and torques to virtual physical objects and query virtual physical objects instantiated in the PBEG infrastructure via a handle or pointer usable to access the record via the object state data manager. The physics environment API also provides for initializing the PBEG environment and registering for simulation events and managing event callbacks. Events may be object events such as creation of the object deletion of the object or change in object appearance or warfare events such as fire event for a weapon or detonation events for explosive devices.

The physics environment API also provides for creating an object in the PBEG environment responsive to which the physics environment API returns a handle or pointer linking to the object state data record in the object state data list. In addition it provides for directing an entity object in the PBEG environment as by giving the object a goal or applying a force to it. It also responds to queries by applications returning data corresponding to the object state for the object queried.

The object state manager is an executable software module that is responsible for managing an object state data structure or list stored in resident computer accessible memory. The object state list has a record for every virtual object in the virtual scene and is updated by the object state manager continuously e.g. once every calculation cycle of the physics engine or once every rendering cycle of an associated image generator. This update is performed by receiving from the synchronizers or the physics manager data reflecting the purely physics based data stored for use by the physics engines and by combining data derived from that physics based data that is useful in generating an image of the object such as position and orientation with other non physics simulation data such as health or appearance changes and attributes set during creation of the object in question such as the type of entity that it is. The result is a constantly up top date list that contains an organized data structure or list accessible by the viewer application or any other application that includes a complete object state data record for each object in the PBEG environment. The object state manager also processes object and warfare events and generates synchronizer requests based on synchronizer requests. The object state manager also modifies the PBEG environment data at the given station to apply for example forces indicated by the SAF or man in loop application that move an object in the virtual world via the physics manager .

Each object in the PBEG environment has a unique identification number or code using which the object manager can be queried to return its object state data. The object state manager includes utilities that allow for efficient access of the object state data record for any virtual object in the PBEG environment. This may include the use of a hash table that convert complex entity types to integer or organization of classes of objects to describe appearance thereof.

The object state manager also provides for initializing the PBEG environment and the objects therein. Objects are created when the object manager receives a create object instruction from the physics environment API and remote objects are created when a create object event is received from the PBEG Environment Event handler which will be discussed below. The object state manager notifies subscribing applications of created removed or objects changed in appearance as an object state notification event.

The object state data is directly based on the current physics based environment data stored in the local computer accessible memory which is the foundational data that gives rise to the displayed views of the PBEG virtual environment prepared by the image generator or viewer and also is the data accessed by the physics engines to ensure that physical laws are followed in the simulated environment. Unlike other systems that rely on the rendering engine and its appearance related scene data as the foundation of the system that defines the appearance of the virtual world the present system relies on the physics based environment data and then based on the physics based environment data accesses data defining the appearance of the virtual world being viewed at any particular simulation station.

Physics manager is preferably an executable software module that manages physics data and activities of the system i.e. it manages the system components that create and interact with the physics based environment. Physics manager initializes the physics based data stored for access by the physics engines by loading the entire physics based scene database inform a repository i.e. a computer accessible mass storage device accessible from the computer system in which the physics manager runs. The PBEG repository contains data that defines the layout of synchronizer objects physics models and attributes needed by the PBEG environment to load and manage physics models. The repository provides a utilities package to access the repository.

In addition the physics manager causes the PBEG synchronizer manager to load the synchronizers for the synchronizer system described above. The physics manager maps the modeled object type and synchronizer class e.g. man in loop SAF etc. to repository naming conventions so that the physics manager when setting up synchronizers for an object and directs the synchronizer manager to load the appropriate synchronizer for the given object. The physics manager also acts similarly to the physics farm manager discussed above in that it will assign which synchronizer is to be the master synchronizer.

Once the synchronizers are loaded the physics manager transfers to the local master synchronizers the movement or force data received from the controlling application which implement it directly to the physics engine. For example the simulation application of a simulator station transmits or passes to the local physics manager a pilot s cockpit inputs which are then passed on to a master synchronizer for the ownship or for an object that is a part of the ownship of the simulator station.

The physics manager or the object state manager also communicate the route data for an object that is received over the network or physics backbone to the appropriate slave synchronizer responsible for the object which processes the route data as set out above.

For efficiency the virtual world that is shared among the simulator stations is preferably broken up into separate scenes. If a user moves from on scene to another the physics manager will load a new scene database to the local physics engine and unload the former scene database as necessary.

Also the physics manager receives warfare events from the object state manager and creates forces corresponding to them in the physics environment stored for access by the physics engines. The physics manager uses stored warfare data munitions types and other data regarding weapons in the simulation to determine the magnitude of any impulse force and inputs this to the physics based environment data. The scale of munitions impulse may be precise or it may be simply classed as small medium or large.

Synchronizer pluggins manager receives requests to load synchronizers from the repository and the proper type of synchronizer specified by the physics manager is loaded. The synchronizer pluggins manager then schedules the loaded pluggin to run and load the appropriate physic module for the client object of that synchronizer. Once the physics model is loaded the synchronizer pluggins manager is set up and runs in the shell of the pluggins manager . The synchronizer pluggins manager schedules the synchronizer to run and unloads the synchronizer and associated physics models responsive to receiving or detecting that there is a request to remove the object.

The three general types of synchronizer pluggins discussed above are shown in the diagram of but there are normally a very large number of synchronizers both master and slave managed by the synchronizer pluggins manager in each system since there is one synchronizer per object.

These synchronizers operate as described above in detail and they communicate with the physics engines which are a wrapper around the COTS physics engines such as described previously such as the PhysX engine sold by Ageia. The wrapper supports plug and play and can be used with a variety of different COTS physics engines . The synchronizers provide force or torque data to the physics engines which then calculate a solution that reflects the physical consequences pursuant to the physical laws of the physics engines of the forces or torques introduced by the synchronizers on the objects defined by the physics data. The physics engines calculate this solution periodically preferably at least once per image rendering cycle preferably about 60 Hz and the result is modifications to the physics data stored in the physics engine memory reflecting movement of the defined virtual objects.

The synchronizers and the physics engines exchange data back and forth to accomplish movement of the objects as directed by the associated application and in compliance with the physical laws of the physics engines . The interaction preferably includes a closed loop control of the parameters of the client object of the synchronizer as was discussed above. In addition the synchronizers whether master or slave transmit at least some of the physics data back to the object state manager which takes the position orientation and possibly velocity or other physical qualities of use in determining the appearance of the object and stores that viewer relevant data in the object state data structure or list. As a result the object state list is an immediate reflection of the location of all the objects defined by the physics data defining the virtual scene as stored in the physics engine memory. In turn the scene data used by the image generator or viewer to render the imagery displayed reflects the current state of the object state data. The result is that the viewer displays to the simulator user imagery that reflects the virtual environment exactly as it is defined at the moment by the local physics data in the physics engine memory.

PBEG Event Handler provides an interface for the PBEG environment to generate and distribute event messages. It provides for creation and distribution of war events e.g. fire or detonations. The event handler also creates object notification events such as creation removal and change of appearance of an object. It also creates simulation management events and provides a way for components of the system to register for event callbacks object state simulation control and other event notices. Also the event handler manages registered callbacks and distributes events based thereon.

The event handler communicates the events which are the real transactional elements of the system to the local physics manager and to the network link. Events are any occurrence within the system for which it is helpful or advisable to alert other client systems to such as the creation of an object or its transformation as by explosion into something else. The event handler also receives the broadcast route data from all the master synchronizers in the system and transmits it to the object state manager which communicates the route data to the appropriate slave synchronizers or controllers for processing into the physics engine as has been described above.

Physics environment control API provides the functionality that allows an instructor to design implement and or edit a training exercise by registering client applications setting the environment starting or terminating the exercise or removing the entity. It is similar to or even redundant with the exercise management module discussed above.

Events and synchronizer data transmissions go to other client systems over the physics communication backbone to which the client is connected by link layers. Low level network layer is responsible for opening connections closing connections sending data and receiving unreliable data. Reliable data is processed at the application level network .

The network support is based on UDP the standard Internet protocol for unreliable connectionless communication. Because of this the network layers are needed to be responsible for maintaining a list of connections and handling their time outs. The network layer is packet oriented meaning that all data sent and received via the network later exists in discrete packets.

The network will send the packets of data unreliably. A packet sent from one client system to another might not arrive might arrive once or might arrive multiple times. The packets might also arrive out of order needing reassembly. The network layer takes steps to ensure that packets are not corrupted. These include checking the packet that its size and contents are identical to what was sent.

Preferably the network layer is portable and multi thread capable. It connects all of the client systems and servers and any distributed PBEG management applications are routed therethrough. Its essential function is to optimally send PBEG messages on the PBEG communications backbone these services employ multicast schemes to partition traffic as by exercise by scene to pack and unpack messages and other communication services to optimize the overall data sharing and communication of the network of the backbone.

The application level network layer sits on top of the low level network and provides services such as reliable message handling multicast message compression network statistics and other message packaging optimizations.

The application which has adequate administrative capabilities to create an object starts the CreateObject routine which communicates with the physics environment API which in turn communicates with the object state manager to create the object. The object state manager causes the physics manager to load the object from the synchronizer physics model repository connected with the client system on which the programs are running. The physics manager determines the appropriate type of synchronizer and publishes the notice of a created object to all the other systems over the network here illustrated as the remote below the black line. In addition the physics manager directs the synchronizer manager to load the proper synchronizer plug in and initialize. The synchronizer for the new object initializes creating a new master synchronizer for the object and loads the physics model from the repository into the physics engine memory and creates the new object in the physics engine an action which provides in response a handle to the physics object in the PBEG environment data that the physics engine accesses. This is returned through the physics manager to the object state manager which creates a record for the new object s object state and transmits a handle for that object state data record back to the physics environment which is passed back to the application or another local application as well such as the viewer at the local simulation station.

The published create object instruction goes through the physics backbone to the remote system where it is received by the event handler which directs the local object state manager to create the object. In reaction the local object manager issues a load object instruction to its physics manager which in turn tells its synchronizer manager to load the plug in and initialize. The synchronizer loads the synchronizer which initializes as a slave synchronizer and a physics model from its repository and creates the object in the PBEG environment physics data with routine CreateActor accessing the physics engine and the version of the PBEG environment data that is stored at the remote system. The physics engine returns a handle meaning a unique pointer identifier or address to the created physics object in the physic engine resident memory which is passed back to the remote object state manager which places a record in the object state data at the remote and transmits a handle linking to that object state data in the object state database. The two client systems local and remote after this process will display the new object in synchronization provided the object is in the virtual field of view of the respective viewers.

The relationship of these components on a given server or client system is illustrated in . The application which may be any type of object controlling application e.g. a simulator a SAF model an environmental model etc. interacts with the surface interface application of the PBEG infrastructure physics application API transmitting to it data indicative of movement or change of the client object affected by application . Physics application API receives that information and transmits or passes instructions create delete or update the object state manager . The object state manager receives this data and transmits to the physics manager data containing the instructions to create or delete the object or to the synchronizer data containing instructions to update the physics object. If the instruction is to create the object the physics manager loads a controller or synchronizer plug in from a repository and this becomes the synchronizer which loads into the resident data memory of the physics engine a physics model for the object from a stored repository which may be the same device as the repository . If the instruction is to update the object in terms of forces or position that data is also routed through the synchronizer by a closed loop control to the physics engine memory. Physics manager only accesses the memory of the physics engine if the instruction is to initialize the physics engine in which case a full scene of physics data is loaded into the physics engine memory. In the event that the update to the object is a transformative event like an explosion the object state manager passes the instruction to the event handler and also to the synchronizer to transmit the appropriate physics data of the transformation.

Data also flows in the reverse direction. There is the reverse flow of data to the synchronizer from the physics engine as part of the closed loop controller process thereof. This data is returned from the physics manager or the synchronizer to the object state manager together with a handle for accessing the physics of the object if a query is to be made to the physics engine memory. This data is combined with other information to yield the object state data record in the object state list in which the object s data record includes data storing the handle identifying it. In turn a handle or address identifying the object s object state data record may be returned to the application via the interface of physics application API to the physics application .

As best seen in a PBEG exercise management module supported on a separate remote server provides for exercises for training in the PBEG environment. The exercise management module provides a variety of functions including selecting the virtual world design for the physics based PBEG environment e.g. the Arizona desert from a library and also setting up the PBEG or controlling a training exercise. The PBEG exercise management allows for applications to join the system and participate in an exercise even after it has started and also applications can re join an exercise after failure. Applications register themselves with the PBEG exercise management component and respond to PBEG exercise management controls. Preferably provisions are also made for applications to operate in a stand alone mode without the PBEG exercise management.

The control flow for the start of an exercise is illustrated in . The PBEG exercise management module transmits a message indicating exercise start across the physics backbone to the event handler at the client system for the application to be involved. The event handler routes this notification to the physics environment control API on the outer functionality layer of the PBEG infrastructure which transfers the notification to the application itself as an exercise callback message requesting a call back to the PBEG exercise management module . A callback is issued either automatically or by operator input acknowledging the start notification which is passed into the physics infrastructure at API then to the event handler and over the network back to PBEG exercise management module .

A request for callback may also be made in the other direction as illustrated in . The application transmits a registration request to the exercise management module . it enters the PBEG infrastructure through API is passed to the event handler which transmits the registration message over the network layer and physics backbone to the PBEG exercise management module . The PBEG exercise management module then responds with an acknowledgement message that returns through the exact same route to application arriving as an acknowledge callback.

The foregoing invention provides significant improvement over earlier distributed systems. The object state manager which organizes object state data allows for a more efficient aggregation of virtual objects even when they are the products of applications as different as legacy SAF systems and current simulator stations. The system and methods herein avoid latency as well as avoiding the problems of tight coupling between the behavior physics and rendering which has presented problems in the prior art. The use of plug ins as synchronizers and for the physics engines provides a very flexible open architecture and the system of the invention is highly scalable.

It will be understood that the systems and methods of the foregoing disclosure are preferably implemented using software operating on electronic computer processor systems linked via a network such as the internet and having computer accessible data storage attached thereto such as disk drives or other mass storage devices. The physics engine components however as discussed above are preferably dedicated hardware implemented in a computer system having memory and display devices as are well known in the art.

As has been mentioned above under certain circumstances the master synchronizer or controller for an object may be replaced by a different master synchronizer at a different client system on the network. The process by which this happens is illustrated in

When the object is first instantiated by application A in a create entity instruction is sent through the physics environment API at computer system to create master Synchronizer A . Master synchronizer A sends a command over the physics network to load appropriate slave synchronizer A which is received at a second computer system which loads and starts slave synchronizer A .

At station an application B is started which may be a manual control or another type of controlling software for the entity that has been created. Application B triggers loading of master synchronizer B by an add synchronizer command . This command may be the result caused by Application B when an instructor at station activates direct human control of an entity at the instructor station and the master synchronizer program starts on the instructor station computer. Loading of master synchronizer B produces a command to load slave synchronizer B which is broadcast over the entire system where every system including system loads a slave synchronizer B .

Subsequently Application B is prompted by the user or by some other event to activate control by Application B. this results in an activate synchronizer command sent to the physics environment API at system which does two things it de activates the then active slave synchronizer following master synchronizer A and it activates master synchronizer B to take control of the entity.

When de activated slave synchronizer A sends a deactivation instruction to its master synchronizer A over the network. The master controller at the simulation station controlling the entity then detects the presence of the superseding master synchronizer and relinquishes control no longer transmitting any route data.

When activated the new master synchronizer B transmits an instruction to activate all the corresponding slave controllers throughout the system including slave synchronizer B on client system . All the slave synchronizers loaded for master synchronizer B then begin to control their respective local copies of the entity according to the control data received from master synchronizer B as operated by Application B. The control data may be route data or man in loop control data depending on what type of application Application B is.

The process can be reversed responsive to Application A asserting control again with an activate synchronizer instruction to system or responsive to a deactivate synchronizer command from Application B at computer system .

The terms used in this specification should be understood to be language of description not limitation as those of skill in the art with this specification before them will be able to make changes and modifications therein without departing from the scope of the invention. In particular the term SAF as it has been used herein should not be seen as limited to legacy types of object force simulation but as referring to any sort of moving entity or object that exhibits a computer generated behavior especially but not limited to computer controlled opposing forces that act according to predefined tactical rules. Similarly the terms object and entity have been used fairly interchangeably herein both intended to refer to virtual objects or virtual collections of object defined by data stored in electronic computer systems.

