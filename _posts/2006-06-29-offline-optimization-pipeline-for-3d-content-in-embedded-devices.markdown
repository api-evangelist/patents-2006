---

title: Offline optimization pipeline for 3D content in embedded devices
abstract: Apparatus are provided including assets defining 3D models, including 3D icons and scenes, and animations of the 3D models. An offline optimization engine is provided to process data to be acted upon by a graphics engine of a target embedded device. A graphics engine simulator is provided to simulate, on a computer platform other than a target embedded device, select functions of a target embedded device running a graphics engine including API calls that directly calls API functions of a hardware level API of the target embedded device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08026910&OS=08026910&RS=08026910
owner: QUALCOMM Incorporated
number: 08026910
owner_city: San Diego
owner_country: US
publication_date: 20060629
---
Priority is hereby claimed to U.S. Provisional Patent Application Nos. 60 696 347 60 696 185 60 696 488 60 696 346 and 60 696 186 each filed Jun. 29 2005.

This patent document contains information subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent as it appears in the US Patent and Trademark Office files or records but otherwise reserves all copyright rights whatsoever.

Aspects of the disclosure relate to tools to facilitate the development and implementation of 3D content used in embedded devices. Other aspects of the disclosure relate to tools to optimize such 3D content. The embedded devices may be mobile devices that capture receive and or transmit voice data text and or images.

Various systems exists which facilitate the development and implementation of 3D content used in embedded devices. Such embedded devices generally included displays to display the 3D content. In this regard Qualcomm Corporation sells many software products under the trade name BREW which include for example SDKs which can be run on a given computer platform to develop programs for providing 3D content in embedded devices just as mobile phones.

In accordance with one embodiment apparatus are provided which include assets defining 3D models including 3D icons and scenes and animations of the 3D models. An offline optimization engine is provided to process data to be acted upon by a graphics engine of a target embedded device. A graphics engine simulator is provided to simulate on a computer platform other than a target embedded device select functions of a target embedded device that runs a graphics engine including API calls that directly call API functions of a hardware level API of the target embedded device.

Referring now to the drawings in greater detail illustrates a 3D content development system . The illustrated system includes one or more device content development platforms and a mobile device . The illustrated mobile device includes a display and keys . The illustrated display may be caused to display a 3D graphical virtual interface which includes 3D icons and scenes. In this regard a 3D icon application may be developed which include icon association mechanisms to associate a given 3D object in a scene with a mobile device interface tool to cause by manipulation of the given 3D object at least one of an input and output of a signal or information regarding the mobile device. The mobile device may be for example a mobile phone. The input may involve a controlling function of the mobile device a switch state change of the mobile device or text input of the mobile device. An output may involve information display a state of the device or a status indication regarding the mobile device. The information that is input or output via use of such a 3D graphical virtual interface including 3D icons may be regarding operations settings events states and or statuses of mobile device .

The illustrated mobile device is one type of embedded device which captures receives and or transmits voice data text and or images. The illustrated mobile device includes a display and keys to allow the control of mobile device and the input of information into mobile device .

The illustrated device content development platform s may be a single or a distributed platform or may include multiple platforms. The illustrated platform set includes a number of software interfaces which interact with and provide corresponding windows or screens on a computer platform. These include a scripting window and a corresponding scripting language interface . A source code window is provided which corresponds to a source code interface . Each of the interfaces and is operable through the use of its corresponding window and for receiving controls and information via a computer screen and for displaying information to the user.

The illustrated platform set is further provided with an offline optimization engine which may include a target simulator .

Scripting language interface is coupled to and generates one or more script files which cater to the building of 3D user interfaces on a target embedded device. Those script files provide information for 3D icon and scene definition as well as for programming the animation of the defined 3D icons and scenes.

Source code interface in connection with source code window allows for the creation of a program using source code typically using commands provided in code provided for original equipment manufacturers OEMs .

A 3D model system may be provided for allowing an artist to perform 3D modeling and or image processing to create 3D user interface assets and to define user interface layouts to each form and ultimately define a 3D user interface. An exporter may be provided to export files i.e. convert such files from 3D model system into certain types of files that can be useable by the compiled script and or source code to cause a particular type of 3D user interface which can be exported to a target embedded device. The exporting performed by exporter is distinct from the exporting performed by device export interface which is provided to export resulting code and data to a target embedded device such as mobile device . Exporter converts information into files that are compatible with the compiled script and or source code and also useable by a graphics engine that operates in accordance with the compiled code while device export interface facilitates the physical exporting of such compiled script and or source code and associated user interface assets and user interface layout files into mobile device .

In the illustrated embodiment exporter exports information from 3D modeling system into a set of files defining user interface assets and and a set of files defining user interface layouts . Specifically the user interface assets include 3D models animations and textures .

Offline optimization engine may include a target simulator that simulates a graphics engine to simulate on a computer platform other than a target embedded device i.e. platform s select functions of a target embedded device running a graphics engine for example the graphics engine illustrated in .

The base structures and APIs include textures meshes animations cameras and math and utilities . These structures and APIs provide full access to all geometry animation streams and other underlying engine data types. In addition fixed point math and container structures may be provided that can be used independently of the rest of the engine. Applications may be implemented embodied within compiled script and or source code so as to interface through managed APIs for some or all functions. They may implement their own resource management and memory instantiation techniques and accordingly interface directly with base structures and APIs . Moreover completely bypassing managed APIs is possible in the event an OEM developer wishes to write source code that takes advantage of exporter and mesh optimization tools or otherwise retain control over how higher level functionality is implemented.

Managed APIs together with base structures and APIs comprise an optimization engine layer . The hardware level API may include for example Open GL ES software Direct 3D mobile software or SKT GIGA software.

Scene nodes are all those nodes that are not linked to a 3D model. Link nodes have 3D models associated therewith. The models associated with link nodes are exported to their own files and their link node association is specified in the UI definition file . Scripting language may be used to provide a set of tags that could be used in connection with externally created 3D assets otherwise referred to as user interface assets and produced by another set of software 3D model system as shown in . These files produced by this external software are exported by exporter and thereby converted into formats compatible with the 3D user interface development code as compiled from script files and or source code .

In the bake animations stage animations for the extracted scene are baked to reduce processing time in performing 3D animation updates in the target embedded device and the baked animations are compressed to reduce the space occupied by animation data in the target embedded device. In the offline setup stage various processing steps are performed including e.g. bookkeeping index structuring data preparation and memory allocation.

In the subsequent hierarchy update pre processing stage each of the hierarchies for the extracted scene are for 3D models and for animations rearranged so that a hierarchy update including a conversion from local coordinates to world coordinates in the target embedded device will involve a non recursive tree traversal by performing a breadth first traversal of the hierarchy tree. In addition in this stage the nodes of the tree are compressed and the hierarchy is packed into a single contiguous buffer including the nodes that need to be present in order to allow the target embedded device to perform the hierarchy update on the fly. In the illustrated embodiment this buffer will take the form of tree data buffer as shown in once it is exported to the target device.

In the pre allocation stage every data structure that will be required for the extracted scene will be identified and a memory allocation required in the target embedded device will be determined. This results in a total memory allocation figure otherwise sometimes referred to herein as a pack total that can be utilized in the target embedded device to perform a single memory allocation call using the MALLOC call of ANSI C for example in comparison to the numerous memory allocation calls that might be necessary otherwise.

The illustrated flow chart shown in is provided to optimize animation updates on the target embedded device by pre evaluating animation curves in an offline step. The illustrated embodiment shown in produces as shown in a baked animation lookup table LUT which will be part of code and data ultimately in target embedded device .

In the illustrating baking process shown in in an initial act animation hierarchy is extracted from the extracted scene. In a next act an animation stream is created for each node of the extracted hierarchy. In act the sampling rate is determined for all animation streams that have been created. In this regard a user may choose a particular sampling rate. Generally the sampling rate is much higher than the standard rate of frames in which the frames of an animation are stored in the animation file exported by exporter as shown in . The sampling rate can be adjusted using an iterative process. For example an author may simulate the resulting script of a 3D user interface application with a particular sampling rate having been chosen. If the quality of the resulting graphics is not sufficient given the expectations of the author the sample rate may be changed accordingly.

In a next act all or a subset in an alternate embodiment of animation curves are evaluated at the chosen sample rate. At this point a raw animation data stream has been obtained which has been baked at the determined sample rate. This data is stored in the offline platform.

By way of example this raw animation data can be stored in an indexed array not shown with each row in the indexed array accessible by inputting into the array an index value e.g. determined with the use of an index look up table LUT not shown . The indexed array stores in respective rows sets of attributes with each row being associated with a particular node and frame. These attributes may e.g. be x y z r r r r r r r r r and color. The x y and z attributes may be local coordinates of a scene or part of a scene. The attributes r r r r r r r r r are rotation and orientation values that may e.g. correspond to a 3 3 matrix.

In a next act the rotation and orientation values for each frame node combination from the baked raw animation data stream are converted to quaternions. Quaternions are another way of representing rotations and orientations for example instead of using Euler angles and matrices. A quaternion may be represented by 4 values . Thus in this example the 9 rotation and orientation values may be transformed into 4 quaternion values.

In a next act a cluster is created for each unique value within the quaternions that have been converted from the rotations and orientations of the baked raw animation data stream. In the illustrated embodiment a cluster is a 7 tuple value which may be formed by using a local set of coordinates x y z and a quaternion value . In one aspect the cluster may be formed when the 7 tuple value is unique. Thus if there are M rows of data in the baked raw animation data i.e. corresponding to respective different combinations of frame and node values there may be N clusters where N is less than M because of non unique 7 tuple values. A cluster may be composed of a cluster vector x y z and a cluster quaterion .

In a next act a determination is made for a given pair of clusters as to whether the error between those clusters is less than a given threshold. Each cluster is provided with an error value. By way of example this error value may be the midpoint value of the respective clusters.

For example a cluster pair may be identified by operating on the 7 tuple in two spaces 1 a cartesian space x y z and 2 a quarternion space. In the Cartesian space the magnitude of the midpoint between any two cluster vectors may generate a midpoint value mpv. Similarly in the quaternion space the magnitude of the midpoint arc distance between any two cluster quaterions may generate a midpoint value mpv.

When the determination at act determines that the error is less than the threshold the process proceeds to act where that pair of clusters is merged into a new cluster and a new least error value i.e. a midpoint magnitude value is computed for that newly merged cluster. The process returns to act for evaluation of another pair of clusters.

This clustering process can be considered a method of reducing the number of rows of data corresponding to unique frame node pairs so that a plurality of unique frame node pairs that may have animation data generally translation information orientation and rotation information has the same set of clustered data.

When no more pairs of clusters meet the conditions of act the process proceeds to act at which point for a given set of animation values for a given cluster the quaternion values generally four different values are packed into a single binary word e.g. of N bits N may be e.g. 32 bits .

The clusters can be made larger or smaller to increase animation playback accuracy or to reduce file size respectively. Once the streams are compressed the individual values in the animation streams are packed into a single contiguous memory buffer which is aligned and optimized for the mobile device s cache line characteristics.

Once the animation stream is compressed the individual values in the animation stream are packed into a single contiguous animation value memory buffer which is ultimately exported to the target embedded device as shown in .

As shown in in order for a given process of the target device to access data in animation value buffer an animation lookup table LUT is provided that outputs for each unique frame node combination an offset value that locates the corresponding animation data in buffer .

If the hierarchy illustrated in is updated using a recursive algorithm where the nodes are processed in a breadth first traversal order the nodes will be processed in the following order first the waist node second the upper right leg node third the left right leg node fourth the left right foot node fifth the upper left leg node and so on. In contrast in the embodiment shown in a breadth first traversal order is used where the waist node is first processed the upper right leg node is processed second the upper left leg node is processed third and the chest node is process fourth. The order in which the nodes are processed is indicated by the numbers to the left of each of the associated nodes. Accordingly the waist upper right leg upper left leg and chest nodes are process first second third and fourth respectively before nodes at the next depth level down are processed. This processing of the nodes ultimately occurs in the target embedded device but the order in which these nodes is processed can be controlled by controlling the order in which these nodes are stored in a contiguous portion of a tree data buffer ultimately as shown in formed in the heap memory of the target embedded device. Accordingly a data structure can be provided offline by the hierarchy update pre processing stage as shown in to provide for a contiguous amount of memory and for the storage of these nodes in that memory in the particular order in which they are to be processed ultimately in the target embedded device.

As shown in breadth first hierarchy update mechanism may be provided as part of code and data in target embedded device for performing on the fly hierarchy updates of a particular hierarchy. In order to determine where the data associated with that hierarchy is within animation data buffer breadth first hierarchy update mechanism locates that data in accordance with the offset value provided by baked animation LUT .

Once breadth first hierarchy update mechanism locates the data within animation data buffer the data is decoded by decoding mechanism by converting the data to a homogeneous transform matrix and the nodes are processed in their consecutive order per the structure of the tree as stored in tree data buffer i.e. the waist node first the upper right leg node second the upper left leg node third and so on per the example in . The updated animation data is then stored per node in holding spaces provided for such data in tree data buffer .

The breadth first approach processes the nodes of a given tree in this order the root node first then child then child . . . child N grandchild grandchild . . . grandchild M great grandchild . . . .

In the example shown in the cache line boundary extends at least the amount of memory that is required for two contiguous nodes. Accordingly if a cache provided within a target embedded device has two lines only one cache miss would be required to process i.e. update the hierarchy for the first through the fourth nodes in the example shown in . To facilitate the ability to store two nodes within the space of one cache line boundary the individual nodes may be compressed for example using the compression that results from the baked animation provided by the baked animation stage as shown in .

A hierarchy update involving a depth first traversal order will generally result in numerous cache misses. Among the reasons for this are the fact that the nodes for the hierarchy are not stored in contiguous memory. In addition since the traversal is recursive for each node the data for each of its parent nodes all the way to the ultimate root note is required for processing and updating that node.

For purposes of the discussion regarding the updating of hierarchy for example in relation to the example shown in updating refers to the conversion of a node from its local coordinates to world coordinates before rendering on a display of the target embedded device.

An advantage of the approach of organizing the node data in the example shown in is that the use of the stack in the target device for updating hierarchy information can be eliminated for this process. Moreover there is no need to emulate a stack in the heap of the memory of the target embedded device. In addition the total space consumed in the heap memory of the target embedded device is minimized so that larger hierarchy trees can be accommodated.

As shown in once node data is updated by breadth first hierarchy update mechanism it is ready for rendering by render mechanism .

In act all of the data accessed by the simulated engine or created by the simulated engine is packed in the order of engine access or creation into contiguous portions of a simulated heap memory. In act meta data structures helpful to the engine in the target embedded device may be created. In addition the allocation data resulting from the pre allocation process is stored. Generally the allocation data includes the total memory space and size of the contiguous memory that was packed in act .

The allocation process shown in which is performed in pre allocations stage of off line optimization pipeline as shown in causes ultimately in target embedded device memory allocation and copy actions to be taken by memory allocation and copy mechanism in accordance with meta data and pack total data produced as a result of the pre allocation process. Specifically a single memory allocation may be made within memory of target embedded device at the start of the execution of the 3D application as well as a single memory copy of all data that was packed during the packing act in the pre allocation process. Any built engine data structures that were built offline can then be copied into the memory resulting in a single allocation and a single memory copy being required to prepare the data for use in the target embedded device. This minimizes the allocations required for the target embedded device. In addition start up and initialization times of the target embedded device can be minimized since all of the packed data is loaded at one time into the target embedded device memory.

The processing performed by each of the elements shown in the figures herein may be performed by a general purpose computer and or by a specialized processing computer. Such processing may be performed by a single platform by a distributed processing platform or by separate platforms. In addition such processing can be implemented in the form of special purpose hardware or in the form of software being run by a general purpose computer. Any data handled in such processing or created as a result of such processing can be stored in any type of memory. By way of example such data may be stored in a temporary memory such as in the RAM of a given computer system or subsystems. In addition or in the alternative such data may be stored in longer term storage devices for example magnetic discs rewritable optical discs and so on. For purposes of the disclosure herein computer readable media may comprise any form of data storage mechanism including such memory technologies as well as hardware or circuit representations of such structures and of such data. The processes may be implemented in any machine readable media and or in an integrated circuit.

The claims as originally presented and as they may be amended encompass variations alternatives modifications improvements equivalents and substantial equivalents of the embodiments and teachings disclosed herein including those that are presently unforeseen or unappreciated and that for example may arise from applicants patentees and others.

