---

title: Annotating multimedia files along a timeline
abstract: A facility for annotating media files is described. In various embodiments, the facility displays a timeline indicating a duration of the media file, determines that an annotation is associated with the media file, and displays in an area near the timeline an indication of the associated annotation. In various embodiments, the facility displays a timeline indicative of a duration of the media file, receives an indication to add an annotation at an annotation time relative to the duration of the timeline, receives and stores an annotation, associates the annotation with the annotation time, and displays an indication of the stored annotation at an area near the timeline.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07954049&OS=07954049&RS=07954049
owner: Microsoft Corporation
number: 07954049
owner_city: Redmond
owner_country: US
publication_date: 20060515
---
Users of computer systems employ various applications to render media files including multimedia files. A media file is a digital file that contains digitized information such as text audio video images and so forth. A multimedia file is a digital file that contains multiple types of media. A common example of a multimedia file is a video file that contains a correlated sequence of images and audio such as a movie. Rendering is the process of converting information from digital to analog form so that a person can perceive the information such as by displaying text playing back audio or video drawing an image and so forth.

Another example of a multimedia file is a collaboration file that is created manipulated or stored by collaboration software. Collaboration software enables multiple users to share an application view an online presentation or collaborate in other ways using computing devices that are engaged in a collaboration session. A collaboration session enables participants to share information or applications via their computing devices. The collaboration software can record the collaboration session in a multimedia file which can contain audio video images presentation graphics mouse cursor movements keyboard input text documents and other facets of the collaboration.

Media files can become very large. As an example users may collaborate in a collaboration session that lasts for several hours. The collaboration session may also span multiple sessions so that for example a collaboration file has information from all collaboration sessions that together last for hours. As another example a movie can span two hours or longer.

It is difficult for users to locate relevant or desirable content in large media files. As an example a user may desire to locate a particular scene in a movie a particular training segment in a training related collaboration file and so forth. The user can find it difficult to locate the relevant or desirable portions because the user may not know the position in the media files at which the desirable portions are located. Conventionally the user may start rendering a media file from the beginning until the relevant or desirable content is rendered. Alternatively the user may estimate a position and employ a user interface element e.g. a slider bar or timeline to begin rendering the media file at various points until the relevant or desirable content is located.

A facility is provided for adding identifying and rendering annotation information that is associated with a media file. Examples of media files include collaboration files that store a collaboration session audio files video files and other multimedia files. A user can add an annotation that is associated with a specified point or region associated with the media file such as a time or time span relative to the beginning of the media file. Alternatively the facility can identify annotations based on user actions during a collaboration session. The facility then stores the annotations in association with the media file. When the media file is later rendered or upon user input the facility can display the stored annotations. Indications of annotations can be identified on a timeline representing the media file such as by using markers near the timeline.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

A facility is provided for managing annotation information that is associated with a media file. Managing annotation information includes adding identifying and rendering the annotation information. Annotation information is information that is added to a media file such as without affecting the multimedia content contained by the media file. In various embodiments the facility receives annotation information from a user or actively collects the annotation information based on the user s actions. The facility receives annotation information when the user directs the facility to add annotation information and provides the annotation information directly. The facility collects the annotation information based on the user s actions by collecting keyboard or mouse events receiving events from an application and so forth. The received or collected annotation information is associated with a particular point or region in a media file and the facility stores the annotation information accordingly. This point or region can be referred to as an annotation time. When a user causes the media file to be rendered the facility informs the user that an annotation is available and can render the stored annotation. The facility can inform the user that an annotation is available by providing an indication such as a marker near a timeline that is associated with the media file. Annotation information can be provided in various formats and can have various content. As an example the annotation information can include an identification of the user that provided the annotation and the point or region with which the annotation is to be associated such as a time span in relation to the beginning of the media file. As another example the annotation information can include annotation text or an identifier of a file containing an annotation e.g. a video or audio file . As another example the annotation can be text audio images video or any other multimedia content.

In various embodiments a user can provide annotation information by selecting a point or region of a timeline associated with the media file and adding an annotation at an indicated point or region. This point or region would then be identified as an annotation time. As an example the user can indicate a point in a timeline that represents the media file or a time span corresponding to a portion of the media file such as by identifying a point with the mouse pointer and depressing a mouse button. The user can then provide the annotation by typing text or selecting a file that contains annotation information that is to be added. This text would then be associated with the media file at the annotation time. Alternatively the facility can associate information provided by a user when creating or rendering the media file. As an example the facility detects mouse move events or keyboard events caused by a user while the media file is created or rendered and captures these events to create annotations. As another example a user may make a change to a spreadsheet cell during a collaboration session in which a spreadsheet is shared among multiple participants. The facility can capture the changes to the spreadsheet cell as an annotation. As another example the facility can capture and include as annotation information an identification of the person who is making a presentation identification of people who have joined or left the meeting and the time text or other content of presented slides and so forth.

The collected annotation information can be stored as metadata that is associated with other data without affecting the other data. The metadata can either be stored in the media file or in another file that is associated with the media file. The metadata can be stored in a form that is modifiable and searchable.

In various embodiments the facility observes and records user activity to create annotations. As an example the facility determines changes that multiple users make to a document during a collaboration session and records as annotations the changes made by the users. The annotations can include comments added by users such as when the collaboration application does not record comments in the collaboration file. The annotations can also include other aspects of the collaboration such as which users were presenting or attending a presentation at what times they joined the collaboration session and so forth. The facility can actively collect this information and store the collected information as annotations relative to an annotation time e.g. the time at which the user made the change or joined a collaboration session .

In various embodiments a user can view the annotation information when the media file is rendered. As an example during playback of a recorded collaboration session a stored annotation may be rendered when the facility renders a portion of the media file corresponding to a time at which the stored annotation is associated with the collaboration file e.g. the annotation time . As an example when playing back a movie the facility can display at twenty three minutes from the beginning of the movie text images audio video etc. that a user added as an annotation that is associated with the twenty third minute position in the movie.

In various embodiments a user can search the annotation information of a media file. As an example the user can search for annotation information that the user or another user associated with a media file. As a further example a user can search for text or other input that was provided or changed during a collaboration session and that was recorded in a collaboration file. If this information is found the facility displays indications such as markers on a timeline corresponding to a point in a media file at which the annotation information was associated with the media file. Thus the facility can search for both collaboration information and annotation information.

When the user causes a portion of the media file near the indications to be rendered the facility also renders the annotations. Alternatively when the user positions a mouse pointer momentarily over an indication the facility can render the stored annotation information associated with that indication. The annotation information may be displayed for a specified duration when the media file is rendered.

Thus the facility enables users to manage annotation information that is associated with a media file such as by adding identifying or rendering annotation information. Doing so removes the difficulty users have in locating relevant or desirable content in large media files.

Turning now to the figures is a block diagram illustrating an example of a suitable computing environment in which the facility may be implemented. A system for implementing the facility includes a general purpose computing device in the form of the computing system computer . Components of the computer may include but are not limited to a processing unit a system primary memory a storage device a network adapter or interface a display one or more speakers and an input device .

The computer typically includes a variety of computer readable media that are operable with the storage device . Computer readable media can be any available media that can be accessed by the computer and include both volatile and nonvolatile media and removable and nonremovable media.

The computer may operate in a networked environment using logical connections to one or more remote computers. A remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above in relation to the computer . A logical connection can be made via a local area network LAN or a wide area network WAN but may also include other networks. Such networking environments are commonplace in homes offices enterprisewide computer networks intranets and the Internet. The computer can be connected to a network through a network interface or adapter such as to a wired or wireless network.

The computer is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the facility. Neither should the computing system be interpreted as having any dependency or requirement relating to any one or a combination of the illustrated components.

The facility is operational with numerous other general purpose or special purpose computing systems or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the facility include but are not limited to personal computers server computers handheld or laptop devices cellular telephones tablet devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The facility may be described in the general context of computer executable instructions such as program modules that are executed by a computer. Generally program modules include routines programs objects components data structures and so forth that perform particular tasks or implement particular abstract data types. The facility may also be employed in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in local and or remote computer storage media including memory storage devices.

The facility may have multiple annotation rendering components such as a text annotation rendering component an audio annotation rendering component a video annotation rendering component and so forth. The facility employs the annotation rendering components to render stored annotations.

The facility may have an annotation creation component that creates annotations such as based on user actions. As an example the facility may create annotations when users in a collaboration session modify a document move a mouse pointer type information and so forth.

The facility may have an annotation search component that searches for annotations matching a criterion or multiple criteria provided by the user.

While various functionalities and data are shown in as residing on particular computer systems that are arranged in a particular way those skilled in the art will appreciate that such functionalities and data may be distributed in various other ways across computer systems in different arrangements. While computer systems configured as described above are typically used to support the operation of the facility one of ordinary skill in the art will appreciate that the facility may be implemented using devices of various types and configurations and having various components.

The techniques may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.

The collaboration session can be recorded in a collaboration file and a user can later view a recorded session by rendering the collaboration file during which a playback controls region may be visible. A user can manipulate the rendering of the recorded collaboration session using the playback controls illustrated in the playback controls region. The playback controls are described in further detail below in relation to . The playback controls region may be hidden when a user is actively engaged in a collaboration session. As an example in various embodiments a user may not see the attendee region and the playback controls region simultaneously.

A timeline indicates a duration of the media file. In some embodiments the actual duration e.g. in hours minutes and seconds may additionally be provided not illustrated . A pointer indicates a position at which the facility is rendering from the media file in relation to the duration of the media file. When the pointer is at the leftmost position of the timeline the beginning of the media file is indicated.

When a user selects control the facility moves the pointer to the leftmost position of the timeline. When the user selects control the facility moves the pointer to the rightmost position of the timeline e.g. the end of the media file .

Controls and enable the user to select a rendering speed. Control enables a user to decrease the rendering speed. Control enables the user to set the rendering speed at a normal speed e.g. a speed at which the media file was originally recorded or at which rendering time corresponds to real time . Control enables the user to increase the rendering speed.

As previously discussed the facility can collect annotation information automatically. As an example the facility may collect annotations when users make changes to a document during a collaboration session. The annotation indications may then be displayed when the user searches for an annotation or indicates that annotations are to be displayed. As an example the user can search for all annotations having particular text. As another example the user can search for all changes made to a particular spreadsheet cell or section of a document. When corresponding annotations are found the facility provides indications near the timeline such as markers.

Text region enables a user to enter a text annotation as is indicated by a text cursor . In various embodiments a text annotation region that receives user input may be indicated using a coloring border or other indication that differentiates it from a text annotation region that provides an annotation. These indications can additionally enable users to distinguish among annotations provided by multiple people. In the illustrated embodiment the facility has automatically provided the name of the user Ellen and the time in relation to the beginning of the media file 12 minutes and 18 seconds . The facility detected the time based on the position at which the media file was being rendered when the user indicated to add an annotation. In some embodiments the time is based on the position at which the user positioned a mouse pointer when indicating to add an annotation.

Annotations table of has ID time type author and content columns. The ID column identifies each stored annotation. The time column indicates a time or time span in relation to the beginning of the media file with which the annotation is to be associated. As an example annotation is associated with the media file at 10 minutes and 24 seconds after the beginning of the media file. The type column indicates the type of the annotation. Other types of annotations include audio video image document change and so forth. Annotations and are text annotations. The author column indicates the user who provided the annotation. The content column stores the contents of the annotation. The content column can contain text an identifier of a file e.g. uniform resource locator or file path identification of a position in a document and a change made by the user and so forth.

Annotations table of is similar to the annotations table of except that annotation indicates that Ellen provided an audio file that is to be associated with the media file at 12 minutes and 18 seconds after the beginning of the media file.

While and their related description show tables whose contents and organization are designed to make them more comprehensible by a human reader those skilled in the art will appreciate that actual data structures used by the facility to store this information may differ from the tables shown in that they for example may be organized in a different manner may contain more or less information than shown may be compressed and or encrypted etc.

At block the routine receives an indication that an annotation is to be stored. As an example the routine may receive the indication when the user selects a command to enter an annotation. As another example the routine may receive the indication when a user makes a change to a document that is being shared.

At block the routine determines the time in relation to the beginning of the media file. The time is used to associate the annotation with a particular point or region in the media file. When the annotation is to be associated with a time span the facility may determine a beginning and end time such as under user direction.

At block the routine determines which user made the annotation. As an example the facility may determine which user is presently logged into the system or is responsible for making mouse or keyboard events that are shared with other participants of a collaboration session.

At block the routine provides a user interface that the user can use to provide the annotation. In embodiments in which the facility automatically determines annotations the facility may not provide such a user interface.

At block the routine receives an annotation or an indication of an annotation such as the uniform resource locator or file path.

At block the routine determines properties for the annotation that are to be stored in an annotations table. As an example the routine may determine a type of the annotation.

At block the routine stores annotation information in an annotations table associated with the media file. As an example the routine stores a time or time span annotation type author identifier and annotation in the annotations table.

At block the routine indicates availability of an annotation such as by illustrating a marker near a media timeline associated with the media file. The position of the indication may correspond to the time at which the annotation is associated with the media file in relation to the duration of the media file. As an example an annotation associated with the media file near the beginning of the media file would appear near the beginning of the timeline. In contrast an annotation associated with the media file near the end of the media file would appear near the end of the timeline.

At block the routine retrieves a list of annotation times from an annotations table associated with the media file.

At block the routine determines a position for the selected annotation near the timeline. The position may correspond to the time at which the annotation is associated with the media file in relation to the duration of the media file. As an example an annotation associated with the media file near the beginning of the media file would appear near the beginning of the timeline. In contrast an annotation associated with the media file near the end of the media file would appear near the end of the timeline.

At block the routine draws an indication of the annotation such as a marker near the timeline at the determined position.

At decision block the routine determines whether there are more annotations in the list that have not yet been processed. If there are more annotations in the list the routine continues at block . Otherwise the routine continues at block where it returns.

At block the routine receives an indication to render an annotation. As an example the routine receives an indication to render an annotation when the user positions a mouse pointer near an annotation indication. Alternatively the routine receives an indication to render an annotation when a media file is rendered to a position at which an annotation was associated.

At block the routine retrieves an annotation from the annotations table corresponding to the time. As an example the routine retrieves an annotation associated with a marker or indication that the user has selected. Alternatively the routine retrieves an annotation associated with a time or time span corresponding to the position of the media file that is being rendered.

At block the routine selects an annotation rendering component for rendering the annotation type. As an example the routine may select a text annotation rendering component audio annotation rendering component video annotation rendering component and so forth.

Those skilled in the art will appreciate that the steps shown in and their relating description may be altered in a variety of ways. For example the order of the logic may be rearranged logic may be performed in parallel logic may be omitted or added etc.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims. Accordingly the invention is not limited except as by the appended claims.

