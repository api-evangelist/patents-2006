---

title: Color sensor
abstract: A color sensor for generating color information defining colors of an image includes an input section, a color processing section, a color comparison section, a color boundary processing section and a memory processing section. The input section includes an array of transducer pairs, each pair defining one of a plurality of pixels. Each transducer pair generates two peak outputs, one for the selected color of each transducer of the pair. A plurality of pixel processors in the color processing section each receives the outputs from one of the transducer pairs. The color processing section generates a color feature vector representative of the brightness of the light incident on the pixels and a color value corresponding to the ratio of outputs from the transducers comprising the transducer pair associated with the pixels. The color boundary processing section generates a plurality of color boundary feature vectors, each representing the difference between the color value for a pixel and its neighboring pixels. The color comparator processor measures and compares the reflective color of two objects and the memory processor section provides a process to recognize a color, a boundary of color and/or a comparison of colors.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=RE042255&OS=RE042255&RS=RE042255
owner: 
number: RE042255
owner_city: 
owner_country: 
publication_date: 20060727
---
The invention described herein may be manufactured by or for the Government of the United States of America for Governmental purposes without the payment of any royalties thereon or therefore.

This patent application is co pending with related patent applications entitled NEURAL DIRECTORS U.S. patent application Ser. No. 09 436 957 NEURAL SENSORS U.S. patent application Ser. No. 09 436 956 STATIC MEMORY PROCESSOR U.S. patent application Ser. No. 09 477 638 DYNAMIC MEMORY PROCESSOR U.S. patent application Ser. No. 09 477 653 MULTIMODE INVARIANT PROCESSOR U.S. patent application Ser. No. 09 641 395 and A SPATIAL IMAGE PROCESSOR Ser. No. 09 853 932 by the same inventor as this patent application.

The invention relates generally to the field of color sensors and more particularly to color sensors having neural networks with a plurality of hidden layers or multi layer neural networks and further to a new neural network processor for sensing color in optical image data.

Electronic neural networks have been developed to rapidly identify patterns in certain types of input data or accurately to classify the input patterns into one of a plurality of predetermined classifications. For example neural networks have been developed which can recognize and identify patterns such as the identification of hand written alphanumeric characters in response to input data constituting the pattern of on and off picture elements or pixels representing the images of the characters to be identified. In such a neural network the pixel pattern is represented by for example electrical signals coupled to a plurality of input terminals which in turn are connected to a number of processing nodes each of which is associated with one of the alphanumeric characters which the neural network can identify. The input signals from the input terminals are coupled to the processing nodes through certain weighting functions and each processing node generates an output signal which represents a value that is a non linear function of the pattern of weighted input signals applied thereto. Based on the values of the weighted pattern of input signals from the input terminals if the input signals represent a character that can be identified by the neural network the one of the processing nodes associated with that character will generate a positive output signal and the others will not. On the other hand if the input signals do not represent a character that can be identified by the neural network none of the processing nodes will generate a positive output signal. Neural networks have been developed which can perform similar pattern recognition in a number of diverse areas.

The particular patterns that the neural network can identify depend on the weighting functions and the particular connections of the input terminals to the processing nodes. The weighting functions in for example the above described character recognition neural network essentially will represent the pixel patterns that define each particular character. Typically each processing node will perform a summation operation in connection with values representing the weighted input signals provided thereto to generate a sum that represents the likelihood that the character to be identified is the character associated with that processing node. The processing node then applies the non linear function to that sum to generate a positive output signal if the sum is for example above a predetermined threshold value. Conventional non linear functions which processing nodes may use in connection with the sum of weighted input signals is generally a step function a threshold function or a sigmoid in all cases the output signal from the processing node will approach the same positive output signal asymptotically.

Before a neural network can be useful the weighting functions for each of the respective input signals must be established. In some cases the weighting functions can be established a priori. Normally however a neural network goes through a training phase in which input signals representing a number of training patterns for the types of items to be classified for example the pixel patterns of the various hand written characters in the character recognition example are applied to the input terminals and the output signals from the processing nodes are tested. Based on the pattern of output signals from the processing nodes for each training example the weighting functions are adjusted over a number of trials. After the neural network has been trained during an operational phase it can generally accurately recognize patterns with the degree of success based in part on the number of training patterns applied to the neural network during the training stage and the degree of dissimilarity between patterns to be identified. Such a neural network can also typically identify patterns that are similar but not necessarily identical to the training patterns.

One of the problems with conventional neural network architectures as described above is that the training methodology generally known as the back propagation method is often extremely slow in a number of important applications. In addition under the back propagation method the neural network may result in erroneous results that may require restarting of training. Even after a neural network has been through a training phase confidence that the best training has been accomplished may sometimes be poor. If a new classification is to be added to a trained neural network the complete neural network must be retrained. In addition the weighting functions generated during the training phase often cannot be interpreted in ways that readily provide understanding of what they particularly represent.

Edwin H. Land s Relinex theory of color vision is based upon three color experiments performed before 1959. A simple mishap showed that three colors were not always required to see accurate color. Land used a short and long record of brightness data black and white transparencies to produce color perceived by human eyes and not by photographic means. He demonstrated a perception of a full range of pastel colors using two very similar in color light sources such as yellow at 579 nm and yellow orange at 599 nm Experiments in Color Vision Edwin H. Land Scientific American Vol. 200 No. May 5 1959 . Land found that in some two record experiments all colors present were not perceived. Although Land demonstrated that two records provided color perceptions he constructed his Retinex theory upon three records such as his long medium and short records An Alternative Technique for the Computation of the Designator in the Retinex Theory of Color Vision Edwin H. Land Proceedings of the National Academy of Sciences Vol. 83 1986 . The invention herein is related to human color perception discovered during Land s color vision experiments as reported in 1959.

The Trichromatic theory in human color vision has been accepted on and off since the time of Thomas Young in 1802 A Vision in the Brain S. Zeki Blackwell Scientific Publishing 1993 . Still and video electronic camera designs are correctly based upon the trichromatic theory but the current designs are highly subjective to color error reproduction due to changes in the ambient light color temperatures and color filtrations. The device in this invention senses color using a new bichromatic theory which includes a mechanism that insures color constancy over a large range of ambient color temperatures. The use of two lightness records as used by Land in 1959 is one key to this invention.

The bichromatic theory is based upon an interpretation of a biological color process that occurs in the eyes and brain of humans and in some animals. The bichromatic theory is defined as a system that functions together under the following assumptions accepted principles and rules of procedure for which are provided for support 

It is therefore an object of the invention to provide a new and improved neural network color sensor.

It is a further object to provide a neural network color sensor in which the weighting functions may be determined a priori.

Another object of the present invention is to provide a neural network color sensor which can be trained with a single application of an input data set.

In brief summary the color sensor generates color information defining colors of an image comparison of colors illuminated under two or more light sources and boundaries between different colors. The color sensor includes an input section a color processing section a color comparison section a color boundary processing section and a memory processing section. The input section includes an array of transducer pairs each transducer pair defining one of a plurality of pixels of the input section. Each transducer pair comprises at least two transducers each generating an output having a peak at a selected color the selected color differing as between the two transducers and each transducer having an output profile comprising a selected function of color. The color processing section includes a plurality of color pixel processors each receiving the outputs from the two transducers comprising the transducer pair associated with a pixel. In response the color processing section generates a color feature vector representative of the brightness of the light incident on the pixel and a color value corresponding to the ratio of outputs from the transducers comprising the transducer pair associated with the pixel. The color boundary processing section generates a plurality of color boundary feature vectors each associated with a pixel each representing the difference between the color value generated by the pixel color processor for the respective pixel and color values generated by the pixel color processor for pixels neighboring the respective pixel.

The color boundary sensor produces object shape feature vectors from a function of the differences in color. This color boundary sensor can sense a colored object shape in a color background where a black and white sensing retina could not detect differences in lightness between the background and the object. The color comparator processor can measure and compare the reflective color of two objects even when each object is illuminated by two lights of different color temperatures. The memory processor section provides a process to recognize a color a boundary of color and a comparison of colors.

With reference to the color sensor includes an input section a color processing section and a color boundary processing section a color comparison processor and a memory processor . The color processing section and a color boundary processing section both generate color and color boundary feature vectors which may be provided to for example a memory processing section . The input section receives an image of an object and generates for each point or pixel color information signals representative of the color at the particular point of the image. The input section includes a retina which comprises an array of transducer pairs through M generally identified by reference numeral m and shown in the expanded view of FIG. A which define the pixels of the image. Each transducer pair comprises two transducers which have output peaks at two different frequencies and which provide a predetermined output value as a function of a color wave band. Preferably all of the pixels will have one transducer m which has a peak output at one frequency identified as and the second transducer m having a peak output at a second frequency identified as . The input section further includes a lens which focuses an image of the object onto the retina and an iris which controls the intensity of light incident on the retina .

The color processing section uses the color information signals from the input section to generate for each pixel a local color feature vector representative of the color of the pixel. The color processing section consists of a color processor array and a feature fusion network array . The structure and operation of the color processing section will be described in detail below in connection with FIG. . Similarly the color boundary processing section generates for each pixel a local color gradient feature vector that represents the gradient of the color at the pixel. The structure and operation of the color boundary processing section will be described in detail below in connection with FIG. . The memory processor is as described in STATIC MEMORY PROCESSOR U.S. patent application Ser. No. 09 477 638. The parallel memory processors and are as described for the memory processor of the MULTIMODE INVARIANT PROCESSOR U.S. patent application Ser. No. 09 641 395 . The multi mode invariant image processor without its input sensor is used for both parallel memory processors and . The possible multiple outputs of the parallel memory processor are the colored input object s classifications. The output vector array of the parallel memory processor is a Positional King Of the Mountain PKOM array mapped to the pixels m in the retina which becomes a map of color classifications of each pixel. It is noted that the PKOM array is a neural network array internal to the parallel memory processor and the remaining neural circuits to the normal output of the MULTIMODE INVARIANT PROCESSOR are not used. The memory processor is a static memory processor and provides an output classification as a degree of color comparison.

The local color feature vectors and the local color gradient feature vectors generated for all of the pixels are processed by the processing section to for example classify the image into one of a plurality of image classes. The processing section may comprise any of a plurality of processing elements for processing the vectors generated by the color processors and or .

Each pixel color processor m includes controlled gain amplifier CGA circuits m m which receive the color amplitude signals generated by the respective transducers m m . Each CGA circuit m m generates an output adjusted by a gain control factor generated by the common control . The gain control factor is a function of the output of the transducer for each frequency having the highest amplitude referred to as H and H . The CGA circuits m m will normalize the respective outputs in relation to the highest amplitude output for their respective frequency. This allows each transducer pair m and their respective CGA circuit m to output differing values which represent the color at each transducer pair m as well as the color temperature of the light incident on the object or retina . The common control senses all transducer outputs for each frequency and uses the highest outputs H H to set each CGA circuit m in the color processor to the same gain as the CGA circuits H H from the pixel s m that sensed the highest light energy in retina . The transducers H H the CGA circuits H H and the common control operate as an automatic gain controlled loop normalizing the output signal at CGA circuit H . Therefore the response of each transducer m is normalized at the output of each CGA circuit m relative to the output of CGA circuit H . It is to be noted that the transducers H H need not be from the same pixel m as the spectral light energy of a visual scene image at two separate frequencies is generally not the same everywhere on retina .

The gain controlled output of each CGA circuit m m is provided to a number of elements including a respective sum circuit m a difference circuit m and the common control . The outputs from the CGA circuits m m are coupled to the difference circuit or difference generator m which generates an output vector that is representative of the difference between the amplitudes of the outputs form the CGA circuits m m . Accordingly it will be appreciated that the output generated by the difference generator m corresponds to the ratio of the amplitudes of the automatic controlled gain signals from the respective transducers H H and the respective pixel transducer m outputs.

As noted above the outputs from the CGA circuits m and m are also coupled to a sum circuit m . The sum circuit m generates an output that corresponds to the sum of the amplitudes of the automatic controlled gain signal from the respective transducers m and m and thus represents the brightness of the light incident on the pixel defined by the transducers.

The output vector from difference circuit m is coupled to the color boundary processor FIG. . The difference vector from difference circuit m and the brightness vector from sum circuit m are also both coupled to a neural director m that disperses these inputs into a local color feature vector. The neural director m is preferably similar to the neural directors as described in NEURAL DIRECTOR U.S. patent application Ser. No. 09 436 957. Neural director m is preferably established to provide an output vector with an increased dimensionality which will aid in distinguishing between similar patterns in the input vector.

The output of the neural director m is coupled to bipolar MKOM m which is described in detail in STATIC MEMORY PROCESSOR U.S. patent application Ser. No. 09 477 638. The bipolar MKOM m generates a number of positive and or negative outputs M through M R generally identified by reference numeral M r each of which is associated with one dimension of the feature vector input thereto. Each positive component M r of the output vector can have a range of values from zero up to a maximum value which corresponds to or is proportional to the maximum positive element value of the input vector. The positive outputs M r that are associated with an input vector component having successively lower positive values are themselves successively lower in value thus forming a positive ranking of the vector components. Outputs M r that are associated with input vector components having negative values are also ranked as negative vector components in a similar manner to the positive components. The rankings for the respective input feature vectors may be global for all of the components of the input feature vector or they may be localized among a selected number of preferably contiguous input feature vector components. The feature vector generated by the bi polar MKOM m is coupled to the memory processing section .

The outputs from CGA circuits m and m of all of the pixel color processors m are also coupled to the common control . The common control includes peak sensing circuits each of which receives the output from the correspondingly indexed CGA circuits m m and each generates an output which corresponds to the one of the outputs from the correspondingly indexed CGA circuits m m with the largest signal value. The outputs from the peak circuits are also connected to control the gain of all of the correspondingly indexed CGA circuits m m .

The outputs from the CGA circuits m and m of all of the color pixel processors m are also connected to a sum circuit . The sum circuit generates an output which represents the sum of the outputs from all of the CGA circuits m m of all of the color pixel processors m . The output provided by the sum circuit represents the total intensity or power of the light incident on the retina . An iris control circuit uses the sum circuit output to control the iris which normalizes the intensity of the light on retina .

Each window difference network m receives a local window array m of difference vectors generated by the correspondingly indexed pixel color processor m . Each window difference network m in turn generates an output vector which represents a color acceleration vector between the difference vectors provided by the correspondingly indexed pixel color processor m and color vectors for pixels within a predetermined area around the pixel m illustrated in as local window m . Local window m may consist of any chosen pattern of pixels surrounding pixel m . e.g. a star pattern or a box pattern. Each neural director m receives the color acceleration vector from the correspondingly indexed window difference network m . As with neural director m each neural director m is preferably established to provide an output local color boundary feature vector with the same or an increased dimensionality which will aid in distinguishing between similar patterns in the input vector.

In a modification to the invention each pixel can be a three transducer set m . Each transducer of the set m is to be matched to the response of the human retinal color cones. The three transducer set m will produce two transducer pairs for each pixel m and with two color processors a color retina will be produced. The retina and two parallel memory processors will sense color matched to the human color perception over a wide range of ambient lighting conditions.

With reference again to the local color feature vectors generated by the pixel color processing section an array of color comparators and the local color boundary feature vectors generated by color boundary processor for all of the pixels m are coupled to the memory processing section . The memory processing section may perform a variety of individual or combined operations in connection with the feature vectors input thereto including object recognition and the like based on preselected object classification patterns or the like.

The invention provides a number of advantages. In particular the invention provides a system for receiving an image of an object and generates for an array of pixels of the image color and color gradient boundary information in the form of feature vectors which may be processed to for example classify the object into one of a plurality of object classes. The system generates the color and color gradient boundary information using only two transducers for each pixel in accordance with a bi chromatic color recognition scheme with the transducers having peak responses at selected colors and and a known output profile as a function of color instead of the non color constancy process produced in accordance with the tri chromatic color recognition scheme.

It will be appreciated that numerous modifications may be made to the system . For example the memory processing section may perform processing in connection with comparisons generated for two images using output color feature vectors generated either by the same color sensor at two points in time or output comparator vectors which are generated by two color sensors the second being denoted by and for respective pixels m for respective images. In that case and with reference to the color processing section in particular the pixel color processors m may provide outputs for the two images to the respective difference circuits m m of color comparison processor each of which generates a difference vector representing the difference between the difference vectors and brightness vectors generated by the color processors for the respective images. The difference vectors of m and m are input to comparator feature fusion network array which operates in a manner similar to feature fusion network array . Similar difference circuits not shown may also be provided for the local color boundary feature vectors generated by the color difference processors for the respective images.

In addition the peak detector circuits of the common control may be replaced with summing circuits that generate a sum output for controlling the CGA circuits m m .

Preferably the iris control will generally rapidly adjust the iris in response to changes in the light intensity levels incident on the retina so as to maintain the light levels incident on the transducers within a predetermined operating range. In that case the CGA circuits m m may have a relatively slower response to changes in the automatic gain control signals from the control circuit . These differences in response will allow the slower response of normalization via the CGA circuits to maintain a steady color constancy in a scene of rapid brightness changes.

The described components of invention provide the necessary components for a uniquely designed photographer s exposure and color temperature meter. A calibration of the common control network provides values for exposure and color temperature data. The meter may be an independent device i.e. a hand held meter or it may be integrated in a camera body either electronic or film to provide automatic exposure and color temperature corrections. The device may also be integrated into color printers or printing presses as a color ink control.

It will be apparent that variations and modifications may be made to the invention herein described and illustrated by those skilled in the art with the attainment of some or all of the advantages of the invention. It is also understood that the color sensor described herein may be connected to the various devices described in the referenced patent applications wherein all the devices act in concert in a manner similar to the human eye. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

