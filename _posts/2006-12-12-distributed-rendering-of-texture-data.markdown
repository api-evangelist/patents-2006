---

title: Distributed rendering of texture data
abstract: A method and apparatus for distributing the workload of rendering an image where texture mapping is involved among multiple graphics processing units (GPUs) are provided. The method generally entails dividing a texture map among multiple GPUs, performing texture mapping in each GPU to render image data in each GPU's frame buffer, combining the image data from each frame buffer, and scanning out the combined image to a display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07969444&OS=07969444&RS=07969444
owner: NVIDIA Corporation
number: 07969444
owner_city: Santa Clara
owner_country: US
publication_date: 20061212
---
Embodiments of the present invention generally relate to graphics processing and more particularly to rendering images on systems with multiple graphics processing units GPUs .

Computer graphics image data typically undergoes several processing steps before each graphics frame is completely rendered for display or storage. Each processing step typically operates on graphics image data utilizing programming steps defined through an application programming interface API enabling the graphics application to utilize high performance hardware such as a graphics processing unit GPU to execute a set of processing steps with minimal real time supervision from a host central processing unit CPU . For example a software application executing on the host CPU may use an API to program processing steps in a GPU including physics geometric transform polygon setup rasterization and pixel shading resulting in the generation of complex graphics image frames for display or storage with minimal impact on the host CPU performance.

Historically computing devices have included only one GPU that was responsible for both processing graphics commands and displaying the resulting images. With only one GPU questions about how to distribute work among multiple processing devices never really arose. However as graphics applications begin to implement more steps with greater complexity in each step the computational load on the GPU executing the processing steps increases resulting in diminished overall rendering performance.

One approach to improving overall processing time has been to configure multiple GPUs to concurrently process a single graphics frame or assign multiple GPUs to process alternating graphics frames. Such approaches generally involve synchronizing the GPUs to simultaneously render portions of the same frame or sequential frames to increase overall rendering performance. However in current systems where multiple GPUs concurrently process a single frame the graphics application has no way to inform the GPUs of the spatial locality of the processed image data. All of the rendered data from each GPU has to be copied to all of the other GPUs to form a combined image thereby limiting the overall system performance. This applies in particular to generating texture data at run time by sending rendering commands to the GPUs that store the rendering results in the texture map memory storage. Several common usage patterns of rendering texture data imply that sections of the texture data are only accessed by a subset of GPUs so not all of the rendered texture data has to be copied to all other GPUs.

Accordingly what is needed is an improved method of rendering texture data in a multi GPU system with enhanced system performance.

One embodiment of the present invention is a method for distributed rendering of texture data in a plurality of graphics processing units GPUs . The method generally includes dividing a texture map into a plurality of texture map sections wherein each texture map section is associated with one of the plurality of GPUs performing texture mapping in each of the plurality of GPUs with the associated texture map section to render image data in a frame buffer corresponding to each GPU and combining the rendered image data from each of the GPUs where the size of the texture map is related to the size of the combined image by a scaling factor.

Another embodiment of the present invention provides a graphics processing system for distributed rendering of texture data from a texture map. The graphics processing system generally includes a plurality of GPUs wherein each of the plurality of GPUs is configured to perform texture mapping on a texture map section from the texture map to render image data without replicating the rendered image data to the other GPUs in the plurality and a means for combining the rendered image data wherein the size of the texture map is related to the size of the combined image by a scaling factor.

Yet another embodiment of the present invention provides a computing system for distributed rendering of texture data from a texture map. The computing system generally includes a central processing unit CPU subsystem for running a graphics application a plurality of GPUs coupled to the CPU subsystem wherein the graphics application utilizes an application programming interface API to control the plurality of GPUs such that each of the plurality of GPUs performs texture mapping on a texture map section from the texture map to render image data without replicating the rendered image data to the other GPUs in the plurality and a means for combining the rendered image data to form a frame requested by the graphics application.

Embodiments of the present invention provide techniques and corresponding apparatus for distributing the workload of rendering an image where texture mapping is involved among multiple graphics processing units GPUs . The techniques generally entail dividing a texture map among multiple GPUs performing texture mapping in each GPU to render image data in each GPU s frame buffer combining the image data from each frame buffer and scanning out the combined image to a display.

An application programming interface API layer may provide a set of procedural entry points also known as API calls for the graphics application to access underlying resources in the computing system such as the GPU driver . The API calls may include without limitation functions to generate the sequence of rendered frames on the GPUs . The graphics application may convey data related to generating the sequence of frames to the API layer via API calls.

The API layer may process the API calls creating without limitation any resulting data and stored state useful in implementing the API calls. The API layer may further process the API calls and convey frame and control data via a sequence of calls to the GPU driver . The GPU driver may transmit rendering commands to the GPUs over a system interconnect such as a high speed bus. For some embodiments the computing system may employ more than one GPU driver each driver managing either one or multiple GPUs.

Each GPU may be coupled to a locally attached frame buffer memory respectively. The frame buffer memory may be utilized when performing texture mapping operations at run time. For some embodiments the frame buffer memory may be embedded in the GPU. The frame buffer memory may have a portion reserved for rendered data respectively. Another portion of the frame buffer memory may be reserved for a fractional frame a portion of a complete frame to display a scene respectively. Fractional frames are described in more detail below.

Although not shown in a display may be attached to the computing system and associated with the multiple GPUs for displaying images scanned out from the multiple fractional frames in frame buffer memory . The display may be a cathode ray tube CRT a liquid crystal display LCD a plasma display or any other appropriate display device.

Methods described herein may distribute the rendering workload among multiple GPUs using any suitable techniques. One method of distributed rendering according to embodiments of the invention may be similar to a multi GPU rendering technique known as Split Frame Rendering SFR . In SFR each GPU manages and renders a different fraction of the image i.e. a group of spatially coherent pixels usually horizontal strips or rectangular groups of pixels in an effort to distribute the workload of rendering an image thereby increasing the performance of the multi GPU system. However unlike conventional rendering methods the texture data processed within a particular GPU is not replicated for the other GPUs to have access to each texel of every texture map according to embodiments of the invention. As used herein the term texel or texture element generally refers to the fundamental unit of a texture map analogous to a pixel within a displayed image.

In step within each GPU texture mapping of the corresponding texture map section to an associated portion of a destination image may occur resulting in rendered data and a fractional frame . Additional post processing such as filtering or interpolation may also occur within each GPU . The fractional frame may be stored in a frame buffer associated with or embedded within the GPU and may represent a spatially coherent portion of the pixels constituting an image to be displayed.

In this manner each GPU is responsible for only one of the texture map sections and for the corresponding portion of the destination image thereby leading to a shared workload and enhanced system performance. In addition for a four GPU system as described approximately only 25 of each GPU s frame buffer memory that was conventionally required is utilized leaving about 75 to be allocated for other purposes if desired. For spatially distributed rendering performed according to embodiments of the invention there should be no interaction between for example the uppermost portion of the rendered destination image and the bottommost portion and therefore there should be no need to copy rendered data from one GPU to all the other GPUs as was done conventionally.

In one approach to prevent such copying and control the GPUs through the GPU driver s in accordance with embodiments of the present invention an extension to the OpenGL API may be written. Such an extension may permit the graphics application to provide important information hints to the graphics system which may allow for alternatives in situations where the application has potentially more information about multi GPU relevant usage patterns than simply the distributed rendering of texture data. As used herein a hint is generally not a graphics command to control multi GPU rendering but the hint may provide information about the type of expected graphics usage such as the expected optimal scaling paradigm or the lifetime of buffer object storage data. The graphics system may decide how to apply the hint.

For distributed rendering of texture data to apply in an optimal manner according to embodiments of the invention a texture map may preferably be roughly the identical size or a scaled version of the destination image i.e. the portion of the rendered scene to which the texture is applied as shown in . Also to apply the texture map or subdivisions thereof may preferably be mapped on to the destination image as a rectangle where each corner vertex may be mapped onto the same corner vertex of the destination image or subdivisions thereof in image space. With these conditions met the texture map may be rendered onto the destination image such that there is for the most part no data dependency across multiple GPUs between texels of the texture and pixels in the destination image .

However an overlap may be defined where texels of the texture map are shared between adjacent texture map sections usually within a specified small region. Such overlaps may provide for data dependencies between the texels and pixels at the border between adjacent parts adjacent texture map sections or adjacent portions of the subdivided destination image . In such cases whichever GPUs are responsible for the overlap may perform post processing e.g. filtering and interpolation for smoothing blending etc. as mentioned above in an effort to resolve pixels at the edge of the split between adjacent parts.

Once the different portions of the destination image have been rendered in the multiple frame buffers the image data may be combined in step . For some embodiments the combination may occur on a video bridge a bus that connects the GPUs together and is used for transferring data from the frame buffer of one GPU directly to the next. The individual GPUs may broadcast or post their image data to the video bridge . For other embodiments one of the multiple GPUs may be designated to combine the image data and form the destination image. After the various parts of the frame are combined the completed image data may be written to a visible buffer and or scanned out to a display in step .

It should be mentioned that for subsequent images involving the same texture map each GPU may process the same texture map section and contribute to the same portion of the destination image. For example GPUmay continually operate on texture map section thereby continually contributing to the bottommost portion of the display .

Spatially distributed rendering of texture data as described herein may be combined with other multi GPU rendering techniques. One particularly efficient technique in the art for utilizing more than one GPU is referred to as alternate frame rendering AFR . This technique distributes the workload for sequential frames to alternating or sequential GPUs. For example if the computing device includes three GPUs then rendering frame N may be assigned to GPU rendering frame N 1 may be assigned to GPU rendering frame N 2 may be assigned to GPU rendering frame N 3 may be assigned to GPU and so forth. The workload for sequential frames tends to be relatively consistent in most graphics applications and therefore alternate frame rendering achieves good efficiency by evenly distributing the average workload across the multiple GPUs.

To combine AFR with spatially distributed rendering of texture data eight different GPUs could be used for example. Rendering frame N may be assigned to GPUs and in this case where the texture map was split between these four GPUs and rendering frame N 1 may be assigned to GPUs and . GPUs and for instance may render the same portion of the alternate frames in this example. Rendering frame N 2 may be assigned to GPUs and and so forth.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

