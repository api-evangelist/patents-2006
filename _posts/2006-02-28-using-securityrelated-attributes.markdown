---

title: Using security-related attributes
abstract: Described is a technology including an evaluation methodology by which a set of privileged code such as a platform's API method may be marked as being security critical and/or safe for being called by untrusted code. The set of code is evaluated to determine whether the code is security critical code, and if so, it is identified as security critical. Such code is further evaluated to determine whether the code is safe with respect to being called by untrusted code, and if so, is marked as safe. To determine whether the code is safe, a determination is made as to whether the first set of code leaks criticality, including by evaluating one or more code paths corresponding to one or more callers of the first set of code, and by evaluating one or more code paths corresponding to one or more callees of the first set of code.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07926105&OS=07926105&RS=07926105
owner: Microsoft Corporation
number: 07926105
owner_city: Redmond
owner_country: US
publication_date: 20060228
---
In contemporary computing computer application programs and other code may be downloaded and installed from the Internet. This leads to potential problems in that untrusted sources such as the Internet often provide code that is intentionally malicious or otherwise capable of harming or providing unauthorized access to important data. However because there are many situations in which computer users benefit from the ability to download code and execute code without prompting completely preventing downloading is not a practical solution to this problem.

One solution to this problem is referred to as sandboxing a generic security term that applies to any environment that reduces the privileges under which an application runs. It is particularly valuable to sandbox applications downloaded from the Internet as they tend to come from unknown or untrusted sources.

Some environments such as one based on Microsoft Corporation s Windows Presentation Foundation and .NET technologies attempt to solve the problems of running untrusted code via a sandbox model that limits what the untrusted code has permission to do. For example the underlying platform can require that its callers have specific permissions and while code can request the permissions it needs for the execution the runtime will only grant permission based on policy that evaluates how much the code is trusted. Such permissions include things like the ability to access files and databases connect to the Internet interact with the user via a user interface call into unmanaged code and so forth. One policy based solution is to prompt the user when code requests such permissions however this solution is not very desirable because a typical user is often not equipped to make a correct security decision when prompted.

As can be readily appreciated writing secure code for platforms that enable applications to be downloaded and installed from the Internet without prompting is an extremely difficult problem. This is because the platform itself needs to have elevated privileges to properly operate. Security flaws can exist if any part of the platform code is written such that it inadvertently exposes an internal way to run untrusted code with elevated permissions privileges that is allow the untrusted code to do something beyond what would otherwise be allowed via its reduced permission set because this would allow the untrusted code to perform unsafe operations. By way of example the platform code needs to be able to call unmanaged code for operating system services such as to render text on a window while untrusted code is not allowed to do so however if the platform code is inadvertently written such that the untrusted code can call unmanaged code via a call to a internal method of the platform code a security flaw exists.

One solution that increases the likelihood that platform code is securely written is to allow the developer to mark e.g. using metadata any part of the platform code that requires elevated permissions to run or mark code that controls whether elevated permissions can be run. In general the metadata indicates that the marked set of platform code is critical code that performs a dangerous operation. Security teams and static code analysis tools e.g. FxCop is one such code analysis tool that checks .NET managed code assemblies then recognize the metadata whereby platform features can be developed so that the likelihood of platform code running with elevated privileges being exposed to untrusted code is dramatically reduced.

However while highly valuable the marking of such code and data as critical results in a complex code review process that burdens a security team with many critical methods that need to be code reviewed.

This Summary is provided to introduce a selection of representative concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used in any way that would limit the scope of the claimed subject matter.

Briefly various aspects of the subject matter described herein are directed towards a technology by which a set of privileged code such as a platform s API method may be marked as being security critical and or safe for being called by untrusted code which for example may include code that the user has not explicitly trusted to run and have access to the user s machine e.g. a random site on the internet that does not require a prompt. Trusted code comprises code that the user has explicitly e.g. through a prompt for that specific application or publisher or the like given permission to run install on the machine . The set of code is evaluated to determine whether the code is security critical code and if so it is identified as security critical. Such code is further evaluated to determine whether the code is safe with respect to being called by untrusted code and if so is marked as safe. For example method code may be considered safe when its inputs may be considered safe when its returned values are not unsafe values e.g. are non critical data and when the API is otherwise safe e.g. does not perform operations known to be unsafe .

To determine whether the code is safe with respect to being called by untrusted code a determination is made as to whether that code leaks criticality including by evaluating one or more code paths corresponding to one or more callers of the first set of code and by evaluating one or more code paths corresponding to one or more callees of the first set of code. For example criticality may be leaked by passing or otherwise providing access to critical data to a callee of the method when that callee in turn stores or leaks critical data without safely brokering access to the critical data.

Other advantages may become apparent from the following detailed description when taken in conjunction with the drawings.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices tablet devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures and so forth which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in local and or remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of the computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

The computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by the computer and includes both volatile and nonvolatile media and removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by the computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media described above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers herein to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a tablet or electronic digitizer a microphone a keyboard and pointing device commonly referred to as mouse trackball or touch pad. Other input devices not shown in may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . The monitor may also be integrated with a touch screen panel or the like. Note that the monitor and or touch screen panel can be physically coupled to a housing in which the computing device is incorporated such as in a tablet type personal computer. In addition computers such as the computing device may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface or the like.

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It may be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

In general a codebase such as platform code can be partitioned into a critical core that reduces the burden of security auditing and increase the probability that a platform is secure. The technology described herein is generally directed towards a technology by which a set of code e.g. a given method API and its code paths e.g. other methods that call the set of code or other methods that the set of code calls may be evaluated to determine whether the code is critical and if so whether the set of code can be treated as safe with respect to allowing its being called by untrusted code. For example code corresponding to an application programming interface API may be deemed by an evaluation methodology possibly using an analysis auditing tool to be transparent whereby the code need not be heavily audited and can be called by an untrusted caller. In general the only interfaces called by untrusted code are those marked public however other code that is trusted but unaudited also may be called. Such unaudited code should be considered by developers as being untrusted and thus as used herein untrusted code also refers to unaudited code.

Alternatively a method is deemed critical when it elevates privileges and or performs certain operations such as those that return store or provide access to critical data in which event the code may be tagged with metadata as needing to be heavily audited. A method is also deemed critical at times when it makes decisions about a behavioral difference from a security standpoint. In general the metadata indicates that the marked set of platform code is critical code that performs a dangerous operation or calls into something that performs a dangerous operation and is not marked TreatAsSafe.

This is done to ensure that any changes to this code are also audited. Although critical there is still a possibility that such a method may be treated as safe including safe for being called by an untrusted caller if the method does not have unsafe or validates inputs e.g. dealing with critical parameters does not work with unsafe values e.g. return or store critical data and is otherwise safe. In other words a critical method may be safe in the event that its criticality does not leak out or up to transparent code and or untrusted callers. One way criticality can be leaked is by providing access to data that required an elevation of permissions to obtain.

In general the technology described herein is primarily described with reference to an example Windows Presentation Foundation managed code environment including code access security a .NET framework and a common language runtime that provide a secure execution environment for untrusted or partially trusted code such as Web Browser Applications e.g. having a .xbap extension . This technology also extends to XPSDocuments and .XAML files. As will be understood however such technology may be implemented in other sandbox type environments and thus may be used various ways that provide benefits and advantages in computing in general.

As mentioned above it is possible that critical code may be called by untrusted code as long as the critical code has certain characteristics by which the critical code may be deemed safe. Among these characteristics is that the overall functionality of the critical code is itself safe. Another characteristic is that any caller untrusted or otherwise can safely call the critical method e.g. so that the called method s criticality cannot leak out to such callers. Still another characteristic is that the critical code does not call any other code any callee to which the calling code passes critical data and to which it in turn leaks out that data to untrusted non critical callers. If these characteristics are not present the method cannot be deemed safe.

Other methods that are represented in include callers A J that form code paths that need to be reviewed including direct callers I and J that may need to be evaluated to determine whether any one of them causes a criticality violation that would prevent the method from being marked as safe and callees X and Y that also need to be evaluated along with any code paths to which they belong.

In general and as described below the method has its own code evaluated for criticality and for whether it can be treated as safe for being called by untrusted callers. If so then the method may be marked as safe e.g. tagged with a TreatAsSafe attribute . To determine this the code path s of the method are reviewed e.g. those of callers I and J . This is generally referred to as reviewing up where the upward direction is arbitrarily defined as in such that callers are above callees reviewing up determines the criticality of the callers and helps determine a new treat as safe boundary if the current method cannot be one. Similarly the downward code path s to the callees of the method are reviewed reviewing down determines the criticality of the callees to ensure that no critical data is leaked out.

While evaluating its callers and callees if a trust boundary is reached in that a caller or callee is already marked as TreatAsSafe then that code path is considered safe and need not be evaluated further. For example in the E method is marked TreatAsSafe TAS and thus a trust boundary is reached on this path whereby methods A and B and any other higher methods that call them need not be evaluated as that particular code path is known safe. Note that some methods that are marked TreatAsSafe are because they will throw a security exception if the appropriate permissions are not available. This is also a viable TreatAsSafeBoundary.

In addition the code developer may mark a certain function method as specifically not being enabled in a sandbox environment e.g. via a demand attribute or a link demand or an explicit demand in the code as represented in by the method C . In such a situation there is no reason to evaluate that path since this calling path will otherwise not be allowed and thus its callers need not be evaluated. This function can essentially be considered treat as safe from the perspective of the method .

Turning to an explanation of the operation of such technology in one example implementation shows the reviewing of code following the initial security exception that that is thrown when some code attempts to do something that it does not have the required permission to do. For example in a Windows Presentation Foundation environment when such a situation occurs the demand fails and the .NET Framework runtime throws a SecurityException.

To locate such potential security flaws a developer of a platform method may intentionally request some action be taken through the method that a requesting sandboxed program does not have permission to do such as to write something to the file system and thus cause a security exception. In general this will start the analysis logic of . Note that in addition to attempted file system reads or writes by some code other examples of actions that will cause a security exception may include attempted reads or writes to a system registry or attempts to call native operating system e.g. Win32 functions.

Step of represents reviewing the method including reviewing it to determine as represented via step whether the code corresponds to an added elevation. Note that step represents determining via a helper class whether the piece of code being evaluated may be refactored into smaller pieces e.g. functions such as to break dangerous operations into smaller isolated functions and determine whether those functions are able to contain the criticality and return safe data whereby those smaller pieces may be marked treat as safe. However for purposes of this example this step may be considered optional or already performed with respect to the code being evaluated.

In the event that there is no elevation being performed step branches to step where the method API in this example can be considered not part of this sandbox. This situation may be documented e.g. in a sandbox specification.

If the method elevates step branches to step where the API is considered part of the sandbox and is marked with a security critical e.g. SecurityCritical attribute tag at step . The method is then further evaluated to determine whether it is safe that is whether it contains its criticality is safe or leaks any of its criticality is not safe to other methods.

Step evaluates the method including whether its inputs e.g. params class fields and so forth may be considered safe whether its returned values are non critical and whether the API is otherwise safe. If so step branches to step where the method is marked as safe e.g. via a TreatAsSafe tag. Note that the evaluation process may continue to evaluate its callees as represented via .

If not safe at because it may leak its criticality the process branches to step of to evaluate the criticality of this method s callers. Essentially this branch corresponds to the reviewing up part of the evaluation wherein each upward code path the method s callers and any caller s callers and so forth may be exploded into it various callers with each caller recursively evaluated for safety.

In general step represents determining each of the primary method under test API s direct callers with step representing the test that ends this reviewing up process when all callers have been examined. Step selects an unexamined caller as a currently selected caller and adds the security critical tag to the currently selected caller as this caller is calling a security critical method as previously determined at step of .

Steps and perform an analysis on the caller similar to that described with reference to and indeed can recursively reuse at least part of the evaluation process described with reference to . Note that step recursively reuses the code of so that each of the currently selected caller s callers are likewise examined. In this manner each code path is evaluated in a reviewing up process that is each caller and its callers are examined and tagged as appropriate unless a code path is stopped via a caller having a demand or treat as safe tag already present . In the event that the callers can not be marked as treat as safe the API is not available in this sandbox.

To this end evaluates for each callee step whether that callee receives or accesses critical data step and if so whether the critical data is stored or leaked by the callee step . Note that critical data is tagged as such by the developer and thus is readily identifiable. In the event that the critical data is not stored or leaked step is performed to confirm that this callee s usage of the critical data is indeed innocuous which may include identifying the callee code for further audit.

Returning to step if the critical data is stored or leaked step is instead executed which represents encapsulating the data e.g. in a security critical data container as described in U.S. patent application Ser. No. 11 051 808 filed Feb. 4 2005 assigned to the assignee of the present invention and hereby incorporated by reference and refactoring. Step represents confirming safe usage e.g. via an audit and step adds a security critical tag to this current callee being evaluated.

Step evaluates the API may be marked with the TreatAsSafe tag and if not the process explodes this callee s callers and evaluates them using the process described above with respect to . In any event this callee s callees are also evaluated e.g. recursively via the code of as represented via step .

In this manner a decision process as to when to mark a set of code e.g. a method as SecurityCritical and or SecurityTreatAsSafe is realized. The process thus helps in developing secure code including by identifying potential or actual security flaws.

While the invention is susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the invention to the specific forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention.

