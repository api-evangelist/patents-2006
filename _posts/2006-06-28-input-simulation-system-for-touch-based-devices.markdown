---

title: Input simulation system for touch based devices
abstract: Performance of automated touch data injection into a stack of software objects is provided. Previously stored data from a touch data file is received and transformed based upon a touch property. The transformed retrieved data is then injected into a lowermost layer of a stack of software objects. A computer-readable medium tool allows a user, such as a software developer, to create data that can consistently be employed to simulate the operation of movement of a user's finger across a touch input area. A buffer management module retrieves data from a touch data file. A data transformation module transforms the retrieved data based upon a touch property. A device management module injects transformed retrieved data into a human interface layer of a device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08269725&OS=08269725&RS=08269725
owner: Microsoft Corporation
number: 08269725
owner_city: Redmond
owner_country: US
publication_date: 20060628
---
Computing devices which allow a user to enter data with a stylus are becoming more and more popular. This type of computing device which includes personal digital assistants and tablet personal computers often allow a user to enter data by writing on a surface with a stylus to create electronic ink. The user moves the pen or stylus over a digitizing surface and an underlying ink enabled software platform converts the physical movement of the pen into ink strokes and eventually into groupings of handwritten words or drawings. Electronic ink is particularly convenient for users who cannot type quickly with a keyboard or when the use of a keyboard is impractical.

As the use of computers in both the workplace and home has increased so has the need to develop user friendly computers. One type of computer that creates a user friendly environment for interaction purposes is one with a digitizer such as a tablet type computer. A tablet style computer allows a user to interact with a computer as if writing on a piece of paper or other flat surface. The tablet style computer has introduced this concept of a pen as an input device and ink as a native data type in an operating system platform. Beyond pen based systems touch based input e.g. using a user s finger across a digitizer on the same platform is a logical next step.

As a user touches across the display surface of a digitizer with her finger digital ink is captured for where the user has positioned her finger. Application programs such as OneNote by Microsoft Corporation of Redmond Wash. run on an operating system. An application program takes the input strokes received from the user touching on the display surface and processes the data to perform some function. For example the input strokes may be used by an application program to produce letters and words handwritten by the user.

While touch enabled platforms and corresponding touch aware software applications and controls are becoming more common it is difficult to efficiently test these platforms and such touch aware applications and controls. Efficient testing is challenging because touching is an inherently manual process and the features of a touch input are highly dependent on the individual touching the touch input. After all a person has to move her finger around in order to drive any touch aware applications.

For example a software developer may want to test how well a soft keyboard of a tablet input panel or TIP i.e. a stand alone user interface for receiving pointer inputs may be through touch converting the input into text and then inserting the text into a target application operates with an application. In order to test the TIP the developer would need to 1 launch the application such as Notepad by Microsoft Corporation of Redmond Wash. 2 launch the tablet input panel 3 switch to a control soft keyboard that will accept input 4 touch in the desired text input such as Hello World and 5 verify that the proper text was accurately inserted into the application.

Each of steps 1 3 and 5 are straightforward and testing automation processes are well known to execute each of these steps. Step 4 however can be time consuming if manually performed especially if the software developer wishes to execute multiple e.g. more than 1 000 tests in a test pass with multiple runs of the test pass. Further if the tester wished to run different variations of the same test then the user would need to repeat step 4 even more often.

In order to make the testing of touch enabled platforms and touch aware applications and controls more efficient and reproducible it would be desirable to automate the process of creating touch input data. In this manner the same touch input data can be created for testing once and used again and again. One such technique for consistently recreating touch input data is to have a test engineer manually enter touch data into the touch enabled platform. While this approach will consistently recreate touch input data it is relatively slow difficult to employ on a large scale and resource intensive.

The following presents a simplified summary of the invention in order to provide a basic understanding of some aspects of the invention. This summary is not an extensive overview of the invention. It is not intended to identify key or critical elements of the invention or to delineate the scope of the invention. The following summary merely presents some concepts of the invention in a simplified form as a prelude to the more detailed description provided below.

Aspects of the present invention are directed to a method and media for injecting touch data into a lowermost layer of a stack of software objects. Various examples allow a user such as a software developer to create test data that can consistently be employed to simulate the operation of touch input. Moreover these examples allow the data to be used to test a variety of different types of software platforms applications and controls hereafter collectively referred to as software objects . With various implementations raw touch input data such as position coordinates pressure and finger size are captured. This raw touch input data is then later injected into a system being tested in place of touch input data from a device driver.

The raw touch input data may be captured through an application programming interface invoked by a host application such as a test software application for testing other software applications. The captured data can then subsequently be injected through another application programming interface invoked by the test application. Still other implementations may employ a special purpose tool for capturing and then injecting raw touch input data.

In the following description of the various embodiments reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration various embodiments in which features may be practiced. It is to be understood that other embodiments may be utilized and structural and functional modifications may be made.

The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with the invention include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

The invention may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to random access memory RAM read only memory ROM electronically erasable programmable read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as ROM and RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disc drive that reads from or writes to a removable nonvolatile optical disc such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disc drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a digital camera a keyboard and pointing device commonly referred to as a mouse trackball or touch pad. Other input devices may include a pen not shown stylus and tablet microphone not shown joystick not shown game pad not shown satellite dish not shown scanner not shown or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

In one example a digitizer with a touch input area and accompanying pen or stylus are provided in order to digitally capture freehand input whether with use of a stylus or by having a user directly touch the input area surface of the digitizer . Although a connection between the digitizer and the serial port interface is shown in in practice the digitizer may be directly coupled to the processing unit or it may be coupled to the processing unit in any suitable manner such as via a parallel port or another interface and the system bus as is known in the art. Furthermore although the digitizer is shown apart from the monitor in the usable input area of the digitizer may be co extensive with the display area of the monitor . Further still the digitizer may be integrated in the monitor or it may exist as a separate device overlaying or otherwise appended to the monitor .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers can be used. The existence of any of various well known protocols such as TCP IP Ethernet FTP HTTP and the like is presumed and the system can be operated in a client server configuration to permit a user to retrieve web pages from a web based server. Any of various conventional web browsers can be used to display and manipulate data on web pages.

Although the environment shows an exemplary environment it will be understood that other computing environments also may be used. For example one or more examples of the present invention may use an environment having fewer than all of the various aspects shown in and described above and these aspects may appear in various combinations and subcombinations that will be apparent to one of ordinary skill.

In various examples the system provides a touch aware platform as a set of COM component object model services that an application program can use to capture manipulate and store touch data. The touch aware platform also may include a mark up language including a language like the extensible markup language XML . Further the system may use DCOM as another implementation. Yet further implementations may be used including the Win32 programming model and the .Net programming model from Microsoft Corporation of Redmond Wash. These platforms are commercially available and known in the art.

In addition to use with full performance tablet type computing systems or tablet PCs e.g. convertible laptops or slate type tablet PCs aspects of the present invention may be used in conjunction with other types of touch aware computing systems and or other devices that accept data as touch input such as hand held or palm top computing systems personal digital assistants pocket personal computers mobile and cellular telephones pagers and other communication devices watches appliances and any other devices or systems that include a monitor or other display device and or a digitizer that presents printed or graphical information to users and or allows touch input or which can process touch input data collected by another device e.g. a conventional desktop computer that can process touch input data collected by a tablet PC .

When a user moves her finger across the touch input surface of the digitizer and with some digitizers above the surface of the digitizer the hardware driver forwards input data to the digitizer driver that creates raw touch input data. This raw touch input data may include for example the position coordinate of the tip of a user s finger relative to a coordinate axis for the digitizer . This raw touch input data may also include the pressure with which the finger presses against the touch input area of the digitizer and the size of the finger pressed against the touch input area . In a conventional implementation the digitizer driver provides this raw touch input data to the human interface device layer which is responsible for managing data generated by various input devices. For example the human interface device layer may manage data generated by various pointing devices including a mouse touchpad trackball or joystick. The human interface device layer may also manage data generated by other human interface device compliant input devices such as a keyboard or keypad.

The human interface device layer then provides the touch input data to the real time touch analysis WISP interface which converts the touch input data into electronic data. For example the real time touch analysis interface may create electronic hand strokes that correspond to sequentially detected coordinate positions of the user s finger against the touch input area . The real time touch analysis interface then provides the electronic data to the user mode application which treats the electronic touch input data as input data. Together the human interface device layer the real time touch analysis interface and the user mode application as well as any other intermediate software objects form a stack of software objects. As will now be explained in more detail the touch input data capture and injection tool captures raw touch input data from the digitizer driver and then subsequently injects the raw touch input data into the bottom of the stack through the human interface device layer and the virtual driver . Injecting the raw touch input data into the bottom of the stack ensures that the whole software stack is exercised each time as it would in normal end user scenarios. Injecting at the lowest layer in the software stack also ensures that touch data is independent of all the processing and formatting that is done by the upper layers in the platform stack.

The touch input data capture and injection tool has two operational modes a capture mode and an injection mode. These modes will now be discussed with reference to the flowcharts shown in . In the data capture mode the touch input data capture and injection tool captures raw touch input data created by moving a user s finger against or in some embodiments over the touch input area surface of the digitizer . More particularly in step the device management module obtains raw touch data from the digitizer driver through the human interface device layer .

Next in step the device management module provides the obtained raw touch data to the buffer management module . The buffer management module then stores the raw touch data in the touch data file in step . The raw touch data may be stored using any of a number of different file formats. For example the touch data may be stored in a file format specifically configured to store raw touch data. Alternately the raw touch data may be embedded within a file having another type of file format such as an extensible markup language XML file. In this manner the touch data capture and injection tool captures raw touch data for future use.

In the injection mode the touch input data capture and injection tool injects the previously captured touch data via the human interface device layer into the bottom of the stack of software objects supporting the touch aware application as previously noted. More particularly referring to in step the buffer management module retrieves previously stored touch data from the touch data file . It should be noted that various embodiments of the invention may allow the use of a variety of different touch data formats.

For example the touch data file may be created with a file format specifically configured to store raw touch data. Further in addition to a file format specifically configured to store raw touch data the touch data file may be another type of file such as an XML file containing embedded raw touch data. Alternately or additionally the touch data file may inherently store touch data in the form of electronic ink file formats. If such an alternate file format is employed then the buffer management module will convert the touch data from this alternate data format to raw touch data in step .

The buffer management module provides the retrieved touch data to the data transformation module in step . The transformation module then transforms the retrieved touch data if necessary according to desired spatial transformations in step . For example the transformation module may rotate the angle of the touch data so that e.g. the direction of electronic data generated from the touch data is angled . The transformation module may also change the scale of the touch data so that e.g. the size of electronic data generated from the touch data changes and the speed at which the touch data is injected into the software stack. The data transformation module then provides the transformed raw touch data to the device management module in step .

In step the device management module injects the raw touch data into the stack through the human interface device layer and the virtual driver . As previously noted the virtual driver is managed by the operating kernel of the computer hosting the user mode application which enables the touch data capture and injection tool to pump raw touch data into the stack of software objects at its lowermost layer. The virtual driver is similar to the digitizer driver but the virtual driver does not require a physical digitizer to function. Further the virtual driver can accept data from external sources other than the user s finger e.g. the device management module of the tool .

Manually reproducing touch scenarios is difficult since two movements even by the same person in succession cannot be guaranteed to be exactly the same. Aspects of the present invention enable reproducing the exact sequence of events each time. It not only helps to run tests in a deterministic manner but also helps in reproducing defective code paths exactly each time which is beneficial for debugging purposes.

In accordance with other aspects of the present invention touch data may be created and stored and or injected out of any input stream that can be converted into touch data. As a result a system may have touch data injected into it even without the actual touch hardware being present. For example a stream of mouse data points with respect to a display screen may be converted by adding defaults for other touch properties. An illustrative touch property includes a confidence level e.g. how likely the hardware interprets the contact to be a finger such as a highly likely to be a finger or more likely to be something larger such as a whole palm. As such when utilizing one or more of these touch properties together moving a mouse may effectively result in the system thinking that someone is moving a finger on a touch aware device.

Other illustrative touch properties include a width of a contact across a touch input surface and a height of a contact across a touch input surface. With respect to these properties some type of measurement algorithm may be used to compare a contact width and or height against a determined measurement for a finger input. Still another property includes a level of pressure force applied to a touch input surface. With such a property the amount of force applied with respect to another property such as a width of a contact may be used to test particular types of code paths that may correlate to an action in a user mode application. For example application of a level of pressure at one point on a touch input surface during a particular time with respect to a user mode application may correlate to an action to initiate an event such as launching a new window. Other properties may include a percentage of area of a touch input surface covered based upon an established threshold level detection of different fingers to test a child s contact versus an adult s contact and proximity e.g. hovering over an area of a touch input surface.

During injection mode of operation in step the buffer management module retrieves the previously stored mouse movement data from the touch data file . It should be noted that various embodiments of the invention may allow the use of a variety of different data formats. If such an alternate file format is employed then the buffer management module will convert the mouse movement data from this alternate data format to raw mouse movement data in step .

The buffer management module provides the retrieved mouse movement data to the data transformation module in step . The transformation module then transforms the retrieved movement data according to one or more desired touch properties in step . For example the transformation module may apply a variable corresponding to an amount of pressure force applied to touch input area . The transformation module may also apply a confidence level to the mouse movement data corresponding to a likeliness of the data corresponding to a finger of a user as opposed to something else such as the palm of a user s hand. Other properties may be applied alone or in combination as needed for the injection of data. The data transformation module then provides the transformed data to the device management module in step .

In step the device management module injects the transformed data into the stack through the human interface device layer and the virtual driver . As previously noted the virtual driver is managed by the operating kernel of the computer hosting the user mode application which enables the touch data capture and injection tool to pump the transformed data into the stack of software objects at its lowermost layer. Still further touch input data may be captured without a measurement of pressure width height or other properties and stored in a touch data file . Then the same previously stored data may be transformed by the data transformation module to include a touch property to apply to the data. As such layers of the software stack may be tested without need for measurements to actually be taken.

Various embodiments of the tool may be implemented as part of a testing software application being used to test the user mode application . More particularly various embodiments of the tool may be implemented using application programming interfaces invoked by a testing software application configured to test one or more operations of the user mode application .

An application programming interface or more simply a programming interface may be viewed as any mechanism process protocol for enabling one or more segment s of code to communicate with or access the functionality provided by one or more other segment s of code. Alternatively a programming interface may be viewed as one or more mechanism s method s function call s module s object s etc. of a component of a system capable of communicative coupling to one or more mechanism s method s function call s module s etc. of other component s . The term segment of code in the preceding sentence is intended to include one or more instructions or lines of code and includes e.g. code modules objects subroutines functions and so on regardless of the terminology applied or whether the code segments are separately compiled or whether the code segments are provided as source intermediate or object code whether the code segments are utilized in a runtime system or process or whether they are located on the same or different machines or distributed across multiple machines or whether the functionality represented by the segments of code are implemented wholly in software wholly in hardware or a combination of hardware and software.

Notionally a programming interface may be viewed generically as shown in or . illustrates an interface Interface as a conduit through which first and second code segments communicate. illustrates an interface as comprising interface objects I and I which may or may not be part of the first and second code segments which enable first and second code segments of a system to communicate via medium M. In the view of one may consider interface objects I and I as separate interfaces of the same system and one may also consider that objects I and I plus medium M comprise the interface.

Although show bi directional flow and interfaces on each side of the flow certain implementations may only have information flow in one direction or no information flow as described below or may only have an interface object on one side. By way of example and not limitation terms such as application programming interface API entry point method function subroutine remote procedure call and component object model COM interface are encompassed within the definition of programming interface.

Aspects of such a programming interface may include the method whereby the first code segment transmits information where information is used in its broadest sense and includes data commands requests etc. to the second code segment the method whereby the second code segment receives the information and the structure sequence syntax organization schema timing and content of the information. In this regard the underlying transport medium itself may be unimportant to the operation of the interface whether the medium be wired or wireless or a combination of both as long as the information is transported in the manner defined by the interface. In certain situations information may not be passed in one or both directions in the conventional sense as the information transfer may be either via another mechanism e.g. information placed in a buffer file etc. separate from information flow between the code segments or non existent as when one code segment simply accesses functionality performed by a second code segment. Any or all of these aspects may be important in a given situation e.g. depending on whether the code segments are part of a system in a loosely coupled or tightly coupled configuration and so this list should be considered illustrative and non limiting.

This notion of a programming interface is known to those skilled in the art and is clear from the foregoing detailed description of the invention. There are however other ways to implement a programming interface and unless expressly excluded these too are intended to be encompassed by the claims set forth at the end of this specification. Such other ways may appear to be more sophisticated or complex than the simplistic view of but they nonetheless perform a similar function to accomplish the same overall result. Some illustrative alternative implementations of a programming interface will now briefly be described.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown some interfaces can be described in terms of divisible sets of functionality. Thus the interface functionality of may be factored to achieve the same result just as one may mathematically provide 24 or 2 times 2 times 3 times 2. Accordingly as illustrated in the function provided by interface Interface may be subdivided to convert the communications of the interface into multiple interfaces InterfaceA Interface B Interface C etc. while achieving the same result. As illustrated in the function provided by interface I may be subdivided into multiple interfaces I I I etc. while achieving the same result. Similarly interface I of the second code segment which receives information from the first code segment may be factored into multiple interfaces I I I etc.

When factoring the number of interfaces included with the 1code segment need not match the number of interfaces included with the 2code segment. In either of the cases of the functional spirit of interfaces Interface and I remain the same as with respectively. The factoring of interfaces may also follow associative commutative and other mathematical properties such that the factoring may be difficult to recognize. For instance ordering of operations may be unimportant and consequently a function carried out by an interface may be carried out well in advance of reaching the interface by another piece of code or interface or performed by a separate component of the system. Moreover one of ordinary skill in the programming arts can appreciate that there are a variety of ways of making different function calls that achieve the same result.

In some cases it may be possible to ignore add or redefine certain aspects e.g. parameters of a programming interface while still accomplishing the intended result. This is illustrated in . For example assume interface Interface of includes a function call Square input precision output a call that includes three parameters input precision and output and which is issued from the 1st Code Segment to the 2nd Code Segment. If the middle parameter precision is of no concern in a given scenario as shown in it could just as well be ignored or even replaced with a meaningless in this situation parameter. One may also add an additional parameter of no concern. In either event the functionality of square can be achieved so long as output is returned after input is squared by the second code segment. Precision may very well be a meaningful parameter to some downstream or other portion of the computing system however once it is recognized that precision is not necessary for the narrow purpose of calculating the square it may be replaced or ignored. For example instead of passing a valid precision value a meaningless value such as a birth date could be passed without adversely affecting the result. Similarly as shown in interface I is replaced by interface I redefined to ignore or add parameters to the interface. Interface I may similarly be redefined as interface I redefined to ignore unnecessary parameters or parameters that may be processed elsewhere. In other words in some cases a programming interface may include aspects such as parameters which are not needed for some purpose and so they may be ignored or redefined or processed elsewhere for other purposes.

It may also be feasible to merge some or all of the functionality of two separate code modules such that the interface between them changes form. For example the functionality of may be converted to the functionality of respectively. In the previous 1and 2Code Segments of are merged into a module containing both of them. In this case the code segments may still be communicating with each other but the interface may be adapted to a form which is more suitable to the single module. Thus for example formal Call and Return statements may no longer be necessary but similar processing or response s pursuant to interface Interface may still be in effect. Similarly as shown in part or all of interface I from may be written inline into interface I to form interface I . As illustrated interface I is divided into Iand I and interface portion Ihas been coded in line with interface I to form interface I . For a concrete example consider that the interface I from performs a function call square input output which is received by interface I which after processing the value passed with input to square it by the second code segment passes back the squared result with output. In such a case the processing performed by the second code segment squaring input can be performed by the first code segment without a call to the interface.

A communication from one code segment to another may be accomplished indirectly by breaking the communication into multiple discrete communications. This is depicted schematically in . As shown in one or more piece s of middleware Divorce Interface s since they divorce functionality and or interface functions from the original interface are provided to convert the communications on the first interface Interface to conform them to a different interface in this case interfaces InterfaceA InterfaceB and InterfaceC. This might be done e.g. where there is an installed base of applications designed to communicate with say an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface in this case interfaces InterfaceA InterfaceB and InterfaceC. The point is that the original interface used by the 2Code Segment is changed such that it is no longer compatible with the interface used by the 1Code Segment and so an intermediary is used to make the old and new interfaces compatible.

Similarly as shown in a third code segment can be introduced with divorce interface DI to receive the communications from interface I and with divorce interface DI to transmit the interface functionality to for example interfaces Iand I redesigned to work with DI but to provide the same functional result. Similarly DI and DI may work together to translate the functionality of interfaces I and I of to a new operating system while providing the same or similar functional result.

Yet another possible variant is to dynamically rewrite the code to replace the interface functionality with something else but which achieves the same overall result. For example there may be a system in which a code segment presented in an intermediate language e.g. Microsoft IL Java ByteCode etc. is provided to a Just in Time JIT compiler or interpreter in an execution environment such as that provided by the .Net framework the Java runtime environment or other similar runtime type environments . The JIT compiler may be written so as to dynamically convert the communications from the 1Code Segment to the 2Code Segment i.e. to conform them to a different interface as may be required by the 2Code Segment either the original or a different 2Code Segment . This is depicted in . As can be seen in this approach is similar to the Divorce scenario described above. It might be done e.g. where an installed base of applications are designed to communicate with an operating system in accordance with an Interface protocol but then the operating system is changed to use a different interface. The JIT Compiler could be used to conform the communications on the fly from the installed base applications to the new interface of the operating system. As depicted in this approach of dynamically rewriting the interface s may be applied to dynamically factor or otherwise alter the interface s as well.

It is also noted that the above described scenarios for achieving the same or similar result as an interface via alternative embodiments may also be combined in various ways serially and or in parallel or with other intervening code. Thus the alternative embodiments presented above are not mutually exclusive and may be mixed matched and combined to produce the same or equivalent scenarios to the generic scenarios presented in . It is also noted that as with most programming constructs there are other similar ways of achieving the same or similar functionality of an interface which may not be described herein but nonetheless are represented by the spirit and scope of the invention i.e. it is noted that it is at least partly the functionality represented by and the advantageous results enabled by an interface that underlie the value of an interface.

Returning now to the particular discussion of the tool various embodiments of the invention may provide a CaptureTouchEvent application programming interface API which enables the data capture and storage of raw touch data in any desired file format. As previously noted with various embodiments of the invention captured raw touch data may be stored using a file format specifically configured to store touch data or it may be embedded in a file using another type of file format such as an XML file . This application programming interface API thus may employ a filename argument e.g. Touch Data Test Data007 which defines the file name for the touch data file to which touch data will be captured.

This API also may employ a mode parameter defining how the API will operate. With various embodiments of the invention for example the CaptureTouchEvent API may operate in a first Capture Stop mode which defines how the touch data capture process will end and a second Data Storage mode which defines how the touch data will be stored in the pen data file . During execution the CaptureTouchEvent API may then return a success message after it has successfully captured the designated touch data an invalid arguments message if the arguments passed to the CaptureTouchEvent API are not correct and a fail message for any other type of failure. The CaptureTouchEvent API may also create a notification event e.g. CaptureTouchEvent to other software objects upon completing the pen data capture. An illustrative calling convention for the CaptureTouchEvent API is CaptueTouchEvent File Name Mode Parameter . The File Name argument defines the touch data file to capture into. The Mode Parameter argument defines the mode to capture the touch data into e.g. first Capture Stop mode second Data Storage mode certain amount of time user input initiated etc.

Various embodiments of the invention also may provide an InjectTouchEventFromFile API which injects touch data from a designated file into the software stack. The InjectTouchEventFromFile API may employ a parameter designating the file from which the touch data will be retrieved e.g. Touch Data Test Data007 and one or more parameters defining how the retrieved touch data will be transformed before being injected into the software stack.

For example the InjectTouchEventFromFile API may employ parameters defined in a metadata structure for manipulating the retrieved touch data. The metadata may include a parameter dwMode which defines the stop mode for replaying or injecting retrieved touch data. Valid values for this parameter may thus include for example PI INJECT STOP TOUCHONLY MODE which will cause the touch data replay to stop when all of the retrieved touch data has been replayed or an End method is called to stop the injection process. This parameter may also have the value PI INJECT STOP EVENT MODE which will cause the replay of the touch data to stop when a previously created event has been signaled. This event named for example TouchEndEvent should have been already created by the caller of this method otherwise the method will fail.

Still further the metadata may include the parameter dwTransform which defines the type of transformation to be performed on the retrieved touch data. This parameter may include such valid values as PI TRANSFORM NONE which causes no transformations to be performed on the retrieved touch data PI TRANSFORM SCALE which causes the retrieved touch data to be scaled along one or both axes. If this value is selected then the metadata will additionally include one or more parameters describing the type of desired scaling such as a parameter psScaleFactor.

If the scaled retrieved touch data is to be injected at a specifically defined rectangle within a user interface space provided by the user mode application then the metadata will also include one or more parameters defining this rectangle. For example the metadata may include a parameter prcLocation defining the left top and right bottom of the new rectangle. Similarly if the touch data is to be injected into a bounding box in the user interface space of the user mode application then the parameter dwTransform may have the value PI TRANSFORM BOUNDINGBOX. Again the metadata may include a parameter prcLocation defining the bounding box.

If the touch data is to be rotated before it is injected into the user interface space of the user mode application then the dwTransform parameter may have the value PI TRANSFORM ROTATE ORIGIN. This value causes the touch data to be rotated anticlockwise with the left top of its bounding box as the center. The value of a parameter flRotationAngle may then define the angle of rotation.

If the touch data is to be injected into the user interface space of the user mode application at a desired speed then the dwTransform parameter may have the value PI TRANSFORM TIME. This value causes the retrieved touch data to be replayed faster or slower than the actual speed of its recording. The value of the parameter flTimescale then defines the factor by which the speed is to be multiplied. A value of 1 may be the same speed at which the touch data was captured. If for example the value of this parameter is 1 then the touch data may be injected at a faster speed than the capture speed. Correspondingly a value between 0 and 1 may cause the touch data to be injected at a speed slower than the capture speed.

During execution the InjectTouchEventFromFile API may then return a success message after it has successfully injected the retrieved touch data and an invalid arguments message if the arguments passed to the InjectTouchEventFromFile API are not correct. The InjectTouchEventFromFile API may also generate an out of memory message if some allocation of memory fails an access denied message if some resource being requested by the API is not present and a fail message for any other type of failure. The InjectTouchEventFromFile API may also create a notification event e.g. InjectTouchEventFromFile to other software objects upon completing the injection of the retrieved touch data. An illustrative calling convention for the InjectTouchEventFromFile API is InjectTouchEventFromFile File Name Struture of Properties . The File Name argument defines the touch data file to be injected into the system. The Structure of Properties argument defines the set of transforms to be applied to the touch data e.g. scaling x and or y bound to defined space rotate data on the screen capture horizontally but apply vertically change inject speed with respect to capture speed etc.

Still further various embodiments of the invention also may provide an InjectTouchEventFromBuffer API to enable injection of data from a user defined buffer. The InjectTouchEventFromBuffer API may employ for example a data buffer parameter e.g. Buffer007 defining the data buffer from which it will retrieve touch data. The InjectTouchEventFromBuffer API may also employ a data packet count parameter e.g. dwCount defining the number of data packets that will be retrieved from the buffer and one or more parameters defining how the retrieved touch data will be transformed before being injected into the software stack.

Like the InjectTouchEventFromFile API the InjectTouchEventFromBuffer API may return a success message after it has successfully injected the retrieved touch data and an invalid arguments message if the arguments passed to the are not correct. The InjectTouchEventFromBuffer API may also generate an out of memory message if some allocation of memory fails an access denied message if some resource being requested by the API is not present and a fail message for any other type of failure. The InjectTouchEventFromBuffer API may also create a notification event e.g. InjectTouchEventFromBuffer to other software objects upon completing the injection of the retrieved touch data. An illustrative calling convention for the InjectTouchEventFromBuffer API is InjectTouchEventFromBuffer Pointer to Buffer Buffer Size Struture of Properties . The Pointer to Buffer argument points to the buffer that includes the touch data file to be injected into the system. The Buffer Size argument defines the size of the buffer being pointed to. The Structure of Properties argument may be the same as for the InjectTouchEventFrom File API which defines the set of transforms to be applied to the touch data e.g. scaling x and or y bound to defined space rotate data on the screen capture horizontally but apply vertically change inject speed with respect to capture speed etc.

As noted above various embodiments of the tool may be implemented within a separate testing application employed by a user such as a software developer using the tool to test a new software application. With some embodiments the testing application may include functionality to test a variety of operations of the user mode application in addition to the processing of touch data.

With still other embodiments of the invention however the tool may be implemented in a testing utility designed solely to test how the user mode application processes touch data. With these embodiments the user may employ the utility to capture data in a desired file format transform and inject touch data into the software stack or both before using the data in the automation code.

For example a capture function of the utility may employ a parameter naming the file in which captured data will be stored e.g. filename while a replay function of the utility may employ a parameter naming the file from which touch data will be retrieved e.g. filename . The replay function of the utility may also employ various parameters specifying how the retrieved touch data will be transformed before it is injected into the software stack. Thus the replay function may employ parameters defining how the touch data will be scaled in an x axis direction e.g. sx scaled in a y axis direction e.g. sy or both e.g. sxy relative to for example a reference point e.g. a left topmost reference point .

The replay function may also use a parameter defining a bounding box for the retrieved pen data e.g. b by for example a left top and right bottom of the bounding box. The replay function may also use a parameter defining a rotational angle for the retrieved pen data e.g. r and a parameter defining a time multiplication factor for a speed at which the retrieved pen data will be injected into the software stack e.g. t . Thus a user may input a command

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

