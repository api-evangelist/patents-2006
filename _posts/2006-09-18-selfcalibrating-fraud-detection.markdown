---

title: Self-calibrating fraud detection
abstract: A method for dynamically updating a model is described. The method includes accessing a model that specifies expected characteristics for a transaction. The model includes variables associated with fraud. The method also includes receiving at least one value for each of the variables while monitoring transactions, and updating a distribution of values for each variable based on the received value. The received value is compared with the updated distribution to determine a deviation from a threshold value associated with a percentile of the updated distribution that is indicative of fraud.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08027439&OS=08027439&RS=08027439
owner: Fair Isaac Corporation
number: 08027439
owner_city: Minneapolis
owner_country: US
publication_date: 20060918
---
This specification relates to fraud detection and more particularly to fraud detection using self calibrating systems and methods.

With the increase in communications and electronic transactions incidents of fraud associated with these activities have increased. For example cloning a cellular telephone is a type of telecommunications fraud where an identifier such as a serial number for a cellular telephone is snooped or read as calls are transmitted captured and used to identify calls transmitted by other cellular telephones. When the other cellular telephones transmit calls the calls may be fraudulently charged to the account holder for the original cellular telephone.

Some current systems attempt to detect fraudulent transactions such as telecommunication fraud by constructing a transaction model based on historical observations of transactions. By observing large number of transactions characteristics may be derived that indicate whether a particular transaction is substantially likely to be fraudulent.

For example characteristics of 100 000 telephone calls can be captured and later characterized as fraudulent or legitimate. The fraudulent calls may share similar characteristics and transaction patterns that are used to build static models that indicate the probability of fraud for incoming transactions. In certain systems these static historical models can be used in a production or real time environment to evaluate a probability of fraud for incoming transactions. However creation of the historical model may be difficult to deploy quickly because a large amount of sample observations may be necessary to construct the model. Additionally if historical observations do not exist for a particular environment a historical model may not have the information needed to be accurate in the detection of fraud.

In a first general aspect a method for dynamically updating a model is described. The method includes accessing a model that specifies expected characteristics for a transaction. The model includes variables associated with fraud. The method also includes receiving at least one value for each of the variables while monitoring transactions and updating a distribution of values for each variable based on the received value. The received value is compared with the updated distribution to determine a deviation from a threshold value associated with a percentile of the updated distribution that is indicative of fraud.

In a second general aspect a method for processing a transaction is described. The method includes receiving a value for a variable associated with a transaction where the variable is indicative of fraud. The method also includes updating a distribution of values for the variable based on the received value. The updated distribution is used to determine a deviation of the received value from a selected value in the updated distribution. Additionally the method includes determining a score indicative of a probability of fraud for the transaction based on the deviation of the received value.

In another general aspect a system for determining fraud is described. The system includes an interface to receive values associated with a transaction. Each value corresponds to a property correlated to fraudulent transactions. The system also includes a profile updater to modify a distribution of values for each property based on the corresponding received value and a score calculator to generate a fraud score for the transaction. Generating the fraud score includes comparing the received value with the updated distribution to determine a deviation from a threshold value of the updated distribution that is indicative of fraud.

In yet another general aspect a method for generating a fraud indicator is described. The method includes generating a score indicative of a probability of fraud for a transaction. The generating includes aggregating self scaling variables where the self scaling variables are determined by updating a distribution of values for each self scaling variable with a received value for the self scaling variable determining an updated threshold value based on the updated distribution where the updated threshold value indicates a beginning of a range of values that are unusual relative to the updated distribution and scaling the received value based on the updated threshold value.

The systems and techniques described here may provide one or more of the following advantages. First a system can be deployed quickly and in environments for which historical data is limited or nonexistent. Second a system can increase accuracy of fraud detection by permitting user specified segmentation of a model population. Third a system may reduce complexity of data mapping and data validation by using a smaller and generic data application programming interface API . Fourth a system can use adaptive variable scaling based on real time online approximation of variable distributions and their percentiles. Fifth a system can use pre built and pre packaged analytic models which are refined using dynamic self scaling variables. Sixth a system can use adaptive score calibration based on real time online approximation of score distributions.

The details of one or more embodiments of the self calibrating fraud detection feature are set forth in the accompanying drawings and the description below. Other features and advantages of the self calibrating fraud detection feature will be apparent from the description and drawings and from the claims.

This document describes systems and techniques for dynamically updating a fraud detection model during run time or application of the model. A system such as system of can evaluate values from transactions such as purchase amount for a credit card transaction for fraud. The evaluation by the system can include integrating predictive variables such as the ratio of the received value to average value e.g. 400.00 160 into a previous distribution of values for a variable e.g. ratio of current to average purchase amount . For example the system can incorporate the ratio of purchase amount for the current credit card transaction into a distribution of previously stored values for ratios of purchase amounts. The system can then use the updated distribution to determine whether the purchase amount of the current transaction is within a range of the distribution commonly associated with a fraudulent transaction. This determination may include assigning a numerical indictor of the probability for fraud for that variable.

The system can aggregate variables for the transaction to form a score that indicates a probability that the transaction associated with the variables is fraudulent. For example a first variable for a credit card transaction can be a ratio of purchase amount and a second variable can be based on the time the transaction occurred. The system can aggregate numerical indicators associated with each of the variables to calculate a fraud score for the transaction. This is described more fully in association with .

There can be flexibility in the system for where certain components of the system reside. In certain implementations the data collector and analytic engine can reside on different computing devices as depicted in . In other implementations they can reside on the same computing device. Additionally the database can reside on the computing device that includes the analytic engine on the computing device that includes the data collector or on another computing device altogether.

For the example shown in transaction begins at a transaction origin and ends at a transaction destination. For example a phone call can originate at a residential phone and can be transmitted to a cellular phone . In another example a retail purchase transaction can originate with the swipe of a credit card at a point of sale POS and information associated with the sale can be transmitted to a bank . As a third example a medical billing transaction can originate with a medical bill and end with processing done at an insurance company .

As transactions occur the data collector collects transaction values and can communicate with the database to store the transaction values . For example for a phone call transaction stored values can include call length originating country code originating phone number destination country code destination phone number call date and call time. For a credit card transaction transaction values can include the purchase amount transaction date and time merchant category code and retailer address. For a medical transaction transaction values that can be stored include diagnosis codes service dates and times and treatment codes.

In certain implementations the database contains profiles that store summary statistics such as percentile values and variables that constitute the fraud feature detectors. The profiles can be updated in the database after the transaction values are stored. For example the profiles can be updated immediately after each transaction is stored or the updates can occur on a periodic or batch schedule. In certain implementations the data collector performs the profile updating. In other implementations the analytic engine can perform the profile updating.

The percentile values stored in the profiles can include parameters used to calculate fraud probabilities. For example the analytic engine can determine that all phone calls which are longer than the 99th percentile phone call value are at high risk for fraud.

The most recently stored transaction value can affect the value of the percentile parameters. For example suppose that a very long phone call transaction occurs such as a twenty hour call and that the call length is greater than the existing 99th percentile parameter for call length. When the 99th percentile parameter is recalculated after the twenty hour call length is stored as part of the previously stored values a new higher 99th percentile value for a distribution of the stored values will be stored in the profile which can affect future fraud detection calculations. This dynamic updating of fraud detection parameters can make the system self calibrating which may increase the accuracy of the system to detect fraud even if the distribution of values shifts over time. This self calibrating feature also may permit the system to be deployed more quickly because the system may not be dependent upon an existence of a large amount of historical data for determining parameter values.

In certain implementations the percentile parameters that indicate fraud for the variables are calculated using techniques described in A Space Efficient Recursive Procedure for Estimating a Quantile of an Unknown Distribution Tierney L. SIAM Journal on Scientific and Statistical Computing 4 706 711 1983 and Incremental Quantile Estimation for Massive Tracking Chen F. Lambert D. and Pinheiro J. Proceedings of the AAAI 2000 Conference on Knowledge Discovery and Data Mining 2000 the entirety of which are incorporated herewithin.

For example for a given variable x its r th percentile may be dynamically computed as the observations of x are received. Additionally the percentile estimation can be iteratively applied. An iteration can include observing M consecutive observations where M 1 is a free parameter. At the n th iteration an estimate of is updated where this estimate is denoted by at the n th iteration. The i th observation is denoted in the n th iteration as x where i is in 1 M . At the n th iteration a density estimate fis computed for the variable x at the r th percentile using the following equation 

In certain implementations the system facilitates a hybrid approach of fixing linear model weights but allowing adaptive scaling. Because the model can be linear in design e.g. self scaling variables are weighted and combined linearly the understanding of the model score may be transparent. Such a white box model gives users a clear view of what is causing the model to predict fraudulent activity.

In certain implementations the data collector collects the transaction values. The data collector stores the transaction values in the database as indicated by arrow . Some values may be stored without the data collector performing any processing but other values may be processed before being stored. For example the value of the call length may be part of the transaction data or it may be calculated by subtracting a start time of the call from an end time of the call. After the transaction data is stored the analytic engine updates the profile as shown by arrow by recalculating summary statistics such as percentile parameters.

For example different threshold parameters can be updated such as the 95th percentile purchase amount or the 99th percentile phone call length where each percentile may indicate a threshold above which fraud is likely. These parameter values can be used in the calculation of fraud probability. One implementation describing the calculation of the percentile parameters is described above.

After updating the profile the analytic engine calculates a probability of fraud for the transaction using the updated customer profile and the updated transaction variable distribution as indicated by arrow .

In the graph two threshold values are plotted. Threshold values can be used to calculate fraud probabilities as will be discussed in more detail below. A 95 percentile threshold value for this distribution has a value of four hours which means that 95 of the phone calls in this example distribution are four hours or less. The symbol is used to represent this threshold parameter.

In certain implementations the percentage to which is set is based on previous empirical studies to determine what characteristics of certain transaction variables are associated with fraud. For example studies of empirical data may show that phone call lengths that are greater than 95 have a relatively high probability of fraud. Different variable values can have different indicative threshold values. For example the 95th percentile may be indicative of fraud for phone call lengths but a 98th percentile may be indicative of fraud for credit card purchase amounts.

In some implementations a maximum expected or received transaction value is labeled as parameter x. In a 99percentile threshold parameter is associated with xand has a value of fifteen hours. As mentioned the value of xcan be substantially equal to the largest value expected or seen thus far in the distribution.

The percentile is treated as a 99 level or some more extreme value rather than 100 because it is often not possible to determine or predict what the largest value might be in the future. Using the extreme percentile for xalso may have the advantages that variable computation is more stable and the variable is less impacted by outliers in the distribution of the variable. For example although 15 hours is the longest call currently received in the example distribution a 17 hour call may occur in the future.

In some implementations a parameter value expresses a variance in the received transaction values and is used to scale a value indicative of fraud. For example can be calculated by subtracting from x. In this example distribution is equal to fifteen minus four i.e. x which is 11 hours.

The values of and can be used to calculate a scaled value which may be substantially proportionate to the existence of fraud using the formula below 

In the equation 3 above xis the received value for a variable. A variable is a property or characteristic of something in a transaction domain such as call length. The received transaction value is a particular value of the variable at a given point in time. The value C is a constant that defines a maximum value to which the scaled determined value can be scaled. For example if C is a value of 1 the scaled values would fall in the range of 0 1 . In other words the values of q are forced to be between 0 and C.

Consider an example of the application of the equation 3 when the received transaction value xis x or a value of 15. The scaled value q would be computed then as 15 4 11 1

A value of 1 would be the highest indicator of fraud for this variable. This indicates that a variable at the extreme end of the distribution e.g. x would be associated with the highest fraud indication. This can be an effective way of handling extreme outliers or variables corrupted by erroneous data inputs.

Consider another example when the received transaction value is equal to or a value of 4 in our example distribution. The scaled value q would be computed then as 4 4 11 0

A value of 0 would be indicative of a very low or substantially zero probability of fraud. This indicates that a variable on the left end of a tail of the distribution e.g. less than or equal to is not be indicative of fraud.

In another example the received transaction value can be equal to something less than such as a value of 12 minutes in our example distribution. The scaled value q would be computed as 0.2 4 11 3.8 11 0.345

The formula can be structured so that only positive values are indicative of fraud. Non positive values can be scaled to zero by the analytic engine which can eliminate the non positive values contribution to a composite fraud score for the transaction.

The scaled value q is an indicator of the presence of fraud for one transaction variable. The analytic engine can calculate a score which indicates a probability of fraud for the transaction by aggregating individual variables that each are associated with fraud indicators. For example in some instances the score can be calculated for the transaction by summing up weighted scaled values for each variable using the formula below The q value is the scaled value determined by equation 3. Although optional the wvalues are weights assigned to variables based on their importance for detecting fraud within the model. For example with a phone call transaction the call length value may be more indicative of fraud than a variable associated with the time of day so the call length variable would have a higher weight e.g. 3 than the weight of the time of day variable e.g. 2 .

The service profile updater updates a service profile. Service profiles can include typical fraud variables associated with a particular kind of service. For example when receiving credit card transaction information the service profile updater can use the credit card number key to look up a service profile associated with the credit card holder.

The service profile updater updates the service profile with the received transaction information. For example when receiving phone call transaction information the service profile updater can look up a phone call service profile using a telephone number that originated the call. After the correct service profile is identified variables included in the service profile e.g. variables related to call length originating country code originating phone number destination country code destination phone number call date and call time can be updated with information from the phone call transaction information.

The model profile updater updates model profiles. Model profiles can include percentile and parameter values that are part of an analytic model used to predict fraudulent transactions. The model profile can be updated after the service level profile is updated. For example a service level profile may include a variable associated with the call length of a phone call. After the service level profile is updated with the received call length value an average call length based on the call lengths received over a predetermine period e.g. a day can be calculated and stored in the service profile.

In one implementation the average call length from the service profile can then be used to update the parameter values associated with call length in the model level profile. For example the average call length can update e.g. be included in a previous distribution of values for call length received from a variety of service profiles.

The analytic engine can then use a percentile threshold of the updated distributions to determine if the value used to update the distribution falls within an outlier range of the distribution which in turn may indicated fraudulent activity.

For example the calculations for determining fraud for phone call length can use the 95th percentile as a threshold above which fraud is probable. The 95th percentile value which is a value that is larger than 95 of all the recent observed values. The distribution of values for the call length variable can be updated after the received call length value is added to the distribution.

The score calculator contains a raw score calculator and a normalized score calculator . In some instances the raw score calculator calculates a raw linear score for the transaction as described above. The raw score distribution can be affected by a plurality of factors such as the number of transactions in a particular environment and the fraud rate existing in that environment. For example raw score distributions for a local phone company may differ from scores in a foreign phone company.

To increase continuity and consistency of score interpretation the score calculator can use a normalized score calculator to normalize the raw scores on a consistent scale such as between 1 and 999. In some implementations the top 1 risky transactions in an environment can be scaled to be above some threshold value less than 999 such as 700. For example for a local phone company the top 1 risky transactions may have a normalized score above 700 and likewise for a foreign phone company the top 1 risky transactions will also have normalized scores above 700 despite the potential differences in distributions of raw scores between the two environments.

In some implementations a normalized score can be formally expressed as follows score 4 score 5 where is the raw score and score is the final score seen by the user. The parameter r is the top percentage of the most risky service IDs is the raw score associated with r and sis the final score to which we would like to map . Equation 4 describes the map from the raw score to the final score where k i 1 . . . I are the parameters of the mapping function. The mapping function g maps the raw score of any given range to a finite range of final scores. The function g is monotonic in .

Equation 5 is an inverse function of g describing the map from to k. The parameters k i 2 . . . I can be fixed and kcomputed based on such that is mapped to score s where sis pre selected. Therefore upon new observations of a new value of kis computed according to Equation 5 and this new value is in turn used in Equation 4 to transform the raw score .

One component in the adaptive score calibration described above is the determination of sgiven r. This is done through the percentile estimation method outlined previously in Equations 1 and 2 . The method is to determine the r th percentile dynamically as the raw score is computed for each transaction coming into the system. The percentile estimation method does not need to wait for the raw scores for all the transactions to compute the r th percentile which may be different from other methods of obtaining percentiles.

To summarize the implementation described above after a transaction is scored with a raw score by the model the adaptive score calibration of the raw score includes the following steps the r th percentile is updated using according to Equations 1 and 2 the parameter kis computed using Equation 5 and the calibrated score score is computed using Equation 4 .

The normalized scaling technique also applies to segments. A segment is a subset of a model which has its own fraud characteristics and therefore its own parameter values. For example in telecommunications domains a global model will include all phone calls whereas a segmented model can include segments such as residential landline business landline residential mobile and business mobile. The fraudulent threshold for phone call length may be 97 e.g. 2 hours 23 minutes for residential landline and 96 e.g. 1 hour 43 minutes for residential mobile. Segment specific parameters are stored in segment model profiles. The raw score distributions may vary between segments in a model for the same reasons that scores in different models may have different distributions. Normalizing raw scores may ensure that normalized scores are on a consistent scale across segments.

In step service level variables are updated. Service level variables can be stored in a service profile . The service profile information is accessed using the key received in step . For example the CDR received in step may contain a phone number which can be used to identify a particular service profile by matching the key from the CDR to a profile key PK in the service profile . Service profiles can include variables indicative of fraud for a particular kind of service. For example for credit card transactions the service profile can contain a set of variables derived from data elements such as purchase amount transaction date and transaction time.

In step model level parameters are updated. Model level parameters can be stored in a model profile . Model profiles can store percentiles and associated values that are related to the fraud variables. For example a value such as 4 hours for a 95th percentile for call length may be a threshold parameter for detecting fraud for phone call transactions. The model profile may be either a global model profile which contains parameters for all transactions or it may be a segment profile which contains parameters specific to certain segments as previously discussed.

The model profile information is accessed by matching the key received in step to a profile key PK in the model profile . For example the CDR received in step may contain a phone number. A determination can be made regarding whether the phone number is in a particular segment such as residential. The associated model profile can be retrieved and the model profile parameters can be updated.

In step a score is calculated. For example the score can be calculated using the variable values that have been stored in the service profiles and the parameters that have been stored in the model profile associated with the segment. In step a determination is made to see whether there are any more transactions. If there are no more transactions the method ends. If there are more transactions the method can branch to step to receive the next transaction values.

In step a global score is calculated using the variable values that have been stored in the service profiles and the parameters that have been stored in the model profile. A global score can use the values for substantially all of monitored transactions.

In step a segment identifier in the API is used to retrieve the segment profile key PK to access the appropriate segment profile that matches the key received in step . An example of a segment profile is shown in .

If step fails because there is no segment identifier specified in the API step is performed. In step the global score calculated earlier is the score used to test for probability of fraud for the transaction.

If a matching segment exists step is performed. In step a segment score is calculated using a segment specific distribution and segment specific percentile values as shown in . In step a determination is made to evaluation whether the segment model is mature or not. Segment models may not have enough values in the distribution for the summary statistics to be reliable. If the segment model is not mature based on a predetermined reliability threshold step is performed and the global score is used.

If the segment model is mature step is performed. In step the segment score is used to determine if the transaction is fraudulent or not.

The memory stores information within the system . In one implementation the memory is a computer readable medium. In one implementation the memory is a volatile memory unit. In another implementation the memory is a non volatile memory unit.

The storage device is capable of providing mass storage for the system . In one implementation the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device.

The input output device provides input output operations for the system . In one implementation the input output device includes a keyboard and or pointing device. In another implementation the input output device includes a display unit for displaying graphical user interfaces.

The features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The apparatus can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output. The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network such as the described one. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

Although a few implementations have been described in detail above other modifications are possible. For example certain variables in the equations such as can be selected from by the user instead of being calculated based upon other variables such as .

In other examples a generic data model may be introduced into production instead of building a model based on a particular environment that is monitored for fraud. The generic model can then be refined by the self scaling variables as described above. This may increase the deployment speed of models in new environments.

In some implementations the generic models may be based on historical data from environments that are similar but not the same as the target environment. For example a model can be developed based on monitored medical billing practices for general physicians. This model may serve as a generic model for monitoring billing practices for other doctors such as orthopedic surgeons. The generic model can be implemented and dynamically refined as billing transactions associated with orthopedic surgery are received and analyzed.

In addition the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

