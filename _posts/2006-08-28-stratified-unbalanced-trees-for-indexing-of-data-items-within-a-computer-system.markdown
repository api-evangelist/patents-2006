---

title: Stratified unbalanced trees for indexing of data items within a computer system
abstract: According to one embodiment, a system may include a number of computing nodes configured to implement a number of index data structures each configured to map ones of a plurality of input values to one or more corresponding data items. Each of the index data structures may include a respective plurality of index nodes arranged hierarchically and each having an associated tag value, where each of the data items corresponds to a respective one of the index nodes, and where for a given one of the data items having a given corresponding index node, each tag value associated with each ancestor of the given corresponding index node is a prefix of a corresponding input value mapping to the given data item.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07702640&OS=07702640&RS=07702640
owner: Amazon Technologies, Inc.
number: 07702640
owner_city: Reno
owner_country: US
publication_date: 20060828
---
This application is a continuation in part of U.S. patent application Ser. No. 11 370 353 filed Mar. 8 2006 which claims priority to U.S. Provisional Patent Application Ser. No. 60 754 726 filed Dec. 29 2005 and each of which is herein incorporated by reference in its entirety.

This invention relates to computing systems and more particularly to index data structures configured to store records of data relationships within computing systems.

Many different types of computing applications require the relationships among different data items to be maintained in a persistent way for reference during data processing. For example a computer file system may be configured to store and manage information indicating the relationships between individual files e.g. as identified according to some type of file name and the specific storage location s within virtual or physical storage devices e.g. logical volumes hard disk drives etc. at which corresponding file data is stored. To access the data of a particular file according to its name the file system may consult data structures that map the name to various storage locations and then access the indicated storage locations to retrieve the file data.

Depending on the type of application in which it is employed a data structure that reflects relationships among data items may cause disruption of application operation or data loss if the data structure becomes damaged or corrupted for example due to hardware or software faults that arise during application operation. Correspondingly in some instances such data structures may be replicated in such a way that reduces the likelihood of unrecoverable data loss. For example a copy of the data structure may be stored at a different geographic site from a primary instance of the data structure. The site may be selected and configured such that a catastrophe that affects the primary data structure instance is unlikely to affect the copy.

As the number of relationships to be tracked among data items increases it may be difficult to correspondingly scale the resources of the data structure that stores the relationships in a way that minimally impacts data structure performance. For example if the size of the data structure exceeds the available physical memory of a computer system seeking to manipulate it read or write throughput to the data structure may become limited by the rate at which the computer system s virtual memory system can swap portions of the data structure to and from physical memory. Additionally in cases where the data structure is replicated it may be necessary to periodically synchronize the replicas for example to ensure that a standby copy is relatively consistent with a working copy or to preserve operational consistency when different replicas are actively being used. However synchronization of data structures may be constrained by the available communication bandwidth between the systems implementing the data structures to be synchronized as well as the computational overhead of performing the synchronization. For example a brute force synchronization approach in which two large data structure instances are compared in their entirety for differences may require a substantial amount of time and or bandwidth to transmit the contents of one instance to the system implementing the second instance as well as substantial processing resources to perform item by item reconciliation within the instances. Such constraints may effectively reduce the frequency with which synchronization can feasibly be performed or limit the size of the data structures for which synchronization may be supported.

Various embodiments of stratified unbalanced trees for indexing data items within a computer system are disclosed. According to one embodiment a system may include a number of computing nodes configured to implement a number of index data structures each configured to map ones of a plurality of input values to one or more corresponding data items. Each of the index data structures may include a respective plurality of index nodes arranged hierarchically and each having an associated tag value where each of the data items corresponds to a respective one of the index nodes and where for a given one of the data items having a given corresponding index node each tag value associated with each ancestor of the given corresponding index node is a prefix of a corresponding input value mapping to the given data item. For each given one of the index data structures each of the plurality of index nodes included within the given index data structure may be associated with a respective fingerprint value where for a given one of the index nodes the respective fingerprint value is indicative of a hash value computed according to a hash algorithm wherein the hash value is computed as a function of ones of the plurality of index nodes that are hierarchical descendants of the given index node. Additionally each given one of the index data structures may be stratified among a plurality of index tree data structures wherein a root node of the given index data structure corresponds to a root node of a first one of the plurality of index tree data structures where each of a plurality of leaf nodes of the first index tree data structure corresponds to a root node of a respective one of the index tree data structures and where at least two of the plurality of index tree data structures are stored on different ones of the plurality of computing nodes.

While the invention is susceptible to various modifications and alternative forms specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood however that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.

As described above conventional data structures for organizing relationships among large numbers of data items may present scalability and data reliability challenges. In the following discussion various embodiments of unbalanced index data structures that may be configured to organize large numbers of data items are described. Subsequently techniques are discussed for reconciling different instances of unbalanced index data structures for example in embodiments where such data structures are replicated. Finally the structure of an exemplary computer system that may be configured to implement these data structures and techniques is described.

One embodiment of a distributed system configured to include several instances of an index data structure that may be managed as replicas of one another is shown in . In the illustrated embodiment system includes a number of computing nodes each of which is configured to implement a respective instance of an index data structure which may be collectively referred to as index . While only two computing nodes are shown it is contemplated that in various embodiments any number of instances of index data structure may be implemented by any number of computing nodes . It is further contemplated that a single instance of index may span multiple computing nodes . For example as described in greater detail below in conjunction with the description of computing nodes may correspond to individual computer systems that may be collectively configured to implement an instance of index data structure e.g. in the event that the size of index exceeds the computing resources of a single computing node .

Generally speaking an instance of index may be configured to store indications of the relationships between various input values and data items to which the input values map or correspond. That is index may be configured to store a collection of mappings between values in a namespace and data items represented by values in the namespace. Specifically index may include at least one corresponding index node record entry or other type of reference for each data item that is indexed and as described in greater detail below may include additional information representative of mapping paths from namespace values to particular index entries such as intermediate nodes records or other indications for example. Generally the collection of data items or data objects organized by index may be referred to as a data store illustrated in as data store instance and optional data store instance . Data store instances may be generically referred to as data store . As shown data store is included within computing node although in other embodiments a data store that is organized or represented by an index may be implemented by one or more computing nodes that are partially or entirely distinct from the computing nodes implementing index .

For various reasons index may be replicated among indexes such that changes that occur in one index replica are at least probabilistically likely to be reflected within other index replicas within various performance constraints e.g. within a bounded period of time . For example replication of indexes within or across nodes may improve fault tolerance and allow system operation to continue in the event a particular instance of index becomes unavailable. Additionally replication may allow index workload to be distributed across different computing resources which may improve index performance. In the illustrated embodiment computing nodes may be configured to implement protocols for reconciling differences that may arise among the replicas of index embodiments of which are described in greater detail below in conjunction with the descriptions of . It is noted that replication of data structures such as index need not be atomic and replicas need not be guaranteed to be consistent at any given time. That is it is not necessary that different replicas of a data structure exhibit identical user visible state at all times such that modifications to data structure state require atomic or transactional commitment of updates to all or a majority of replicas although in some embodiments replication may be implemented using such update semantics. It is also noted that in some embodiments the items of data store that are organized by index may also be replicated using similar or different strategies from those used to replicate and reconcile instances of index . However replication of data store need not be a necessary condition for replication of index and data store may be omitted in some embodiments.

As an example of an application in which system may be deployed in one embodiment computing nodes may be configured to implement a keymap service for a web based data storage system configured to store data objects such as files on behalf of various system users. For example a user may supply to the storage system the contents of an object to be stored e.g. text image audio video or any other type of data or executable code along with a desired name or key to be associated with the object such that the object may be later retrieved by specifying the key. The specified key which in some embodiments may be a text string such as a Uniform Resource Locator URL may be one possible value within a namespace of allowable keys.

Within data store of the storage system the user provided object contents may be stored in a variety of ways. For example objects may be replicated across different computing nodes to improve reliability of object data. Additionally new replicas of objects may be generated if existing ones fails for example due to failure of a computing node hosting a replica or failure of communication paths by which such a computing node is accessible to the rest of the system. Correspondingly the relationships between object keys and the actual instances of objects stored within data store may be complex and dynamic particularly in a system configured to store many objects on behalf of many different clients.

In this example index may be configured to implement a keymap that stores relationships between object keys and index entries representative of the locations of objects within data store . For example in response to receiving a particular key as an input value index may be configured to identify and retrieve an index record or index entry corresponding to the particular key. The index entry may be a data structure configured to include system specific data that may be used to identify one or several instances of the object corresponding to the particular key. For example the entry may include data e.g. Internet Protocol IP addresses URLs etc. that identifies particular computing nodes or devices on which the object is stored and may or may not include more specific information about how the object is stored within the referenced computing nodes or devices. As objects are created deleted or migrate within data store index may be configured to update corresponding entries in order to maintain a consistent mapping between keys and their corresponding objects. More details regarding keymap service implementation and operation within an object storage system may be found within U.S. patent application Ser. No. 11 370 353 referenced above filed Mar. 8 2006 and entitled Keymap Service Architecture for a Distributed Storage System. 

It is noted that in some embodiments a given data item to which index maps a particular input value such as a key may itself correspond to one or more other data items within data store . That is in some embodiments index may be configured as an indirect index such that further processing of the data item to which a given input value maps may be required to identify an ultimate data item to which the given input value maps. Referring once again to the keymap example given above in one embodiment data store may be configured to store multiple functionally equivalent replicas of a given data object corresponding to a given key. Rather than distinguishing and separately indexing each replica of the given data object index may be configured to index a keymap entry that corresponds to the given key. The keymap entry may include pointers references or other information distinguishing the replicas of the given data object though it may not correspond directly to any particular instance of the given data object. In such an embodiment the collection of keymap entries indexed by index each entry corresponding to a particular key may correspond to the data items within data store that are directly indexed by index . However a given keymap entry returned by index for an input key value may be further processed e.g. by a client of system to select a particular instance of a corresponding data object. These instances may correspond to data items within data store that are indirectly indexed by index .

In some embodiments system may scale to support very large numbers of data items within data store to be indexed e.g. on the order of billions or more. Thus in such embodiments each instance of index may have a similarly large number of data items to manage. Further in many circumstances the indexing functionality provided by index may be central to the operation of the overall system . For example in one embodiment index may be configured to mediate every request generated by clients of system involving access to a data item within data store . In such an embodiment the performance of system from the perspective of its clients may depend directly on the efficiency and speed with which instances of index access and process their internal state given an input value. In turn the performance of index may depend directly on the data structures used to organize its state.

Designing index data structures to support sorting and synchronization operations in a large scale implementation may present considerable challenges. Conventional applications that require indexing of large amounts of data such as e.g. databases frequently employ conventional balanced data structures such as B trees or other types of balanced trees. Generally speaking when used to index a given quantity of data items balanced data structure algorithms attempt to distribute data items across the balanced data structure according to the quantity of items being managed. For example given 10 000 data items to index a balanced data structure algorithm may attempt to choose breakpoints among the data items such that their corresponding index entries e.g. index data elements representative of the data items which may correspond to nodes discussed below or to data structures associated with such nodes are divided into 10 groups of roughly 1 000 entries per group. The balanced data structure algorithm may create further levels of balanced hierarchy within each group for example subdividing each group of roughly 1 000 entries into five subgroups of roughly 200 entries each. As data items are added to and deleted from the balanced data structure groups and or subgroups within the data structure may become unbalanced. Thus conventional balanced data structure algorithms may rebalance the data structure by reallocating entries among groups creating additional groups and or creating additional levels of hierarchy. Such rebalancing may take place on the fly as data items are added or deleted or may occur after a certain number of data item modifications have taken place or a certain amount of time has elapsed since the last rebalancing.

By virtue of segregating entries in a balanced fashion balanced data structures may present a predictable roughly uniform access latency for any given data item indexed within the data structure which may be desirable in a large scale implementation where a large number of data items need to be indexed. However it may be particularly difficult to efficiently reconcile or synchronize distributed instances of balanced data structures for example using a relaxed synchronization model in which discrepancies among instances are allowed to arise and are subsequently resolved using reconciliation techniques. Specifically as instances of balanced data structures are independently modified the breakpoints that divide data items into groups within each instance may become divergent. As a result there may be no direct correspondence in terms of data item membership between groups or subgroups of different balanced data structure instances. To reconcile two such instances then it may be necessary to exhaustively compare the entirety of the two instances which may be extremely time consuming in cases where each instance indexes a large number of data items.

As an alternative to balanced data structures that distribute data items among groups according to quantity in some embodiments the data structures employed by index may be configured to implement unbalanced data structures which may also be referred to as tries that distribute data items among groups according to some relationship among the data items within each group. Specifically index may be configured to data items according to prefixes of keys or names corresponding respectively to the data items e.g. as defined within a suitable namespace for the data items . As an example consider a case in which there exist 600 data items having corresponding case insensitive alphanumeric keys. A corresponding balanced index having 600 entries might divide the entries into three balanced groups of 200 entries each. By contrast in one embodiment an unbalanced index might define three alphanumeric groups such that those entries beginning with the characters a through l are assigned to the first group those entries beginning with the characters m through x are assigned to the second group and those entries beginning with the characters y or z or the numerals 0 9 are assigned to the third group.

Entries may be unevenly distributed across the groups of the unbalanced index. For example there may be 300 entries in the first group 250 entries in the second group and only 50 entries in the third group. However it is noted that for any given index entry membership of the given entry in a particular group of an unbalanced index may be a function of its corresponding key that is the namespace value mapping to the given entry s corresponding data item without dependence on the number of entries in any particular group. Thus if two instances of an unbalanced index maintain the same group definitions each group may be independently synchronized without dependence on the other groups. For example the a l groups between the two instances may be synchronized independent of the m x groups and the y 9 groups. By contrast as described above synchronization of two instances of a balanced index may require all entries across all groups to be considered.

One example illustrating the use of an unbalanced data structure to index a number of data items is shown in . In the illustrated embodiment unbalanced index or simply index may be representative of an instance of index . As shown index includes a number of nodes arranged in a hierarchical fashion to index a number of string values beginning with the prefix al . It is noted that nodes of the index data structure have no necessary relationship to computing nodes of system . For example the indexed values may correspond to keys of various data items within data store . Each node within index includes an associated tag value that may or may not directly correspond to a data item being indexed. In the illustrated embodiment nodes depicted as ovals may correspond to interior nodes of index that do not have corresponding data items while nodes depicted as rectangles may correspond to indexed data items. Thus for example node corresponds to the string al and is related to a number of other nodes within index but there may not exist an actual key or data item corresponding to the string al . By contrast node having the tag alicia may correspond to a key of a data item specifying the same string. Generally a non interior node of index may be associated with a corresponding data item. In particular a non interior node may include or be associated with an entry or record including information about the node s corresponding data item. For example the record may include data describing properties of the corresponding data item an indication of where the data item may be located etc. The distinction between interior and non interior nodes may or may not be explicitly reflected in the state of a node as stored within an embodiment of index .

As described below in some embodiments an unbalanced data structure may be configured as an index of other indexes. In some such embodiments a data item indexed within a first instance of index may be a root node of another index and the corresponding node within the first index may be considered a non interior node. That is in some embodiments a non interior node of a given index may be generally defined as any node associated with a data value such as a record corresponding to a data item or a root node of another index which is external to the given index . Similarly an interior node of a given index may reference only other nodes within the given index and may not bear any association with an indexed data item or with other indexes distinct from the given index . It is also noted that as shown in non interior nodes are not necessarily leaf nodes e.g. nodes that do not reference other nodes at lower hierarchical levels .

In various embodiments each node may encode a variety of information. One embodiment of a generic node illustrating various data fields that may be encoded within the node is shown in . In the illustrated embodiment node includes a tag field a count field a fingerprint field and one or more pointer fields . Generally tag may be configured to store a value corresponding to a given node that may be used in the course of traversing or manipulating index as described in greater detail below. In some embodiments tag may uniquely identify a node among all nodes within index . Also in some embodiments a tag of a given node may include as prefixes the tags of all direct ancestors of the given node within index . That is a tag of any given node may be determined through appending some value to the tag of that given node s immediate parent node . For example consider node of which has the tag alicia . Each of node s direct ancestor nodes and has a tag alic ali and al respectively that forms a proper prefix of the tag of node

As shown in certain nodes refer to one or more child or descendant nodes farther below in the hierarchy of index . In one embodiment pointer field s may be configured to store data reflecting pointers or references from a given node to another node . For example a given pointer field may include an address that identifies a location of the referenced node within an address space such as a memory address space. The given pointer field may also include additional tag information regarding the referenced node . For example as shown in each are from a given node to a descendant node is labeled with the first character of the tag of the descendant node that differs from the prefix formed by the tag of the given node . In one embodiment this additional tag information may be stored within a corresponding pointer field along with a pointer to the referenced node . For example the pointer fields included in node may respectively include references to nodes and as well as corresponding tag data a e f i and z .

As mentioned previously an index such as index may be used to organize data items for selection given some input value. In some embodiments the pointer fields of a non interior node that is a node that maps directly to a data item being indexed may also include a pointer to a corresponding data item itself or to a record or other data structure corresponding to the data item. For example a data value in pointer field of a given node may reference a record e.g. a keymap entry in the keymap example cited above configured to store information about the locations of multiple data items to which the input value corresponding to given node maps. In some embodiments as described in greater detail below unbalanced indexes such as index may be implemented hierarchically such that a non interior node of one index may refer to another index . A pointer field that references an indexed data item may be distinguished from a pointer field that references another node via any suitable technique such as by using distinct encodings for the different types of pointer fields . For example in embodiments where tag information associated with arcs to descendant nodes is encoded within pointer fields as described in the previous paragraph a null tag may be used to distinguish a reference to an indexed data item from references to descendant nodes .

For a given node count field and fingerprint field may be configured to reflect the state of nodes beneath the given node . In one embodiment count may be configured to store the count of all nodes that are descendants of e.g. are hierarchically beneath the given node . For example node of has eight other nodes beneath it within index . Correspondingly its count may indicate a value of 8 using any suitable encoding or format.

In various embodiments fingerprint field of a given node may be configured to store a value indicative of a hash e.g. the result of a suitable hash algorithm performed on some portion of the data of the nodes hierarchically beneath the given node . For example fingerprint field of a given node may reflect the sum of the hashes of the tags of all nodes that are descendants of the given node . Alternatively fingerprint field may reflect the hash of the concatenation of tags of descendant nodes according to a particular consistent order of traversal e.g. breadth first or depth first traversal . In other embodiments other fields of a node besides tag may participate in hashing. In some embodiments the data associated with a given node may be reflected within its own fingerprint field whereas in other embodiments a fingerprint field of given node may be determined strictly on the basis of its descendant nodes. For consistency of description as used herein a fingerprint of a given node may refer to a hash value that is a function of at least some descendant nodes of the given node while a hash of given node may refer to a hash value that is a function of data associated only with given node and not its descendants.

Generally speaking a hash algorithm may be configured to map a given source data value of possibly arbitrary length onto a smaller typically fixed length hash value such that if two hash values differ the original source data values from which the two hash values were generated must also differ in some way. As hash algorithms are typically not one to one functions identity between two hash values does not necessarily imply identity between original source data values. However for some classes of hash algorithms given identical hash values identity between original source data values used to generate the identical hash values may be statistically likely to within a quantifiable probability or degree of confidence particularly for source data values that exhibit some degree of redundancy. Different types of hash algorithms may also be referred to as signature fingerprint or checksum algorithms. It is contemplated that any suitable type of hash algorithm may be employed to generate a hash value to be stored in fingerprint fields including by way of non limiting example any suitable version of the Message Digest 5 MD5 algorithm or the Secure Hash Algorithm SHA such as SHA 1 SHA 256 SHA 512 etc.

In some embodiments nodes may include respective data fields for or otherwise be associated with respective data values in addition to or instead of count or fingerprint values. In one embodiment such a data value may be determined for a given node as a suitable function of the nodes that are descendants of given node . For example the data value may be defined as the sum maximum minimum or any other suitable function of corresponding values of the descendants of given node . For example the data value may be determined as a function of the tag value fingerprint value count value or data item corresponding to the descendants of given node . The values of the descendants on which the data value determined for given node depends may but need not themselves depend on values of further descendants. For example as described above the tag value of a given node may not depend on the given node s descendants while in some embodiments the count or fingerprint values of a given node may depend on some or all of the given node s descendants.

Where large numbers of data items need to be indexed as may be common in large scale instances of system it may be impractical to use a single instance of index for all the data items. For example a single large index may not completely fit into the memory of a system processing the index which may negatively affect the performance of operations that depend on the index. In some embodiments a large index may be implemented using a stratified unbalanced data structure which may also be referred to as a stratified index. Generally speaking in a stratified index multiple instances of index may be hierarchically defined where instances higher in the hierarchy may index other indexes and indexes lower in the hierarchy may index particular data items within data store .

One embodiment of a stratified index is illustrated in . In the illustrated embodiment stratified index includes five indexes . Index includes nodes each of which is a non interior node that references a respective root node of one of indexes . In turn indexes each include various ones of nodes that were shown in . In some embodiments of stratified indexes higher level indexes such as index may be configured to reside in the memory cache or another higher level of a memory hierarchy of a system processing the index while lower level indexes such as indexes may primarily reside in disk or another lower level of such a memory hierarchy. In such embodiments lower level indexes may be relocated from lower levels to higher levels of the memory hierarchy as needed for example using paging or virtual memory type techniques. By supporting hierarchical partitioning of indexes of large numbers of data items stratified indexes may more efficiently and effectively use system resources.

For example using the aforementioned paging techniques frequently used indexes of stratified index may be kept in higher levels of a memory hierarchy which are typically faster to access but limited in capacity while less frequently used indexes may be stored in lower memory hierarchy levels which are typically slower to access but have greater storage capacity than higher levels. It is contemplated that in some embodiments as nodes are added to indexes within stratified index individual indexes may grow beyond a target size such as the size of a disk block or memory page on the system implementing the indexes . In such embodiments if a given index grows to exceed the target size it may be split into two or more index instances. In the course of performing such a split nodes may be added to a higher level index as necessary to account for the new index instances.

During the course of operation of system system clients may generate requests to access various data items within data store for example by specifying a key or input value corresponding to a given data item in order to read or modify that data item. In response to a request to access an indexed data item according to a specified key stratified or non stratified unbalanced indexes may be traversed to determine whether the specified key corresponds to a node within the index . One embodiment of a method of unbalanced index traversal is illustrated in . In the illustrated embodiment operation begins in block where the key value to be searched also referred to as the search value within the index is specified for example via a relevant operational request to system . Subsequently the root node of the index e.g. the node having no parent node is selected block .

For the selected node the node s corresponding tag value is compared against the search value to determine whether the tag value matches the search value exactly is a prefix of the search value or neither block . If the tag value of the selected node matches the search value then the selected node is examined to determine whether it is an interior or non interior node blocks . For example the pointers or other content of the selected node may be examined to determine if the node references a data value indexed by index such as an record of a data item or another instance of an index . If the selected node is an interior node an index miss may occur as described below block .

If the selected node is a non interior node the data value referenced by the selected node is retrieved block . In embodiments that support stratified unbalanced data structures where some data structure instances may index other data structure instances the retrieved data value may either correspond to an indexed data item of data store or a record thereof or a root node of another instance of index . If the retrieved data value references a data item index traversal may be complete and the retrieved data item may be processed according to the operation that initiated traversal blocks . For example if the initiating operation was a data item read operation the retrieved data item may be returned to the initiating client as a result of the read operation. If the initiating operation was a data item write operation the data item may be modified within data store according to the parameters specified by the client.

If the retrieved data value does not correspond to an indexed data item then in the illustrated embodiment it may correspond to a root node of another index . Correspondingly this root node may be selected blocks and operation may proceed from block where traversal of the newly selected index may proceed. Thus in one embodiment execution of the method of may proceed iteratively until the presence or absence of a node corresponding to the search value is definitively determined.

Returning to block if the tag of the selected node does not match the search value but is a prefix of the search value then descendants of the selected node may be examined to determine if any descendant corresponds to the search value block . If so the corresponding descendant node may be selected block and operation may proceed from block . In one embodiment the pointer s of the selected node may be examined to determine whether additional tag information associated with a particular pointer when taken in conjunction with tag of the selected node also forms a prefix of or entirely matches the search value. For example referring to the tag al of node may be determined to be a prefix of a search value of alibaba . Additionally the arc from node to node which may be represented by a corresponding pointer is associated with the additional tag information i . This tag information when appended to the tag al of node forms the value ali which is also a prefix of the search value. Therefore node may be selected for further traversal.

Returning to block if no descendant of the selected node corresponds to the search value the search value does not have a corresponding node within the index which may also be referred to as an index miss block . The index miss may then be processed according to the type of operation that initiated the index traversal block . For example a data value read operation may process an index miss by returning an appropriate status indication to the client indicating that no data item corresponding to the specified key exists within data store . In contrast a data value write operation may process an index miss by inserting into index a new node corresponding to the data item specified by the client as a descendant of the selected node . For example the new node may be created and its various fields appropriately set for the data item to be stored and a pointer to the new node may be stored within the selected node . In some embodiments generation of a new node may include generation of a corresponding record to be reference by the new node and that includes detailed information regarding how to access the specified data item. For example the specified data item may be stored at some location within data store and this location may be reflected in the record corresponding to the new node . It is noted that if a new node is added to an index or an existing node is modified the count fields and fingerprint fields of all ancestor nodes of the added or modified node may be updated to reflect the change.

Returning to block if the tag of the selected node does not match the search value and is not a prefix of the search value then an index miss may also occur and processing may continue from block . In some instances this case may occur when the selected node is the root node of an index . Correspondingly in one embodiment adding a new node to the index in response to this miss case may include creating a new root node having a tag that is a common prefix of both the search value and the tag of the existing root node in this case the selected node . In some instances the common prefix of the new root node may be null which may be interpreted as a valid prefix for any value. The new root node may then be configured to refer to the selected node as a descendant. If necessary an additional node may be created to correspond to the search value and configured as an additional descendant of the new root node .

It is noted that in some embodiments an index miss may not immediately occur while traversing stratified unbalanced indexes if the tag of the selected node does not match the search value and is not a prefix of the search value. In one embodiment if this case is encountered then if selected node has a parent the parent node is selected. If the parent node is a non interior node that references another index the root node of the referenced index may be selected and processing may continue from block . Otherwise an index miss may occur. It is noted however that this case may not arise in non stratified self contained indexes that do not index other indexes . As an example of this case consider the stratified index of in which the search value is alice . Traversal of index may proceed to node having tag ali . Since node has a pointer to descendant node with associated tag information c which together with ali forms a prefix of the search value node may be selected. However the tag of node is alicia which does not match and is not a prefix of the search value. Thus traversal may return to node the parent of node which is a non interior node that references index . Correspondingly traversal may continue to node and ultimately to node which has a tag that matches the search value.

As noted above in some embodiments multiple instances of index each of which may include one or more instances of stratified index or non stratified index may be implemented within system and configured as replicas of one another. In some embodiments replica consistency may be enforced by employing replica update semantics that require commitment of updates to all or a majority of indexes of index . However such strong replica synchronization semantics may have deleterious effects on system performance particularly as system scales to serve larger numbers of clients. For example requiring updates to be committed to multiple instances before updates are considered complete and become visible to clients may prolong the latency of index update operations. Further if transactional semantics are employed in which unsuccessful updates must be rolled back to a previous state e.g. if the minimum number of replicas cannot be successfully updated the synchronization process may become particularly complex.

While some embodiments of system may use any of the aforementioned synchronization approaches in an alternative embodiment system may employ a lightweight or relaxed synchronization model. In one embodiment of such a model individual instances of index may independently operate to service client requests. Upon completing an operation that changes its state e.g. an operation to add a data item to data store which may require adding a node to an instance of index or index may be configured to forward the operation and its relevant parameters to all or a subset of other instances of index . Upon receiving a forwarded update operation a given instance of index may be configured to perform the operation locally thus effectively synchronizing the given instance with respect to the received operation.

Generally speaking it may be expected that forwarding index update operations among instances of index will succeed a majority of the time. Therefore minimizing the overhead involved in forwarding such operations may decrease the time and or bandwidth required to achieve synchronization among index instances in a majority of cases. For example eliminating acknowledgement responses or other types of protocol verification or handshaking from the forwarding process may free communications bandwidth for other uses such as to support a larger scale of index implementation involving a greater degree of synchronization traffic. In many instances the time required to propagate index updates throughout system which may generally correspond to the window of potential inconsistency of the index replicas may be limited to the communication latency required to forward the operation to the various instances of index and the processing latency required for nodes hosting the instances to apply the forwarded operation. Frequently this total time may be on the order of seconds or fractions of seconds. In some embodiments clients or applications that may be sensitive to this window of potential inconsistency may employ quorum techniques in which a given index read operation is conveyed to multiple instances of index and the read result having majority agreement among the instances is regarded as the result of the read operation. 

In some instances however forwarding of index update operations within system may fail. For example a communication link failure may render one node unreachable from another or may cause a forwarded operation to be lost truncated or otherwise damaged in transit. Alternatively a node may fail to receive or correctly process a properly forwarded update operation for example due to transient hardware or software issues. If as in one embodiment no attempt is made on the part of an originating instance of index to verify or assure that forwarded index update operations are successfully received and processed by targeted instances of index forwarding failure of individual operations may result in inconsistency among the index instances with respect to certain nodes .

Correspondingly in one embodiment a relaxed synchronization protocol among instances of index may include an anti entropy or set reconciliation task. This task may be referred to as an anti entropy task in that generally operation of the task may serve to reduce differences and increase similarities among different replicas of index thus decreasing the overall entropy among the replicas that may be introduced by random or systemic failure of update propagation to properly synchronize instances. In one embodiment set reconciliation may be performed when an initiating instance of index randomly selects another index instance with which to perform reconciliation. In various embodiments such selection may occur at predetermined or dynamically determined intervals. For example reconciliation may occur at a static rate of once per minute or at intervals determined according to a random or other statistical probability distribution. In some embodiments reconciliation may be performed after a certain number of index accesses have occurred or after access to certain individual ones types or groups of index nodes has been detected.

Generally speaking the methods of update propagation and set reconciliation or anti entropy described above may operate in a complementary fashion. Under the majority of circumstances update propagation may satisfactorily synchronize different instances of index within system . In those instances where index inconsistencies arise due to the failure of update propagation the anti entropy task may generally operate to reconcile such inconsistencies. It is noted that in some embodiments execution of the anti entropy task may not guarantee that two instances of index are precisely synchronized in their entirety. However in one embodiment the anti entropy task may be implemented to guarantee that its operation will not increase the degree of inconsistency between two instances of index . Thus over repeated applications the anti entropy task may facilitate convergence of replicas of index .

In some embodiments set reconciliation of different instances of index may be performed using exhaustive protocols that traverse each node of the respective index data structures in a consistent order e.g. a depth first or breadth first search order to identify discrepancies in index structure or indexed content. However various features of the unbalanced indexes described above such as the distribution of data according to key information rather than numbers of keys and the inclusion of count and or cumulative hash information within the index data structure may facilitate the implementation of more computationally efficient synchronization algorithms.

Numerous possible versions of the anti entropy set reconciliation protocol described previously are contemplated for use with unbalanced possibly stratified indexes implemented within instances of index . A description of one embodiment of such a protocol follows although it is understood that contemplated variations on the general protocol may exhibit different implementation priorities for example in choosing to optimize certain cases over other cases or to use one or another particular type or class of algorithm to perform a general step of the protocol. Thus it is intended that the described embodiment be regarded as illustrative rather than limiting.

In one embodiment an anti entropy protocol configured to reconcile different instances of an unbalanced index or a stratified unbalanced index may include the exchange between instances of various types of messages between the instances. An exemplary set of messages upon which one embodiment of the anti entropy protocol may be based may include a DATA message a REQUEST message a HASH message a FILTER message and a FINGERPRINT message. The general function of respective embodiments of each of these messages is described below followed by a discussion of how the messages may be used to implement an embodiment of the anti entropy protocol. In the following discussion reference may be made to exchange of data among instances of index although it is understood that such instances may implement one or more instances of unbalanced indexes or stratified unbalanced indexes that include any of the features described above.

The DATA message may be used to convey data about one or more index nodes from one index instance to another. In one embodiment the DATA message may be configured to convey only the tag associated with a given node while in other embodiments the DATA message may convey other fields associated with given node . In some embodiments if a given node is a non internal node the DATA message may also include all or some portion of the data item associated with the given node e.g. a record corresponding to the data item the data item itself as stored within data store or information about a root node of another index .

The HASH message may be used to convey information about one or more index nodes from one index instance to another without explicitly conveying the fields of a given node or a data item associated with a given node . In one embodiment the HASH message may be configured to convey a tag associated with a given node as well as a hash of the given node computed according to a suitable hash algorithm. In some embodiments the hash of the given node may also reflect a data item e.g. as stored within data store associated with the given node but may exclude any descendants of given node .

The REQUEST message may be used to convey a request for information associated with one or more nodes . In one embodiment the REQUEST message may be configured to convey one or more tag prefix values. In response the requesting instance may expect to receive information about those nodes having tags for which the conveyed tag prefix value is in fact a prefix. For a given node the received information may include the contents of the corresponding fields of the given node and or the data item corresponding to the given node . In some embodiments the REQUEST message may support further qualification of the requested tag prefix values such as by specifying that a value or range of values within the result space defined by a particular tag prefix value should be excluded from the results returned for that tag prefix value. For example a REQUEST message may specify that information about all nodes matching the tag prefix value alex should be returned except for those nodes that match the prefixes alexe or alexj .

The messages just described may generally operate at the level of granularity of individual nodes . However if the differences between index instances are generally small e.g. confined to a minority of nodes it may facilitate the synchronization process to quickly ascertain the status of multiple nodes at once. In one embodiment the FINGERPRINT and FILTER messages may be configured to communicate information about aggregations of nodes . Specifically in one embodiment the FINGERPRINT message may be configured to convey the fingerprint field of a node along with its tag from one index instance to another. As described above the fingerprint field of a given node may be configured to store a hash value that is determined as a function of the descendants of the given node . Thus if the fingerprint fields of respective nodes in different index instances are equal it may be highly probable depending upon the characteristics of the hash algorithm used that the arrangement and content of the descendants of the respective nodes are the same. That is it may be highly probable that the portions of the index instances descending from respective nodes are synchronized.

The use of fingerprints may allow a quick determination as to whether portions of index instances including substantial numbers of nodes are synchronized or not. However fingerprints indicating that corresponding portions are not synchronized generally may not provide further detail regarding how the portions differ. In one embodiment a FILTER message may be configured to convey a filter value that encodes a number of nodes corresponding to a particular prefix value from a first index instance to a second index instance . The second instance may then use the received filter value to test its own nodes that correspond to the prefix value to ascertain which nodes of the second instance are not present in the first instance if any.

In one embodiment the filter value conveyed by the FILTER message may be a Bloom filter although it is contemplated that any suitable filtering technique for recoverably encoding a set of data values into a filter value may be employed. Generally speaking a Bloom filter of a set of values e.g. nodes may correspond to an M bit binary value where M is an integer. Before any values are encoded into a Bloom filter its initial value may be zero. That is all bits of the filter may be in a deasserted state. A Bloom filter may be populated by passing each value to be encoded within the filter through each of a set of k independent hash functions each of which maps the value to be encoded onto a value in the range 0 M 1 . For each of the k resulting hash values a corresponding bit within the Bloom filter is asserted e.g. set to a logical 1 value . M and k may be selected as design parameters according to the number and type of values to be encoded within the Bloom filter as well as the desired probability of false positives discussed below . For example in a 1 024 bit Bloom filter using eight hash functions each hash function may produce a corresponding 10 bit hash value specifying a particular one of the 1 024 bits of the filter to be asserted.

To test whether a given value has been encoded into a Bloom filter the value is passed through the same set of k independent hash functions used to encode the filter and the resulting k bits of the filter value are examined. If any of the resulting k bits of the filter are not asserted the test value is definitely not encoded in the filter. If all of the resulting k bits of the filter are asserted the test value may or may not be encoded in the filter. That is the test value may have been originally encoded in the filter or it may be a false positive. In some embodiments the hash functions may be parameterized with a salt or seed value that is randomly or spontaneously generated e.g. as a function of the current system time on each separate occasion a Bloom filter is generated to reduce the probability that the same false positive values will be generated when a given set of values is successively encoded into a filter.

Thus for example a first index instance may encode a set of nodes A B C D E corresponding to a prefix P into a Bloom filter and may convey the filter to a second index instance using a FILTER message. In the second index instance a set of nodes A B X Y Z may correspond to prefix P. The second index instance may test each of the nodes against the filter and may determine that nodes A B and X may be encoded in the filter while nodes Y and Z are definitely not encoded in the filter. Thus the second index instance may correctly conclude that nodes Y and Z are not present in the first index instance and may conclude that nodes A B and X are probably present in the first index instance where X is a false positive. As a result the second index instance may take action to convey information about nodes Y and Z to the first index instance .

It is contemplated that the DATA HASH REQUEST FINGERPRINT and FILTER messages may be implemented and conveyed according to any suitable protocol or API and may include various types of fields or parameters configured to convey the information described above as well as any additional information necessary to decode and properly process the message. In one embodiment messages may include additional parameters that indicate whether for a given tag value included in the message the sending index instance either has corresponding data or needs corresponding data respectively referred to as the got data and need data parameters. For example if an index instance sends a FINGERPRINT message for a node that has the tag al and some number of descendants the instance may include a got data parameter indicating that the instance has some nodes within the prefix space defined by al . The instance may also include a need data parameter for example if its copy of the prefix space defined by al is believed to be incomplete. In some embodiments the got data parameter may be implicit in the DATA and HASH messages while the need data parameter may be implicit in the FILTER and REQUEST messages although a DATA or HASH message may explicitly specify a need data parameter while a FILTER or REQUEST message may explicitly specify a got data parameter. In one embodiment a FILTER message may be required to specify at least one of the need data or got data parameters.

In one embodiment an anti entropy protocol conducted by two index instances may begin when the two instances establish contact with one another. Each instance may assume that it both has and lacks some data. Correspondingly each instance may send a FINGERPRINT message to the other instance that specifies the tag and fingerprint of the root node of the instance and includes the got data and need data parameters. For example in an embodiment of index instance employing a stratified unbalanced index the root node may correspond to the node having no parent node within the index that has no parent or superior index .

One embodiment of a method of processing a FINGERPRINT message is illustrated in . In the illustrated embodiment operation begins in block where a FINGERPRINT message is received from a message sender. For example a first index instance may convey a FINGERPRINT message including a tag value a fingerprint and one or more of the got data or need data parameters to a second index instance . After a FINGERPRINT message is received then the index es of the message receiver are traversed to identify whether a node exists for which the received tag value is a prefix of or exactly matches the corresponding tag field block . For example the indexes of an index instance may be traversed starting from the root node using the method of or a suitable variant thereof.

If the received tag value is not a prefix or exact match of a tag field of any node then a node corresponding to the node referenced by the FINGERPRINT message may not exist at the message receiver. Correspondingly the receiver may respond by conveying a REQUEST message to the message sender specifying the tag value included in the originally received FINGERPRINT message block . In one embodiment processing of the REQUEST message may proceed as described in greater detail below. In some embodiments the REQUEST message may be conveyed only if the received FINGERPRINT message indicates the got data parameter.

It is noted that in some embodiments completion of individual messages exchanged during operation of the anti entropy protocol may not depend on whether additional messages generated in response to a given message successfully complete. That is in some embodiments the processing of individual messages may occur in a stateless and asynchronous fashion with respect to other messages. In discussion of the exemplary embodiments described herein this stateless asynchronous model will be assumed. Thus after the REQUEST message has been generated processing of the FINGERPRINT message itself may be considered complete block . However this model is not essential to the general operation of the anti entropy protocol and it is contemplated that in alternative embodiments any given message may block wait or otherwise maintain synchronization with messages generated subordinately or in response to the given message. For example explicit handshaking acknowledgement retry or other types of protocols may be employed in some embodiments to convey the state of completion of one message to another dependent message.

If the received tag value does correspond as a prefix or match of a tag of a particular node at the message receiver the received fingerprint value may be compared against the fingerprint field of the particular node to determine whether the two fingerprints match block . If so then it may be highly probable e.g. subject to the probability of the fingerprint algorithm in use producing two fingerprints that collide or have the same value despite being generated from different data that the message sender and the message receiver are synchronized with respect to the received tag value. For example it may be highly probable that any nodes having the received tag value as a prefix are in the same state within the index instance from which the FINGERPRINT message was sent and the index instance at which the message was received. Thus no additional messages may be generated in response to the FINGERPRINT message and the message may be considered complete block .

If the fingerprints do not match then the message sender and message receiver are not synchronized with respect to the received tag value and additional work may be needed to bring the sender and receiver closer together in state. As described above the FILTER message may be useful in allowing a sender to communicate specific information about certain nodes to a receiver. However in some embodiments the number of nodes that may be encoded into the FILTER message while preserving a reasonable false positive rate may be limited to a certain threshold value. If the number of descendant nodes exceeds this threshold at the message receiver node that matches the received tag value it may be more efficient to perform additional FINGERPRINT message processing before sending FILTER messages.

Thus in the illustrated embodiment if the fingerprints do not match the count field of the particular node at the message receiver may be examined to determine if it exceeds the threshold value for FILTER message processing block . If so the message receiver may be configured to subdivide its portion of the index range corresponding to the received tag value according to the children of the particular node for which the received tag value is a prefix block . For each child node the message receiver may be configured to send a corresponding FINGERPRINT message back to the original message sender specifying the tag and fingerprint field of the respective child node block . Additionally if there are gaps in the portion of the index range corresponding to the received tag value for example as indicated by the children of the particular node the message receiver may be configured to send one or more REQUEST messages for the tag values that correspond to the gaps block . Processing of the received FINGERPRINT message may then be considered complete block . In one embodiment in addition to the above actions if the received tag prefix value is an exact match of the particular node a HASH message corresponding to the particular node may be returned to the message sender.

For example as shown in a particular node of an index of a message receiver might have the tag al and children having corresponding tags alan alex alfred ali and alz . This suggests that the message receiver has some information about nodes that begin with alan and alex but not about nodes that might begin with alb alc or aid . Correspondingly the message receiver may convey a FINGERPRINT message for each of the children of node as well as REQUEST messages for gaps among the tags of these children. In embodiments where negative REQUEST syntax is supported the message receiver may convey REQUEST messages for tags other than those corresponding to the children of the particular node. For example the message receiver may send REQUEST messages for tags other than those prefixed with alan alex alfred ali and alz .

If the count value of the particular node does not exceed the threshold value for FILTER message processing then if the received FINGERPRINT message includes the got data parameter the message sender may have specific information about nodes not present at the message receiver. Correspondingly the message receiver may be configured to send a FILTER message that encodes into a filter e.g. a Bloom filter as described above each node that is a descendant of the particular node blocks . For example referring to if the particular node corresponds to node then a Bloom filter encoding each of nodes may be generated and returned via a FILTER message. In the illustrated embodiment if the got data parameter was not included in the original FINGERPRINT message respective FINGERPRINT messages may be generated and returned to the message sender for each of the children of the particular node instead of the FILTER message block . These FINGERPRINT messages may include the got data parameter. Following either generation of FILTER or FINGERPRINT messages in this case processing of the received FINGERPRINT message may be complete block .

One embodiment of a method of processing a FILTER message is illustrated in . In the illustrated embodiment operation begins in block where a FILTER message including a tag value and a filter value is received from a message sender for example in response to a FINGERPRINT message as described above. Once the FILTER message is received the index es of the message receiver are traversed to identify the particular node that corresponds to the received tag value e.g. for which the received tag value is a prefix or match in a manner similar to the described above with respect to block . In some embodiments if a FILTER message is generated in response to another message a node corresponding to the received tag value will generally exist.

The message receiver may then test each descendant of the particular node against the filter value provided in the FILTER message to identify those nodes that are not encoded in the filter value if any block . For each node at the message receiver that is not encoded in the filter value a corresponding DATA message may be returned to the message sender block . Processing of the FILTER message may then be considered complete block . As noted above depending on the type and configuration of the filter algorithm employed for the FILTER message false positives may occur. That is the message receiver may falsely conclude that certain ones of its nodes are encoded in the filter value and thus are present in the same state at the message sender when in fact they are not. Thus it is possible that a single round of the anti entropy protocol may not result in two index instances becoming synchronized with respect to every node . However it may be expected that in many embodiments a single round of the anti entropy protocol may not cause the instances to become more divergent and repeated applications of the protocol may be expected to converge within a certain number of rounds with a certain degree of probability depending on the degree to which the instances differ and the characteristics of the filter algorithm used e.g. the probability of false positives given the threshold value for filter encoding .

In some embodiments processing of the HASH REQUEST and DATA messages may be considerably simpler than the FILTER and FINGERPRINT messages. In one embodiment a HASH message receiver may attempt to identify a node corresponding to the tag value included in the message and may then compute a corresponding hash value of the identified node . If the received hash value matches the computed hash value the identified node may already be synchronized with a corresponding node at the message sender. Otherwise a REQUEST message including the received tag value is returned to the message sender to obtain a more current data version.

Processing of a REQUEST message in one embodiment may simply include the message receiver identifying each node for which the received tag value included in the message matches or is a prefix of the corresponding tag field for example using the unbalanced index navigation techniques described above. For each identified node a corresponding DATA message configured as described above is returned to the message sender. In one embodiment processing of a received DATA message may include identifying whether a node corresponding to the tag value indicated in the message exists at the message receiver. If not a corresponding node may be created and populated with data extracted from the message. If so the data associated with the existing node and or its corresponding data value may be replaced with data extracted from the message. In some embodiments data of an existing node may only be replaced if the received data is more current. For example a DATA message may include the contents of a record corresponding to a node at the message sender and the record may include timestamp information that may be compared with corresponding timestamp information at the message receiver to ascertain whether the received record is more current than the existing record. If so the received record may replace the existing record.

Variations of the general synchronization protocol of are possible and contemplated. For example in embodiments in which communication between index instances is performed using packets having a fixed length bandwidth utilization may be improved by conveying multiple FINGERPRINT messages for multiple nodes within a single packet rather than a single FINGERPRINT message corresponding to a particular node . An instance receiving such a packet may then be able to rapidly discern which particular ones of its index es mismatch with the sender without necessarily exchanging further messages with the sender. For example if the first FINGERPRINT message does not match the receiver may consider other FINGERPRINT messages within the packet prior to issuing a REQUEST FILTER or other message to the packet sender. In so doing the receiver may be able to narrow the discrepancy to a particular portion of the data structure which may reduce unnecessary network traffic to exchange messages regarding other portions of the data structure that are already synchronized.

In general it is contemplated that any of the methods or techniques described above for performing index instance reconciliation using an anti entropy protocol and or an update propagation protocol may be implemented by a process executable by one or more of nodes to implement the functionality of an instance of index . It is noted that numerous variations of the aforementioned methods and techniques for implementing anti entropy protocols for unbalanced data structures are possible and contemplated and the above discussion is intended to be illustrative rather than limiting. For example the general class of protocols via which some entities frequently communicate with other randomly selected entities in order to distribute information throughout a network may be referred to as gossip based protocols and other techniques or aspects of gossip based protocols may be employed for use in an anti entropy protocol among index instances . In various embodiments the example synchronization messages described above or other suitable messages may be combined in different ways to yield synchronization protocols having different characteristics.

Additionally while the keymap index application discussed above has been described as one possible application in which the stratified indexed data structure and synchronization techniques described above with respect to may be employed it is contemplated that such data structures and synchronization techniques may be employed in any application in which large quantities of data may be indexed for rapid access. Such applications need not necessarily include object storage systems but may include key value database systems search systems or any other applications where data indexing may be applicable.

Generally speaking the methods and techniques described above may be applicable to any system in which each member of a collection of data items is associated with a respective key or name defined within a namespace where the data item names are capable of being organized in some suitable hierarchical prefix based fashion such as described above. For example the data items may correspond to files within a file system having corresponding names within the file system namespace. Alternatively the data items may correspond to web pages or other web based resources having corresponding URLs within a URL namespace which may be defined relative to the public Internet a private intranet or a combination of these .

It is also contemplated that the indexing techniques described herein may be applied within data objects having some degree of internal structure in addition to or instead of among collections of such data objects. For example a given complex document such as a book may be regarded as a single object. As such at one level of abstraction the given document may be treated as a single data item and indexed along with other data items such as other documents or files within a storage system or another type of namespace. However the given document may have substantial internal structure that may be defined according to a namespace corresponding to the document such as sections chapters pages etc. Correspondingly it is possible that in some embodiments the structural elements within a given document s namespace may correspond to data items within data store and may be indexed according to the techniques described above. In other embodiments it is contemplated that hybrid indexing techniques may be employed in which different data items may be indexed according to different levels of granularity. For example the given complex document may be regarded as a data item unto itself among other documents some of which may have no additional internal structure to be indexed. For those documents that do possess such additional internal structure elements of that structure may be treated as additional data items to be indexed. Thus in various embodiments applications of the indexing techniques described herein may range among different levels of abstraction or granularity and may support combinations of different levels of abstraction or granularity.

In some embodiments the methods for accessing nodes of and synchronizing instances of index may be implemented along with the data contents of an instance of index as part of a single computational construct for example as methods associated with an object in an object oriented programming paradigm. In other embodiments portions of index configured to store data may be implemented as distinct separate structures from portions of index configured to access data and perform other control related tasks such as set reconciliation client interfacing etc. It is intended that references to an index data structure such as index encompass both the passive structures in which data may be stored as well as the active functionality that may be configured to operate on the stored data to implement desired index data structure operations such as index read and write accesses index reconciliation or other operations.

It is noted that in various embodiments implementation of any type of random generation or selection of events described herein may employ any suitable algorithm or technique for random number or event generation. In many cases computational techniques for implementing random methods may not produce purely random results but rather pseudorandom results. For example pseudorandom algorithms may specify deterministic processes configured to generate statistically random results. As used herein the generation of random or substantially random data is intended to include any suitable pseudorandom computational techniques as well as purely random data sources.

It is contemplated that in some embodiments any of the methods or techniques described above may be implemented as program instructions and data capable of being stored or conveyed via a tangible computer accessible storage medium. Such methods or techniques may include for example and without limitation the functions of instances of index data store and indexes and . Such methods or techniques may further include any of the methods illustrated in and any suitable variations thereof. Such program instructions may be executed to perform a particular computational function such as a particular method or portion of a method described above as well as to provide more general operating system functionality application functionality and or any other suitable functions. It is noted that in some embodiments components or methods described above as distinct may in other embodiments be integrated into fewer entities than those shown or functionality may be partitioned differently across components or methods from the partitioning described above.

One exemplary embodiment of a computer system including computer accessible storage media is illustrated in . Computer system may represent one embodiment of computing node . As discussed previously in one embodiment the functionality of any of the various storage system components described above may be distributed across a number of computing nodes such that a given component may be implemented by one or more computing nodes or partitioned across several computing nodes. While in some embodiments a computing node may exclusively implement the functions of a single component of system such as an instance of index or data store in other embodiments a computing node may implement the functionality of all or portions of several different components of system . In the illustrated embodiment computer system includes one or more processors coupled to a system memory via an input output I O interface . Computer system further includes a network interface coupled to I O interface .

In various embodiments computer system may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processor capable of executing instructions. For example in various embodiments processors may be a general purpose or embedded processor implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store instructions and data accessible by process . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing desired functions such as any of those storage service system components and other functions described in detail above are shown stored within system memory as code . It is noted that in some embodiments code may include instructions and data implementing desired functions that are not directly executable by processor but are represented or encoded in an abstract form that is translatable to instructions that are directly executable by processor . For example code may include instructions specified in an ISA that may be emulated by processor or by other code executable on processor . Alternatively code may include instructions procedures or statements implemented in an abstract programming language that may be compiled or interpreted in the course of execution. As non limiting examples code may include code specified in a procedural or object oriented programming language such as C or C a scripting language such as perl a markup language such as HTML or XML or any other suitable language.

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computer system and other devices attached to a network such as other computer systems for example. In various embodiments network interface may support communication via wired or wireless general data networks such as any suitable type of Ethernet network for example via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a tangible computer accessible storage medium configured to store program instructions and data as described above. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible storage media. Generally speaking a computer accessible storage medium may include storage or memory media such as magnetic or optical media e.g. disk or CD DVD ROM coupled to computer system via I O interface . A computer accessible medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computer system as system memory or another type of memory. Program instructions and data stored via a computer accessible medium may be transmitted by transmission media or signals such as electrical electromagnetic or digital signals which may be conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface .

Although the embodiments above have been described in considerable detail numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications.

