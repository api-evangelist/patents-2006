---

title: Method and apparatus for managing configuration information in a distributed computer system
abstract: A configuration manager federated bean is provided for each host computer in the three-tiered management system. The configuration manager federated bean for a host computer is contacted by federated beans that manage each of the data services when a data service starts and stops using a data storage volume associated with the host computer. The configuration manager bean maintains persistent configuration information for each data service. In one embodiment, configuration manager beans can operate in a clustered environment where several beans store configuration information in a single storage area. Each of the beans implements an arbitration protocol so that only one bean writes to the storage area at any given time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07555541&OS=07555541&RS=07555541
owner: Sun Microsystems, Inc.
number: 07555541
owner_city: Santa Clara
owner_country: US
publication_date: 20061107
---
This application is a divisional patent application of U.S. patent application Ser. No. 10 012 150 filed Nov. 16 2001 and entitled Method and Apparatus for Managing Configuration Information in a Distributed Computer System the disclosure of which is hereby incorporated herein in its entirety.

This invention relates to data service configuration information including the users of data volumes and the type of use and to methods and apparatus for storing such information and for persisting such information.

In a distributed computer system it is convenient to have distributed management capability for data services such as data imaging networked data replication and caching services. However these services are typically implemented by low level kernel routines running on each machine in the distributed system. One method of accomplishing such distributed management capability is to use a three tiered data services management system. The lowest tier comprises management facade software running on each machine that converts a platform dependent interface written with the low level kernel routines to platform independent method calls. The middle tier is a set of federated Java beans that communicate with the management facades and with the upper tier of the system. The upper tier of the inventive system comprises presentation programs that can be directly manipulated by management personnel to view and control the system. The federated beans allow managers located in one node of a multi node network to locate and control data services running in other nodes.

Since the management system is distributed and multiple data services can be using the same data storage volumes it can be difficult to determine which data service is using a given volume and how the data service is using the volume. Conflicts over the use of resources such as data storage devices can arise for a number of reasons. For example in a multi node system managers in different nodes may attempt to use the same storage devices for different conflicting purposes. Alternatively in a clustered system in which several host processors share the same storage device managers in different host systems may also be in conflict over the common storage devices.

Further it may also be necessary to persist configuration information so that the system can be restarted correctly in the case of power outages or device failures.

In accordance with the principles of the invention a configuration manager federated bean is provided for each host computer in the three tiered management system. The configuration manager federated bean for a host computer is contacted by federated beans that manage each of the data services when a data service starts and stops using a data storage volume associated with the host computer. The configuration manager bean maintains persistent configuration information for each of the data services.

In accordance with one embodiment the data services can access the configuration information during the host system boot process and before file systems are mounted and management software can obtain the same information at a later time in a consistent manner.

In accordance with another embodiment the configuration information is stored in such a manner that the information never is corrupted by multiple writes from different management software pieces.

In accordance with still another embodiment the configuration information is stored in a human readable file such that the information can be used for disaster recovery.

In accordance with yet another embodiment configuration manager beans can operate in a clustered environment where several beans store configuration information in a single storage area. Each of the beans implements an arbitration protocol so that only one bean writes to the storage area at any given time. In this embodiment the beans communicate over a network to determine which of the beans will write to the storage area.

A data services configuration management system constructed in accordance with the principles of the invention operates in a data services system that comprises three layers or tiers. The first or upper tier is a presentation layer with which a manager interacts at a single host location. The upper tier in turn interacts with the middle tier comprised of a plurality of federated beans each of which performs specific tasks in the system. The federated beans can communicate with each other both in the same host and in other hosts via a network connecting the hosts. Some of the beans can communicate with the lowest tier that comprises the aforementioned kernel modules that actually perform the data services. In this manner an entire data services system can be configured and managed from a single location.

The middle tier is implemented with a plurality of Federated Java trademark of Sun Microsystems Inc. beans. These beans comply with the Federated Management Architecture FMA Specification 1.0 a Java technology based component architecture and management services for automated dynamic network management developed by Sun Microsystems Inc. The FMA specification provides a standard for communication between applications services and devices across a heterogeneous network which enables developers to create solutions for complex distributed environments. The FMA Reference Implementation RI source code is available at http java.sun.com aboutJava communityprocess final.html.

The federated beans use a distributed management framework that implements the FMA specification for distributed management of data services. This framework is called the Jiro framework trademark of Sun Microsystems Inc. and is developed by Sun Microsystems Inc. This framework uses the concept of a management domain to provide services. A management domain is a portion of a network with attached managed resources and available management services used to manage those resources. Within a management domain the framework provides for base and dynamic services. The base services include a controller service an event service a logging service a scheduling service and a transaction service. Dynamic services are provided by the federated Java beans of the middle tier. Dynamic services require a hosting entity called a station which is a mechanism to allow many services to run within a single Java Virtual Machine. Every management domain contains one or more general purpose shared stations.

In addition the Jiro technology provides a lookup service that is used to register and locate all Jiro technology services including both base and dynamic services that are available in a management domain. Details of the Jiro framework and its use are available in the Jiro Technology SDK Programmer s Reference Manual available at http www.jiro.com which manual is incorporated by reference in its entirety. The Jiro lookup service is implemented by means of the Jini lookup service described above.

The configuration management system constructed in accordance with the principles of the present invention is implemented by a federated bean called a configuration manager CM bean . The data services themselves are implemented by other federated beans running in host . These other beans include an SNDR bean and a data services volume DSV bean . SNDR bean implements a network data replication service and DSV bean locates configures and manages volumes used by the SNDR bean. Other beans may implement other data services including a data imaging service a configuration service a notification service and a caching service. These other beans and services are not shown in in order to simplify the figure. Whenever changes are made in the data replication configuration of host both the SNDR bean and the data services bean can inform the configuration manager bean of the change in configuration information. SNDR bean also retrieves configuration information from configuration manager bean under appropriate situations. Configuration manager bean maintains a persistent view of the configuration of the data replication on host . In this manner if the host is interrupted during a data replication operation it can be restored to the proper state when the operation is resumed.

The data services are managed by means of stacked layers between the host file system not shown and a resource . For example in order to manage a network data replication system data replication bean communicates with a data replication layer in the layered stack via a data replication management facade and a native interface . The data replication capability is actually implemented in the kernel layer shown running in host in . In particular access by the host to a resource which can be a data storage component is provided by a layered stack comprising a data service volume layer a network data replication layer and a cache layer and may also include other layers not shown in . Application programs running in host and the host file system access resource though the layered stack and layers cooperate to implement the various data services. For example the data service volume layer places itself between device drivers in the normal data path and shunts I O information through the other data service layers and .

The data services layers would generally by implemented in platform specific code for example in C routines that expose application programmer interfaces APIs that can be accessed only from the host in which the layer is installed. In order to provide for remote management capability in accordance with the principles of the invention the data replication layer and the data service volume layer are controlled by software running on the lower tier of the data services system. The lower tier includes native interfaces and that convert the APIs exported by the layers and into a platform independent language such as Java .

The native interfaces are in turn controlled by management facades and that provide the required remote management capability. In particular the management facades provide a means by which the respective layers and can be accessed and managed as Jiro services. The management facades are essentially object oriented models of the kernel resident layers and and provide a collection of APIs to manage their associated layers.

In accordance with the principles of the invention the CM bean is provided in the middle tier of each host in the system and is responsible for storing and retrieving configuration information required by the management services and the data services. Each of the management services and data services has its own unique set of information that must be persistently stored. illustrates a host computer system with a plurality of data services and a CM bean running therein. As shown in the CM bean can interact with several different data services.

The data services are represented in by the federated beans that manage them and include a Storage Network Data Replicator SNDR bean an Instant Image II bean a Data Services Volume DSV bean that manages local Storage Volumes SV and exported SCSI Target Emulation volumes STE a Storage Cache Manager SCM bean and a Remote Notification RN bean . The CM bean will provide an interface to each service with which it interacts. In addition a command line interface is provided to allow a manager to specify resource groups for which the CM bean is responsible when the CM bean is operating in a clustered environment.

Each of the federated beans representing a data service interacts with the CM bean by calling methods in the appropriate interface. In order to call these methods the federated bean representing a data service obtains a proxy an identifying handle to the CM bean either by using the Jiro lookup service or by using another lookup service such as a lookup service implemented with another federated bean. Once the proxy has been obtained it can be used to directly call the CM bean interface methods. In a similar manner management systems that use a graphic user interface GUI or a command line interface CLI can also obtain a proxy to the CM bean so that the interfaces can call the appropriate methods.

The CM bean has two modes of operation so that it can work in both clustered and non clustered environments. In order to operate in both environments CM bean can use a native interface which in turn uses a native C library called the libcfg library to read and write directly into a storage device file containing the configuration information. The libcfg library is discussed below and defines a set of application programming interfaces APIs which enable storing and retrieving information in a storage device thereby enabling the bean to work in both a clustered and a non clustered environment. In addition since the CM bean reads and writes directly to the file the data services can access the information during a boot up without waiting for the conventional file system to begin operation.

Each of the management services and data services has a unique set of information that must be stored. Accordingly the CM bean exports a set of interfaces where one interface in the set is used by each of the services. illustrates the interfaces used by the CM bean implementation to interact with the various data services. Each interface has a method that stores and retrieves configuration information. The method takes as parameters a service name to identify the service and a plurality of fields that contain the information to be stored or retrieved. In an SNDR system a secondary copy or mirror of information located in a primary volume at a primary host is maintained at a secondary host. When changes are made to the primary volume updates are also made to the secondary volume so that the primary data and the secondary data remain synchronized. The changes that are made are recorded in bitmap volumes associated with the primary and the secondary volumes. Together the primary volume the secondary volume and bitmap volume are called a volume set. Volume sets can also be grouped together so that various operations can be performed on the group with a single command. The SNDR interface uses sndr as the service name. In addition the SNDR federated bean uses an additional sndr temp service name. For both services the fields are named as follows 

In a similar manner in a point in time instant image or data imaging system data in a master volume is copied to a shadow volume so that a snapshot of the data is made at a given point in time. A complete copy may be made all at once and the resulting shadow volume is called independent. Alternatively the copy can be made as read and write operations are performed in which case the shadow volume is called dependent. A bitmap volume can also be used to track changes between the master and shadow volumes. As with the SNDR system the master shadow and bitmap volumes together are called a volume set and volume sets may be grouped in order to simplify management of volume sets. In addition an overflow volume may be assigned to a volume set if the shadow volume is smaller than the master volume and may fill. The Instant Image interface will use ii as the service name. In addition the II federated bean may need to store II group information and if so can use ii group as a service name.

Two interfaces are used with the data service volume bean because the bean offers two volume service types. The first is a storage volume SV data service interface that provides data redirection if I O data through other data services and is used for local volumes. The second type is called a SCSI Target Emulation STE data service that allows any backend storage to be exported for use on another host through a fiber channel. The SV data service will use sv as the service name. The fields are as follows 

The STE data service interface requires three different service names ste tm for associating ports with drivers ste vd for associating volumes with ports and ste ph for defining phantom headers and tails. For the ste tm service the fields are as follows 

The remote notification service provides notifications to remote managers of significant events in the data service management system generally via e mail. The Remote Notification RN bean that manages the service is the only bean that is not based on a data service. The RN bean interface requires an rn service name with the following fields 

The SCM data service performs conventional data caching operations and needs to store only three pieces of information. The SCM interface requires an scm service name and uses the following fields 

The CM bean implementation persists the information which is presented for storage by the data services by means of the libcfg library routines which are called via an interface . The libcfg interface performs simple parsing of configuration data and persistent data as well as handling of shared configuration information between multiple hosts. All data is assumed to be ASCII string data.

The configuration information exists either in a shared file on a distributed file system or in a shared disk partition and may be accessed by multiple logical hosts within a cluster. Thus care must be taken when accessing the configuration to properly open and lock the configuration when updating.

In one embodiment the design of the libcfg library breaks the configuration information into two major sections. The first section is a shared data service and management service section that contains configuration information that will be used by the data service command line interfaces and GUIs boot programs and management service applications. The second section contains persistent data that can be used by other programs.

In an illustrative embodiment the basic design is called a key driven parser in which keys are used to identify entries in the configuration and persistent information sections. The possible keys are contained in a parser configuration file that will exist on disk and in memory once the configuration file is loaded. The configuration file may be updated to add or extend the keys that are used to access or place data into appropriate information sections. A checksum is used to track changes with each new parser configuration. Each of the basic parser configuration file entries is a rule having the following form 

The rule consists of a service name followed by one or more field names. Field Names name1 name2 name3 etc. are positionally ordered separated by a . character and are used for retrieving or storing values. All values are ASCII strings. If a value is not present for a given field then a placeholder will be inserted.

For example an illustrative parser configuration file for the data services mentioned above might include the following rules 

Each parser configuration rule defines what fields may be specified the positional order of fields and how they may be retrieved or written into a specified information section. For example the parser configuration rule 

This key would return all of the specified field value strings defined in the parser configuration rule for II data set 1. If only the master volume information is needed then the following key can be used 

The persistent data section can use the same service names as the configuration section. For example such a key might have the following form 

Sometimes a configuration field may need to contain freeform data. In this case the freeform data can be stored and retrieved as option data that has the form 

Any specified parser configuration field may contain options data but generally fields named options contain this data. For example the sndr.set1.options field could contain the option values row 1 col 2 .

The libcfg library can support systems that are configured as clustered systems and as standalone systems. As set forth above many configuration rules include a field with a field name of cnode which can be used to indicate with which cluster disk device group or resource this entry will participate in the configuration. The cnode field on a standalone system will be NULL and in a clustered system the value in this field can be entered by a special resource interface. If the cnode field has a NULL value then all storage and retrieval routines will operate on all configuration entries. If the cnode field has a non NULL value then only those entries whose cnode field is values match the cnode value in the key will be retrieved. All storage operations will automatically include the specified node value in the cnode data field value.

The actual methods for storing and retrieving data in both the configuration section and the persistent data section are shown in the interface section of . These methods include the cfg get cstring file key value method that is used to retrieve into the variable value information from the configuration section file as identified by key. For example a call to method cfg get cstring file ii.set1.master value would return in the variable value the master volume for set 1. Similarly the cfg put cstring file key value stores information in the variable value into the configuration section file in the entry identified by key. 

The methods also include the cfg get pstring file key value method that is used to retrieve into the variable value information from the persistent data section file as identified by key. For example a call to method cfg get pstring file ii.set2.master value would return in the variable value the master volume for set 2. Similarly the cfg put pstring file key value stores information in the variable value into the persistent data section file in the entry identified by key. Other conventional methods that allow new keys to be entered into the parser configuration file and that lock and unlock the configuration file have been omitted to simplify .

In a standalone or non clustered environment the CM bean operates in a first mode in which it reads and writes to the configuration file using the libcfg interface in an unrestricted manner since it is the only bean that will write to the file. However In a clustered configuration such as that shown in each host and has a CM bean and respectively running in it. Each CM bean can write to the configuration file via the libcfg interface as indicated schematically by arrows and . In such a clustered environment the CM beans operate in a different mode. In this clustered mode any CM bean can read from the file but only one CM bean can write to the configuration file at any given time since all of the hosts and in the cluster share the same configuration file .

In order to prevent two CM beans from attempting to simultaneously write to file while operating in clustered mode each CM bean must implement an arbitration protocol to decide which bean will perform the writing. Once arbitration is complete only one CM bean will be considered to be in active mode and can write to the configuration file . The remaining beans will be in hot standby mode. If the active bean fails or its host fails the arbitration protocol will be used to choose which CM bean in hot standby mode assumes the active mode. When a CM bean is in the hot standby mode it still receives configuration information from the other data service beans running on its host. However a CM bean in hot standby mode does not write to the configuration file. Instead it sends the configuration information to the active CM bean which performs the write.

Each CM bean follows an arbitration protocol that is designed to determine which CM bean will be responsible for writing to the configuration file. The arbitration protocol is used during three scenarios. The first scenario is a full restart. For example a full restart can occur when power is restored after a failure or a reboot is done after kernels are upgraded. During a full restart scenario all hosts begin operation at or near the same time and a decision must be made as to which CM bean will be in active mode. In this case it is not important which host has the active CM bean but it is important that only one CM bean becomes active.

The second scenario is a single node restart. A single node restart occurs when a single host with a CM bean is added into an existing and already running cluster. This addition might be made because additional capacity is needed or because a broken machine has been repaired. In this case the arbitration protocol allows the CM bean in the added host to determine whether another CM bean is already in active mode.

The last scenario is a failure of the CM bean that is in active mode. The CM bean in active mode could fail for several reasons. When this occurs one of the other CM beans on hot standby must take over active role. The arbitration protocol discussed below handles all three of the aforementioned scenarios.

When a CM bean begins operation it has no way of knowing whether it is part of a full restart scenario or a single node restart. However the protocol is designed to handle both cases at once. In order to decide which CM bean assumes active mode each CM bean is assigned a unique ID number. In one embodiment this unique ID number can be the network address of the host or node on which the CM bean resides. In accordance with the protocol the ID numbers are compared to determine which bean will assume active mode. For example the CM bean running in the node with the lowest network address could assume the active mode. In the arbitration process the CM beans and exchange information over a network as schematically illustrated by arrows and using for example the existing Jiro event service. If this network is the Internet then IP addresses would be used. By comparing IP addresses the CM beans can determine which one has the lowest number and thereby choose the active bean.

The steps a CM bean follows when starting operation in a system where many nodes are starting at or near the same time are shown in and illustrated in the following pseudocode.

The arbitration process begins in step and proceeds to step where a CM bean sends out its the IP address of its own host to all other hosts. The bean then starts a timer that operates for a predetermined interval of time for example one minute. If the bean receives no response from another host within the time interval and the timer expires as determined in step then the process proceeds via off page connectors and to step where the bean assumes it is the active CM bean and enters active mode. The process then finishes in step .

If the bean does receive a response message from another host before the timer expires as determined in step it can be one of two things another IP address which means that another CM bean started and is performing the same start up protocol or a command to go to hot standby which means that either another CM bean is already in active mode or that the other CM bean has a lower IP address . In particular if an IP address is received as indicated in step the process proceeds to step .

In step the arbitration protocol determines whether the received IP address is lower than the IP address of the CM bean host. If so the CM bean cannot enter active mode. Instead in step the CM bean enters hot standby mode and proceeds via off page connectors and to step where the beam stores the received IP address as the address of the active mode CM bean. The process then finishes in step .

Alternatively if in step it is determined that the CM bean host IP address is lower than the received IP address then the process proceeds via off page connectors and to step where the CM bean sends a message to the CM bean in the other host telling that CM bean to enter hot standby mode. The process then returns via off page connectors and to step to determine whether the timer has expired and to await possible other messages.

When a single CM bean is added to an already running system it follows the above protocol as shown in . In particular it sends its own IP address to the Jiro event service as indicated in step . The CM bean in active mode listens for events such as this and responds by sending back a message telling the newly started CM bean to go into hot standby mode. Thus the newly added CM bean will follow process steps and .

The final case that the arbitration protocol must cover is the case where the CM bean in active mode fails. This failure is detected when a CM bean in hot standby mode is not able to send messages to the active CM bean. This protocol is shown in in is also set forth below in pseudocode.

The process begins in step and proceeds to step where a hot standby CM bean attempts to send new configuration information to the active CM bean. In step a check is made to determine if the send operation failed. If not the process proceeds via off page connectors and to finish in step . However in this case we are assuming the active CM bean may have failed and consequently the send operation will fail. Thus the process proceeds to step where the active CM bean is cleared set to NULL . Then in step the hot standby CM bean sends out a message to all other CM beans telling them that it is entering active mode.

Then in step the hot standby CM bean starts a timer for a predetermined period of time for example ten seconds. In step a determination is made whether the timer has expired and the active CM bean identification is still cleared. If the timer has not expired the process proceeds via off page connectors and to step where the hot standby bean listens for responses to its message.

The hot standby bean may receive two types of responses. The first response type would be generated by the real active CM bean and is detected in step . Such a response would mean that the original configuration message send operation failed for reasons other than that the active CM bean had failed. In this case the process proceeds to step where the host IP address of the current active CM bean is stored in the active CM bean identification area. The process then proceeds via off page connectors and back to step where the hot standby CM bean tries to re send the configuration information and the steps described above are repeated.

The second type of message that a hot standby CM bean could receive in response to its message would be generated by another CM bean in hot standby mode. Such a scenario could occur if that other CM bean also tried to send information to the active CM bean and its send operation also failed. This message is detected in step and includes the host IP address of the other CM bean. In step the received IP address is compared to the IP address of the hot standby CM bean to determine if the received address is lower. If it is then in step the bean enters the hot standby mode and in step the host IP address of the other CM bean is stored in the active CM bean identification area. The process then proceeds via off page connectors and back to step .

Alternatively if in step the hot standby CM bean determines that its host IP address is lower than the received IP address it sends a message to the other CM bean causing the other CM bean to enter the hot standby mode. The process then proceeds via off page connectors and back to step . This part of the protocol only lasts for a predetermined time interval as determined by the timer for example 10 seconds or until another CM bean has successfully asserted the active mode.

In particular when the timer has expired or another CM bean asserts that it is active the process proceeds from step via off page connectors and to step where a check is made to determine if the timer has expired. If the timer has expired the process proceeds to step where the hot standby CM bean enters the active mode and the process finishes in step . Alternatively if the timer has not expired because another CM bean has assumed active mode then the process finishes in step .

A software implementation of the above described embodiment may comprise a series of computer instructions either fixed on a tangible medium such as a computer readable media for example a diskette a CD ROM a ROM memory or a fixed disk or transmittable to a computer system via a modem or other interface device over a medium. The medium either can be a tangible medium including but not limited to optical or analog communications lines or may be implemented with wireless techniques. It may also be the Internet. The series of computer instructions embodies all or part of the functionality previously described herein with respect to the invention. Those skilled in the art will appreciate that such computer instructions can be written in a number of programming languages for use with many computer architectures or operating systems. Further such instructions may be stored using any memory technology present or future including but not limited to semiconductor magnetic optical or other memory devices or transmitted using any communications technology present or future. It is contemplated that such a computer program product may be distributed as a removable media with accompanying printed or electronic documentation e.g. shrink wrapped software pre loaded with a computer system e.g. on system ROM or fixed disk or distributed from a server or electronic bulletin board over a network e.g. the Internet or World Wide Web.

Although an exemplary embodiment of the invention has been disclosed it will be apparent to those skilled in the art that various changes and modifications can be made which will achieve some of the advantages of the invention without departing from the spirit and scope of the invention. For example it will be obvious to those reasonably skilled in the art that in other implementations different arrangements can be used for the scope and arrangement of the federated beans. Other aspects such as the specific process flow as well as other modifications to the inventive concept are intended to be covered by the appended claims.

