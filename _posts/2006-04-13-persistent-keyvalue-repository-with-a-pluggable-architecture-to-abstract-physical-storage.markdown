---

title: Persistent key-value repository with a pluggable architecture to abstract physical storage
abstract: A system and techniques are described for managing key-value pairs using an architecture that does not restrict its users to any specific platform or storage subsystem. According to one aspect of the invention, the repository is portable in that the architecture need not change based on the environment and platform in which the repository is used. Rather, the portion of the architecture that is platform-specific is limited to plug-ins at a storage abstraction layer of the repository. The plug-ins expose the same storage abstraction interface to the other layers of the repository, but are implemented to interact with different platforms and storage subsystems. Consequently, in response to being ported from one platform to another, the repository may simply change the plug-in to invoke for persistent storage operations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07617218&OS=07617218&RS=07617218
owner: Oracle International Corporation
number: 07617218
owner_city: Redwood Shores
owner_country: US
publication_date: 20060413
---
This patent application is a divisional application of and claims priority under 35 U.S.C. 120 to U.S. patent application Ser. No. 10 253 088 filed Sep. 23 2002 now U.S. Pat. No. 7 096 213 entitled PERSISTENT KEY VALUE REPOSITORY WITH A PLUGGABLE ARCHITECTURE TO ABSTRACT PHYSICAL STORAGE the contents of which are hereby incorporated by reference as if fully set forth herein.

U.S. patent application Ser. No. 10 253 088 claims priority to the following provisional U.S. Patent Applications the entire contents of which are incorporated herein for all purposes 

U.S. Provisional Patent Application No. 60 370 963 entitled Personalized Content Within a Global Namespace filed Apr. 8 2002 and

U.S. Provisional Patent Application No. 60 372 186 entitled Approach for Personalized Content Within a Global Namespace filed Apr. 12 2002.

U.S. patent application Ser. No. 10 304 449 entitled Mechanism for Creating Member Private Data in a Global Namespace filed on Nov. 25 2002 by Surojit Chatterjee and Alok K. Srivastava 

U.S. patent application Ser. No. 10 308 809 entitled Metadata Format for Hierarchical Data Storage on a Raw Storage Device filed on Dec. 2 2002 by Surojit Chatterjee and Alok K. Srivastava and

U.S. patent application Ser. No. 10 232 907 entitled Use of Dynamic Multi Level Hash Table for Managing Hierarchically Structured Information filed on Aug. 30 2002 by Surojit Chatterjee and Sameer Joshi.

The present invention relates to data repositories and more specifically to repositories for storing key value pairs.

Many types of information are commonly stored in the form of key value pairs where the key portion of the pair is a label and the value portion of the pair provides a value associated with the label. For example information about the configuration of a computer system may include the following key value pair memory 512M to indicate that the amount of dynamic memory in the computer system is 512 megabytes.

Typically a software program or system that needs to store large amounts of key value pairs will include a repository for storing the information and include logic for managing the repository. When such repositories are used for storing configuration data the repositories are often referred to as registries.

When each program or system that requires a key value pair repository implements and manages its own repository the result is a proliferation of proprietary repositories and a massive duplication of work. To address this problem key value pair repository designers can expose an application programming interface API to their repository to allow certain third party applications to make use of their repository. For example an operating system may allow third party applications designed for the operating system to store key value pairs in the repository that is managed by the operating system.

Unfortunately such open repositories do not provide a general solution because they are typically tied to a specific platform or storage subsystem and are therefore not portable or useable as general purpose key value pair repositories. Because they are designed using certain assumptions about the environment and platform in which they will be used they are generally not available for use by applications or systems that do not conform to those assumptions.

A method and system for providing cluster wide access to a shared key value pair repository is described. In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent however that the present invention may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.

Techniques are provided for managing key value pairs using an architecture that does not restrict its users to any specific platform or storage subsystem. According to one aspect the repository is portable in that the architecture need not change based on the environment and platform in which the repository is used. Rather the portion of the architecture that is platform specific is limited to plug ins at a storage abstraction layer of the repository. Each of the plug ins exposes the same storage abstraction interface to the other layers of the repository but is implemented to interact with a different platform or storage subsystem than the other plug ins.

In addition the pluggable nature of the architecture results in cross platform portability. For example the repository may be used on any number of popular Operating System Hardware combinations such as Solaris Sun AIX IBM HPUX HP Windows Dell etc. Consequently in response to being ported from one platform to another the repository may simply change the plug in to invoke for persistent storage operations.

According to one aspect performance of the repository is enhanced by maintaining a master cache of key value pair information and local caches of key value pair information. According to one embodiment a single local cache is managed on each node where the client associated with the cache on any given node is not dictated by the repository. For example the cache for a node may be associated with the client on that node that will most heavily use the repository by causing that client to make the appropriate calls to the repository.

Referring to it is a block diagram illustrating a system for providing cluster wide access to a shared key value pair repository according to an embodiment of the invention. Specifically illustrates a cluster that includes two nodes and . A two node cluster embodiment is shown to simplify the description of the system. However the invention and techniques described herein are not limited to clusters having any particular number of nodes.

The term cluster is used herein to refer to any set of nodes that are able to communicate with each other. A cluster may include for example a group of networked computers. In some situations clusters are managed as a unit by cluster management software. Cluster management software is an example of a software system that could make use of key value pair repository . Specifically cluster management software may use key value pair repository as a cluster registry to store information about the configuration of the cluster that is managed by the cluster management software. It should be noted however that cluster management software is merely one example of a client that might make use of repository . The present invention is not limited to any particular type of client. Rather in many situations numerous disparate types of clients will use repository .

Referring again to node includes two clients of repository while node includes one client of repository . Clients and are referred to as clients because they request services of the repository in order to manage the key value pairs in which they are interested. Clients and generally represent any form of software program that requires storage of key value pairs and are not limited to any particular type of software program.

In the embodiment illustrated in repository includes several layers of functionality. Specifically repository includes an API layer a service abstraction layer a messaging and cache layer a storage abstraction layer and storage subsystems . In general API layer presents a common interface to all clients and through which clients can make calls to store access and manage key value pairs in repository . As shall be described in greater detail hereafter routines within API layer expose to clients and an interface that is independent of the actual storage subsystem that is ultimately used to durably store the key value pairs.

Service abstraction layer includes routines that determine how to process calls received by the routines at API layer . Messaging and cache layer includes routines that may be called by components of repository to communicate with other components of repository . In addition messaging and cache layer includes routines for managing a cache of key value pairs so that all requests made by a client do not result in accesses to storage subsystems .

Storage abstraction layer includes plug ins and . Each plug in exposes the same storage access API to the routines in layers and . However the routines that implement the common storage API differ from plug in to plug in based on the type of storage subsystem associated with the plug in. Storage subsystems represent any form of durable storage system that is able to store key value pairs.

According to one embodiment one component of repository is designated as the master component. The routines in the messaging and cache layer of the master component have exclusive access to the storage abstraction layer . The master component also manages a master cache of information from repository . In the embodiment illustrated in component is the master component. Consequently the routines in the messaging and cache layer of component manage a master cache and have exclusive access to plug ins and that reside at the storage abstraction layer .

Each node in the cluster also includes a single caching component . The caching component for a node maintains a cache of information from the repository . The client associated with the caching component is referred to herein as the caching level client . According to one embodiment the master component is the caching component for the node on which the master component resides.

In the illustrated embodiment component is the caching component for node and as such manages a cache . Client which is associated with component is the caching level client for node . Component which also resides on node is not a caching component and therefore does not maintain its own cache of information from repository .

According to one embodiment a client establishes its associated component as a caching component based on information passed to repository through calls made by the client to routines in API layer . For example client may establish itself as the caching level client for node by making the appropriate call into API . The call may pass to API a value that indicates that component is to be the caching component for node .

Because the caching level client generally has faster access to the cache managed by the caching component it is preferable for the caching level client on the particular node to be the client that uses the repository most heavily. For example client and client may represent two different kinds of clients where client makes heavy use of repository and client uses repository rarely. Under these circumstances client would be selected as the caching level client. Client could then be designed to make the appropriate calls to component to cause component to be the caching component for node .

According to an alternative embodiment the actual repository use of clients on node may be monitored and the component that is using repository most heavily may be dynamically selected as the caching component. In such an embodiment routines may even be provided for dynamically passing the caching responsibility from one component to another based on the changing access patterns of the clients that are associated with the components.

Various techniques may be used to manage the cache when write operations are performed against the repository. For example one embodiment may use a write through approach to maintaining the cache during write operations. The present invention is not limited to any particular approach to managing caches during write operations.

In the embodiment illustrated in cluster has a single master component with rights to interact with storage abstraction layer . Because abstraction layer is accessed from a single master component various problems associated with resource sharing and concurrency control may be avoided. However alternative embodiments may include a plurality of master components with rights to directly interact with storage abstraction layer . Various concurrency control techniques may be used to avoid potentially harmful interactions in such a system. For example the namespace of the keys may be partitioned where each master component is assigned one of the namespace partitions. Under such an embodiment each master component may be allowed to access storage abstraction layer only for operations involving keys that fall within the namespace partition assigned to the master component.

Clients that wish to use repository to manage key value pairs do so by making calls to routines in API layer . According to one embodiment the routines in API layer expose interfaces for all operations supported by repository . In one embodiment the routines in API layer perform parameter validation and error checking. If calls made to the routines in API layer pass the tests performed at API layer then the calls are passed down to the appropriate routines in the service abstraction layer .

The routines of API layer may be provided to the developers of such clients in the form of a code library. The developers may then include in their clients code that makes calls to the routines in the code library. The code library may then be statically linked with the client code at the time the client code is compiled or dynamically linked to the client code at runtime.

According to one embodiment the interface exposed by API layer may include interfaces for multiple programming languages. For example API layer may expose both a JAVA API for use by clients written in or compatible with the JAVA programming language and a C language API for use by clients written in or compatible with the C programming language.

According to one alternative embodiment API layer exposes only a C language interface and repository includes one or more additional modules for making calls into API layer based on calls received from clients written in other languages. Such modules effectively transform calls from the clients in one language to calls in the language supported by the interface exposed by API layer . For example such a module may expose the JAVA based repository API to Java based clients and then use JONI Wrappers to convert calls made through the JAVA based repository API into calls made by the module into the C based repository interface exposed by API layer .

The service abstraction layer determines how to process calls made from clients. A variety of factors may determine how any given call is handled. Such factors include for example the identity of the client making the call the access mode applicable to the call and the type of operation requested by the call. Access modes shall be described in greater detail below.

Depending on these factors the routines in the service abstraction layer may access a local cache access a master cache or make a call to a messaging routine in messaging and cache layer to send a request to a different component of the repository . If the called routine in the service abstraction layer is not in a caching component or master component then the called routine in the service abstraction layer calls a routine in the messaging and cache layer to pass request on to the local caching component.

If the called routine in the service abstraction layer is in a caching component then the called routine in the service abstraction layer checks the local cache to see if the cache contains information to answer the request. If the local cache does not contain information to answer the request then the called routine in the service abstraction layer calls a routine in the messaging and cache layer to pass the request on to the master component.

If the called routine in the service abstraction layer is in the master component then the called routine in the service abstraction layer checks the master cache to see if the cache contains information to answer the request. If the master cache does not contain information to answer the request then the called routine in the service abstraction layer calls a routine in the messaging and cache layer to invoke the appropriate plug in at the storage abstraction layer to retrieve the information from durable storage on one of the storage subsystems .

According to one embodiment all calls made from routines in the service abstraction layer to messaging routines in messaging and cache layer are stateless. In such an embodiment each message that the service abstraction layer sends through messaging routines within the messaging and cache layer contains all the necessary information to perform the desired operation.

According to one embodiment routines in the service abstraction layer of caching components and the master component have the responsibility of authenticating clients. During the authentication operation the routines determine whether or not the client is trusted . Clients that are not trusted are not allowed to perform certain types of operations.

The messaging and cache layer includes routines for accessing and managing a cache and routines for communicating with other components of repository . According to one embodiment the caching routines are only used by one component in each node. Other components on the node use the cache indirectly by forwarding requests to the component that is managing the cache.

According to one embodiment how a caching routine satisfies a request is completely transparent to the routine that calls a caching routine. Specifically upon receiving the request the caching routine checks the cache that it manages. If the cache contains the information required to satisfy the request then the caching routine retrieves the information from the cache and provides the information to the calling routine. However if the cache does not contain the information required to satisfy the request then the caching routine obtains the required information by other means. For example if the caching routine belongs to a caching component then the caching routine may call a messaging routine to request the required information from the master component. If the caching routine belongs to the master component then the caching routine may call the appropriate storage abstraction layer plug in to retrieve the requested information from a storage subsystem. The caching routine may cause the information to be stored in the cache that it manages in addition to providing the requested information back to the calling routine.

According to one embodiment the messaging routines in the messaging and cache layer are configured to send requests in network byte order at least when the messages must traverse a platform boundary within a cluster. For example assume that node is running on a first platform and node is running a second platform. In such a scenario the messaging routines in node send messages to the messaging routines on node in network byte order. Similarly the messaging routines on node send messages to the messaging routines on node in network byte order. By sending messages across platform boundaries in network byte order the messages sent by senders can be accurately reconstructed by recipients that reside on different platforms than the senders.

According to one embodiment routines provided in the storage abstraction layer completely abstract what kind of backend storage is being used to durably store the key value pair information managed by repository . For example both plug in and plug in expose an identical interface to the caching routines in messaging and cache layer of the master component even though plug in may be designed to operate with a completely different storage subsystem than plug in . While plug ins and expose the same interface to the caching routines the logic of the routines that implement the interface may be completely different based on what kind of backend storage the plug in is designed to interact with.

Significantly because all of the platform specific logic is contained in the plug ins at the storage abstraction layer the routines at all other layers of repository are not platform specific or storage subsystem specific. Consequently clients that use repository are effectively insulated from platform specific design details making both the clients and the upper layer components of repository portable across platforms.

Because storage abstraction layer is implemented using one or more plug ins that expose a common interface repository is not limited to any particular backend subsystem or platform. Any subsystem or platform capable of providing the functionality associated with the exposed common interface may be used. Such backend platforms may include but are not limited to LDAP MSCS shared raw devices raw devices and or private file system files within a shared nothing cluster Cluster File Systems CFS and distributed configuration repositories.

When repository is requested to perform an operation that requires access to key value pairs on persistent storage a call is made typically from a caching routine in the messaging and cache layer of the master component to storage abstraction layer . According to one embodiment repository selects the specific plug in to call based on one or more of a variety of possible factors. For example repository may include an environment variable whose value may be set by an administrator where the value of the environment variable indicates which type of storage subsystem is to be used for persistently storing the data managed by repository . Alternatively repository may include discovery logic that detects which storage subsystems are available to a particular installation of repository . If only one type of subsystem is available then the plug in associated with that type of subsystem is selected. If several types are available then repository may select among the available types based on various other considerations. These considerations may include but are not limited to storage capacity or available free space in the storage sub systems . Once selected the appropriate plug in may be dynamically loaded into volatile memory and routines within the plug in may be called.

Because each plug in is designed to interact with a different type of backend storage system the selection of the plug in determines the nature of the back end platform on which the key value pairs managed by the repository are persistently stored. For example if the target key value pairs are to be located on a shared storage device a routine in plug in may be called. If the target key value pairs are to be managed within a storage subsystem managed by an LDAP server then a corresponding routine in plug in may be called. According to one embodiment the called routine name and the parameters of the call are the same in both instances because the interfaces exposed by plug ins and are identical thereby making the nature of the storage subsystems transparent to clients and and routines in the upper layers of repository .

The interface exposed by the storage abstraction layer allows processes external to the storage abstraction layer to make calls through the interface to routines in the storage abstraction layer to perform the various functions required of repository . In one embodiment repository supports node dependent keys. Specifically multiple clients clients and on node and client on node of repository may each want to store a key value pair where the key name used by each client is the same but the value used by each client on different nodes for that key name may be different. For example each client may want to store the key value pair backgroundcolor X where X may be any one of blue green or purple. Using node dependent keys repository will separately store the values for backgroundcolor for each client depending upon the node on which the client happens to be running. For the current example clients and on node will see the same value for the backgroundcolor key but the client on node will see a different value for the same backgroundcolor key.

According to one embodiment requests for information managed by repository are processed by first checking the cache that resides on the same node as the requestor. If the information is not in the local node cache then the master cache is checked. If the information is not in the master cache then a call is made to the storage abstraction layer to retrieve the information from durable storage.

For example assume that client requires a certain key value pair that is managed by repository and that does not currently reside in any cache. According to one embodiment the operation of retrieving that key value pair for client would proceed as follows 

Initially client calls a routine API in the API layer to request a read of the desired key value pair. API sends the request to a routine SVC ABST in the service abstraction layer . SVC ABST determines how to handle the request. In the present example SVC ABST determines that the request should be forwarded to the cache that is local to node . Since component is not the caching component of node forwarding the request to the cache involves component communicating with another component . To accomplish this communication the request is passed to a routine MSG in the messaging and cache layer of component .

MSG communicates the request to a routine MSG at the messaging and cache layer of caching component . MSG passes the request up to a routine SVC ABST in the service abstraction layer of caching component . SVC ABST determines that cache should be inspected to determine whether it contains the requested information. SVC ABST makes the appropriate call to a routine in the messaging and cache layer .

When the information is not found in the local cache a message is sent from MSG to a routine MSG in the messaging and cache layer of the master component . MSG passes the request up to a routine SVC ABST in the service abstraction layer of master component . SVC ABST determines that master cache should be inspected to determine whether it contains the requested information. SVC ABST makes the appropriate call to a routine in the messaging and cache layer .

When the information is not found in the master cache a message is sent to the appropriate plug in e.g. plug in at the storage abstraction layer . The plug in causes the requested information to be retrieved into cache from persistent storage on one of storage subsystems . MSG then returns the call from MSG by passing back the requested information. MSG causes the information to be stored in cache and returns the call from MSG by passing back the requested information.

MSG passes the information back to SVC ABST which in turn passes the information back to API . Finally API delivers the requested information to client .

Because the requested information was stored in cache subsequent requests for the same information by any clients on node may be handled by retrieving the data from cache . Because the requested information was stored in master cache subsequent requests for the same information by clients on nodes that do not have the information cached locally may be handled by retrieving the data from master cache .

According to one embodiment the routines provided at the API layer may be accessed in any one of four access modes. A client may indicate a particular access mode to a routine in the API layer by for example passing to the routine a parameter value that indicates the mode. Rather than pass such a parameter with each call to the API layer the first call made by a client to the API layer may specify the desired mode to an initialization routine . The initialization routine may pass a handle back to the client which the client then uses to make all future calls to API layer . The handle may be associated with data that indicates the access mode of the client. Consequently passing the handle in all subsequent calls effectively informs the routines that process the subsequent calls about the access mode that should be used in servicing those calls.

According to one embodiment different modules of the same client may access repository in different access modes. For example a first module within client may access repository in read only mode while another module within client accesses repository in caching access mode. Similarly a client may transition from one access mode to another access mode by making the appropriate calls into API layer .

The access mode that a particular client requests is dictated by the role of the client and or the type of operation that the client intends to perform. According to one embodiment the modes supported by repository include an installation mode a read only access mode a caching access mode and a default access mode.

Installation mode installation mode is the mode used by a client typically a repository installation program to perform the operations of creating or re creating a repository. According to one embodiment installation mode can be held by only one client at a time and excludes all other clients from performing any repository operations.

Read only access mode by requesting read only access mode a client indicates that it will only be performing read only operations. When performing operations for a client in read only access mode all of the concurrency control logic within repository is disabled circumvented. Consequently operations can generally be performed faster and with less overhead than if performed in modes that allow write operations. Read only access mode may be concurrently shared by multiple clients since read operations do not generally cause access conflicts with other read operations.

According to one embodiment repository uses cluster configuration software to perform some of the concurrency control during operations within repository . Such cluster configuration software may also use repository to store boot up information for cluster . In such an embodiment the cluster configuration software uses read only access mode to access the cluster configuration information while cluster is being booted up to ensure that the concurrency control routines of the cluster configuration software will not be executed until the cluster configuration software is itself fully initialized.

Caching access mode caching access mode is the mode used by a client to establish the component used by the client as the caching component for a node. For example component is established as the caching component of node in response to client initializing component in caching access mode. When client makes a call to initialize component resources may be allocated for cache . When read operations are performed in caching access mode the routines within service abstraction layer invoke caching routines in messaging and cache layer to search for required information within cache .

Default access mode default access mode is the mode used by clients that are not associated with the caching component and are not performing an operation that requires installation or read only access modes. When performing operations in default access mode routines in the service abstraction layer use messaging routines in messaging and cache layer to forward read requests to the local caching component.

According to one embodiment clients are able to transition from one mode to another. Such a transition may be initiated for example by passing a different access mode parameter value in subsequent calls to routines in the API layer that was passed in previous calls to routines in the API layer. According to yet another embodiment different threads or modules of a single client process may use different access modes. For example all calls in a first module of a client may pass one access mode value to API layer routines to obtain one access mode while all calls in a second module of the same client may pass a different access mode value to the API layer routines to obtain a different access mode.

Computer system may be coupled via bus to a display such as a cathode ray tube CRT for displaying information to a computer user. An input device including alphanumeric and other keys is coupled to bus for communicating information and command selections to processor . Another type of user input device is cursor control such as a mouse a trackball or cursor direction keys for communicating direction information and command selections to processor and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes a first axis e.g. x and a second axis e.g. y that allows the device to specify positions in a plane.

The invention is related to the use of computer system for implementing the techniques described herein. According to one embodiment of the invention those techniques are performed by computer system in response to processor executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory from another computer readable medium such as storage device . Execution of the sequences of instructions contained in main memory causes processor to perform the process steps described herein. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus embodiments of the invention are not limited to any specific combination of hardware circuitry and software.

The term computer readable medium as used herein refers to any medium that participates in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example optical or magnetic disks such as storage device . Volatile media includes dynamic memory such as main memory . Transmission media includes coaxial cables copper wire and fiber optics including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio wave and infra red data communications.

Common forms of computer readable media include for example a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium a CD ROM any other optical medium punchcards papertape any other physical medium with patterns of holes a RAM a PROM and EPROM a FLASH EPROM any other memory chip or cartridge a carrier wave as described hereinafter or any other medium from which a computer can read.

Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor for execution. For example the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system can receive the data on the telephone line and use an infra red transmitter to convert the data to an infra red signal. An infra red detector can receive the data carried in the infra red signal and appropriate circuitry can place the data on bus . Bus carries the data to main memory from which processor retrieves and executes the instructions. The instructions received by main memory may optionally be stored on storage device either before or after execution by processor .

Computer system also includes a communication interface coupled to bus . Communication interface provides a two way data communication coupling to a network link that is connected to a local network . For example communication interface may be an integrated services digital network ISDN card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example communication interface may be a local area network LAN card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation communication interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

Network link typically provides data communication through one or more networks to other data devices. For example network link may provide a connection through local network to a host computer or to data equipment operated by an Internet Service Provider ISP . ISP in turn provides data communication services through the world wide packet data communication network now commonly referred to as the Internet . Local network and Internet both use electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link and through communication interface which carry the digital data to and from computer system are exemplary forms of carrier waves transporting the information.

Computer system can send messages and receive data including program code through the network s network link and communication interface . In the Internet example a server might transmit a requested code for an application program through Internet ISP local network and communication interface .

The received code may be executed by processor as it is received and or stored in storage device or other non volatile storage for later execution. In this manner computer system may obtain application code in the form of a carrier wave.

In the foregoing specification the invention has been described with reference to specific embodiments thereof. It will however be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

