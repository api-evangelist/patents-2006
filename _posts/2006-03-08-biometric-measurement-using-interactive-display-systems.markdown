---

title: Biometric measurement using interactive display systems
abstract: Biometric data are produced in response to user input to an interactive display. The user input occurs when the interactive display senses a user input proximate to an interactive display surface that is able to respond to simultaneous multiple inputs. A detection signal based on a user input is processed to identify biometric indicia associated with the user input. User input can be by any biometric entity, such as an animalâ€”not just by a human. Based on the biometric indicia identified, user biometric data are produced. The user biometric data includes parameters describing physical characteristics associated with the portion of the user that provided the user input. The biometric data can be compared to stored biometric data associated with a specific user and/or user profile, e.g., to enable access by the user to an account, and can also be employed to provide other functions, such sizing information, to applications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07630522&OS=07630522&RS=07630522
owner: Microsoft Corporation
number: 07630522
owner_city: Redmond
owner_country: US
publication_date: 20060308
---
The utility and enjoyment of computer systems can be enhanced by providing better user interfaces. User interfaces for computers systems have evolved significantly since the personal computer PC first became widely available. Early PCs were limited to user input devices such as the keyboard and serial mouse and were primarily text based. However a vast improvement in the speed and the power of microprocessors greater availability of low cost memory and improved programming functionality have all contributed to the creation of much more sophisticated user interface designs and hardware and the development of much more user friendly graphic operating systems.

One particular area of advancement in user interface technology pertains to the recent development of an interactive display to which a number of commonly assigned patent applications have been directed. An interactive display presents graphic images to a user on a flat surface such as the top of a table or other housing format. In addition this surface is responsive to input by a user. A PC is coupled to the interactive display to provide the processing power that yields a rich user interactive experience offering more sophisticated command and interface features and a far more natural interactive approach in providing input to the system particularly as related to displayed images.

Interactive display systems that have been developed typically employ specialized optical systems adapted for projecting images and for detecting user input. An optical user input detection system can be based on illuminating a surface of the interactive display with infrared light which is invisible to a user and does not interfere with the display of images by a projection system or other form of display device. With these types of detection systems any objects that are located on or near the surface of the display will reflect the infrared light back to the detection system where it can be detected as user input.

Interactive displays are thus being developed with the capability to process the signals produced in response to the non visible light reflections from an object placed on or near the display surface to determine the size geometry and even the trajectory of the object. This functionality of an interactive display provides a technological platform for developing completely new applications that were not possible with prior generations of conventional user interfaces. For example this form of interactive display lends itself to simultaneous use by multiple users positioned around the interactive display surface. However tracking multiple users of an interactive display system presents a challenge particularly if the users are allowed to simultaneously access different individual user accounts or profiles that are associated with use of the interactive display system.

This new type of interactive display provides an opportunity for users to more efficiently conduct online commerce since a user can readily interact with and navigate within programs and websites using gestures and by moving objects around on the display surface. However in addition to simply selecting input options an interactive display can assist in completing transactions in other ways. Frequently consumers shopping online for clothing are required to select a size for an item in order to complete a transaction. For example shoes pants shirts jackets and gloves are all items that are available in different sizes. However users may not recall the correct size for an item such as a glove. It would be desirable to employ the imaging capability of an interactive display to directly determine the size of user s hand thereby enabling the correct size of glove to be determined. Also user profiles can be associated with biometric data such as hand sizes so that the sizing of other articles of clothing stored in association with the profile of each user of an interactive display can readily be recalled from memory to complete a size selection during an online transaction. Therefore interest currently exists in employing interactive displays and developing appropriate software for biometric measurements that can be employed to facilitate user identification and provide other functionality.

The description below includes a discussion of a method that can be implemented using a computer for producing user biometric data based on user input to an interactive display. The interactive display is able to simultaneously detect inputs at a plurality of locations proximate to the surface of the interactive display that is employed both for displaying images and detecting a user input. As discussed in more detail below the method includes first receiving a user input based on detecting the user input from a portion of a user e.g. from a user s hand. However the user input can be from other types of biological entities such as an animal like a dog or cat and is not limited just to being provided by a human. A detection signal produced in response to the user input can be processed to identify biometric indicia associated with the user input. Based on the biometric indicia identified user biometric data can be produced. The user biometric data can include parameters describing one or more physical characteristics associated with the portion of the user that was sensed or can be employed to simply identify the user from among a group of users of the interactive display.

This Summary has been provided to introduce a few concepts in a simplified form that are further described in detail below in the Description. However this Summary is not intended to identify key or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Exemplary embodiments are illustrated in referenced Figures of the drawings. It is intended that the embodiments and Figures disclosed herein are to be considered illustrative rather than restrictive. Furthermore in the claims that follow when a list of alternatives uses the conjunctive and following the phrase at least one of or following the phrase one of the intended meaning of and corresponds to the conjunctive or. 

The following discussion is intended to provide a brief general description of a suitable computing environment in which certain methods may be implemented. Further the following discussion illustrates a context for implementing computer executable instructions such as program modules with a computing system. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. The skilled practitioner will recognize that other computing system configurations may be applied including multiprocessor systems mainframe computers personal computers processor controlled consumer electronics personal digital assistants PDAs but likely not when used as a server of digital media content and the like. One implementation includes distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

With reference to an exemplary system suitable for implementing various methods is depicted. The system includes a general purpose computing device in the form of a conventional PC provided with a processing unit a system memory and a system bus . The system bus couples various system components including the system memory to processing unit and may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory includes read only memory ROM and random access memory RAM .

A basic input output system BIOS which contains the fundamental routines that enable transfer of information between elements within the PC such as during system start up is stored in ROM . PC further includes a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a compact disk read only memory CD ROM or other optical media. Hard disk drive magnetic disk drive and optical disk drive are connected to system bus by a hard disk drive interface a magnetic disk drive interface and an optical disk drive interface respectively. The drives and their associated computer readable media provide nonvolatile storage of computer readable machine instructions data structures program modules and other data for PC . Although the described exemplary environment employs a hard disk removable magnetic disk and removable optical disk those skilled in the art will recognize that other types of computer readable media which can store data and machine instructions that are accessible by a computer such as magnetic cassettes flash memory cards digital video disks DVDs Bernoulli cartridges RAMs ROMs and the like may also be used.

A number of program modules may be stored on the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . In one implementation programs can include object recognition software that is suitable for use with the optical system of an interactive display. In another implementation program modules can include various program modules for determining biometric parameters and for applying biometric data for use with applications. A user may enter commands and information in PC and provide control input through input devices such as a keyboard and a pointing device . Pointing device may include a mouse stylus wireless remote control or other pointer but in connection with the presently described embodiments such conventional pointing devices may be omitted since the user can employ an interactive display system for input and control. As used in the following description the term mouse is intended to encompass any pointing device that is useful for controlling the position of a cursor on the screen. Other input devices not shown may include a microphone joystick haptic joystick yoke foot pedals game pad satellite dish scanner or the like. Also PC may include a Bluetooth radio or other wireless interface for communication with other interface devices such as printers or the interactive display table described in detail below. These and other input output I O devices can be connected to processing unit through an I O interface that is coupled to system bus . The phrase I O interface is intended to encompass each interface specifically used for a serial port a parallel port a game port a keyboard port and or a universal serial bus USB . System bus can also be connected to a camera interface not shown which is coupled to an interactive display in order to receive signals from a digital video camera that is included within interactive display as discussed in greater detail below. The digital video camera may be instead coupled to an appropriate serial I O port such as to a USB port. System bus can also be connected through I O interface or another interface to a light source within an interactive display in order to provide control signals to the light source as discussed in greater detail below. Furthermore system bus can also be connected through I O interface or another interface to a light detector within an interactive display in order to receive user input. Optionally a monitor can be connected to system bus via an appropriate interface such as a video adapter however the interactive display system described below can provide a much richer display and also interact with the user for input of information and control of software applications and is therefore preferably coupled to the video adaptor. In general PCs can also be coupled to other peripheral output devices not shown such as speakers through a sound card or other audio interface not shown and printers.

Certain methods described in detail below can be practiced on a single machine although PC can also operate in a networked environment using logical connections to one or more remote computers such as a remote computer . Remote computer can be another PC a server which can be configured much like PC a router a network PC a peer device or a satellite or other common network node all not shown and typically includes many or all of the elements described above in connection with PC although only an external memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN . Such networking environments are common in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment PC is connected to LAN through a network interface or adapter . When used in a WAN networking environment PC typically includes a modem or other means such as a cable modem Digital Subscriber Line DSL interface or an Integrated Service Digital Network ISDN interface for establishing communications over WAN such as the Internet. Modem which may be internal or external is connected to the system bus or coupled to the bus via I O device interface i.e. through a serial port. In a networked environment program modules or portions thereof used by PC may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used such as wireless communication and wide band network links.

In an exemplary interactive display table is shown that includes PC within a frame and which serves as both an optical input and video display device for the computer. The depicted embodiment is a cut away figure of one implementation of interactive display table . In the embodiment shown in rays of light used for displaying text and graphic images are illustrated using dotted lines while rays of infrared IR light used for sensing objects on or just above an interactive display surface of interactive display table are illustrated using dashed lines. The perimeter of the table surface is useful for supporting a user s arms or other objects including objects that may be used to interact with the graphic images or virtual environment being displayed on interactive display surface .

A light source can comprise any of a variety of light emitting devices such as a light emitting diode LED laser diode and other suitable light sources. In some implementations light source can be a light source that can be driven to scan in two orthogonal dimensions i.e. in the X and Y directions. In this implementation the scanning mechanism used for light source can be a rotating mirror a galvanometer mirror or other well known scanning mechanisms commonly used for producing a raster scan of a surface with a light beam. In general light source is configured for emitting light having a wavelength in the infrared IR spectrum which is therefore not visible to the human eye. However any wavelength of light can be used that is invisible to the human eye so as to avoid interfering with the display of visible images provided on interactive display surface . Light source can be mounted in any position on the interior side of frame depending on the particular light source used. The light that is produced by light source is directed upwardly toward the underside of interactive display surface as indicated by dashed lines and . Light emitted from light source is reflected from any objects that are on or adjacent to interactive display surface after passing through a translucent layer of the table comprising a sheet of vellum or other suitable translucent material with light diffusing properties.

As used in the description and claims that follow the term proximate to is used with the intent that this phrase encompass both an object that is either touching the interactive display surface or is separated from the interactive display surface by short distance e.g. by up to 3 centimeters or more depending on factors such as the reflectivity of the object. Although only one light source is shown it will be appreciated that a plurality of such light sources may be mounted at spaced apart locations around the interior sides of frame to provide an even illumination of the interactive display surface. The light produced by light source may either exit through the table surface without illuminating any objects as indicated by dash line illuminate objects on the table surface as indicated by dash line and or illuminate objects a short distance above i.e. proximate to the interactive display surface but not touching it as indicated by dash line . Also although the discussion herein refers to infrared light being used for detecting a portion of a user it should be understood that any other non visible light can be used for this purpose such as ultraviolet light and it is considered that such other non visible light is encompassed within the scope of the claims included herein. Further it is contemplated that the present approach can be used in connection with other methods for detecting an object that is positioned proximate the interactive display surface. For example a capacitive sensor might be used to detect a portion of a user placed proximate to the interactive display surface.

In the example shown in this exemplary embodiment objects above interactive display surface include a touch object that rests on or at least partially touches the display surface and a hover object that is close to but not in actual contact with the interactive display surface. Thus both touch and hover objects can be adjacent to the display surface as that term is used in the following description. As a result of using translucent layer under the interactive display surface to diffuse light passing through the interactive display surface as an object approaches the top of interactive display surface the amount of IR light that is reflected by the object increases to a maximum level when the object is actually in contact with the display surface.

As illustrated in a light detector is mounted to frame below interactive display surface in a position appropriate to detect IR light that is reflected from a touch object or hover object disposed above i.e. adjacent to the interactive display surface. In general light detector can be any light detection device suitable for detecting light reflected from objects on or adjacent to interactive display surface . For example light detector can be an area CMOS or area charged coupled device CCD sensor or a digital video camera. While the implementation shown in depicts one light detector a plurality of light detectors can be employed within interactive display . Light detector can be equipped with an IR pass filter that transmits only IR light and blocks ambient visible light traveling through interactive display surface along dotted line . In this implementation a baffle is disposed between light source and the light detector to prevent IR light that is directly emitted from light source from entering light detector since it is preferable that light detector produce an output signal that is only responsive to IR light reflected from objects that are proximate to interactive display surface . It will be apparent that light detector will also respond to any IR light included in the ambient light that passes through interactive display surface from above and into the interior of the interactive display including ambient IR light that also travels along the path indicated by dotted line

IR light reflected from objects on or above the table surface may be a reflected back through translucent layer through IR pass filter and into light detector as indicated by dash lines and or b reflected or absorbed by other interior surfaces within the interactive display without entering light detector as indicated by dash line

Translucent layer diffuses both incident and reflected IR light. Thus as explained above hover objects such as hover object that are closer to interactive display surface will reflect more IR light back to light detector than objects of the same reflectivity that are farther away from the display surface. Light detector senses the IR light reflected from touch and hover objects within its operating field and produces a detection signal corresponding to the reflected IR light that it receives. This detection signal is input to the PC for processing to determine a location of each such object and optionally other parameters such as the size orientation shape and trajectory of the object. It should be noted that a portion of an object such as a user s forearm may be above the table while another portion such as the user s hand or finger can be in contact with the display surface. In some implementation the interactive display includes software modules for recognizing portions of a user and generating biometric data related to the detected portion of the user. In addition other parameters associated with an object may be detected. For example an object may include an IR light reflective pattern or coded identifier such as a bar code on its bottom surface that is specific to that object or to a class of related objects of which that object is a member. Accordingly the detection signal from one or more light detectors can also be used for detecting each such specific object as well as determining other parameters of the object or associated with the object in response to the IR light reflected from the object and or from a reflective pattern.

Embodiments are thus operable to recognize an object and or its position relative to the interactive display surface as well as other information by detecting its identifying characteristics using the reflected IR light from the object. Details of the logical steps implemented to thus detect and identify an object its orientation and other parameters are explained in the commonly assigned patent applications including application Ser. No. 10 814 577 entitled Identification Of Object On Interactive Display Surface By Identifying Coded Pattern and application Ser. No. 10 814 761 entitled Determining Connectedness And Offset Of 3D Objects Relative To An Interactive Surface both of which were filed on Mar. 31 2004. The disclosure and drawings of these two patent applications are hereby specifically incorporated herein by reference as background information.

PC may be integral to interactive display table as shown in the embodiment of or alternatively may instead be external to the interactive display table as shown in the embodiment of . In an interactive display table is connected through a data cable to an external PC which includes optional monitor as mentioned above . Alternatively external PC can be connected to interactive display table via a wireless link i.e. WiFi or other appropriate radio signal link . As also shown in this Figure a set of orthogonal X and Y axes are associated with interactive display surface as well as an origin indicated by 0. While not discretely shown it will be appreciated that a plurality of coordinate locations along each orthogonal axis can be employed to specify any location on interactive display surface . Also illustrated in the Figure is a user appendage which is depicted to illustrate that a user can provide input to table by directly placing a hand on the surface of the table within the interface region defined by the illustrated coordinate system. In other embodiments table can be configured for use with other parts of a user including feet fingers and portion of a face. In each of the described implementations display can be configured for control by a user manipulating objects proximate to the display surface. In an example not shown table can be configured as a kiosk placed close to a floor that can be employed by user to determine a shoe size by placing a foot onto the display surface. In another example table can be configured to assist a user with selecting a glove size or even assist with the sizing of eyeglasses in addition to facilitating a purchase through a web enabled product ordering system.

If an interactive display table is connected to an external PC as in or to some other type of external computing device such as a set top box video game laptop computer or media computer not shown then interactive display table comprises an input output device. Power for interactive display table is provided through a power lead which is coupled to a conventional alternating current AC source not shown . Data cable which connects to interactive display table can be coupled to a USB 2.0 port an Institute of Electrical and Electronics Engineers IEEE 1394 or Firewire port or an Ethernet port on PC . It is also contemplated that as the speed of wireless connections continues to improve interactive display table might also be connected to a computing device such as PC via such a high speed wireless connection or via some other appropriate wired or wireless data communication link. Whether included internally as an integral part of the interactive display system or externally PC executes algorithms for processing the digital images from light detector configured as a digital video camera and executes software applications that are designed to employ the more intuitive user interface functionality of interactive display table to good advantage as well as executing other software applications that are not specifically designed to make use of such functionality but can still make good use of the input and output capability of the interactive display table. As yet a further alternative the interactive display system can be coupled to an external computing device but include an internal computing device for doing image processing and other tasks that would then not be done by the external PC.

An important and powerful feature of interactive display table or i.e. of either of the embodiments of the interactive display table discussed above is its ability to display graphic images or a virtual environment for games or other software applications and to enable a user interaction with the graphic image or virtual environment visible on interactive display surface by identifying objects or characteristics thereof that are resting atop the display surface such as an object or that are hovering just above it such as an object . It should be understood that objects and are illustrative rather than limiting and represent any object proximate to display surface that will reflect IR light including portions of a user. Furthermore these objects may also be detected using an entirely different approach so that a signal responsive to the detection of such objects can be employed for determining biometric data for the object as discussed herein.

Again referring to interactive display table can include a video projector that is used to display graphic images a virtual environment or text information on interactive display surface . The video projector can be a liquid crystal display LCD or digital light processor DLP type or a liquid crystal on silicon LCoS display type with a resolution of at least 640 480 pixels for example. An IR cut filter can be mounted in front of the projector lens of video projector to prevent IR light emitted by the video projector from entering the interior of the interactive display table housing where the IR light might interfere with the IR light reflected from object s on or above interactive display surface . Video projector projects light along dotted path toward a first mirror assembly . First mirror assembly reflects projected light from dotted path received from video projector along dotted path through a transparent opening in frame so that the reflected projected light is incident on a second mirror assembly . Second mirror assembly reflects light from dotted path along dotted path onto translucent layer which is at the focal point of the projector lens so that the projected image is visible and in focus on interactive display surface for viewing.

Alignment devices and are provided and include threaded rods and rotatable adjustment nuts for adjusting the angles of the first and second mirror assemblies to ensure that the image projected onto the display surface is aligned with the display surface. In addition to directing the projected image in a desired direction the use of these two mirror assemblies provides a longer path between projector and translucent layer to enable a longer focal length and lower cost projector lens to be used with the projector. In some alternate implementations an LCD panel or an organic light emitting diode OLED panel can be employed instead of a video projector for producing images on the interactive display surface. In one alternative implementation a different type of user input detection system can be employed such as a planar capacitive detector. In another such implementation an area light detector can be employed that is integrated with a flat panel display. These and other alternatives will be recognized by the skilled practitioner as providing a substantially similar functionality relative to the above described embodiments although different in technological implementation.

The foregoing and following discussions describe an interactive display device in the form of interactive display table and . Nevertheless it is understood that the interactive display surface need not be in the form of a generally horizontal table top. The principles described in this description suitably also include and apply to display surfaces of different shapes and curvatures and that are mounted in orientations other than horizontal. Thus although the following description refers to placing physical objects on the interactive display surface physical objects may be placed adjacent to the interactive display surface by placing the physical objects in contact with the display surface or otherwise adjacent to the display surface.

In the discussion that follows the illustrated methods can be implemented in some embodiments with components devices and techniques as discussed with reference to . In some applications one or more steps of the exemplary methods are embodied on a computer readable medium that stores computer readable code so that a series of steps are implemented when the computer readable code is executed on a computing device such as a microprocessor of PC . In the following description various steps of methods and are described with respect to a processor of a computing device that can perform certain method steps. In some implementations certain steps of methods and can be combined and performed simultaneously or in a different order without deviating from the objective of the methods or without producing different results. In the description that follows the term user includes both human and non human biological entities. Thus for example the following methods can be readily employed to determine biometric data for pets and other animals as well as for human users.

Method begins at a step when user input is received by the interactive display. The user input can be provided by the user positioning a portion of the user s body so that infrared light is reflected from the portion of the user and detected by the interactive display. User input can be received at any time that a detection system of an interactive display table is enabled for detecting infrared light reflected from objects that are proximate to the interactive display surface. While the user input will likely most often be provided with a user s hand or portions thereof in some cases the user input can alternatively be provided by a foot a portion of a user s face or another physical part of the user that is positioned on or sufficiently close to the interactive display surface to reflect infrared light back into the interactive display for detection by the video camera or other suitable detector.

In a step a detection signal is generated e.g. by video camera based on the received user input. The detection signal can be generated anytime after user input is provided when a detection system of the interactive display is enabled. In some implementations the detection signal can be an image representation of light reflected from the portion of the user. In an example an image map of infrared intensity can be produced corresponding to the infrared light reflected back through the interactive display surface from the portion of the user that is proximate to the second side of the interactive display surface such as when a user places a hand directly upon the interactive display surface. In another implementation an image map of infrared intensity can be further processed to produce three dimensional image information associated with the portion of the user reflecting the infrared light. Image processing techniques suitable for producing a pseudo three dimensional mapping based on varying intensity will be known to the skilled practitioner and therefore will not be further discussed. However it should be noted that such a mapping has particular utility in estimating physical dimensions of a user s hands feet and face.

In a step the detection signal is processed to identify biometric indicia associated with the user input. In certain implementations the biometric indicia identify one or more physical characteristics of a portion of a user for example the user s hands fingers face and feet. The foregoing list is not intended to be exhaustive but rather illustrative of the several forms of user biometric data that are expected to have particular utility for implementation with an interactive display. In one implementation the detection signal is analyzed with an object recognition algorithm in order to identify one or more biometric indicia and produce a biometric recognition signal in response to each identified indicia. In another implementation the detection signal can be conditioned to specifically prepare the signal for processing with the object recognition algorithm. In this implementation the signal which may represent an image can be subjected to filtering and other digital image processing techniques that enhance imaging of certain physical characteristics of the portion of the user captured in the image. One example of such a processing technique includes applying an optical Fourier transform to the signal produced by detecting the reflected infrared light.

In another implementation the biometric indicia can include a predetermined set of biometric measurements that can be used to model the detected portion of a user. For example a biometric recognition signal can be generated that corresponds to a distal or proximal measurement from a geometrically determined position such as the base of a hand to another portion of the hand such as the tip s of one or more phalanges where these parts of the hand are identified by an object recognition algorithm or other suitable technique. In this manner an estimation of the distance between the geometrically determined position and a tip of one or more phalanges can be determined providing biometric data corresponding to the user input. These types of estimations of physical properties enable the biometric data to be associated with a user profile for the user.

Furthermore these biometric data distinguish the user from another user of the interactive display system. Once a user has been identified by providing user input employed by the interactive display system to produce the biometric data the biometric data can be employed to access the user profile for that user.

In a step the user biometric data are thus produced based on the biometric indicia identified in step as discussed above. The user biometric data can include one or more parameters describing various physical characteristics associated with the portion of the user that reflected the infrared light. For example the biometric data can include a parameterized representation of a portion of the user s hand face or foot with each parameter identifying a specific measurement or estimation of a physical characteristic that is usable to uniquely identify the portion of the user. Many biometric identification techniques will be known to the skilled practitioner and therefore need not be discussed herein in detail.

In one implementation the biometric recognition signal is analyzed to first select one of a plurality of predetermined biometric archetypes templates. In this implementation the biometric archetype templates are each associated with a specific portion of a user and define a set of biometric parameters for describing one or more physical characteristics of that specific portion. For example a hand archetype template can include parameters for measurements for one or more of the phalanges e.g. distances from tip to tip of each phalange or distances from the tip of one or more phalanges to the base of the palm proximal and distal measurements of the palm and other measurements determined to be biometrically relevant. Similarly a biometric archetype for a foot and a face will each have unique parameters that are quite distinct from the parameters for the hand archetype. Thus each biometric archetype template describes a specific set of predetermined parameters for measurement and can also include mathematical models and predetermined ratios related to specific part of a user s body that tend to differ from one individual to another. The predetermined biometric archetype template can be selected based upon an initial set of estimations and can be compared to selected parameters of each archetype. Since the expected biometric parameters for a hand will be significantly different from those of a foot or a face the archetype of each can be readily automatically selected by the software on the interactive display system based on a comparison of a few simple estimations produced using the image signal.

In another implementation once the biometric archetype has been selected at least one biometric parameter is determined from the user input. In one example a subset of parameters for each archetype can be designated as essential parameters with the remaining parameters designated as nonessential. In this example essential parameters can be measured or estimated to populate the template while nonessential parameters can be populated with default values.

In yet another implementation a user biometric archetype can be generated that includes the determined biometric parameters. In this implementation a specific user s measured or estimated parameters are employed to populate an instance of a biometric archetype. The instance can then be saved or used for interfacing with other currently running processes. In another embodiment the biometric data can be associated with a particular user profile. In one example the biometric data can be the instance of the biometric archetype populated with a specific user s measured or estimated parameters. In this manner biometric parameters determined for a specific portion of a user as determined from user input can be specifically associated with a particular user account or user profile associated with the interactive display system. In some implementations the user account can be related to logging on to the interactive display system. In other implementations the user biometric data can be associated with a process hosted by a service at a remote location for example an online application. Generally a user profile or user account associates and stores certain personal preferences that a user has previously selected. These preferences can include desktop configuration preferences access permissions and other security settings shopping cart information including address and payment data transaction history information and biometric data such as a user biometric archetype.

Turning now to a flow diagram illustrating the steps of an exemplary method for enabling use of user biometric information with an interactive display is illustrated. Method begins at a step when a user is prompted to provide biometric input. The user can be prompted to provide the biometric input at any time that the interactive display is enabled to generate and display images such as a prompt message. In one implementation the user can be prompted to place a hand on or near a surface of the interactive display so that a biometric measurement of the hand can be performed. In another implementation the user can be prompted to place a foot on or near the surface of the interactive display. In yet another implementation the user can be prompted to position their face on or near the display surface of the interactive display so that a biometric measurement of the face can be performed.

In a step the biometric input is received. The biometric input can be received at any time that an interactive display is enabled for receiving the input. In some implementations the receiving of the biometric input can be based on infrared light that is transmitted through a first side of the interactive display surface such that a portion of the infrared light is reflected back through the interactive display surface from an object such as a hand that is proximate to a second side of the interactive display surface as described with references to .

In a step biometric data is determined for the user form from the biometric input. In some implementations the biometric data can be determined at any time after the user input is received. In some implementations a user profile can be determined by comparing the biometric data derived from the user input to stored user biometric data associated with a set of stored user profiles. In this implementation the user profile can be determined by identifying when a predetermined number of properties of the stored user biometric data match or otherwise correspond to the biometric data derived from the received user input. In this manner a user authentication can be provided for a user account when the predetermined properties match the user biometric data associated with a specific user account. In one example a user can place a hand on the surface of the interactive display which can be received as user input and the biometric data derived from the user input can be compared to biometric data stored in the memory of the interactive display for one or more users having access rights to the interactive display system. When a certain number of predetermined properties in the biometric data for the user input match those of a specific one of the stored biometric data the user is associated with the matching stored biometric data and is authenticated so that access can be granted to that user s interactive table account.

In another implementation the user s biometric data can be determined by invoking a biometric data control that is configured for communicating with a user input detection system and for processing the user input. In this implementation an object recognition analysis can then be performed on the user input to identify at least one biometric parameter and a biometric profile template can be populated with biometric data derived from the object recognition analysis.

In a step one or more properties of the determined biometric data are exposed enabling an application to access or call the properties. The properties can be exposed at any time that a biometric data control is active and configured to expose the user properties to a calling application. In yet another implementation an application programming interface API can be configured to facilitate exposing the biometric data properties. In this implementation the API can issue a get properties call having a plurality of call parameters comprising one or more user properties included in the biometric data for the user. The call can originate from an application for example an authentication routine. The get properties call can then be received by a biometric data control process and parsed to retrieve the plurality of called parameters. Finally a user profile can be returned to the biometric data control process in response to the get properties call thus enabling the properties of the user profile to be exposed to and accessed by the calling application.

Another implementation can include further steps such as associating the biometric data with a specific user account. In this implementation in the event that biometric data are received but do not match a user biometric data a new user profile can be associated with the biometric data and with a new user account assuming that authorization for creating such a new user profile has been granted the new user. In another implementation an existing user profile and biometric data can be associated with another user account. In some implementations more than one user biometric data set can be associated with a specific user account. In still another implementation the associated biometric data and or user profile can be stored in memory in the interactive display or alternatively at a remote location.

By way of illustrating an additional use of biometric data is a schematic illustration of an exemplary web page illustrating an application of the interactive display system and methods illustrated by . A title of web page reads The Glove Store indicating that web page is used as a commercial shopping web site designed to sell gloves. A category navigation bar provides navigation amongst category choices such as men s gloves women s gloves leather gloves work gloves fingerless gloves etc. Another navigation bar provides navigation amongst choices such as View Cart Check Out Live Chat etc. Web page has a window title that reads Gloves Sizing indicating that this web page is designed for assisting a user with selecting a proper glove size. The user is instructed with a prompt message that reads Put your hand flat on the table over the black rectangle then use the buttons. A black rectangular measurement field is shown below the prompt message with an image of a user s hand within the field. Buttons labeled Measure hand and Cancel are positioned below the prompt message for controlling the user input. A result window provides a graphical indication field for the result of a hand measurement process that can be performed based on the user input provided when a user places a hand on measurement field .

Although the use of web page will likely be apparent from the Figure an exemplary transaction using the web page might proceed as follows. A user navigates to web page using the input capabilities of the interactive display. Web page is then displayed on the surface of the interactive display enabling the user to interact with the web page. Following the prompt instructions the user places a right hand over the measurement field while using a finger of the left hand to activate the Measure hand button. A biometric control module in the interactive display facilitates the transfer of the user input to an object recognition algorithm and then transfers properties of a calculated biometric data measurement based on the user input back to the web page for display of the glove size for the user in the result window where it is indicated that the user s glove size is M or medium . As illustrated by the example in various biometric data can be determined by user interaction with an interactive display. It should be understood that the system and methods discussed with references to this and the other Figures can be employed to facilitate many other web based interactions including without limitation for example assisting a user with selecting a shoe boot or ski binding size and in the selection of eyeglasses and hats.

Although the concepts disclosed herein have been described in connection with the preferred form of practicing them and modifications thereto those of ordinary skill in the art will understand that many other modifications can be made thereto within the scope of the claims that follow. Accordingly it is not intended that the scope of these concepts in any way be limited by the above description but instead be determined entirely by reference to the claims that follow.

