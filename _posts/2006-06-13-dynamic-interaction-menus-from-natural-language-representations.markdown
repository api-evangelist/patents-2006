---

title: Dynamic interaction menus from natural language representations
abstract: Natural language dialog elements may be dynamically generated in a virtual world when an interaction is initiated between a user and a computer-controlled character. The dialog elements may be generated by combining abstract semantic representations from a knowledgebase of a computer-controlled character involved in the interaction, with abstract semantic representations from a current state of the virtual world. For example, the abstract semantic representations from the current state of the virtual world may describe the user's progress in accomplishing a set of interrelated goals. A program enables developers of games and other virtual worlds to provide dynamic dialog generation after simply entering natural language descriptions of potential game states and computer-controlled character knowledge. Compared to manually scripting dialog in advance, enabling a program to dynamically generate dialog elements provides for exponentially increasing variety, flexibility, and apparent intelligence in computer-controlled character dialog.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07627536&OS=07627536&RS=07627536
owner: Microsoft Corporation
number: 07627536
owner_city: Redmond
owner_country: US
publication_date: 20060613
---
Applications executed by computing devices are often used to simulate virtual worlds with computer controlled characters. Such virtual worlds may be used for example in video games in training programs or in educational programs among other uses. Many separate computer controlled characters also known as non player characters may be included in a single virtual world. This is particularly true in the illustrative example of large scale virtual worlds which may be used in single player or multi player computer games for example. Other useful applications using less extensive virtual worlds may include for example a virtual assistant that may answer questions or otherwise provide help to a user. Virtual worlds and computer controlled characters support a broad range of applications that have demonstrated a strong and persistently growing demand. There is correspondingly a great interest in improving the sophistication with which game players and other users of virtual worlds may interact with virtual worlds and computer controlled characters.

Interaction with computer controlled characters has been of limited sophistication due in part to the labor required to try to anticipate and author user dialog elements that a computer controlled character can recognize and computer controlled character dialog elements that a computer controlled character can use appropriately to respond to the user dialog elements. Authoring dialog for virtual worlds is costly and does not scale well. Every increase in the size and sophistication of the possible dialog interactions between users and computer controlled characters requires the additional labor of manually authoring each new dialog element. Costs associated with such manual dialog authoring are a significant factor in constraining virtual world developers to narrow the scope of possible dialog and restrict the options available to users of the virtual world. Developers of virtual worlds in general are very interested in increasing the variety and sophistication of computer controlled character dialog and creating the illusion of intelligence in computer controlled characters but that illusion is quickly dispelled when a user attempts to engage in dialog that is outside the range that was previously authored for the computer controlled character. While it is physically possible to keep authoring more and more dialog elements that a computer controlled character can recognize and use in response in practice this is severely limited by the amount of investment in developer time and effort that can be justified by the utility of the virtual world so that dialog authoring beyond nominal limits of sophistication can become prohibitively expensive.

The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.

Automatically dynamically generating dialog elements for dialog between users and computer controlled characters in a virtual world is provided in a wide variety of different embodiments. This enables rich new levels of sophistication variety and flexibility in dialog with computer controlled characters while limiting the need for dialog elements to be individually manually authored.

The Summary and Abstract are provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. The Summary and Abstract are not intended to identify key features or essential features of the claimed subject matter nor are they intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the background. Various embodiments provide a wealth of additional and unexpected advantages beyond the resolution of difficulties with current solutions. A variety of other variations and embodiments besides those illustrative examples specifically discussed herein are also contemplated and may be discerned by those skilled in the art from the entirety of the present disclosure.

Methods and other implementations described below enable rich new levels of sophistication variety and flexibility in dialog with computer controlled characters while limiting the need for dialog elements to be individually manually authored. Developers of virtual worlds are enabled to define potential aspects of a state of the virtual world and virtual computer controlled characters with knowledgebases associated with them. State aspects of the virtual world and elements of knowledge in the knowledgebases of its computer controlled characters may be stored as abstract semantic structures that comprise logical representations of natural language elements. These new semantic structures can be generated from natural language inputs by the developers and combined during runtime of the virtual world to generate new semantic structures. These semantic structures can then be converted back into natural language form to populate menus of potential user dialog elements and computer controlled character dialog elements responsive to the user dialog elements.

These natural language dialog elements can be dynamically generated in response to a user initiating an interaction with a computer controlled character also known as a non player character or a computer controlled character initiating an interaction with a user. The natural language dialog elements thereby make use of an updated set of semantic structures potentially including the products of combined semantic structures from throughout the prior runtime of the virtual world. These automatically dynamically generated dialog elements thereby provide a great variety and sophistication of potential computer controlled character dialog without such dialog having to be manually scripted.

Furthermore because the dialog elements are dynamically generated using combinations of potentially any semantic structures from the virtual world and the computer controlled character s knowledgebase the potential sophistication of the computer controlled character s dialog may grow exponentially relative to the increasing size and sophistication of the surrounding virtual world.

Methods and other implementations for dynamically generating natural language elements are disclosed as follows according to a variety of embodiments. Different embodiments may be applied in computer games such as single player or multi player role playing games which may be hosted on a local computing device or may be conducted over the Internet or other network for example. Various embodiments may also be advantageously applied to other virtual environments such as interactive tutorial applications training or educational applications or a general user interface and potentially to any kind of computer controlled character interaction. Various embodiments disclosed herein may enable low cost methods of providing interesting and context sensitive dialogue between a user and a computer controlled character.

The core of method includes step of extracting one or more semantic structures from a knowledgebase associated with a computer controlled character step of combining the semantic structures from the knowledgebase with one or more structures from a virtual world state into one or more combined semantic structures and step of generating one or more natural language elements from the combined semantic structures. Steps and provide a way to generate new dialog between a computer controlled character and a user that incorporates the computer controlled character s particular knowledge and aspects of the current state of the virtual world.

The surrounding steps of method provide examples of a context for using steps and in an illustrative implementation. A user through her user controlled character may encounter a computer controlled character as in step . Either the user or the computer controlled character may initiate an interaction as in steps and which engage steps and and associated steps according to a user initiated track or a computer controlled character initiated track respectively. The user may provide input that defines a narrower scope for the interaction as in step such as by selecting a certain object in the virtual world to ask the computer controlled character about for example.

Once the initiation of the interaction is received by a computing device running the virtual world or by an object in the virtual world application for example steps and are carried out leading at the end of step to natural language elements that have been generated based on the combined semantic structures from the computer controlled character s knowledgebase and the current state of the virtual world. The combined semantic structures may be screened and or ranked such as by prioritizing them on the user s immediate goals in the current game state eliminating dialog elements that refer to things the user hasn t learned about yet or has already accomplished or prioritizing dialog elements referring to something the user is particularly asking about or to some other narrowed scope the user has defined as in step . If the natural language elements are intended as the computer controlled character s dialog elements they are provided as such as in step . If the natural language elements are intended as the user s dialog elements they are provided as user selectable dialog elements in a user menu that is provided as in step .

The user may then select a dialog element from the user menu to communicate to the computer controlled character as in step . The user selectable dialog elements are provided to the user menu already having corresponding computer controlled dialog elements responsive to them in this illustrative embodiment. Those responsive computer controlled dialog elements can then be provided as in step . After the computer controlled character has provided its dialog element the user may choose to continue the interaction as in step and repeat the process the user may choose to end the interaction as in step or the computer controlled character may end the interaction as in step . The computer controlled character may also issue a dialog element or a final dialog element as a parting comment after it or the user chooses to end the interaction. These and other illustrative steps are further described as follows.

According to one illustrative embodiment method may be used in a Restricted Domain Question Answer RDQA system where a user controlling a character in a virtual world initiates an interaction with a computer controlled character in the virtual world such as by making a query of the computer controlled character and is provided a finite number of different questions or other dialog elements the user may select from a menu for example to express to the computer controlled character. The computer controlled character similarly has a restricted amount of dialog elements available to provide in response with the responses for each user dialog element pre set before the optional user dialog elements are provided to the user in one illustrative embodiment. This process begins when the computer receives a query from a user or other initiation by a user or a computer controlled character of an interaction between the two within the runtime of a virtual world. The initiation of the interaction may take any of a wide variety of forms including a simple greeting such as hello a command such as Enchant this sword for me or a query such as Where can I find this amulet No sharp distinction is made between different types of ways to initiate an interaction since the same type of communication may be couched in different ways such as a command a query or a threat.

The depiction of displays the virtual world after the user has controlled player character to initiate an interaction with computer controlled character . In response to the initiation of the interaction the computer executes the steps needed to provide one or more menus such as menu to the user. The menus include various user dialog elements visibly provided on the menu that the user may select to express to the computer controlled character. Each of the user dialog elements is associated in a dialog element pair with a responsive dialog element representing an appropriate response that the computer controlled character provides to the user in response to the associated user dialog element. This process provides the user with a relatively restricted selection of dialog elements and potential responses based on criteria that ensure the user is offered dialog elements that are necessary or highly relevant to the user s current situation in the virtual world.

In the depiction of the initial initiation of the interaction and dialog selection have been performed and the computer controlled character has responded to a first dialog element selection by providing a corresponding dialog element in speech bubble . The response by the computer controlled character may also be provided as an audible spoken word response instead of or in addition to a visible speech bubble or may take any other form perceptible to the user. The user has in turn responded to the computer controlled character s message in speech bubble by continuing the interaction with the computer controlled character such as by again querying the character. This second query prompts the computer to repeat the process of composing and providing a user dialog menu with new dialog elements selected to take into account the new state of the user s situation now having knowledge of the computer controlled character s initial message.

The computer produces user dialog menu with different options for questions the user may select as dialog elements to pose to computer controlled character . Menu also includes an option to see an additional menu i.e. a next menu page in this case and an option to cancel the interaction and close the menu. The non dialog options on menu are listed in brackets.

To produce the menu dialog elements for each menu iteration in response to an initiation of an interaction the computer extracts one or more semantic structures from a knowledgebase associated with computer controlled character as in step and combines the semantic structures from the knowledgebase with structures from the current state of virtual world as in step . The semantic structures are abstract representations of knowledge which facilitate being logically combined to generate new structures. The structures are extracted and combined dynamically in the sense that they are extracted and combined only after an initiation of an interaction is received from the user or from a computer controlled character. The natural language elements are generated from the combined semantic structures as in step . Because the state of the virtual world changes over time and the knowledgebase associated with a computer controlled character may also change over time as reflected in the structures in the virtual world state and in the character s knowledgebase combining them dynamically may generate different results at any time and are therefore sensitive to when the user or the computer controlled character initiates the interaction.

A particular computer controlled character s knowledgebase may contain a hierarchy of knowledgebase components. For example computer controlled character may have an associated knowledgebase that includes knowledge attributed to every computer controlled character in the virtual world knowledge attributed to everyone in the town in which computer controlled character lives and knowledge held uniquely by computer controlled character . The knowledgebases associated with each of the computer controlled characters with each of the computer controlled characters may be pre set and unchanging in one embodiment or may be updated according to aspects of the changing state of the virtual world that a computer controlled character learns from in a different embodiment.

In the case of computer controlled character knowledgebases that are being added to over time the recently added semantic structures and the original semantic structures are equally subject to being dynamically extracted and combined in response to an initiation of an interaction. The dynamic generation of natural language elements may therefore incorporate the computer controlled character s recently acquired information. Additions to the computer controlled character s knowledgebase may incorporate any kinds of information from the virtual world including information on changes that occur in the virtual world changes introduced by user characters and information on prior words or actions of a user character.

The semantic structures composing computer controlled character knowledgebases may take any of a wide variety of forms in different embodiments. In one illustrative embodiment the semantic structures are composed of logical forms based on a tree structure. Each node of a tree structure corresponds approximately to a content word in an original sentence of natural language. In this structure function words have been removed and the words have been normalized to their base form.

In one embodiment the semantic structures may be entered directly by the developer of the virtual world. This has the advantage that it allows the developer s intended semantic meanings to be encoded with precision. It uses a formal notation that allows logical precision and forestalls ambiguity. However it also has the drawback that coding semantic structures from scratch requires mastery of a fairly difficult understanding of semantic representations. A wide range of semantic representation systems are used for example several semantic representation systems are based on different variations of a first order predicate calculus representation.

Another system of creating semantic structures works indirectly but requires far less training to use natural language descriptive inputs that are automatically parsed by natural language processing tools into a representation style known as logical forms. The logical forms encode semantic relations between terms in different semantic descriptions.

Logical forms are relatively easy and intuitive for a developer without prior training to pick up and use while those with the needed training may prefer to write semantic code directly to ensure greater precision. In different embodiments either or both of these methods or still other methods may be used to create the semantic structures to be associated with the knowledgebases associated with the computer controlled characters. Encoding semantic structures with logical forms is further described as follows.

In one example a developer uses a software application embodying a method or computer executable instructions implementing an illustrative embodiment to add semantic structures to a virtual world that describe potential state aspects of the virtual world and to add semantic structures to the knowledgebases of computer controlled characters. The semantic structures added to the virtual world may be input by the developer in natural language form annotated with reference tags for example such as this is a cave. This natural language description as input by the developer is then translated into a semantic structure by a natural language processing tool such as a parsing tool associated with or included in a software application embodying a method of the illustrative embodiment. The semantic structures may take a form corresponding to the following illustrative representations. This is a cave may be semantically represented as 

This semantic structure encodes the semantic relations or semrels between the content words. In this semantic structure the Dsub or the deep subject is this this1 which is indicated to be a singular pronoun and to be associated with an identifier tag not depicted in . The verb relating the subject to the object is be be1 the infinitive normalized form of is which is the present tense form . The translation of is into be plus a marker indicating present tense illustrates how a word is normalized and how syntactic features are recorded in a tree structure. The Dobj or deep object of the semantic structure is a cave cave1 it is also indicated in this case to be indefinite and singular.

A first semantic structure added to the computer controlled character s knowledgebase may refer to a particular aspect of the virtual world state having to do with the cave with the identifier tag and may be input by the developer in natural language form as There s a dragon in that cave . The developer may also add another natural language description to the computer controlled character s knowledgebase that encodes a piece of general knowledge rather than referencing a particular aspect of the virtual world state for example a description reading Dragons have treasure. 

These natural language descriptions as input by the developer are also translated into semantic structures by a natural language tool associated with or included in the present embodiment. There s a dragon in that cave may be represented in the form of the following semantic structure 

In this semantic structure the Dsub or the deep subject is dragon dragon1 which is indicated to be a noun. Because dragon1 is indicated to be indefinite and singular Indef and Sing it refers to dragons in general rather than a particular dragon or multiple dragons. The verb relating the subject to the object is to be be1 indicated as a present tense verb. The object of the semantic structure is a location Locn which is indicated to be cave1 associated with object identifier tag which will associate it with cave from the object semantic structure described above.

Similarly Dragons have treasure may be semantically represented in the form of the following semantic structure 

If a user selects another computer controlled character who lacks knowledge about cave the semantic structures from that computer controlled character s knowledgebase will not include any descriptions of the cave to combine with structures from the virtual world state that describe the cave. So the natural language dialog elements generated by combining the semantic structures from this computer controlled character s knowledgebase with structures from the virtual world state will not include any interactions that will tell the user what she cannot find out for herself about the cave and will only include general interactions such as What is that That is a cave. 

However if the non player character s knowledgebase does include semantic structures that relate to the cave these may be combined with structures from the current virtual world state to provide new natural language dialog elements about the cave enabling the user to select new questions and receive answers that reveal new information to the user. For example the computer controlled character may have in its knowledgebase semantic structures indicating that cave has treasure and a dragon in it. Combined with a semantic structure from the virtual world state indicating that that cave nearby being indicated by the user s character corresponds to cave the non player character will be able to dynamically combine the semantic structures to produce the natural language response That cave has a dragon in it and dragons have treasure. 

Dynamically combining the semantic information in a manner such as this provides for dramatically more sophisticated and interesting interaction with the computer controlled characters than is typically feasible or cost effective through manual dialog scripting. In different embodiments both the semantic structures from the virtual world state may change over time and the semantic information stored in a non player character s knowledgebase may change over time reflecting new knowledge gained by the non player character. In contrast with pre scripted outputs which a player may quickly find predictable after a nominal amount of time playing a game the dynamically created outputs of the present embodiment provide a great variety of different natural language element outputs making use of semantic structures from any possible permutation in which the semantic structures of its knowledgebase and of the transient state of the virtual world may be combined. This engine of variety is likely to produce a greater diversity of possible natural language dialog from computer controlled characters than would be practically or economically feasible by manual scripting. As a virtual world is made bigger and more complex this exponentially multiplies both the possible natural language outputs and the advantage over manual dialog authoring and also enables the computer controlled characters to generate new responses from new combinations of structures that might have been unforeseen by the game developer or that might only become possible after significant changes have taken place in the virtual world.

This becomes especially significant in the case of very large and complex virtual worlds such as may be used in large and sophisticated single player computer games for example where there may be a large number of computer controlled characters for the player to interact with. To try in such a virtual world to match the possibilities of dynamically generated outputs using semantic structures by instead trying to rely on scripted outputs would be prohibitively difficult. The response provided by a particular non player character at various times may therefore remain sensitive to the current context and show a far greater variety than could be feasibly or economically achieved by manual scripting thereby contributing greatly to the illusion of intelligence on the part of the computer controlled characters.

Semantic structures may describe the size shape color history or any other descriptive properties of a state of a virtual world or something in it at a given point in time. All the semantic structures may be associated with various potential game states during creation of the virtual world prior to the beginning of game play within the virtual world and may continue to change during runtime of the virtual world to reflect changes taking place in the virtual world. The events and changes initiated by users within the course of the game may also alter the state of the virtual world and the associated semantic structures.

Tokens may also be used to track aspects of the virtual world state. depicts a diagram of a goal graph of a virtual world state showing dependencies of interrelated objectives or goals in a game a tutorial or another goal oriented activity in a virtual world. These may be for example accomplishing missions in a game that open the way for the player to pursue new missions or finishing lessons in an educational program where certain lessons are prerequisites to begin more advanced lessons as a couple of illustrative examples. The virtual world state may include descriptions of the current state of components of the virtual world. The virtual world state may also include indicators of progress by a user in accomplishing a set of interrelated goals as part of a game or other activity in the virtual world. The illustrative example of a game is described below with the understanding that none of the description is limited to games as opposed to any of a broader range of goal oriented activities in a virtual world.

The virtual world state goal graph includes several tokens occupying nodes in a network that indicates dependencies of goals in the virtual world in this illustrative embodiment. The prerequisite dependencies of the different goals are indicated from left to right and form an interlocking network of different dependencies.

Different indications may be applied to each node including whether the corresponding goal has already been accomplished is currently available for the user to pursue and accomplish or whether the user has not yet cleared the prerequisites for a goal to be available for example. Different indications such as these constitute part of the current state of the virtual world over time.

Node indicates a starting goal in the game. From the introductory goal associated with node three goals are available for the user to accomplish. Goal graph is depicted in a game state in which some early goals have been accomplished represented by the additional exed out nodes .

Goals that are currently available for the user to pursue and accomplish according to the current world state have their corresponding nodes marked with a cross in the diagram of . These include nodes and . For each currently available goal the goal nodes connected to the left have already been accomplished indicated by being exed out. Many of the goal nodes remain blank in the depiction of indicating goals that are not yet available for the user to pursue because their prerequisite goals have not yet been accomplished. Node represents a goal for which one prerequisite goal but not the other has been accomplished. In the present illustrative embodiment the goal graph uses an implicit AND dependency so that each goal can only be performed when all prerequisite goals have been previously accomplished. Alternative embodiments could also use OR dependencies for some or all goal prerequisites so that any one of several preconditions would suffice. For example different parallel nodes may represent discovering the location of the dragon s cave either from finding and reading a map or from finding and talking to a wizard where either goal enables the pursuit of the subsequent goal. Different embodiments could also use XAND XOR and other logical dependencies or a combination of any of the above. Node represents the ultimate goal of the game which can only be accomplished after all the subsidiary goals have been fulfilled.

The tokens associated with the nodes of goal graph may represent the focus of the associated goal which may represent anything the game designer might imagine. For example the nodes might involve possession of an item or subject so one node may indicate possession of a potion another node may be associated with a token indicating possession of a sword and so forth. Nodes may also be associated with knowledge of a certain item or subject such as a token indicating knowledge of a cave and its location and yet another node may be associated with a token indicating knowledge of a dragon for example. Still other nodes may represent accomplishment of a particular task such as arriving at a cave or slaying the dragon. Any other type of goal is also possible.

For example in a game embodiment the starting goal associated with node may be simply to receive information from a computer controlled character who explains what the user s ultimate goal is and gives an overview of what the user must do to accomplish that ultimate goal. After accomplishing that initial goal of discovering the overarching goal of that level of the game the user may become enabled to pursue any of three subsequent parallel goals corresponding to nodes and . These may be for example to find a map to receive a password for opening a door of a secret chamber shown on the map and to find a magic potion respectively. Finding the map and receiving the password may both be required to gain access to a magic sword the goal corresponding to node . So in the game state depicted in the user has found the map and the password nodes and has used those to acquire the sword node but has not yet found the potion node which is a currently active goal and the user has two additional goals currently available corresponding to nodes and that became available once the user acquired the sword.

The tokens in the goal graph of the virtual world state correspond to nodes representing objectives while tokens in the logical forms in a computer controlled character knowledgebase correspond to nodes in the semantic tree structure of the knowledgebase. Combining the semantic structures from the knowledgebase with the structures from the virtual world state as in step may include performing algorithms that automatically associate semantic structures in the knowledgebase with structures from the virtual world state that share tokens in common such as cave dragon or potion for example. Combining these structures enables the computer to generate natural language elements from the combined semantic structure to the user such that these natural language elements reflect the computer controlled character s knowledge of the state of the virtual world.

There may be a great many intersections between the knowledgebase associated with a computer controlled character and the state of the virtual world as represented by tokens in common between the two. Methods are provided for screening out combined semantic structures that are not relevant or evaluating the relevance and ranking the combined semantic structures by their evaluated relevance according to various illustrative embodiments. This may be accomplished by comparing the combined semantic structures to the virtual world state such as the virtual world state represented by goal graph of as described above. This comparison may include comparing the combined semantic structures to the current goals associated with the user at the time of the initiation of an interaction that is the goals that are currently available for the user to pursue in the current world state such as those associated with nodes and in . It may further include checking which of the possible goals have already been accomplished by the user and which of the possible goals remain available to be pursued and accomplished based on the goals that have already been accomplished.

A scoring function may be used to assign various scores to combined semantic structures based on how interesting and relevant they would be to a user based on the current virtual world state with combined semantic structures that include a token associated with a currently available goal ranked highest. Combined semantic structures containing tokens associated with goals that are not yet available to pursue may be ranked low potentially in an ordering with those that are only one node removed from the currently available goals being ranked higher than those that are two nodes removed from the current goals and so on in one illustrative embodiment. Alternately in other cases combined semantic structures associated with goals that are not yet available may be screened out altogether corresponding with the user not yet having enough information to have reason to ask about that information.

Knowledge associated with goals that have already been accomplished may likewise either be ranked low or screened out altogether. It may be desirable to include them but with a low rank in the case where information previously given may still be necessary or useful for a later goal but which the user may have forgotten and might usefully be reminded of. In other cases information related to a goal already accomplished may serve no further use in the game or the goals of the virtual world and so may be screened out altogether.

Methods of screening and ranking the combined semantic structures giving rise to the natural language dialog elements provided to the user are effective in providing the most useful interesting and relevant natural language dialog options to the user. The highest ranked natural language elements may be listed in a first level menu that appears first in response to an initiation of an interaction such as when a user queries a computer controlled character. The first menu may include an option to go on to a second menu of natural language dialog elements to select from and this may lead to a third and so on. However screening and or ranking the combined semantic structures ensures that the user does not have to scroll through a long list of marginally relevant dialog before turning up dialog elements that are useful and relevant to her current situation. In some embodiments it is also desirable to limit the number of menus and the number of natural language dialog elements available to the user to ensure that the user may seek the knowledge that is relevant and useful without having too many options to distract from continuing to subsequent aspects of the virtual world.

After each iteration of the user selecting a dialog element from a menu and receiving the computer controlled character s response the computer may repeat the method of combining semantic structures to provide a new menu or set of menus of natural language dialog elements in one illustrative embodiment. This may ensure that the knowledge the user received from the previous dialog exchange is re ranked to a low rank or is now screened out so that the user does not have the likelihood of eliciting the same knowledge from the computer controlled character all over again. This may also introduce new knowledge that was screened out before because the user did not yet know enough to ask the right question but that is now available for the user to discover. For example if the non player character has knowledge of a mountain that the user doesn t know anything about yet that sits on the other side of a mountain range currently visible to the user and there is a goal that the user must accomplish at that mountain but that is still a few nodes removed from the user s current goals then the combined semantic structures associated with that mountain may be either ranked low or screened out altogether for the natural language dialog elements provided for that user.

In another illustrative embodiment instead of menus being presented for the user to choose natural language dialog elements from the user may instead engage in spoken or written language to initiate an interaction with the computer controlled characters. In this case after the user initiates the interaction with the computer controlled character and the natural language elements are generated the user may pose a spoken word question or other dialog element to the computer controlled character. One of the natural language elements may then be selected that presents the greatest similarity to the spoken word dialog element as interpreted using methods of automatic speech recognition ASR to translate the spoken word dialog element into text.

The comparison between the text input or the ASR text translation of the user s spoken word dialog element and the generated natural language dialog elements may be performed by natural language processing NLP methods such as a support vector machine or a maximum entropy classifier for example among a variety of other implementations. A confidence threshold may also be applied so that if the user s dialog element does not correspond to any of the available natural language dialog elements with sufficient confidence an appropriate default action can be taken such as the program providing the user with a visible menu to choose from or the computer controlled character asking the user to repeat himself or ending the dialog with the user for example. When using automatic speech recognition instead of a menu of pre provided optional dialog elements it may be more effective to generate a wider variety of natural language dialog elements providing a variety of different ways in which the same question or other dialog element might be posed in natural language to try to anticipate a greater fraction of the likely variety with which different users may phrase their dialog with the computer controlled characters.

In another illustrative embodiment a software application is provided that enables developers to create a three dimensional virtual world and populate the virtual world with computer controlled characters having associated knowledgebases enabled for dynamic dialog generation. The virtual world and computer controlled characters are defined by inputs from the developer such that semantic structures or language representations from the knowledgebases may be combined with structures representing the state of the virtual world to generate natural language dialog elements in response to an initiation of an interaction between a user and a computer controlled character. The three dimensional virtual world as it is modeled on a computer may be depicted in two dimensional views on a flat computer monitor. These views may represent the perspective view of a player character within the game for example or the virtual world may be depicted according to a bird s eye view from above the player character such as in .

The software application may further enable a computer to receive the inputs defining the virtual world and its state structure and the computer controlled characters with their knowledgebases in the form of natural language inputs that may be automatically parsed by natural language processing tools into representations of language as described above according to this illustrative embodiment. The software application is further enabled to combine the language representations from both the computer controlled character knowledgebases and the virtual world state in an abstract form to dynamically generate dialog elements from the combined language representations and to translate the dynamically generated dialog elements from the abstract form to a natural language form.

A developer using this software is also enabled to test the state structure of the virtual world to ensure that a user character is able to receive the needed dialog elements to progress through the network of goals to achieve the ultimate goal without either too much difficulty or too little. In one illustrative embodiment a developer may wish to ensure that it is possible for a game player to progress through an entire game using the dialog elements available on top level menus and that the appropriate dialog elements are therefore being correctly given high rankings throughout the progress of the goal graph . The developer may also ensure that the game has no dead ends or ways in which it becomes impossible to progress through all the goals. The software application may also be tested to ensure there are no parsing generation errors and that the semantic structures and virtual world state structures are being combined and translated into natural language dialog elements appropriately and not producing spurious natural language elements.

Methods and media that implement the subject matter described above according to a wide variety of embodiments may be implemented in a broad range of different computing devices and computing environments. For example method may be implementable by a computing device by enabling the computing device through executable instructions stored on a medium readable by the computing device for example. The term computer may be used interchangeably with the term computing device without implying any limitation on the particular form of computing device that may be involved in different embodiments. A few illustrative systems and environments with which various embodiments can be used are provided in .

Embodiments are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with various embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers telephony systems distributed computing environments that include any of the above systems or devices and the like.

Embodiments may be described in the general context of computer executable instructions such as program modules being executed by a computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Various embodiments may be implemented as instructions that are executable by a computing device which can be embodied on any form of computer readable media discussed below. Various additional embodiments may be implemented as data structures or databases that may be accessed by various computing devices and that may influence the function of such computing devices. Some embodiments are designed to be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing some embodiments includes a general purpose computing device in the form of a computer . Components of computer may include but are not limited to a processing unit a system memory and a system bus that couples various system components including the system memory to the processing unit . The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus also known as Mezzanine bus.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into the computer through input devices such as a keyboard a microphone and a pointing device such as a mouse trackball or touch pad. Other input devices not shown may include a joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer may be operated in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a hand held device a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Memory is implemented as non volatile electronic memory such as random access memory RAM with a battery back up module not shown such that information stored in memory is not lost when the general power to mobile device is shut down. A portion of memory is illustratively allocated as addressable memory for program execution while another portion of memory is illustratively used for storage such as to simulate storage on a disk drive.

Memory includes an operating system application programs as well as an object store . During operation operating system is illustratively executed by processor from memory . Operating system in one illustrative embodiment is a WINDOWS CE brand operating system commercially available from Microsoft Corporation. Operating system is illustratively designed for mobile devices and implements database features that can be utilized by applications through a set of exposed application programming interfaces and methods. The objects in object store are maintained by applications and operating system at least partially in response to calls to the exposed application programming interfaces and methods.

Communication interface represents numerous devices and technologies that allow mobile device to send and receive information. The devices include wired and wireless modems satellite receivers and broadcast tuners to name a few. Mobile device can also be directly connected to a computer to exchange data therewith. In such cases communication interface can be an infrared transceiver or a serial or parallel communication connection all of which are capable of transmitting streaming information.

Input output components include a variety of input devices such as a touch sensitive screen buttons rollers and a microphone as well as a variety of output devices including an audio generator a vibrating device and a display. The devices listed above are by way of example and need not all be present on mobile device . In addition other input output devices may be attached to or found with mobile device .

Mobile computing system also includes network . Mobile computing device is illustratively in wireless communication with network which may for example be the Internet or some scale of area network by sending and receiving electromagnetic signals of a suitable protocol between communication interface and wireless hub . Wireless hub in turn provides access via network to a wide array of additional computing resources illustratively represented by computing resources and . Computing device is enabled to make use of executable instructions stored on the media of memory component such as executable instructions that enable computing device to perform steps such as combining language representations associated with states of a virtual world with language representations associated with the knowledgebase of a computer controlled character in response to an input from a user to dynamically generate dialog elements from the combined language representations as one illustrative embodiment.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. For example while references are made in particular embodiments to entering or generating natural language elements in text format other embodiments may be combined with other user interface and natural language technologies to use other forms of input and output such as handwriting input or text or speech input and output for example. The embodiments related to computer games are only illustrative examples and other embodiments are not limited to games. In various additional embodiments for example the virtual world with computer controlled characters may serve as a training or educational program. Developers may also be enabled by various embodiments to create virtual worlds with computer controlled characters for such training or educational programs. This may include for example training and testing programs for firefighters policemen or astronauts. It may also include training and testing programs for medical students for example to simulate emergency room experiences where they must evaluate injuries and symptoms and ask appropriate questions of computer controlled characters accompanying the computer controlled patient characters of what they saw of the injury or what potential symptoms they might have noticed at earlier times. In another illustrative embodiment it may also include training and testing programs for science students who are presented with virtual models of scientific phenomena and may try to come up with the right clues to ask of a computer controlled professor character as they try to calculate answers to problems involving the interactions depicted in the virtual world. While illustrative examples have included certain specific techniques using tokens associated with nodes in knowledgebases and world states and screening and ranking based on proximity of tokens in combined semantic structures to currently active goals in the world state additional embodiments are contemplated that are not limited to these illustrative examples. While English language examples have been used different embodiments could apply to any other languages generating natural language elements in any languages and using natural language processing tools appropriate to those languages. The specific features and acts depicted in the figures and described throughout the Detailed Description are disclosed as illustrative examples that embody or implement the claims while the broadest and most generalized applications of the claims are not limited to the illustrative embodiments herein and define a very wide range of additional embodiments.

