---

title: Method and apparatus for digital image filtering with discrete filter kernels using graphics hardware
abstract: The invention provides, in some aspects, methods and apparatus for signal and/or image processing which perform convolution-based filtering utilizing a graphics processing unit (GPU, also called “graphics card”) to compute multiple output pixels at once. This has the advantage of saving memory bandwidth, while leveraging the GPUs vector multiplication and dot product units during the calculation. Related aspects of the invention provide such methods and apparatus in which multiple output pixels are computed simultaneously by using render targets with more than one channel, e.g., an RGBA render target, or multiple render targets, or a combination thereof. By way of non-limiting example, methods and apparatus according to the invention implement convolution on a GPU by executing the steps of defining input image I(x,y) as input texture of size N×N; defining an RGBA render target (output) of size N/4×N; and, for each RGBA output pixel aggregating o(x,y) by (i) reading all input pixels I(x*4+i,y), with i=−4,0,4, and computing o(x,y) for the all four components of the output tuple.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07623732&OS=07623732&RS=07623732
owner: Mercury Computer Systems, Inc.
number: 07623732
owner_city: Chelmsford
owner_country: US
publication_date: 20060426
---
This application claims the benefit of a U.S. Provisional Patent Application Ser. No. 60 675 067 filed Apr. 26 2005 the teachings of which are incorporated herein by reference.

The invention pertains to digital data processing and more particularly to image and signal processing and still more particularly by way of non limiting example to image processing operations that are based on convolution. The invention has application by way of non limiting example in medical imaging microscopy and geo sciences to name but a few fields.

Convolution is an important image and signal processing operation. It is used for example in image reconstruction image enhancement and feature detection among other critical operations. A formal statement of the challenge faced by designers of image and signal processing that perform convolution is as follows.

Given a digital image of size N NI x y x 0 . . . N 1 y 0 . . . N 1 and a discrete filter kernel K x y x 0 . . . N 1 y 0 . . . N 1 of size N N convolve or filter the image with that discrete filter kernel in accord with the formula 

This formula evaluates the digital image outside its domain to compute output values near the boundaries. Depending on the application different approaches for the boundary treatment may be chosen including defining pixels outside the domain to be a constant value mirroring of the image wrapping around or constant continuation.

For sake of simplicity the challenge or problem statement above is expressed with respect to 2D images as is again for sake of simplicity much of the discussion in the sections below. However as will be appreciated from the text below both the challenge and the inventive solutions provided hereby can be applied to 1D as well as 3D or higher dimensions.

In view of the foregoing an object of the invention is to provide improved methods and apparatus for digital data processing and particularly for example for image and signal processing.

A further object of the invention is to provide such methods and apparatus as provide improved performance of image and signal and signal processing operations based on convolution. A related object of the invention is to provide such methods and apparatus as provide for convolution or filtering of digital image data with discrete kernels.

Yet further objects of the invention are to provide such methods and apparatus as can be implemented at lower cost and yet as provide optimal performance.

A related object of the invention is to provide such methods and apparatus as can be implemented using standard off the shelf components.

The foregoing are among the objects attained by the invention which provides in some aspects methods and apparatus for signal and or image processing which perform convolution based filtering utilizing a graphics processing unit GPU also called graphics card to compute multiple output pixels at once. This has the advantage of saving memory bandwidth while leveraging the GPUs vector multiplication and dot product units during the calculation.

Related aspects of the invention provide such methods and apparatus as are implemented on a GPU having programmable vertex shaders and programmable pixel shaders. Further related aspects of the invention provide such methods and apparatus in which multiple output pixels are computed simultaneously by using render targets with more than one channel e.g. an RGBA render target or multiple render targets or a combination thereof.

Further aspects of the invention provide such methods and apparatus wherein a filter implemented on such a GPU performs convolution with a 9 1 kernel by way of non limiting example by executing the steps of defining input image I x y as input texture of size N N defining an RGBA render target output of size N 4 N and for each RGBA output pixel aggregating o x y by i reading all input pixels I x 4 i y with i 4 0 4 and computing o x y for the all four components of the output tuple.

Still further related aspects of the invention provide such methods and apparatus wherein the GPU is utilized to multiply two four vectors and add the result to another four vector in one operation. In these and other aspects of the invention the input can be packed into RGBA or other tuples thereby saving read operations.

According to further related aspects of the invention methods and apparatus as described above can store the filter kernel as constants in registers in pixel shaders of the GPU. Alternatively or in addition the kernel can be stored in a separate texture.

Further aspects of the invention provide methods and apparatus as described above in which output aggregation varies with kernel size GPU hardware and or driver software selection e.g. maximum number of simultaneous outputs supported maximum number of instructions allowed in a pixel shader and or maximum number of constants or registers available to store the kernel values among other factors .

Yet other aspects of the invention provide methods and apparatus as described above which computes 1D convolutions as well as 3D and higher order convolutions. Such methods and apparatus for 1D convolutions can by way of example store multiple lines in one input image and then to process that image in the manner described above as a convolution of a 2D input image with a 1D kernel. Such methods and apparatus for 3D convolutions can use correspondingly dimensioned input texture and or alternatively of a set of n lower dimensional textures. Still further multiple slices of a volume can be packed into a lower dimensional texture in a tile like fashion.

Yet still other aspects of the invention provide such methods and apparatus as provide optimized filtering using separable kernels. This can be achieved for example by using the results of row wise convolutions as inputs to column wise convolution and more particularly by treating convolution with the 2D filter kernel as equivalent to a 1D convolution of the rows of the image with K followed by a 1D convolution of the columns with K where those 1D convolutions are executed as described above.

In further related aspects of the invention such methods and apparatus further optimize filtering with separable kernels by first computing the row wise convolution transposing the image then performing a second row wise convolution with K followed by another transpose operation.

Still further aspects of the invention provide methods and apparatus of signal and or image processing which perform convolutions involving constant filter kernels. Such methods and apparatus capitalize on the separable nature of constant filter kernels by implementing a recursive computation methodology e.g. a box car convolution e.g. on a GPU with programmable vertex shaders and programmable pixel shaders yet ensuring correct order of processing.

Related aspects of the invention provide such methods and apparatus as in effect draw vertical lines from left to right covering one column of the render target each. More particularly these execute the steps of defining image I x y as input texture N N defining a render target output of same size defining render target as second input texture initializing column leftmost of render target with correct output values for column . . . N 1 for each pixel o x y in that column read value o x 1 y from render target second input texture read

Related aspects of the invention provide methods and apparatus as described above in which orderly processing order of pixels by the GPU is ensured by one or more of the following sending a flush command after each line drawn inserting fence tokens into the stream of commands sent to the GPU and querying for their them using multiple render targets and swapping them after each line is drawn correcting sporadically miscalculated pixels in subsequent render passes issuing dummy geometry after each line working with multiple advancing fronts.

Still further aspects of the invention provide methods and apparatus as described above in which parallelization in the GPU is exploited for efficiency by instead of initializing the left most column initializing multiple columns spread across the image. Recursive computation is performed by drawing lines advancing from these seedlines.

Yet still further aspects of the invention provide methods and apparatus as described above in which hardware filtering on the GPU is utilized to decrease the number of instructions in the convolution filter code leveraging additional hardware in the graphics device and further accelerating the filtering process. In related aspects of the invention this additional filtering is carried out in parallel with calculations occurring within the pixel shaders. As a result by way of example according to some aspects of the invention an entire 1D convolution can be calculated in a single pass.

Further aspects of the invention provide methods and apparatus as described above in which the operations ascribed above to a single GPU are carried out by multiple GPUs or other processing elements such as array processors game engine processors and so forth .

Described below are methods and apparatus according to the invention which perform convolution filtering of signal and image data by utilizing a graphics processing unit GPU also called graphics card to compute multiple output pixels at once thereby saving memory bandwidth and leveraging the GPUs vector multiplication and dot product units during the calculation. Also described are methods and apparatus according to the invention which implement the well known box car convolution on a GPU for the special case of a constant filter.

The methods and devices described herein have numerous applications for example in medical imaging such as computed tomography CT position emission tomography PET single photon emission computed tomography SPECT and other medical applications. Non medical applications not limited to examples such as geo sciences microscopy general computer tomography and confocal microscopy can also utilize aspects of the present invention.

Such methods can be implemented in an imaging and digital processing environment of the type disclosed in copending commonly assigned U.S. patent application Ser. No. 10 756 172 filed Jan. 12 2004 entitled Improved Methods and Apparatus for Back Projection and Forward Projection and specifically in FIG. 1 thereof and the corresponding text e.g. at page 7 line 14 through page 8 line 26 the teachings including illustration of which are incorporated herein by reference. Although that figure and the text refer by way of example to mammography systems and computed tomosynthesis it will be appreciated that the invention hereof and its embodiments are more broadly applicable to the full range of medical and non medical imaging applications and techniques such as by way of non limiting example geo sciences or microscopy computer tomographs magnetic resonance imaging devices or confocal microscopes to name just a few.

It will be further appreciated that methods as described above when implemented in an imaging and digital processing environment of the type disclosed in the aforementioned incorporated by reference application form apparatus according to practice of the present invention.

In view of the foregoing depicts by way of non limiting example a computer aided tomography system of the type with which the invention can be practiced and forming apparatus according to the invention.

The system includes an image acquisition apparatus that generates multiple projection images of an object in a volume . In the illustrated system this is accomplished in the conventional manner e.g. by illuminating the object with radiation from a source and detecting by a detector such as a charged coupled device or other 2D sensor array radiation not absorbed by the object . Generally multiple projection images obtained at different respective angles are required for reconstructing a three dimensional representation of the object. Such projection images can be captured by moving the source and or the detector around the volume to illuminate the object from different angles and to detect a portion of the illuminating radiation that is not absorbed by the object.

In the system of those projections can be generated in accord with the principles of computed tomography CT i.e. with the source at discrete foci on an arc that completely surrounds the volume . Alternatively those projections can be generated in accord with principles of computed tomosynthesis i.e. with the source at discrete foci along a smaller arc above the object. For example the radiation source can be an x ray source and the detector is an x ray detector both mounted at opposite ends of a C arm that rotates about the volume . The rotatable C arm is a support structure that allows rotating the source and the detector around the volume e.g. a long a substantially circular arc to capture a plurality of projection images of the object at different angels. It should however be understood that the teachings of the present invention can be applied in a multitude environments of which the foregoing are merely examples.

To continue those examples however schematically depict generation of a measured projection image by apparatus of a volume containing a rib cage . X ray radiation emitted by the source shown at one of its axial positions as it rotates about the volume during a scanning operation travel through the imaged volume . A portion of the x ray radiation not absorbed by the imaged volume impinges on the detector array depicted opposite source vis vis the volume as the detector moves about the volume in tandem with the source. The volume is characterized by x y and z axes as indicated and the detector and specifically the imaging portion thereof is characterized by u and v axes defining an imaging or detection plane that is parallel to the axis of rotation i.e. the z axis and has a normal perpendicular to a tangent of the rotational path . Referring to the imaging arrangement of is shown with the additional superposition on detector of an image of the type generated by projection of x ray radiation from the source through the rib cage . As evident in the drawing the image is a silhouette or as more often referred to herein a projection or a projection image e.g. in the nature of a conventional x ray image. The projected images provide digital image data from which a reconstructed volume is obtained.

Referring again to the system further includes a digital data processor that analyzes the images to reconstruct the volume and more specifically to generate a three dimensional representation of the contents of that volume e.g. the object or a portion thereof in a manner discussed in more detail below. Illustrated object is the head of a human patient. However the invention can be used in analyzing images of other objects biological archeological industrial or otherwise.

Reconstruction of the volume from the projected images can be achieved by a number of mathematical reconstruction techniques. One non limiting example is filtered back projection. In this technique the various projections are summed with a weighting factor that acts to filter artifacts. In such an instance Equation 1 can be used to implement the filtering with I x y acting as the projection image data and K x y being the filtering function. Accordingly embodiments of the present invention can be utilized to perform the filtered back projection operation however as noted previously embodiments of the invention can be applied in a variety of other imaging operations for reconstruction or otherwise.

Illustrated digital data processor is a workstation personal computer mainframe or other general or special purpose computing device of the type conventionally known in the art albeit adapted as discussed below for processing projections including exercise of method and apparatus for convolution according to the invention. As shown in the drawing it includes a central processing unit CPU dynamic memory RAM and I O section all of the type conventionally known the art. The digital data processor may be coupled via I O section with a monitor or other graphical display or presentation device as shown.

Illustrated digital data processor also includes a graphical processing unit GPU that is coupled to the CPU through which it can access the other elements of the digital data processor as shown. In one embodiment the GPU serves as a coprocessor operating under the control of the CPU to convolve the imaging data e.g. while reconstructing the volume from the measured projection images. Other embodiments of the invention employ multiple GPUs for this purpose each responsible for a respective portion of the convolution process. The GPU is preferably of the variety having programmable vertex shaders and programmable pixel shaders that are commercially available from ATI research for example the Radeon 9700 processor NVIDIA for example the GeForce FX and Quadro processors . However it will be appreciated that the invention can be practiced with processing elements other than commercially available GPUs. Thus for example it can be practiced with commercial proprietary or other chips chipsets boards and or processor configurations that are architected in the manner of the GPUs e.g. as described below . It can also be practiced on such chips chipsets boards and or processor configurations that though of other architectures are operated in the manner of GPUs described herein.

Components of the digital data processor are coupled for communication with one another in the conventional manner known in the art. Thus for example a PCI or other bus or backplane industry standard or otherwise may be provided to support communications data transfer and other signaling between the components . Additional coupling may be provided among and between the components in the conventional manner known in the art or otherwise.

A typical architecture of the GPU suitable for use in the practice of the invention is shown by way of expansion graphic in . The GPU includes a geometrical mapping section and a pixel processing section interconnected with one another as well as with a local memory by way of a bus . The GPU communicates with other components of the digital data processor by interfacing with the bus via a bus interface . A further interface is provided between the bus and the CPU by way of one or more interfaces of the type standard in the art or otherwise for CPU GPU intercommunication. In the illustrated embodiment that further interface is a VIP video input port interface and AGP accelerated graphics port interface or otherwise as conventionally known in the art or otherwise.

Local memory supports both the short term and long term storage requirements of the GPU . For example it can be employed to buffer the projection image data iterative estimates of the density distribution of the volume under reconstruction forward projection images generated based on those estimates as well as parameters constants and other information including programming instructions for the vector processors that make up the mapping and pixel processing sections .

In the illustrated embodiment the mapping section comprises a plurality of programmable vertex shaders that generate mappings between the coordinate space of the projection images and that of the volume . For example the vertex shaders map each pixel in a projection image to one or more voxels in the volume. The pixel processing section comprises a plurality of pixel shaders that can adjust pixel intensities in forward projection images generated from estimates of the density distributions of the volume e.g. based on comparison of the forward projection images with respective measured projection images and to modify density values of voxels in the volume to reflect back projection of those forward projection images as discussed in more detail below.

DMA engines and provide coupling between the local bus and respectively the vertex shaders and pixel shaders facilitating access by those elements to local memory interfaces or otherwise. A further DMS engine provides additional coupling between the pixel shaders and the bus . In addition filters labeled F are coupled between the DMA engine and the pixel shaders as illustrated. These perform interpolation anisotropic filtering or other desired functions. Also coupled to the vertex shaders are respective iterators labeled I as illustrated. Each iterator generates addresses in volume space for the voxels defined by the corresponding vertex shaders .

With this context described below are methods for operation of GPU or other suitable processing elements as described above. Those skilled in the art will appreciate how the elements referred to in the discussion below map to elements of the GPU as well as to corresponding components of other suitable processing elements .

We first describe a simplistic implementation of a convolution filter on a GPU for the special case of a filter kernel with dimensions 9 1. Similar simplistic implementations have been proposed in the prior art. We then explain how systems and methods according to the invention implement the filter differently thus highlighting its operation and innovations. Then we explain the generalisation to other kernel.

In contrast systems and methods according to the invention utilize a convolution filter with a significantly more efficient implementation. Thus for example that filter computes multiple output pixels at once. This can be realized by using render targets with more than one color channel e.g. an RGBA render target or multiple render targets or a combination thereof.

Continuing the above example a filter according to the invention utilizing a 9 1 kernel can be implemented on a GPU e.g. GPU for fast convolution by executing the steps of 

Modern GPU hardware that is graphics processing units having programmable vertex shaders and programmable pixel shaders e.g. the offerings of ATI Research and Nvidia referred to in incorporated by reference U.S. patent application Ser. No. 10 756 172 or otherwise described in that application are beneficially employed in systems and methods according to the invention to multiply two four vectors and add the result to another four vector in one operation MAC . Thus the computation of one output value only requires three such operations plus one dot product with a four vector of ones to perform the final sum. As a further optimization the input can be packed into RGBA tuples as depicted in thereby saving read operations not decreasing memory bandwidth though .

Aspects of the example of can be further interpreted with reference to . Considering the case where the value of y is set at some particular value Y each input data point I x Y can be denoted as ix e.g. i i i . . . . In this example the component filter values of the 9 1 filter can be denoted k k k . . . k k.

To calculate the output data points corresponding to o o o and o Equation 1 can be applied to give the following relationship in terms of the scalar input data points filter values and scalar output data points 

The output data points can also be calculated using vector operations as employed with by a GPU for example. The input data points can be arranged as input vectors IV IV IV . . . where each input vector IVj has 4 corresponding input data points iv 4 j iv 4 j 1 iv 4 j 2 iv 4 j 3 . As well the filter values that are used to convolute the input data points can also be arranged in a set of filter vectors KV KV KV . . . KV KV where each filter vector has four components given as shown in . Using these input and filter vectors the output data points o and can be obtained by generating corresponding temporary vectors TV TV TV and TV. All the necessary input data points i i i . . . i i are stored in input vectors IV IV and IV to generate the four output data points. Thus as the four input data point components of each input vector IVj are read portions of each temporary vector can be generated according to the following relationships 88 1 99 31 1010 61 1111 91 where each equation represents a float4 multiplication of two vectors and a vector summation which can be performed as a single operation by a GPU. After all three input vectors IV IV and IV have been read and used to create TV TV TV and TV the temporary vectors can be converted to corresponding output data values using the following dot product relationships o8 dot TV8 1 1 1 1 o9 dot TV9 1 1 1 1 o10 dot TV10 1 1 1 1 o11 dot TV11 1 1 1 1 As well the output data points themselves can be stored in a corresponding output data vector.

The foregoing example clearly illustrates the advantage of systems and methods according to the invention. While prior art implementations of the type described earlier require nine read accesses for each output pixel produced convolutions filters according to the invention require twelve reads for four output pixels i.e. three reads per output pixel. This three fold improvement in memory bandwidth utilization results in significantly improved performance. In addition reading four pixels at a time decreases the number of texture reads and instructions within the shader which are both limited on some architectures. This becomes increasingly important when processing multiple lines of the filter per pass in multi dimensional filters.

In preferred embodiments of the invention e.g. implementations of a 9 1 convolution according to the invention as described above the filter kernel is encoded as constants in registers in pixel shaders of the GPU. Where this is not possible or not desired e.g. for very large kernels the kernel can be stored in a separate texture. Note that respective memory bandwidth savings apply for the kernel read access as well in the fast implementation.

Those skilled in the art will appreciate that systems and methods according to the invention are not restricted to 9 1 kernels nor to one dimensional kernels. For a given kernel size there are often different possible patterns of output aggregation. For illustration some examples are listed below 

The choice of the configuration for a given kernel size depends on the specific GPU hardware and driver software used. For example GPUs currently available in the marketplace have limitations with respect to the maximum number of simultaneous outputs supported e.g. four render targets of at most four channels each i.e. sixteen simultaneous outputs. Furthermore the maximum number of instructions allowed in a pixel shader the maximum number of constants or registers available to store the kernel values the particular memory and cache subsystem design the available input and output data type formats as well as other properties of the GPU hardware and driver software influence performance. Therefore where optimal performance is required the best possible configuration for a given platform is determined by thorough analysis or empirically by benchmarking the different possible configurations. Such benchmark can be performed at run time.

It should be pointed out that the filtered image computed via GPU based convolution according to the invention will be distributed across multiple render targets and or across the RGBA tuples of a four component render target. For many subsequent operations this is not a restriction. For example for direct display it doesn t matter if the intensity values to be displayed are read from a single one component texture or from multiple input textures possibly with packed RGBA tuples. Where necessary the filtered image can be copied into a single one component texture in an additional render pass.

The described method can be generalized to 1D convolution by choosing the input and output images to be one pixel high. However still further improved methods are provided for the case that multiple one dimensional convolutions need to be performed on input vectors of the same size. In these cases it can be advantageous to store multiple lines in one input image and then to process that image in the manner described above as a convolution of a 2D input image with a 1D kernel. Because of the memory cache design and the way parallel execution of pixel shaders occurs on current generation GPU hardware this can increase performance.

In order to generalize to 3D or higher dimensionalities 3D or higher dimensional input textures are used. Since current generation GPU hardware does not necessarily support 3D or higher dimensional input textures a set of n lower dimensional textures can be used instead or multiple slices of a volume can be packed into a lower dimensional texture in a tile like fashion. The same applies to the output render targets .

Embodiments of the invention can be configured to treat still more efficiently separable filter kernels i.e. ones that can be written in the form of 

In such a case the convolution with the 2D filter kernel is equivalent to a 1D convolution of the rows of the image with K followed by a 1D convolution of the columns with K . As described in the previous section the proposed method applies to 1D convolutions as well. Therefore an efficient implementation for separable kernels is possible by using the result of the row wise convolution as input to a second column wise convolution.

In some embodiments the output of the first pass row wise convolution is distributed across multiple render targets and or stored in RGBA tuples that span multiple horizontally neighboring pixels. This has to be taken into account for the second pass column wise convolution . It can be done by either reading from multiple render targets or by operating on those horizontal RGBA tuples and thereby computing the convolution for four columns at once or by performing an intermediate data reorganization pass.

Depending on kernel size image size and hardware architecture a further performance improvement is achieved in some embodiments by first computing the row wise convolution transposing the image then performing a second row wise convolution with Ky followed by another transpose operation.

Embodiments of the invention can also be configured to process still more efficiently cases involving constant filter kernels. Here the result of the convolution is the scaled average of the neighbours of a pixel in a neighborhood of size N N.

The methods for convolution with constant filter kernels described below can like those discussed above be implemented in an imaging and digital processing environment of the type disclosed in copending commonly assigned U.S. patent application Ser. No. 10 756 172 filed Jan. 12 2004 entitled Improved Methods and Apparatus for Back Projection and Forward Projection and specifically in thereof and the corresponding text e.g. at page 7 line 14 through page 8 line 26 the teachings including illustration of which are incorporated herein by reference. And again although that figure and the text refer by way of example to mammography systems and computed tomosynthesis it will be appreciated that the invention hereof and its embodiments are more broadly applicable to the full range of medical and non medical imaging applications and techniques such as by way of non limiting example geo sciences or microscopy computer tomographs magnetic resonance imaging devices or confocal microscopes to name just a few.

A constant filter kernel is always separable. We therefore first focus on one dimensional kernels again. An interesting observation is that the output value of a pixel can be computed from the output value of its left neighbour with only a small correction term as expressed by the following relation 

Of course the processing does not necessarily need to proceed from left to right but may also be right to left. Additionally the other dimension can also be processed first top to bottom or bottom to top . For illustrative purposes in the present description we ll choose a left to right implementation for the first pass and a top to bottom implementation for the second pass.

By taking advantage of this observation a recursive computation scheme can be implemented which in the limit only requires two memory reads and two additions per output pixel. In particular for larger filter kernels this can be a significant saving compared to straight forward computation of each output pixel independently. This optimization is well known for central processor unit based CPU implementations and is often referred to as the boxcar algorithm. The implementation of the boxcar filter on a GPU however is not straightforward because outputs are generated in parallel and out of order on the GPU. Simply reading the left neighbour will produce erroneous results since it may not have been computed yet. The following describes the convolution of a 2D image with a N 1 constant filter kernel ensuring a correct order of processing generation of correct results and excellent performance.

Embodiments of the invention implementing the boxcar filter force generation of the output pixels in a defined sequential order. Whereas a simplistic implementation of this type of algorithm would be to draw one or few large polygons to cover the entire render target and read the left result within the pixel shader this produces erroneous results in the case of a GPU because of the inherent out of order processing of the GPU. The solution provided in embodiments of the invention is to draw vertical lines from left to right covering one column of the render target each 

It will be appreciated that the pixels are processed in left to right order because the computation of one output pixel value relies on the previously computed value for its left neighbour. Depending on the specific hardware and drivers used sending lines into the graphics pipeline in left to right order may not guarantee the right processing order on the pixel level. Current GPUs have a large number of pixel shaders that compute output pixels simultaneously. The order and pattern in which those pixels are computed varies with hardware and driver types and versions and is currently not defined in API standards like DirectX or OpenGL.

Listed below are multiple ways to force correct execution order. Which one is the most efficient depends on the specific hardware and driver.

The parallelization in the GPU can in some cases be more efficient if the following modified method is used Instead of only initializing the left most column multiple columns spread across the image are initialized. Then the recursive computation is performed by drawing lines advancing from these seedlines. Example For an image with 100 columns one can have four simultaneously advancing fronts by initializing columns and then drawing columns 

Such a methodology can not only improve performance but also help avoiding execution order issues as pointed out above.

In the embodiments described above the input data has been point sampled and the kernels applied by a discrete multiplication within the pixel shader s vector processor. The GPU also includes hardware which is able to perform various filtering operations before the data is read into the vector processors. This hardware filtering can be taken advantage of to decrease the number of instructions in the filter code leveraging additional hardware in the graphics device and further accelerating the filtering process. Additionally since this operation is performed outside the pixel shader these calculation may be carried out in parallel with calculations occurring within the pixel shader.

If the two adjacent filter kernel elements Kand Kare both between 0 and 1 inclusive and sum to 1 Kcan be used as the pixel address offset from the center of pixel P. If linear interpolation is then enabled in the sampler the net effect is that the pixel read into the shader is P K P K. This operation is performed in hardware prior to the data entering the pixel shader s vector registers and does not require any pixel shader instructions.

If the adjacent kernel values do not meet the aforementioned range and sum criteria a scaling can be performed to enable this method. If we define S to be S 1 K K then the address offset is S K which again would be calculated in the vertex shader no additional instructions in the pixel shader . This does however require that a multiplication by the constant 1 S be performed within the pixel shader to recover the result. Even with the introduction of this multiplication this still results in fewer instructions then discretely reading the two samples performing two multiplications and an add.

This method can be used to calculate an entire 1D convolution in a single pass the vertex shader calculates the appropriate addresses for each kernel pair and they are passed through to the pixel shader. The pixel shader then performs a single sample for each kernel pair summing the result and performing the 1 S multiplications where necessary.

Since the GPU can perform linear interpolation in multiple dimensions e.g. 1D 2D and 3D as described above this method is readily extensible to higher dimensions. Additionally as GPUs add additional hardware to perform more complex filtering in hardware this method can be employed if the kernel accommodates it.

A further understanding of the foregoing may be appreciated by reference to the following publications the teachings of which are incorporated herein by reference the citation of which is not intended as nor shall it be deemed an admission that any or all of them is are prior art I. Viola A. Kanitsar E. Gr ller Hardware Based Nonlinear Filtering and Segmentation using High Level Shading Languages Technical Report TR 186 2 03 07 May 2003 Vienna University of Technology M. Hopf T.Ertl Accelerating 3D Convolution using Graphics Hardware Proc. IEEE Visualization 1999 pp 471 474.

Described above are methods and apparatus meeting the objects set forth herein. Those skilled in the art will appreciate that the embodiments described above are merely examples of the invention and that other embodiments incorporating changes thereto fall within the scope of the invention. Thus for example it will be appreciated that in the embodiments described above the GPU serves as a coprocessor operating under the control of a CPU. Other embodiments of the invention employ multiple GPUs for this purpose each responsible for a respective portion of processing. Still other embodiments use no GPU at all relying on other types of processing elements such as array processors game engine processors and so forth to provide or supplement such processing all in accord with the teachings hereof. In embodiments which use GPUs e.g. as described above preferred such devices are of the variety having programmable vertex shaders and programmable pixel shaders and are commercially available in the marketplace from ATI Research for example the Radeon 9700 processor Nvidia for example the GeForce FX and Quadro processors and or otherwise compatible with methods according to the invention discussed herein.

