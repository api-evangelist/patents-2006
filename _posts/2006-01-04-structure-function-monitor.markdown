---

title: Structure function monitor
abstract: Methods and apparatus for a structure function monitor provide for generation of parameters characterizing a refractive medium. In an embodiment, a structure function monitor acquires images of a pupil plane and an image plane and, from these images, retrieves the phase over an aperture, unwraps the retrieved phase, and analyzes the unwrapped retrieved phase. In an embodiment, analysis yields atmospheric parameters measured at spatial scales from zero to the diameter of a telescope used to collect light from a source.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08103045&OS=08103045&RS=08103045
owner: STC.UNM
number: 08103045
owner_city: Albuquerque
owner_country: US
publication_date: 20060104
---
This application claims priority under 35 U.S.C. 119 e from U.S. Provisional Application Ser. No. 60 641 655 filed 4 Jan. 2005 which application is incorporated herein by reference.

This invention was made with Government support under Contract DE AC04 94AL85000 awarded by the United States Department of Energy. The Government has certain rights in the invention.

Atmospheric turbulence is an indicator of mechanical turbulence. Turbulence associated with tiny temperature differences in air a refractive medium are detectable by optical and infrared propagation techniques. This implies that these same refractive index variations degrade images made horizontally or vertically through a column of air.

Most atmospheric turbulence detectors including microthermal sensors and a multi path Differential Image Motion Monitor DIMM while very sensitive to turbulent effects between its optical paths only measure turbulence on a single or at most a few spatial scales. This limitation is critical in studies of the atmosphere because atmospheric turbulence is expected to deviate from model predictions especially for horizontal optical paths. While a design can be extended to multiple microthermal sensors to test multiple spatial separations simultaneously such a design may become impractical with more than a dozen probes per altitude increment.

In the following detailed description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific embodiments in which the invention may be practiced. These embodiments are described in sufficient detail to enable those skilled in the art to practice the present invention. Other embodiments may be utilized and structural logical and electrical changes may be made without departing from the scope of the invention. The various embodiments are not necessarily mutually exclusive as some embodiments can be combined with one or more other embodiments to form new embodiments. The following detailed description is therefore not to be taken in a limiting sense.

In an embodiment a device a structure function monitor SFM measures the phase structure of a wavefront at the pupil of an imaging system. The structure function monitor may be an atmospheric structure function monitor. An atmospheric phase SFM provides detection and detailed measurement of turbulence in the atmosphere. Atmospheric turbulence principally perturbs wavefront phase and far less perturbs the amplitude. Thus the phase provides a more significant measure of turbulence. Additionally by measuring the phase perturbations and correcting them a perfect image can be reconstructed in the presence of blurring caused by atmospheric turbulence. A SFM may detect and measure atmospheric turbulence and may provide phase corrections necessary to reconstruct near diffraction limited turbulence blurred images.

In an embodiment using a known source a SFM may detect and characterize turbulence for avoidance purposes such as at airports where wake turbulence wind shear and microbursts are threats to airport safety. In various embodiments a SFM may be utilized in energy and information delivery. Robustly characterized turbulence allows for correcting a propagating wavefront leading to enhanced fidelity for energy and information delivery and imaging. For example correcting the atmospheric phase variations induced in a wavefront propagating from an astronomical source allows diffraction limited imaging. Diffraction limited imaging provides the best imaging of which an optical system is capable as determined by the diameter of its aperture and the wavelength of the electromagnetic radiation being observed.

Mapping the phase of an atmospherically perturbed wavefront has multiple applications. In particular simultaneous continuous knowledge of the amplitude and phase of the incoming electromagnetic wave over an aperture has long been the holy grail of imaging optics. An atmospheric SFM may be used to measure directly the amplitude and phase of an electromagnetic wave at the aperture the pupil of an imaging optical system.

Another atmospheric turbulence detector is a Surface Layer Atmospheric Turbulence Differential Image Motion Measurement SLAT DIMM also referred to as SDIMM which is presented in co pending commonly assigned application U.S. Ser. No. 11 016 966 which application is incorporated herein by reference. While the SDIMM for example can be extended to more than two sources the practical number of SDIMM apertures that can be placed on a small telescope is but a few. Similar modifications can be made to microthermal probes to test multiple spatial separations simultaneously but may become impractical with more than a dozen probes per altitude increment. The SFM provides a technique that measures turbulence on many scales.

In addition turbulence monitoring necessary for image reconstruction requires measuring the effects of turbulence especially the wavefront phase over as many spatial and temporal scales as possible. The techniques that come closest to direct measurements of the amplitude and phase of a wavefront over a telescope aperture such as the wavefront sensors used for adaptive optics yield the greatest possible direct information about atmospheric turbulence. It is ultimately these phase variations that degrade ground based and astronomical images.

The effect of optical elements at and subsequent to the pupil is to superpose the amplitude and phase of the complex electromagnetic wave in the pupil to produce an image in another plane. The process of image formation is a Fourier transform and thus the bounded electromagnetic wave in the pupil and the resulting wave in the image plane are Fourier conjugates. Thus perfect knowledge of the amplitude and phase of the electromagnetic wave in the pupil corresponds to perfect knowledge of the amplitude and phase of the wave in the image plane and vice versa. This relationship is difficult to achieve in practice because measurements of optical and infrared radiation are almost always photon counting or intensity measurements. With such measurements the phase information is lost because only the squared amplitude of the complex wave is retained. This is generically known as the phase problem and overcoming it is known as phase retrieval. The structure function monitor may implement a method of phase retrieval to recover the phase of the incoming wave across the aperture from intensity measurements made simultaneously in the image and pupil planes. From a map of the phase all atmospheric quantities as well as image detail resolution may be obtained on spatial scales of the diameter of the aperture and smaller.

At the phase over the aperture is retrieved. In an embodiment a Gerchberg Saxton algorithm may be used to retrieve the phase. Various other processes may be used to retrieve the phase. At the retrieved phase may be unwrapped. Various processes may be used to unwrap the retrieved phase. At the unwrapped retrieved phase may be analyzed to generate a parameter of a refractive medium. Refractive medium induced wavefront phase errors over the entire aperture may be determined from analyzing the unwrapped retrieved phase. Wavefront phase correction data may be provided to an imaging system in real time from analyzing the unwrapped retrieved phase. A structure function may be generated from analyzing the unwrapped retrieved phase. Various other parameters may be generated depending on the application of the embodiment of the method for phase retrieval.

Analysis unit may be adapted to provide a recovered phase map based on application of a phase retrieval algorithm to the first and the second images and to compute a parameter of a refractive medium based on the recovered phase map. Analysis unit may use a process in which edges of the first and the second images are padded with zeros to begin an algorithm to retrieve the phase of an electromagnetic wave across an aperture. Analysis unit may compute various parameters such as a structure function that characterize a refractive medium in which the received light propagates. The refractive medium may be the atmosphere. Apparatus unit may include an output to transmit information of a measurement of perturbation of a wavefront of the received light at a pupil corresponding to the second image. Apparatus may be configured as a device or system providing parameters to other devices or systems. Apparatus may be configured as a system that has an imaging components that use the measured and analyzed data to correct images.

In an embodiment a SFM device may include a receiver and a monitoring optical system. In an embodiment a SFM device may include an artificial point source as a transmitter and a receiver as a monitoring optical system. The transmitter may be configured to be 30 m away from the receiver though this can be varied from 10 m 50 m dependent upon the configuration of the receiver. The transmitter and the receiver are not limited to separation distances of 10 m 50 m but shorter or longer separation distances may be used depending on the application. In an embodiment the receiver optical system may include a small telescope and two high speed imaging detectors one detector to image the focal plane and one detector to image the pupil plane via a Fabry lens. Images from each detector are acquired sufficiently rapidly to freeze the atmospheric turbulent effects. In such a situation a frame rate faster than 200 frames per second may be used.

In an embodiment a transmitter is a source of electromagnetic radiation. The theoretically simplest source is unresolved by the receiver thus a device may use small bright sources that fulfill this criterion. A resolved source could be used for a SFM device though the data reduction system may become somewhat more complex. A star for example is a valid source for observations of the night sky or for astronomical purposes.

The primary parameters that determine the choice of the transmitter source include brightness physical size spatial coherence of the emission and the spectral energy distribution. The source should be bright enough to illuminate the pupil image significantly in short exposure times. In an embodiment short exposure times may be used that are less than 5 ms. The source should produce an adequate signal to noise ratio S N per pixel in the pupil image. In an embodiment a pupil image has approximately 6500 pixels in 5 ms when the illumination source is 50 m distant from the receiver. In such a case the source should be of the order 1 mW which allows detectors which have a low quantum efficiency QE and poor optical fill factor a combined QE

The most stringent requirements for an application of a SFM may come from the source dimensions. In an embodiment to make the interpretation of the phase maps straightforward for a given SFM device a point source may be used because resolved sources have phase variations from the source structure added to that of the atmosphere and optical system. For a source to be unresolved by a 0.254 m telescope at a distance of about 30 m 50 m the diameter of the source emission region should be smaller than 50 microns. In an embodiment this eliminates both LEDs because a typical LED emission region is 1 mm or more in diameter and halogen lamps because the incandescent filament is typically many millimeters long. These larger sources cannot be spatially filtered with a pinhole because the efficiency with which LEDs and halogen lamps can be coupled to pinholes is very low and thus produce very dim point like sources. However a laser illuminating a 25 micron pinhole or a single mode optical fiber produces a source that is small enough and bright enough. However laser coherence causes interference effects in the optical system that lead to pupil images with prominent fringes that do not accurately depict the true source amplitude. Both HeNe and diode lasers may be too coherent because they have coherence lengths on the order of centimeters. In an embodiment a superluminescent diode may be used as the artificial source. Alternatively LEDs lasers or other sources may be implemented in a SFM with additional apparatus that provides the appropriate characteristics for the electromagnetic radiation for the SFM.

The SLD has characteristics qualitatively described as halfway between a normal LED and a laser diode. Unlike a standard laser diode the SLD has much broader emission bandwidth 8 nm rather than 

In an embodiment a SFM includes a receiver having a telescope. shows an embodiment of a SFM receiver optical system based on a 10 inch Meade LX200 f 10 Schmidt Cassegrain telescope . The SFM may use telescope to obtain simultaneous image plane and pupil plane images of an artificial source. The SFM is not limited to obtaining images of artificial sources. SFM receiver optical system may include a JMI electronic focusing stage to allow a high precision and repeatable focus where the focusing stage may be attached to the telescope instrument mount. SFM receiver optical system may include a flip mirror pickoff that goes to an eyepiece used for initial alignment. Following flip mirror may be a 50 50 beamsplitter to split the light collected by telescope . In an embodiment 50 50 beamsplitter may be a 25 mm 50 50 beamsplitting cube the through path leading to the pupil plane detector and the reflected path leading to the image plane detector . In an embodiment beamsplitter may have a ratio different from 50 50. Light traveling through splitter encounters a 9 mm diameter f 1 lens that makes an image of the primary mirror on a high speed CMOS camera. Lens may be a 9 mm f 1 double convex BK7 lens that images the primary mirror onto detector .

Light that is reflected by splitter encounters a Barlow lens that adjusts the effective focal length of the incoming light so that the field scale on the image plane detector another high speed CMOS camera is the Fourier conjugate of the pupil plane image. Barlow lens may be realized as a filter and a 12 mm f 1 double concave lens to adjust the field scale in the image plane. The filter attenuates the amount of light incident on the image plane detector because the beamsplitter directs equal amount of light to both detectors and the pupil plane image is far more spatially disbursed than the image. The pupil image covers roughly 6500 pixels and requires an acceptable signal to noise in each pixel whereas in the image plane the same amount of light is focused into fewer than 100 pixels with the vast majority of the light going into the central few pixels. The source brightness required to make an acceptable signal to noise pupil image taken at the longest exposure time of 5 ms to freeze atmospheric effects saturates the image plane detector at the shortest possible exposure time of 77 microseconds. The filter attenuates the light going to the image plane detector by a factor greater than 100 resulting in an acceptable image plane exposure time of roughly 4 ms. The filter may be a blue filter. A beamsplitter that divides the beam at a higher through to reflected ratio such as 50 1 instead of 1 1 may help reduce these difficulties though some attenuation may still be needed.

In an embodiment both the pupil plane and image plane detectors may be based on EPIX SV2112 CMOS high speed cameras which are in turn read out by a dedicated peripheral component interconnect PCI card in a 2.0 GHz personal computer PC . Embodiments using SV2112 detectors may be built around a 1288 1032 6 micron pixel CMOS detector such as one manufactured by Zoran. These detectors are capable of very fast readouts up to 60 million pixels per second but have a very low quantum efficiency of 30 at 680 nm a low pixel fill factor of 40 and a 10 bit analog to digital converter. This combination may lead to poor sensitivity and a small dynamic range by typical astronomical imaging standards. Because it is a CMOS device it does not have the capability to bin pixels on chip. Devices that are capable of binning pixels on a chip may be used in various embodiments. Other embodiments for a SFM receiver optical system are not limited to the individual components used in this embodiment.

Various design considerations may be taken into account to create a functioning SFM. In an embodiment a primary requirement of a phase retrieval algorithm for a SFM may include that the images from which the phases are recovered must be Fourier conjugates of each other. The practical ramification is that the pupil and image scales must be matched to maintain that relationship in terms of pixels. There are many trade offs that exist between the choice of Fabry lens to image the pupil which determines the physical sampling of the pupil the size of the aperture the size of the arrays read out and analyzed the pixel size of the detector the f of the telescope and several other parameters.

Consider a pupil detector of a SFM receiver optical system. In an embodiment the pupil may be sampled to enable detection of phase fluctuations of at least 2 cm in size and larger at the entrance aperture. With the primary mirror of a telescope having a 25.4 cm in diameter a goal may include at least 25 25 cm 2 cm 2 pixel sampling pixels across the diameter of the pupil. For the 6 micron pixels of detectors of where CMOS detectors cannot be multi pixel binned 25 pixels across a 25.4 cm pupil that appears 254 cm distant requires a lens with a 1.25 mm focal length. Commercial lenses are typically not available any faster than f 1 and no smaller than about 3 mm in diameter. Lab tests showed it was not practical to use 3 mm diameter lenses because they are difficult to hold and given telescope system of difficult to align and focus. In an embodiment a 9 mm diameter f 1 lens which may be obtained from Edmund Industrial Optics may be used which may make a pupil image roughly 100 pixels across.

In an embodiment a 128 128 subframe of the pupil plane detector with a 2image dimension chosen to optimize the performance of a Fast Fourier Transform FFT algorithm centered on the pupil image may be read out. In the image plane this corresponds to an effective focal ratio of f 11 and yields an image plane point source image with a FWHM of 1.5 pixels.

In an embodiment a Gerchberg Saxton GS algorithm may be used for phase retrieval in a SFM device. The originators Gerchberg and Saxton of the GS algorithm noted that the only way they made the algorithm fail was to incorrectly sample one of the two planes though they did mention a sampling requirement. See Gerchberg R. W. et al 35 2 237 246 1972. Tests using a GS algorithm with the f 11 image scale and 128 128 image plane images and 128 128 pupil plane images did not converge even after 10 000 iterations.

In an embodiment the edges of both the pupil plane and image plane images may be padded with zeros to make the new image size 256 256. In the image plane this has the effect of doubling the resulting pixel scale required to match the sampling in the pupil plane and corresponds to an effective focal ratio of f 22 set by the negative lens in front of the image plane detector and a FWHM of 3 pixels.

Because of the Fourier transform relationship between the sampled planes padding one image around the edges is equivalent to interpolating the conjugate image doubling the image size in the pupil plane then expands the required image scale in the image plane by a factor of two. By acquiring the images at 128 128 a 200 frames per second frame rate may be maintained. Interpolation achieved by padding the acquired data arrays enables the GS algorithm to converge by appropriately adjusting the spatial frequencies in the image and pupil planes.

downside of padding the images to 256 256 is that the processing time to compute the FFT increases by a factor of N log N roughly 5 . Without the ability to bin images on the CMOS detector this inefficiency may be acceptable.

The image plane scale may be set and verified using a series of aperture masks with 1 2 and 4 of 25 mm diameter regularly spaced circular openings. This aperture size guarantees diffraction limited images under the relatively calm conditions of the lab. The resulting images are then compared to the FFT of the simultaneously acquired pupil image to make sure the scales match. In this case the phase across the sub apertures amounts only to shifts in the position of the diffraction pattern. For the single aperture the diffraction pattern moves slightly. For multiple apertures the overall spacing between maxima and minima are the same and only the position with respect to the centroid of the pattern changes. In an embodiment a SFM uses a software system to acquire data from two detectors at a required rate. In an embodiment acquisition software may be written in Microsoft Visual C and may utilize a camera control function library such as obtained from EPIX. All fundamental parameters of the camera may be set in the acquisition software. Primary acquisition parameters include exposure time acquisition cadence and autofocusing. Acquisition software is not limited to a particular software language or software vendor.

The cadence of the data acquisition can be tailored to meet the needs of the monitoring project subject to available processing power and data storage. In an example embodiment that may be used in association with the system of data may be acquired in bursts up to 1000 frames in both the image plane and pupil plane five seconds per burst but more typically in one or two second bursts. These bursts may be stored in a pair of FITS flexible image transport system format data cubes one each for pupil and image planes with the time of the first frame encoded in the filename. In the example embodiment the maximum data acquisition rate is limited by disk performance which makes the fastest possible observational cadence possible two seconds of continuous data acquired every three seconds which will generate over 10 GB of data in 15 minutes. A somewhat more useful cadence for long term monitoring is to acquire one second of data every minute which leads to a similar data quantity in 24 hours.

Initial test operations showed that diurnal temperature variations can change the spacings of the optical elements by more than 2 mm most of which is due to the thermal expansion of the aluminum tube that holds the secondary Schmidt corrector combination and the primary mirror. The system should be able to focus itself every 15 minutes to compensate for the effects of a 1 C. change in ambient temperature which is roughly a 250 micron range of focus. Because of the low fill factor and low dynamic range of the detectors a stable focus metric is not straightforward variations between measurements of focus quality are of the order the same as the effects of a 250 micron change in focus. During the focusing procedure the telescope vibrates from the focus motor motion causing the image to move. This image motion across the low fill factor pixels results in the total light detected changing by 30 or more as the peak of the intensity alternately falls onto the active pixel region or in the dead space which is indistinguishable from the intensity variation in intensity due to focus. Averaging over many exposures reduces this effect.

Bias and flatfield structure can be removed from the frames on the fly by the software if bias and flat frames are taken ahead of time. The pixel readout rate may be chosen so that the bias level is zero for these devices. In an example embodiment removal of the flatfields has only a very small effect on the resulting phasemaps because variations caused by the low pixel fill factor dominate and so flatfield instrumental signature removal may not routinely be performed.

In an embodiment operation of the SFM uses a software algorithm to map and follow the wavefront phase. A software algorithm that may be employed in a realization of a SFM employs the published GS algorithm for phase retrieval over an aperture. GS provides a method for recovering the phase of a wave that had been recorded simultaneously in two Fourier conjugate planes of an optical system such as the image and pupil planes of a telescope. Previous phase retrieval methods relied either on approximations that were valid only for small phase variations required relatively intensive brute force computation or both. The key to overcoming these limitations for GS was the advent of the now ubiquitous Fast Fourier Transform FFT Algorithm. By sampling the wavefront in planes that are Fourier conjugates of each other and then iteratively transforming back and forth between them Gerchberg and Saxton showed that the phase errors in each iteration tend to get smaller or at worst stay the same . A flowchart of the GS algorithm is shown in .

The GS algorithm is an iterative method to retrieve phase from intensity measurements in Fourier conjugate planes. Gerchberg and Saxton showed that by Fourier transforming back and forth between the image and pupil planes each time asserting the measured amplitudes in each plane instead of those generated by the transform the phases in the pupil plane converge modulo a minus sign given appropriately chosen starting phases. Starting with area format images of the pupil and image planes the amplitudes are obtained by taking the square root of the recorded intensities. Next a guess is made about the initial pupil plane phases. Gerchberg and Saxton advocated using a randomly generated phasemap as the initial guess but acknowledge that any map will do except for a constant map . The initial pupil phases are then complex exponentiated and multiplied by the measured amplitude. This becomes the initial estimate of the pupil plane wavefront.

The pupil plane wavefront is then Fourier transformed and the phases extracted in the usual way by calculating the arctangent of the imaginary part divided by the real part of the transform. These extracted phases are the first estimate of the image plane phase. These phases are then complex exponentiated and multiplied by the measured image plane amplitudes to form an estimate of the image plane wavefront. The image plane wavefront is then Fourier transformed back into the pupil plane and the phases extracted. This process of Fourier transforming and then imposing the measured amplitudes is repeated until the phases no longer change to within some predetermined small amount. Given properly sampled images in each plane Gerchberg and Saxton showed that the technique will converge to the correct phases in the pupil plane and hence in the image plane as well.

A GS algorithm has been previously applied with some success in various applications. A GS algorithm has been applied to a theoretical model of a wavefront sensor for adaptive optics. The GS algorithm has been extended for image reconstruction in the case where only pupil image information was available by applying positional and non negativity support constraints. From this approach one can think of the traditional GS method as imposing the measured amplitudes in both planes as very specific support constraints. The GS algorithm has also been used in radio interferometry to recover image data from measured amplitudes and phases in the pupil u v plane. A form of GS is included in the well known AIPS data reduction package though this technique has fallen into disuse as more robust methods such as CLEAN MEM MLM and self calibration have matured though the GS algorithm does have some utility with sparsely sampled data. More recently GS was used to evaluate the figure of the Hubble Space Telescope optical system. Also a proposed Phase Retrieval Camera for measuring the shape of the mirrors of the Next Generation Space Telescope NGST uses a modified version of GS. In the Hubble and NGST applications the goal is to characterize the time independent phase structure of the optical system. In the case of measuring the NGST optics effects of the turbulent air in the test facility are averaged over. In various embodiments for a structure function monitor an opposite approach is used where the time dependent fluctuations caused by the atmosphere are of most interest and the shape of the optics used is of rather less interest.

The SFM phase retrieval processing need not be limited to the GS algorithm and it need not necessarily be an iterative process.

The GS Algorithm recovers the phase across the aperture but it is insensitive to both the global phase piston and to phase differences of more than 2 . The recovered phasemap from the GS Algorithm can be represented piston mod 2 The recovered phases from the GS algorithm are a combination of the true pupil phases plus a global piston offset wrapped between and . The wrapped phasemap thus includes numerous 2 jumps that must be resolved into a continuous function through the process of phase unwrapping. Phase unwrapping is a research field unto itself that has been applied extensively in synthetic aperture radar interferometry optical interferometry and medical imaging.

In the case of propagation of optical wavefronts through atmospheric turbulence there are some factors that make unwrapping phase a more straightforward process. Firstly the phase across an aperture will be continuous. A trivial Huygens Wavelets analysis shows that a sharp discontinuity in a wavefront such as that cause by the edge of an aperture stop or an abrupt change in index of refraction is smoothed out in a few wavelengths of propagation. Secondly the largest contributor to the phasemap will be the overall tip and tilt of the wavefront due both to turbulence on scales larger than the aperture and motion of the optical system itself with respect to the source. Because these terms appear as a simple plane in the phase map existing phase unwrapping algorithms perform well and it is apparent when the unwrapping process is unsuccessful. In practice under strong turbulence when the light in the image plane is spread out so much that it is not measured with appreciable signal to noise or when strong scintillation causes the pupil intensity to vanish in some place the GS Algorithm will inject artifacts in the form of singularities in the recovered phasemap that cannot be resolved by unwrapping.

There are many algorithms for phase unwrapping where a wide variety of the most commonly used algorithms have been compared in the literature. In an embodiment for a SFM Flynn s Minimum Discontinuity Method FMDM may be used for unwrapping the phasemaps produced by the GS Algorithm. See Flynn T. J 14 10 2692 2701 October 1997. FMDM works by identifying lines of phase discontinuity where the map has been wrapped and searches for discontinuities that form loops. The pixels inside the loops then have the appropriate multiple of n 2 added to them so that the total number of loops is minimized.

In practice FMDM does an excellent job of unwrapping phasemaps succeeding in totally unwrapping over 95 of the frames analyzed. In those it does not unwrap completely it has left at most 6 pixels out of over 6000 at the edges of the map caused by the edge of the pupil being discontinuous. Further processing detects and masks off the erroneous pixels. A more rigorous implementation of FMDM which uses pixel quality maps to help guide the unwrapping succeeds all of the time. However the more rigorous implementation costs significantly more in processing time and may be unwarranted given how few pixels are given up in the faster implementation.

Under most real world atmospheric conditions the majority of turbulent optical power occurs at spatial scales much larger than the primary aperture of all but the very largest modern telescope systems. Phase variations arising from these large scale disturbances are manifested as tip tilt and piston fluctuations. Single aperture optical systems are insensitive to piston overall phase offset variations. For small telescope systems where the mount is not isolated from ambient vibrations tip and tilt are indistinguishable from the oscillatory motions of the telescope. For embodiments in which a SFM is designed around small off the shelf telescopes approaches may be taken so that the effects of telescope motion which appears as tip and tilt of the wavefront do not contaminate the phase data. In an embodiment overall tip and tilt may be first removed from each unwrapped phase map by means of a straightforward linear least squares fit of a plane to the map. Removing the tip and tilt may be used for calculating the short exposure structure function.

In an embodiment analysis of the data frames acquired by a SFM device such as the example SFM device discussed herein may be performed by an automated software pipeline running under MATLAB the bulk of which is compiled code either internal MATLAB routines or compiled C code executed by MATLAB . Image and pupil cubes are processed in the order that they were acquired and each frame is processed independently and in sequence. The processing sequence proceeds from the GS algorithm through correction operations of unwrapping detilting deflipping to measuring the time average phase map and final calculation of the parameters relevant to characterizing atmospheric turbulence. Each of these operations the algorithm used to calculate and apply the operation is described here. Application of automated software is not limited to running under MATLAB .

At an image plane image and a pupil plane image are acquired. At an initial step includes padding the edges of each the image and pupil arrays to 256 256. Let Wand Wbe the complex wave in the image and pupil planes and similarly for the recorded intensities Iand I the amplitudes A I and the phases and . Superscripts indicate the iteration number. At the GS algorithm is applied. A guess at the pupil plane phases is made. Gerchberg and Saxton suggest a random phasemap for the initial guess but also acknowledge that the choice of initial phasemap doesn t impact the final solution other than possibly starting closer to the solution. For azimuthally symmetric intensity maps such as the example embodiment associated with one cannot choose a constant phase across the aperture or the algorithm will not converge. It has been suggested to model the source and take the phases of its FFT as the initial pupil phases. In an embodiment a source is modeled as a Gaussian with diffraction limited FWHM W. The initial pupil plane phases are then given by Angle FFT2 where Angle is the MATLAB function that computes the complex phase angle from the arctangent of the quotient of the imaginary part divided by the real part and FFT2 is the internal MATLAB 2D FFT implementation using the FFTW 3.0 library. The phases calculated from the MATLAB FFTs are also corrected for a problem in the implementation of the FFT that causes the phases to have a checkerboard appearance the phase of every other pixel is offset by . Though there is no note of this effect in the literature testing simple Fourier transform cases also shows this same phase offset. Correction by subtracting a mask with phases alternating by on a checkerboard pattern yields the proper answer.

With the initial pupil plane phases calculated the first estimate of the image plane phases and pupil plane phases is obtained Angle FFT2 Angle FFT2 Then iterate 

At tip tilt component may be removed. A plane may be fit to the unwrapped phasemaps using internal MATLAB linear least squares code. The residuals of the fit then become the tilt removed phasemap. At phase discontinuities may be unwrapped. To unwrap the output pupil phasemap MATLAB may be used to call an outside routine that implements FMDM. Pixels on the edges of some maps that are not successfully unwrapped are detected by looking for 2 discontinuities at the edges of the map masked off and ignored in further analysis. At 670 complex conjugate degeneracy may be removed deflipped . The GS algorithm does not distinguish between solutions that are complex conjugates of each other in the case where the input images are azimuthally symmetric. This manifests itself as some of the maps being flipped that is nearly the negative of the previous map. This does not affect instantaneous measurements but it may have drastic consequences on time averaged quantities. In an embodiment the sign convention of the first analyzed frame may be adopted. If the rms phase of the sum of two adjacent frames is less that the rms phase of the difference then the second frame is flipped with respect to the first and multiplied by 1 to remove the effect.

In an embodiment a SFM may be designed to produce atmospheric turbulent structure characterization parameters. Having retrieved the phase unwrapped detilted and deflipped it a primary data product is provided x y t From these values five other fundamental characterization quantities may be derived 

3 x y t x y t is the time averaged phase removed phasemap shown at in . The motivation for removing the time average of the phasemaps is that the recovered phase has contributions from both the atmosphere and the optical system. On the timescales 10 15 minutes that are averaged over the phase aberrations of the optical system can be considered constant. Removing them leaves the rather more rapidly changing effect of the atmosphere. After each autofocus operation a new average may be calculated.

5 D t is the short exposure e.g. tip tilt removed structure function after the average phase has been removed.

The single most used turbulence characterization parameter is the structure function. In various embodiments the structure function is a primary product of SFM. The code to calculate the short exposure structure function may be compiled C code that takes the detilted phasemap as input and outputs both the 1D and 2D structure functions. Mathematically the structure function is the variance of the difference in phase at all available separations in the pupil. right arrow over right arrow over The input phasemap is shifted against itself in both x and y. For each shift the code calculates the difference between overlapping pixels and finds the variance for all the pixel differences at that shift. For a 128 128 array the 2D structure function is 255 128. The 2D structure function is then azimuthally averaged to form the ID structure function which is a function only of the scalar separation. The code is not limited to compiled C code but may use other codes to calculate the structure function.

In an embodiment the Strehl ratio may be estimated. The Strehl ratio is a useful measure of image quality. It is the ratio of the amplitude of the measured point spread function to that of the diffraction limited optical system. From the rms phase over the aperture the Strehl ratio for the SFM map can be calculated trivially as S e. The Strehl ratio is a particularly useful metric because it does not depend on a model of atmospheric turbulence.

In an embodiment Fried s parameter may be estimated. Fried s parameter r is the usual parameter for characterizing the size of the mean phase coherent i.e. diffraction limited aperture for the time averaged turbulence. Interpretation of Fried s parameter as the size of a coherent patch depends upon the atmospheric turbulence having a Kolmogorov parent distribution which is often the case for vertical optical paths through the entire atmosphere but seldom true for truncated vertical or any horizontal paths.

There are two different ways of estimating rfrom the recovered phasemaps. Fried s approximation for the short exposure structure function depends only on r. One can therefore fit Fried s expression to measured structure functions. However as can be see in Fried s expression does not well represent the recovered phase structure. Fried s parameter can also be related directly to the rms phase across the aperture. Measured values of rmust be taken with a grain of salt as the entire framework upon which Fried s parameter rests depends on the validity of a Kolmogorov spectrum in the measured turbulence.

For transmitters at a finite distance from the receiver the turbulence measured by the SFM receiver has a distance weighting function. Turbulence near the transmitter does not affect the propagating wavefront in the same way as turbulence near the receiver. The net effect is an overall underestimate of the total turbulence in the volume probed and a bias towards turbulence near the receiver. This effect has been quantified in the literature in terms of the integral of C the range resolved index of refraction structure constant. In the case of a source with finite altitude the integral becomes 

If the turbulence in the volume probed can be assumed to be constant i.e. C h is constant then the cone effect on measured rvalues can be quantified as 

Turbulence induced refractive power may be distributed along the optical path. This makes segregation of the turbulent components a valuable measurement. An example is the Earth s atmosphere. In an astronomical application SFM applied both to stars at essentially infinite distance and outside the Earth s atmosphere and tower mounted transmitters at for example 30 m altitude resolves the turbulent components and measures the effect of the important surface layer.

A useful schematic representation of the contribution of atmospheric turbulence portrayed as the altitude weighted refractive index structure constant C with height is shown in 31 13 62 1993 . The panels in show atmospheric turbulence h C h plotted as a function of altitude for an observatory at sea level and another at 2630 meters above sea level. Surface generated turbulence is shown as the dashed line. The middle peak which decreases dramatically with increasing altitude arises from the planetary boundary layer. The approximate altitude at which the planetary boundary layer turbulence contribution is equal to that typically created by a surface layer occurs at an altitude of about 2135 m. Higher observatory sites are less affected by planetary boundary layer turbulence. As noted there are three conceptually separate physical contributions to atmospheric turbulent structure distributed in altitude and represented by the three peaks in . represents a sea level observatory and represents another observatory at 2630 m altitude. There is overall less turbulence represented as the integral of these curves at the higher site. In particular compare the middle peak of each panel 1 km altitude and note the dramatic decrease in turbulence with increasing altitude.

The surface layer can contribute 50 of the total C. However it is apparent that not all telescopes can be built in Hawaii or Chile to reduce such effects. In various embodiments telescopes may be enhanced in design and operation based on information about the surface layer to account for or reduce surface layer effects. shows a block diagram of features of apparatus for measuring turbulence in the atmosphere. Apparatus includes source detectors and primary optic where source and primary optic may be separated by a distance . In an embodiment distance may range from about 10 m to about 100 m. Other separation distances are possible. Source may be a laser or an LED and unresolved by optics. In an embodiment for a 25 cm optic at about a 10 m separation distance source may have a spot size less than or about 50 m. Various detectors may be used as detectors . In an embodiment detectors include Epix SV2112 CMOS Cameras which captures simultaneous 128 128 subframes at 200 Hz for the image I and pupil I plane. Embodiments are not limited to use of a particular detector camera or vendor. The images may be analyzed by applying a GS algorithm to recover a phase unwrapping the phase to minimize phase discontinuities with a global cost function detilting the unwrapped phase and calculating a phase structure function. The GS algorithm may be applied to a FFT model of source to obtain a first phase estimate and then iteratively determine the phase until a desired phase error condition is achieved. Phase unwrapping may be performed by applying a known algorithm. Detilting the unwrapped phase may include a best fit plane subtraction. The phase structure function may be calculated for the entire aperture of interest and azimuthally average to obtain 1D Phase Structure Function.

SFM may be combined with other techniques of characterizing the surface layer. Such combinations may enable decisions about telescope and enclosure design telescope siting both horizontal and vertical and telescope operation. Information regarding seasonal daily and real time operation may include queued observing selection criteria and local seeing quality factor. Various embodiments may include combining a SFM with a SDIMM and or microthermal probes. See Zimmer P. C. THE PATTERN SPEEDS OF M51 M83 AND NGC 6946 USING CARBON MONOXIDE AND THE TREMAINE WEINBERG METHOD NOVEL TECHNIQUES FOR THE CHARACTERIZATION OF OPTICAL TURBULENCE IN THE SURFACE LAYER PhD Dissertation University of New Mexico October 2004 which is incorporated herein by reference. In an embodiment the two Source Differential Image Motion Monitor 2SDIMM measures the apparent separation of a pair of transmitters suspended from the top of a tower extending the traditional Differential Image Motion Monitor concept to surface layer studies. In an embodiment the Structure Function Monitor SFM adapts the Gerchberg Saxton phase retrieval algorithm to the recovery of the phase of the incoming wavefront from an artificial source across the aperture of a small telescope. From the wavefront phase all relevant atmospheric turbulence parameters can be obtained on all spatial scales available to the aperture.

Novel instrumentation and techniques such SFM and combination of SFM with SDIMM and or microthermal probes may allow informed decision making in the design and siting of small 

To date every atmospheric turbulence characterization technique short of full wavefront sensing such as that accomplished with adaptive optics systems on large telescopes is fundamentally limited in how it converts its measured quantities into real atmospheric parameters. Most techniques measure turbulence on one or at best a few spatial scales and several of the most common techniques measure non optical physical quantities all of which must be converted into atmospheric parameters via model dependent methods. These models are based on assumptions that most likely never hold in the surface layer. In various embodiments application of SFM may be implemented stressing model independent measurements.

Because there are several physical mechanisms creating turbulence in the surface layer such as time dependent terrestrial thermal heating orographic flows and directionally dependent surface friction it cannot be expected to closely follow a simple model such as the momentum cascade that creates a Kolmogorov spectrum. An approach may include making multiple complementary and supplementary measurements that characterizes the atmosphere in terms of data sets. In various embodiments the instrumentation to make these measurements is sufficiently inexpensive and robust that multiple systems can be deployed at potential telescope sites and long term data streams can be directly compared to select the optimum site.

The 2SDIMM while very sensitive to turbulent effects along its optical paths only measures turbulence on a single spatial scale. This limitation is critical in studies of the surface layer because the turbulence is expected to deviate from model predictions. While the 2SDIMM can be extended to more than two sources the practical number of DIMM apertures that can be placed on a small telescope is only a few. Similar modifications can be made to microthermal probes to test multiple spatial separations simultaneously but become impractical with more than a dozen probes per altitude increment. It is desirable therefore to develop techniques that measure turbulence on as many scales as possible.

The techniques that come closest to direct measurements of the amplitude and phase of a wavefront over a telescope aperture such as the wavefront sensors used for adaptive optics yield the most direct information about atmospheric turbulence possible. It is ultimately these phase variations that degrade ground based astronomical images. Simultaneous continuous knowledge of the amplitude and phase of the electromagnetic wave over an aperture is a significant goal of imaging optics.

The effect of optical elements at and subsequent to the pupil is to superpose the amplitude and phase of the complex electromagnetic wave in the pupil to produce an image in another plane. The process of image formation is a Fourier transform and thus the bounded electromagnetic wave in the pupil and the resulting wave in the image plane are Fourier conjugates. Thus perfect knowledge of the amplitude and phase of the electromagnetic wave in the pupil corresponds to perfect knowledge of the amplitude and phase of the wave in the image plane and vice versa.

This relationship is difficult to achieve in practice because measurements of optical and infrared radiation are almost always photon counting or intensity measurements the phase information is lost because only the squared amplitude of the complex wave is retained. This is generically known as the phase problem and overcoming it is known as phase retrieval. 

In various embodiments the Structure Function Monitor may be designed to leverage a well known method of phase retrieval to recover the phase of the incoming wave across the aperture from intensity measurements made simultaneously in the image and pupil planes. From a map of the phase all atmospheric quantities can be obtained on spatial scales of the diameter of the aperture and smaller.

In an embodiment a SFM uses the GS phase retrieval algorithm to recover an estimate of the phase of incoming wavefronts originating from an artificial point source from simultaneous rapid images of the intensity distributions in the image and pupil planes of a small telescope. From the recovered phase maps the phase structure function of the phase changes caused by atmospheric turbulence which relates directly to the optical transfer function can be computed directly for all spatial scales up to the diameter of the aperture. The ability of the SFM to measure turbulence on multiple scales is its key advantage over other turbulence characterization techniques. Similar techniques that use wavefront sensors such as those commonly used in adaptive optics require a considerably larger investment in equipment and are not well suited to field testing.

Testing of the SFM in parallel with microthermal and 2SDIMM systems shows that it is capable of detecting the same turbulence as these other techniques albeit with overall lower sensitivity which is traded for better spatial sampling. Comparisons of the resulting atmospheric parameters are complicated by the model dependencies in the conversion of measurements into common atmospheric parameters. However the results are consistent with a turbulence spectrum that has significantly less energy at scales of 1 m or larger than is expected in the models which in laboratory tests is consistent with air motions in an enclosed space. The temporal correlations between the three systems are excellent.

Applicability of a SFM to field use may be determined by both the sensitivity of the detectors it uses and the computational requirements of retrieving phasemaps from the data it produces. Enhancement of a SFM system for field use may be directly related to improvements of standard components used in the system. Commercial improvement in detectors and computational resources such as faster computers or a computing cluster such as dedicated FFT processors will provide enhanced SFM performance. In example embodiments EPIX CMOS cameras may be used as they are inexpensive and can be read out very rapidly. However the low quantum efficiency low pixel fill factor low dynamic range and high read noise of these devices inhibit high precision high resolution phase measurements. Because CMOS devices cannot be binned at readout the pupil image scale is fixed by the availability of suitable lenses for the pupil imager. The spatial frequencies of the phase changes in the recovered phasemaps are limited by the sampling of the image plane and the dynamic range of the image plane imager. Points in the image plane further from the central peak intensity correspond to higher spatial frequency information in the recovered phase maps. Because the dynamic range of the EPIX CMOS cameras is 10 bits 1024 levels of digitization portions of the image plane image with intensity less than 0.1 that of the peak 3 amplitude are not measured. Detectors with lower noise higher sensitivity and higher dynamic range 16 bits per pixel 65000 levels may measure these fainter portions of the image plane and allow recovery of much more detailed phasemaps.

A second factor for a SFM device is the computation time required to generate phase data from the input intensity measurements. In an example embodiment discussed herein each frame currently takes between five and ten seconds to process. One second of continuous data takes 15 45 minutes to completely process on a 2 GHz class PC which converts to roughly one day of processing time per minute of acquired data. The computational load is almost entirely due to the computation time of each FFT in the GS algorithm which is of the order 50 ms for a 256 256 array. Binning detectors would allow smaller arrays to be used in the computation and more favorable pupil image scales could be used. Use of 128 128 pixel arrays would improve computational speed by a factor of better than 5 4 1 n 4 . In an embodiment one or more dedicated FFT processing PC boards may be employed which may provide improvements in operation. Using processors that can perform a 256 256 pixel complex FFT in less than 50 s would enhance operation to such a point that the processing may be limited by other computing operations. A combination of enhanced detectors and dedicated processing hardware may improve performance to near real time with possible 50 real time processing one second of data would take two seconds to analyze .

In an embodiment enhancements to a SFM technique may use very bright stars as a source. Currently because a large number of pixels in the pupil image need to be illuminated using SFM on stars is impossible unless this factor is taken into account. In the literature a theoretical wavefront sensor is described that uses a generalization of the GS algorithm to retrieve phase using only the image plane intensity and knowledge of the shape of the pupil. See Cederquist J N. et al 6 7 1020 6 July 1989. Because amplitude fluctuations are overall much less important than phase fluctuations to image fidelity the pupil intensity is allowed to vary though its geometry is bounded and the phase can still be recovered. With this technique as a guide SFM may be modified to measure the pupil intensity much less frequently than the image plane intensity. Coupled with higher sensitivity detectors this would allow for sources ten thousand to a hundred thousand times fainter than the current transmitters to be used with improved SFM receiver setup.

In an embodiment a SFM acquires images of the pupil plane and image plane of a small telescope observing a bright artificial point source located away from the telescope. In an embodiment the separation distance may be about 30 m. From these images the phase over the aperture is retrieved unwrapped and analyzed to yield atmospheric parameters measured at all spatial scales from zero to the diameter of the telescope used. A current example implementation of SFM provides a proof of concept. Enhanced performance of the SFM will accompany improvements in component CCD detectors and data processing power. Improved detectors will enable higher sensitivity imaging in the image plane opening up higher spatial resolution phase maps and lowering the errors in rms phase over the aperture due to detector noise. Dedicated FFT processing hardware may speed up the data processing pipeline by as much as a factor of 1000. Embodiments of apparatus and methods for implementing a surface function monitor are not limited to the components of the embodiments discussed herein.

Various embodiments for a device referred to as a structure function monitor that detects and characterizes turbulence in the atmosphere may have a variety of applications. Embodiments for a structure function monitor may be applied in any refractive medium e.g. air water . A structure function monitor may measure the perturbation of the wavefront at the pupil almost always the entrance aperture of an imaging device such as a telescope over the entire pupil. A structure function monitor may measure perturbations on all spatial scales defined by the aperture. A structure function monitor may operate from low to very high speed to provide real time wavefront characterization. In an embodiment a structure function monitor may operate at rates greater than 200 measurements per second. The output from a structure function monitor may be used to calculate several relevant physical characterization parameters for the detected turbulence including the structure function. Parameters calculated from data acquired by the structure function monitor may be turbulence model dependent or independent. The structure function monitor may use a transmitter and a receiver where the transmitter may incorporate a sufficiently bright unresolved point source. The transmitter for a SFM may be adapted as a natural sufficiently bright point source such as a star. The transmitter need not be a point source.

In an embodiment a receiver for the SFM may be a telescope. A receiver may measure images at two Fourier conjugates. A receiver may measure images at the focal plane and a pupil plane which are Fourier conjugates of each other. A receiver may use an appropriately selected beamsplitter to direct energy from a transmitter simultaneously to the two conjugate planes. A receiver may use an automatic system to maintain focus in the two conjugate planes. A receiver may use area format detectors to record the conjugate images. A receiver may use two area format detectors to separately and simultaneously record data in the image and pupil planes. A receiver may use optical bandpass filters to optimize the signal to noise performance of the structure function monitor and maintain measurements within the dynamic range of the detectors. A receiver may use a Fabry lens to image the pupil plane onto an area format detector at the correct image scale. A receiver may use an appropriately selected Fabry lens to adjust the pupil plane image scale on an area format detector.

In an embodiment a structure function monitor measures the refractive medium induced wavefront phase errors over the entire aperture. The refractive medium may be the atmosphere. A structure function monitor may use a software data acquisition system to control the transmitter and receiver. The data acquisition system may operate at rates high enough to make real time measurements of turbulence. A structure function monitor may detect turbulence in real time. A structure function monitor may characterize turbulence in real time. A structure function monitor may provide wavefront phase correction data in real time. A structure function monitor may use a data analysis system. The data analysis system may calculate turbulence parameters. The data analysis system may calculate wavefront phase corrections for imaging purposes. The data system may calculate real time phase corrections for imaging purposes.

Although specific embodiments have been illustrated and described herein it will be appreciated by those of ordinary skill in the art that any arrangement which is calculated to achieve the same purpose may be substituted for the specific embodiment shown. This application is intended to cover any adaptations or variations of the present invention. It is to be understood that the above description is intended to be illustrative and not restrictive. Combinations of the above embodiments and other embodiments will be apparent to those of skill in the art upon reviewing the above description. The scope of the invention includes any other applications in which the above structures and fabrication methods are used.

