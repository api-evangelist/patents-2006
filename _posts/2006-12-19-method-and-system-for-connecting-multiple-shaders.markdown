---

title: Method and system for connecting multiple shaders
abstract: A method and system for connecting multiple shaders are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of configuring a set of shaders in a user-defined sequence within a modular pipeline (MPipe), allocating resources to execute the programming instructions of each of the set of shaders in the user-defined sequence to operate on the data unit, and directing the output of the MPipe to an external sink.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08223158&OS=08223158&RS=08223158
owner: NVIDIA Corporation
number: 08223158
owner_city: Santa Clara
owner_country: US
publication_date: 20061219
---
The present invention generally relates to computer graphics and more particularly to a method and system for connecting multiple shaders.

Unless otherwise indicated herein the approaches described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.

Over the past decade graphics hardware has gone from a simple memory device to a configurable device and relatively recently to a programmable graphics processing unit GPU . To fully realize the parallel processing capabilities of a GPU as much GPU functionality as possible needs to be programmable and be exposed to developers. Among other things doing so enables developers to tailor their shader programs to optimize the way a GPU processes graphics scenes and images. In a prior art approach a GPU includes a series of processing units each is configured to carry out a different and often dedicated function of a graphics pipeline where the output of one processing unit is the input to the next processing unit in the chain. Some of these processing units in the graphics pipeline are programmable such as a vertex processing unit and a fragment processing unit but other processing units perform fixed functions such as a primitive assembler a geometry processor and a rasterizer.

The aforementioned prior art approach has some shortcomings. First without full programmability the aforementioned graphics pipeline is unable to efficiently respond to changes in Application Programming Interface API such as OpenGL and DirectX or address any bugs identified to be associated with the pipeline. Second because many functions of the graphics pipeline and the sequence of performing such functions are fixed a graphics application utilizing the graphics pipeline does not have the full flexibility to maneuver various shader programs such as invoking shader programs in a different sequence than the sequence of the pipeline stages e.g. invoking a geometry shader ahead of a vertex shader or repeating a particular shader program multiple times e.g. invoking a vertex shader six times . Even with workaround approaches capable of emulating the maneuvering of various shader programs on the prior art system these approaches are cumbersome to implement and are inefficient to operate. For example one workaround approach is to configure a graphics pipeline to execute a particular shader program stream the output of the shader program into a frame buffer reconfigure the graphics pipeline to execute another shader program re inject the stored data from the frame buffer back to the reconfigured pipeline for processing and repeat these steps until all the shader programs are processed in a specific sequence. The repeated configurations of the graphics pipeline and the accesses of the frame buffer likely consume significant processing and memory resources and introduce undesirable delays. Another workaround approach involves merging the multiple shader programs and recompiling the merged program to generate a single all encompassing shader program for the graphics pipeline to process. This approach is inefficient because if any of the shader programs or the sequence of executing the shader programs needs to be altered then these extra steps of merging and compiling also need to be repeated.

Lastly the prior art approach does not support a mechanism that reconciles different input and output requirements of multiple shader programs. To illustrate suppose a first shader program to be operated on a prior art GPU requests for 40 outputs but a second shader program coupled to the first shader program only requests for 6 inputs. In other words the second shader program is designed to read only 6 of the 40 outputs from the first shader program. Without considering the requirements of the second shader program the GPU still allocates the resources for all 40 outputs for the first shader program.

As the foregoing illustrates what is needed in the art is a method and system for supporting a user configurable graphics pipeline capable of efficiently executing various shader programs.

A method and system for connecting multiple shaders are disclosed. Specifically one embodiment of the present invention sets forth a method which includes the steps of configuring a set of shaders in a user defined sequence within a modular pipeline MPipe allocating resources to execute the programming instructions of each of the set of shaders in the user defined sequence to operate on the data unit and directing the output of the MPipe to an external sink.

At least one advantage of the invention disclosed herein is the flexibility and the programmability of configuring a set of shaders in any user defined sequence so that at least the problems described above are addressed.

Throughout this disclosure unless indicated otherwise the terms shader and shader program are used interchangeably and broadly refer to a program that performs the processing for one or more graphics pipeline stages within a GPU. Generally many different shaders in many different configurations are used to render an image.

Host processor executes programming instructions stored in system memory to operate on data also stored in system memory . System interface bridges communication between host processor and GPU . In alternate embodiments host processor GPU system interface or any combination thereof may be integrated into a single processing unit. Further the functionality of GPU may be included in a chipset or in some other type of special purpose processing unit or co processor. GPU receives instructions transmitted by host processor and executes the instructions to render graphics data and images stored in video memory . GPU causes certain graphics images stored in video memory to be scanned out to a display . GPU accesses video memory via a memory controller .

System memory further includes an application program one or more shader programs an API and graphics driver . The application program generates calls to the API in order to produce a desired set of results typically in the form of a sequence of graphics images. The application program also invokes the shader programs with programming instructions that are designed to be executed by one or more streaming multiprocessors SM within GPU . Graphics driver transmits the programming instructions of the shader programs to GPU .

Display is an output device capable of emitting a visual image corresponding to an input data signal. For example the display may be built using a cathode ray tube CRT monitor a liquid crystal display or any other suitable display system.

SM is further coupled to a modular pipe MPipe controller which includes a resource manager . As will be described in further details in subsequent paragraphs MPipe controller is responsible for setting up and triggering one or more instances of an MPipe to be executed on SM. An MPipe here broadly refers to a configurable construct enabling one or more shader programs to be executed in any user defined sequence. In another implementation a software graphics pipe instead of SM executes one or more instances of an MPipe and allows distribution of packets among these MPipes. With the graphics pipe implemented as a software controlled program configuring the graphics pipe in any arbitrary sequence becomes possible. SM is further coupled to a MPipe controller which includes a resource manager . SMn is further coupled to a MPipe controller which includes a resource manager . MPipe controllers are similar to Mpipe controller .

To identify the various shaders that are loaded in a memory system one embodiment of generic MPipe utilizes an MPipe table. It should be apparent to a person with ordinary skills in the art to recognize that this memory system can be any memory system that is accessible by GPU shown in . However for illustration purposes the following discussions assume the shaders are loaded in video memory . is a simplified diagram of an MPipe table according to one embodiment of the invention. MPipe table includes a number m of slots each containing a pointer pointing to a block of memory locations in video memory that store the programming instructions of a shader in generic MPipe . In particular slot of MPipe table contains a pointer which points to shader A in video memory . Similarly slot and slot m contain pointers and which point to shader B and shader C respectively. As shown MPipe table is not required to use contiguous slots to store the pointers. So instead of storing pointer in slot pointer is stored in slot m suppose m 2 in this example . In one implementation each slot of MPipe table is associated with an enable bit. If the enable bit for a slot such as slot is set to 1 then the content of slot is retrieved meaning the configuration for slot and the program for slot are read from memory and the MPipe stage is put into a state where work packets can be received and processed. On the other hand if the enable bit for a slot such as slot is set to 0 then slot is skipped.

Based on commands from a graphics application graphics driver shown in configures MPipe table with appropriate pointers pointing to the memory locations containing the shaders that the graphics application intends to execute. With the configured MPipe table and the shaders already loaded in memory MPipe controller waits for an external event to trigger the operations of generic MPipe . One external event is the arrival of a packet of work at the head of generic MPipe . This external event along with the traversal of the packet through generic MPipe defines an instance of the MPipe. Each SM is capable of executing multiple instances of an MPipe concurrently to operate on multiple streams of work. illustrates a flowchart of method steps for one instance of generic MPipe to process an incoming packet of work according to one embodiment of the invention. For discussion purposes suppose SM of executes this instance of the MPipe MPipe controller manages MPipe table and resource manager of MPipe controller manages certain resources of SM. In step resource manager checks whether there are available resources of SM to execute a new instance of generic MPipe . If not MPipe controller waits for the resources to free up. Otherwise in step one implementation of resource manager allocates the necessary resources up front to execute this instance of generic MPipe and MPipe controller primes this generic MPipe by loading the packet of work in an input buffer to the first shader of generic MPipe shader A . In another implementation instead of MPipe controller managing all the data movement among the input and output buffers of the shaders a primitive engine within GPU not shown in actually moves data from external sources into the input buffer to the first shader and a buffer management unit also within GPU not shown in copies data from an input buffer to an output buffer. Also it is worth noting that improper resource allocation here may cause deadlock. In step MPipe controller obtains and provides certain state information to SM. In one implementation MPipe controller obtains a slot number for MPipe table from the packet of work. Suppose the obtained slot number is slot . Then MPipe controller looks up slot identifies pointer and provides pointer to SM. In addition to pointer MPipe controller also obtains and provides the pointers to the input buffer and the output buffer of shader A to SM. All three aforementioned types of pointers are some examples of the state information discussed in step .

With these pointers SM loads the programming instructions for shader A from video memory shown in executes shader A to operate on the data stored in the input buffer of shader A and generates and places output data in the output buffer of shader A . If SM completes the aforementioned tasks in step then in step MPipe controller verifies whether all the slots of MPipe table have been processed. If not that means more shaders in generic MPipe still need to be executed and MPipe controller converts the output buffer of the current shader into the input buffer of the shader immediately following the current shader in step . In this example the output buffer of shader A becomes the input buffer of shader B . Then the process of feeding SM with relevant state information to execute a shader continues until all the slots of MPipe table are processed. When MPipe controller finishes processing MPipe table MPipe controller in step directs the last output buffer to an external sink such as a distribution point to another SM executing a particular MPipe or to a fixed function unit e.g. a setup raster unit . More specifically multiple MPipes can be chained together where each of the MPipes may be executed by a different SM. In a graphics pipeline multiple MPipes can be defined at any point in time. For example the graphics pipeline can include a geometry MPipe setup raster unit and a pixel MPipe. Lastly resource manager deallocates resources of SM in step . It should be noted that an MPipe is not required to output a single output packet.

As discussed above each of the n number of SMs in GPU is capable of executing multiple instances of an MPipe concurrently. One approach for GPU to execute n different types of MPipes is to assign a mask to each SM. In particular the mask may enable the SM to process one type but disable it to process any other types of an MPipe. As a result using this mask potentially limits each of n SMs to execute a distinct type of an MPipe.

To ensure resources are efficiently utilized to execute the various shaders in generic MPipe one approach is to match the expected output of a first shader at a current stage and the expected input of a second shader at an immediately subsequent stage. Specifically a shader typically has a shader header which is generated by a compiler along with executable program instructions and includes an input map and an output map. The input map describes the input that the shader expects to receive and the output map describes the output that the shader expects to generate. An overlap between the output map of the first shader and the input map of the second shader is referred to as a buffer map. is a conceptual diagram of a buffer map in between shader A and shader B according to one embodiment of the invention. Continuing with the example of SM executing generic MPipe SM uses buffer map to determine the appropriate resources to allocate at the output of shader A and at the input of shader B . To illustrate suppose in the first scenario the output map of shader A contains attributes of a b and c and the input map of shader B contains attributes of b and c. where a b and c can be scalars vectors or some other resource. Whenever shader A generates an output including the attribute of a SM recognizes that a is not in buffer map and thus removes a before it reaches shader B . In other words instead of allocating resources for a b and c only the resources for b and c are allocated. In the second scenario suppose the output map of shader A still contains attributes of a b and c but the input map of shader B contains b c and d. Here before shader B reads its input SM recognizes that d is not in buffer map and thus adds a default value e.g. 0 0 0 1 for a vector or 1.0 for a scalar in place of d. Therefore with buffer map only the needed resources are allocated and the remaining resources can be reserved for operating additional instances of generic MPipe . Both of the aforementioned scenarios assume the output from one shader e.g. shader A is used as input for also only one shader e.g. shader B and each entry in buffer map is the result of performing a logical AND operation between corresponding entries in an output map and an input map e.g. the output map of shader A and the input map of shader B . However if the shaders are organized as a directed graph with the output from one shader being the input to a plurality of other shaders then each buffer map entry is formed by performing the logical AND operation between the following two items 1 an entry in the output map of the shader generating the output and 2 the result from performing a logical OR operation among the corresponding entries in the input maps of all the shaders using the output as their inputs. In other words the buffer map here indicates which shader output is needed as an input to a subsequent shader.

The shader header of a shader may include any or all of the following information a the type of the shader such as without limitation a vertex shader a tessellation shader or a geometry shader b the number of temporary registers needed by the shader c the output primitive type such as a point a line a triangle a line strip a triangle strip lines with adjacency or triangles with adjacency and d the maximum number of vertices outputted by the shader. Referring back to and suppose shader A includes a shader header as well as executable code. In one implementation the shader header is of the same fixed size for all shaders in generic MPipe and pointer points to a program header for shader A and with the executable code of shader A residing a fixed offset from pointer . Alternatively the shader header of Shader A includes a pointer or a relative offset to the executable code of shader A . Yet in another implementation MPipe table shown in contains separate pointers to the shader header and the executable code for the shaders. In addition the shader header can be configured via commands and stored as part of the entries in MPipe table .

To traverse through while accommodating potentially different types of shaders in generic MPipe is a conceptual diagram of a packet format suitable for the MPipe according to one embodiment of the invention. Specifically the packet of work corresponds to an Inter Stage Buffer Element ISBE which includes a vertex packet and a primitive packet . Vertex packet contains attribute information such as color and position information for multiple vertices. Primitive packet contains topology information such as indices of a primitive pointing to a set of the vertices specified in vertex packet . Because each shader in generic MPipe defines its expected input data and output data ISBE traversing through the MPipe may change as each shader acts on it. For example a vertex shader can modify vertex packet and a geometry shader can modify both vertex packet and primitive packet . Other types of shaders may even generate multiple output ISBE s each of which is independent of the others.

To illustrate further suppose shader A is a vertex shader and shader A expects to operate on an input primitive of a certain type e.g. triangle and generates an output primitive of the same type e.g. triangle . Here since the topology information is expected to remain the same shader A does not modify ISBE . On the other hand suppose shader B is a geometry shader and shader B expects to operate on an input primitive of a first type e.g. triangle and generates an output primitive of a second type e.g. point . Here since the topology information is expected to change if ISBE flows through shader B then shader B modifies primitive packet of ISBE to reflect the topology change.

The above description illustrates various embodiments of the invention along with examples of how aspects of the invention may be implemented. The above examples embodiments instruction semantics and drawings should not be deemed to be the only embodiments and are presented to illustrate the flexibility and advantages of the invention as defined by the following claims.

