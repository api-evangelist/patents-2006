---

title: Method for allocating shared computing infrastructure for application server-based deployments
abstract: A shared computing infrastructure includes a plurality of computing engines, applications servers, and computing domains. A broker component executes a method for dynamically allocating the computing engines among the computing domains. The allocation method begins with the step of determining an expected number of computing engines to be allocated to each of the computing domains as a function of a predetermined service policy and a predicted demand for the domain While fewer than the expected number of computing engines has been allocated to each domain, the computing domains are sequentially selecting as a function of predetermined domain priorities. Unallocated computing engines are identified, and the unallocated computing engines are allocated to each selected computing domain according to predetermined selection rules for the domain. During an allocation improvement step, allocations among the computing domains are further adjusted to maximize a fitness statistic computed for the allocations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07584281&OS=07584281&RS=07584281
owner: DataSynapse, Inc.
number: 07584281
owner_city: New York
owner_country: US
publication_date: 20060714
---
The present application is a continuation in part of U.S. patent application Ser. No. 11 395 586 which was filed on Mar. 30 2006 and claims the benefit under 35 U.S.C. 119 e of U.S. Provisional Application No. 60 688 418 filed on Jun. 7 2005. Each of U.S. patent application Ser. No. 11 395 586 and U.S. Provisional Application No. 60 688 418 is hereby incorporated by reference in its entirety.

The present invention is directed to a method for dynamically allocating shared computing resources in a distributed computing environment. More specifically the present invention is directed to a method for dynamically allocating shared computing resources among a plurality of computing domains that host a plurality of software applications running in a plurality of run time environments by means of a rules based allocation policy.

The global marketplace is forcing companies to respond quickly to dynamic market conditions while reducing costs. Businesses increasingly must have the ability to meet or beat competitors by introducing new and innovative products and services. These new offerings are often customer facing and transaction oriented and introduce additional complexity and higher levels of volatility for the enterprise computing resources called upon to provision these products and services. Higher transaction volumes and demands for improved response times create an ever increasing need for computing resources.

In a conventional enterprise computing environment computing resources are usually manually assigned and provisioned to support various applications. This approach creates several problems. As the assigned resources are generally fixed at a point in time to meet a current demand level the conventional enterprise computing environment is ill equipped to adapt over time to meet increasing demand levels for some applications and decreasing demand levels for others. In order to meet minimum service requirements computing resources are often assigned and provisioned according to peak level demands. As a result during periods of less than peak level demands computing resources are underutilized.

With the advent of grid computing conventional enterprise computing environments have been adapted to virtualize applications so that computing resources may be dynamically provisioned to applications in response to current demand levels. For example the GRIDSERVER Virtual Enterprise Edition adaptive grid infrastructure software available from DataSynapse New York N.Y. provides a computing operating environment that virtualizes application and data services independent of specific system resources. Client applications submit service requests to the grid environment and GRIDSERVER dynamically provisions services on specific system resources in the grid to meet the service requests. For example requests from multiple client applications cause GRIDSERVER to create multiple service instances to handle the requests in parallel on different computing resource nodes in the computing resources grid. As a result underutilization of resources can be substantially reduced and service levels can be commensurately improved.

GRIDSERVER has been particularly effective at providing a virtualized computing environment that adapts to meet resource demands for computing intensive processes. U.S. patent application Ser. No. 11 395 586 upon which the present application is based and which is incorporated by reference herein in its entirety discloses a virtualized computing environment that effectively adapts to meet resource demands for high throughput low latency transactional applications such as distributed web applications and other services based application. The present application is directed to an inventive method by which computing resources in this virtualized computing environment may be dynamically and adaptively provisioned to optimally serve the web and other services based applications.

The present invention is directed to a method for adaptively provisioning a shared computing infrastructure to support a plurality of software applications and a plurality of types of applications servers each providing a run time environment for one or more of the software applications. The shared computing infrastructure includes computing engines assigned to execute instances of the plurality of software applications clients accessing the computing engines to request and receive services from the software applications and a broker that dynamically allocates and provisions computing engines to the clients for executing the software applications.

The broker includes an optimization module that periodically determines an optimal allocation of the computing engines to the software applications and applications servers. To provision resources based on an optimal allocation the broker device also includes a configuration manager for reconfiguring a computing engine by halting a current instance of a software application of a first type and for loading and starting an instance of a software application of a second type.

According to the present invention a method is performed by the optimization module of the broker for allocating the plurality of computing engines among the plurality of computing domains. The method begins with the step of determining an expected number of computing engines to be allocated to each of the plurality of computing domains where the expected number is determined as a function of a predetermined service policy and a predicted demand for the computing domain. Then while one or more of the plurality of computing engines is unallocated and one or more of the plurality of computing domains has been allocated fewer than its expected number of computing resources the method continues by sequentially selecting a next computing domain as a function of predetermined allocation priorities for the computing domains selecting an unallocated computing engine according to engine selection rules for the selected computing domain and allocating the selected computing engine to the selected computing domain.

After the computing engines have been initially assigned to the computing domains the method enters an allocation improvement stage. First a fitness value is calculated for the current allocation of computing engines to computing domains. A first computing domain is identified having fewer than its expected number of allocated computing engines and a computing engine is identified for re allocation to the first computing domain. The identified computing engine may be an unallocated computing engine or may be a computing engine allocated to a second computing domain to which the expected number of computing engines has been fully allocated. After re allocation the fitness value for the allocation of computing engines to computing domains is re calculated. If the re calculated fitness value exceeds the previously calculated fitness value the re allocation is maintained. Otherwise the re allocation is discarded and the computing engine is returned to its previous allocation state. The re allocation process repeats either for a predetermined number of iterations or until no computing domain has fewer than its expected number of allocated computing engines.

The present invention is directed to an application virtualization and provisioning AVP platform that creates a highly adaptive shared computing infrastructure. Within this infrastructure application servers and other service oriented components are hosted and virtualized on shared computing resources and are adaptively provisioned and activated in response to demand. The shared computing resources may be geographically localized or may be distributed over a wide geographic area and managed as a computing grid. See Mark Baker et al. Softw. Pract. Exper. John Wiley Sons Ltd. 2002 which is hereby incorporated by reference.

Application virtualization enables the removal of static host specific configuration dependence from the application environment by using the AVP platform to automatically and adaptively allocate configure start deploy monitor and manage software applications and services. Explicit usage policies are defined that guide provisioning and dynamic allocation of the shared computing resources The configuration of software applications and services is in particular enabled by a broker component of the AVP platform that stores applications servers configurations and software applications in a central repository for deployment to the shared computing resources as required according to the resource allocation and manages the allocation of the shared computing resources based on the usage policies. This component also includes a facility for deploying new application code to the shared computing resources while existing applications are running in the currently allocated configurations.

The AVP platform is directed to managing domains which may comprise an enterprise business application utility service or data source that is allowed a certain percentage of available resources at a specified time based on the usage policy. Domains consist of the artifacts that make up the application service or data source e.g. web archive WAR files making up a web application and may be classified among three domain types service domains data domains and web domains.

Service domains are used to virtualize Java programming objects including plain old Java objects POJOs Spring Beans and Enterprise Java Beans EJBs by turning them into services. These virtualized services may then be accessed by Java clients via dynamic proxies.

Data domains provide data services such as databases or scalable caching services. Data domains may preferably be implemented for example as JBOSS cache and TANGOSOL s COHERENCE cache.

Web domains provide web applications and services such as web servers messaging brokers message driven services and other services that typically require multiple running instances at any given point in time. Web domains include collections of application services that are accessible over the Internet via communications based on the hypertext transfer protocol http .

Domains can be launched or hosted on one or more application servers or containers . Containers are effectively sandboxes for hosting the domains. Each container type is capable of hosting one or more domain type and a given domain can be launched by any container that supports its type. For example a JBOSS container can host web application web service and EJB service domains. Other container types may include but are not necessarily limited to APACHE TOMCAT containers CAUCHO RESIN containers IBM WEBLOGIC containers and other generic containers supported by the AVP platform.

A service level policy or consistent set of rules is applied to dictate the operation and division of computing resources. The service level policy may be defined for example by software application and or by user group and may be conditioned on certain performance requirements including but not necessarily limited to response time throughput and minimum maximum allocation of computing resources percentage of grid . In accordance with the defined service level policy the AVP platform operates to provision and activate services according to demand for improved performance and utilization of resources.

A system level architecture for the AVP platform is illustrated in . The architecture includes four fundamental elements clients engines associated with domains and a broker . Clients and are software applications that access and utilize the domains . Engines are processes that provision and run software applications in the domains . The broker is a software application that carries out policy driven resource allocation e.g. allocation of engines to domains and clients and performance monitoring. Each of the clients engines and broker may be implemented on conventional INTEL and or SUN SPARC hardware platforms running for example WIDOWS WINDOWS SERVER SOLARIS RED HAT Linux or RED HAT Enterprise Linux operating systems

As illustrated in clients and engines both interact with the broker . The broker assigns engines to domains and provides information for example to JAVA clients that instructs the clients how to access to the engines . Thereafter JAVA clients are able to submit service requests directly to the connected engines . Http clients submit service requests via a router Vgateway which acts as a virtual gateway and load balancer for directing the service requests to engines running web service or web application domains.

Broker also configures a daemon that runs on each host computer in each grid node that monitors the host manages the engines that are running on the host and deploys binary code provided by the broker for running a container or applications server and or an application service or data source to be run by the container . In addition broker collects performance statistics provided by the engines and or by clients and Vgateway for storage in a database for reporting and or as inputs to the allocation optimization. Broker may also provide failover services for reallocating an application service or data source from a failed host computer to an operating host computer.

AVP platform of B and C further includes an administrative interface not shown of the broker that enables a platform administrator to define register and deploy domains to manage workloads and to configure the AVP platform environment. By way of example illustrates a broker web page of the administrative interface that provides access to a variety of wizards available for creating data web and service domains and for establishing policy.

In addition the administrative interface allows the platform administrator to monitor and manage various performance metrics including but not necessarily limited to throughput latency resource usage and exceptions. For example illustrates a dashboard page of the administrative interface that provides a pie chart indicating a current allocation of resources among domains and illustrates a broker monitor page of the administrative interface that graphs the allocation of resources among domains over time.

As illustrated in the AVP platform is directed to manage three types of domains service domains web domains and data domains .

Web domains provide web applications and services for example including web servers messaging brokers message driven services and other services that typically require multiple running instances. Web domains represent any collection of application services that are accessible via http and can effectively represent any object or process that can be started stopped and interrogated for its current load. Types of web domains include web applications accessible via a browser and web services made available via simple object access protocol SOAP over http.

Web domains are preferably targeted for J2EE application servers. For example an existing J2EE application may be represented as a web service with an application cluster size varying between 2 and 5 nodes base on policy. The physical locations of the web domain instances are decided by the AVP platform at runtime and the resources are provisioned dynamically. The AVP platform then instantiates each domain on one or more grid nodes The policy that dictates how many instances are created and at what time they are created are dictated by a service level policy that is maintained by the broker .

As illustrated in web clients may preferably access web domains via a virtual gateway router Vgateway . VGateway is preferably implemented as part of the broker and functions essentially as a smart load balancer routing web service requests and responses from external clients to resource virtualized engines. Unlike conventional static load balancers Vgateway is informed when the configuration of host computers and or domains changes and adjusts its load balancing scheme accordingly.

Service Domains Service domains include a collection of interfaces that can be virtualized across distributed computing resources grid resources . By grouping these resources within a service domain specific policies can be set to determine how many resources each service domain will be allowed to consume. JAVA based service domains may be defined for example using J2EE plain old JAVA objects POJOs or the Spring framework

Service domains may be used for example to define any standard JAVA class or Enterprise Java Bean EJB . No proprietary application programming interface API or class format is required to virtualize the associated Java service. For example POJOs can be defined with application context or the complete and necessary environment for making the associated Java object instance work correctly. For example a JAVA class that represents a business service would be defined with access to database connections and messaging services in order to perform the required processing. Preferably a simple Extensible Markup Language XML format is provided for declaring the proper context for each object.

Among supported service domain types the POJO domain type is the simplest to construct. Any JAVA class can be included in a POJO service domain. In addition a Spring service domain type may preferably be supported. See Rod Johnson May. 2005 available at www.theserverside.com articles article.tss l SpringFramework which is hereby incorporated by reference. The Spring framework simplifies J2EE development by using POJOs instead of EJBs and allowing for the abstraction and encapsulation of implementation dependent components for example Hibernate and JDBC mapping tools . In addition this framework allows for dynamic proxy based aspect oriented programming AOP . AOP is a programming facility that allows developers the ability to inject logging transaction security and transaction capabilities across modules and components. The Spring framework also uses AOP to provided declarative transaction management for POJOs. For legacy components that are packaged as EJBs an EJB service domain allows for virtualized access to EJB functionality.

Data domains of provide data services such as databases or scalable caching services. These services are essentially clientless as no gateway or proxy to the services in provided via the broker. Instead the AVP platform may provide a centralized lookup for example such as a Java Naming and Directory Interface JNDI that allows clients to discover and connect to these domains.

According to the principles of the present invention domains are launched or hosted on one or more applications servers or containers. Each container type is capable of hosting one or more domain types and a given domain can be launched by any container that supports its type. provides an exemplary listing of container types supported by a domain wizard of the administrative interface. For example a JBOSS container can support web application web service and EJB service domains. Other container types include but are not limited to APACHE TOMCAT containers CAUCHO RESIN containers IBM WEBLOGIC containers and other generic containers supported by the AVP platform. The administrative interface preferably includes a container software development kit SDK enabling the addition of additional container types as required.

Domains may be created for example by means of a domain wizard within the administrative interface. illustrates an exemplary web page of the domain wizard for creating or editing a web application domain that deploys a specified web application. As illustrated in the web application domain may be newly created or modified by selecting and specifying an appropriate container and by specifying domain settings associated archive files for example JAVA archive JAR Enterprise archive EAR or web archive WAR files servlets and Enterprise JAVABEANS EJBs . In addition tracked statistics for associated service level policies may be specified. For web applications and web services URL patterns to be used by the Vgateway of may also be specified.

The broker of is configured with a service level policy that provides a consistent set of rules for the assignment and allocation of computing resources from the resource grid. This policy enables the broker to select a resource allocation among the domains. In the absence of this policy the broker may operate to assign an equal percentage of grid resources to each of the domains.

The service level policy defines a hierarchical constraint based division of computing resources in the grid. For example a first level of partitioning may be by domain followed by a second level of partitioning by user group. Additional and or alternate partitioning criteria may be arbitrarily selected for example partitioning by work project all of which are fully contemplated within the scope of the present invention.

The service level policy will generally define a minimum number and a maximum engines that should be allocated for each domain either in terms of a number of engines or a percentage of available engines. A minimum allocation percent specifies a least amount of resource always held by an associated domain. If no clients are running in a domain the rule may be excepted in order to make resources available to other grid clients i.e. the minimum allocation percent is set to zero so that no resources are assigned unless no other clients are running in other domains . However these resources are relinquished as soon as a non running client starts up in the affected domain. If the minimum allocation percents for grid clients do not sum to 100 and all types of grid clients are active the broker may continuously redistribute resources to optimize service level agreements SLAs for the grid clients or domain.

A maximum allocation percent specifies a cap on the amount of resources to be given to an associated domain. This maximum is preferably enforced even if idle resources are available. As illustrated in the administrative interface preferably provides an editor for editing the minimum and maximum engine allocations for domains. In addition as shown in the editor provides a means for specifying a priority ranking for each domain that is used by the broker for deciding a sequence in which unallocated resources are allocated among the domains.

Additional rules may further limit or change the engine allocations performed by the broker. For example rules nay be administered through the administrative interface of the broker to limit which engines may be assigned to individual domains. The engines may be limited for example according to engine identifier engine configuration engine memory characteristics e.g. amount of free memory number of central processing units CPUs supported by the engine and engine operating system OS .

Allocation of engines may also be influenced by service level agreements SLAs . SLA targets may be set through the administrative interface to provide a means for changing engine allocation based on the performance of domain. For example if a domain requires a particular level of network throughput an associated SLA target can be attached to the domain and monitored. If throughput falls below the target level allocation of engines to the domain can change according to associated rules. These additional rules may also include assigned priorities which will essentially dictate the order in which the rules are processed.

When an engine fails to meet a target threshold for a rule the broker may perform an additional statistical analysis to determine whether a reallocation is warranted. For example the broker may calculate a normalized variance of the performance of all engines in an associated domain for example a normalized geometric variance of a performance statistic calculated as the ratio of the geometric mean to the arithmetic mean . In the case of the normalized geometric variance a value close to 1.0 indicates little variance in performance among the engines in the domain providing strong evidence of the need for additional computing resources. Conversely a value near 0.0 indicates a wide variance and lack of balance in performance among the engines. In this case instead of immediately reassigning resources the broker waits to see if balance is achieved and thereby if underutilized resources enable thresholds to be met without further allocation of resources.

The broker may in addition apply a policy schedule that indicates how policies are to be change over the course of a day. As illustrated for example in the grid resources assigned to a domain for an application varies with time. Domain at 8 15 AM is allocated four computing engines from the grid. At 8 30 AM the number of allocated engines in domain is reduced to three engines . At 8 45 AM the number of engines allocated to domain is increased to five engines .

Once the minimum and maximum number of engines is established the broker proceeds to provision resources to a minimum level. The broker may choose to allocate more than the minimum number of engines to a domain if there is a statistical rule that can be used to understand the performance of the application. For example if queue size can be measured as an indication of current load on the application a rule can be established for adding an additional engine when the average queue size for all engines in the domain over a specified time interval exceeds a specified level. In addition a rule for relinquishing an engine can be established based on the average queue size falling below a specified level over the specified time period. illustrates a policy wizard web page of the administrative interface that may be used for setting statistical rule based constraints.

The broker allocates engines or application server instances to domains based on a current active policy and current application performance statistics. The broker reevaluates and reapplies this policy periodically for example every 5 minutes and then decides to take one of three courses of action a to make no change in the current allocation b to assign available engines to some domains or c to re assign some engines from some domains to other domains. illustrates an allocation of engines across domains.

As illustrated in each engine in the AVP platform manages a container to host and run a domain. Further as illustrated for example in an engine service instance is managed by an engine daemon both installed on a host computer .

Engines create service instances on demand based on scheduling decisions made by the broker. A service is created with the first client request for an operation having the created service type. After creating and running the requested operation the engine stores the newly created service in a cache. A scheduler is made aware of the contents of the cache such that it will route other requests for that service to the engine.

By default engines operate as single threaded processes engine instances performing only one service operation at a given time. As a result more than one engine instance is generally running at one time on the host computer . Processes running on multiple engine instances are started and managed by an agent that also runs on the host engine daemon .

Engine daemon is capable of starting and stopping engines based on a pre defined engine policy. Engine policies may for example be based on one or more of CPU utilization of the host user activity in the case that the host is a user s desktop or time of day. In most cases the engine daemon starts and monitors engine instances and restarts the engine instances in response to failures or reconfigurations.

One engine daemon runs per host. In addition to starting engine instances the engine daemon preferably controls the configuration of engine instances . For example when changes to an engine configuration are made by a platform administrator for example to configure a new application server the changes may be automatically propagated to an engine instance via the engine daemon . Engine daemons may log into the broker for administration and configuration.

Engine instances are the processes that perform tasks for executing application software in the domain. On multi CPU hosts an engine daemon will be able to run multiple engine instances . In addition more than one engine instance may be run on a single CPU.

Engines report to the broker when they are available to perform work. After logging in and synchronizing resources the engines accept work assignments perform tasks for executing the applications software and notify the broker when results are ready. Because the engine daemon controls the state of configuration for each engine instance and engine configuration can be controlled centrally via the administrative interface of the broker it is easy to control and configure engine instances across the computing resource grid.

Engines can be configured to run in a variety of modes depending upon the type of host machines on which they will be installed. Dedicated machines are configure to run continuously and are best suited for computing resources devoted to full time processing on the grid. A non dedicated mode may be enabled for host machines that are only used on a part time basis on the grid and otherwise used for other purposes for example user PCs sometimes made unavailable to the grid for user process use .

Engines configured in the non dedicated mode determine when to run based on two different modes. In the user interface UI idle mode a non dedicated engine will start running after user inactivity on the host machine. Alternatively in CPU idle mode the engine will start to run when CPU utilization is sufficiently low. Engines are installed only once on a host machine. As engines are centrally managed by an engine daemon they can be easily upgraded when later versions to the AVP platform are available by using the administrative interface. In addition to gain additional efficiencies configuration profiles may be created by the administrative interface which may be used by multiple host machines to synchronize configurations.

At step a client having received information relating to the engine instance and its associated domain from the broker connects to the engine instance to run a service. At step when the service has completed the engine instance establishes another connection to the broker to indicate that it has completed the service and to request another assignment.

At step if the engine instance is interrupted or otherwise fails gracefully it connects to the broker to send a message indicating that it has logged out. Otherwise if the engine instance fails unexpectedly an engine monitor of the broker will log the engine instance off. In either case if available the broker will provision anther engine instance to the associated domain to replace the failed instance.

As illustrated in requests for access to service domains may be forwarded to the broker by Java clients . The clients for example may make a request to invoke a method for processing in a service domain using simple application programming interface API access. In the case of web domains a web client for example a web browser or other http client may access a web application or web service via Vgateway . In this case the client simply opens a uniform resource locator URL that is directed to Vgateway and configured to run the selected application virtualized on a web domain.

As illustrated for example in a client synchronously invokes a method for processing in a service domain by sending an invocation message including service method call information and a wait lock to a corresponding service domain . The service domain adds the message to an invocation queue . A thread running on the engine is then blocked by the service domain using the wait lock. The process for asynchronous invocation is similar except a result listener message is sent in the invocation message indicating that a listening process will be created by the client and wait until the engine indicates that the task has been completed.

Communications between the engine and the client are managed by an engine proxy . As illustrated in the engine proxy creates a new thread for each thread that has been started on the engine . With these threads the proxy continuously asks for a next invocation process. The threads will block if the queue is empty. If the proxy fails to process an invocation it notifies the queue manager which places the unprocessed invocation back in the queue .

Each client has a performance monitor not shown for monitoring call requests and keeping statistics on recent history. Request statistics monitored by the client preferably include but are not necessarily limited to total response time time in the queue time in transport and time in user code i.e. direct application or service processing time . The client monitor calculates average statistics for each of the measured statistics as well as average throughput. The average statistics are periodically sent by the client to the broker as further described herein.

The broker provides policy driven resource allocation and monitoring for the AVP platform . Specific broker tasks include message routing and client authentication engine allocation engine provisioning and resource management performance monitoring and application and application server code distribution. Engines and clients are able to log in to the broker in support of these tasks.

The broker provisions engines according to the service policy based on the operational mode of the broker allocation policies and client activity. Schemas include broker initiated provisioning and client initiated provisioning. Broker based provisioning is useful for controlling engine allocation across domains and is required to enable engine sharing.

As illustrated in broker based provisioning begins with a service domain specific request transmitted by a client to the broker . In response the broker provides the client with an engine proxy that is already assigned to a specific service domain. With broker based provisioning a client may not directly ask the engine to change the assigned domain.

Two kinds of engine allocation are supported by broker based provisioning. With exclusive allocation as illustrated in engines are assigned with the delivery of associated engine proxies to clients such that each engine provisioned in a domain is assigned to perform work for exactly one client . With shared allocation as illustrated in two or more clients may respectively use shared engine proxies to send requests to the same engine in domain .

As illustrated in under the client initiated provisioning schema clients receive blank slate engine proxies and are able to provision them with service domains of their choice. A service domain independent request is first transmitted by the client to the broker . In response the broker provides the client with unassigned proxy allowing the client to activate a service domain of its choice via engine . Under this schema no sharing of engines is possible.

The broker performs a number of additional functions on behalf of the AVP platform . For example the broker configures and stores a variety of operational settings and parameters including but not necessarily limited to user identification passwords client information routing properties and engine configuration. Using this stored data for example associated tasks may be carried out by platform administrators via the administrative interface of the broker .

An internal database of the broker stores reporting data including for example user engine client and broker information and an external reporting database is used to log events and performance statistics. Associated database configurations may be managed by platform administrators via the administrative interface.

Domain resources are staged on the broker for deployment to engines. For example files may be uploaded to deploy service web and data domains using the domain wizard component of the administrative interface as illustrated in . Domains can be deployed at the time of uploading or can be deployed or undeployed at a later time.

The broker carries out a performance monitoring function with the assistance of the clients and engines . schematically illustrates how the this function is performed.

At regular intervals the broker asks at least one of each client and engine associated with service and web domains preferably at least each engine to collect and forward averaged performance statistics. The information is collected and forwarded by at least one of a statistics collector of the client and a statistics collector of the engine to the statistics manager of the broker . This process may for example be facilitated by means of a JMx proxy for clients and engines running J2EE applications.

The statistics manager places the forwarded information in client and engine statistics queues of . Periodically for example hourly statistics persister consolidates the collected data by averaging the accumulated data for each client and engine calculating statistics for the entire computing resource grid and storing the calculated statistics in grid usage statistics database . Additional averaging and archiving is preferably performed periodically on the database to further consolidate the data. The accumulated data in the database may be displayed on a reporting screen via the AVP platform administrative interface.

A sample list of statistics tracked is provided in . Statistics used will vary according to application. For example load on a JAVA application serve may be assessed by statistics such as queue depth service throughput or thread count rather than user response time.

With frequent collection of statistics from each client and engine large amounts of statistical data accumulate. Accordingly at frequent intervals the broker operates to average the data collected for each client and engine to calculate statistics for the entire grid and to save the resulting records in the broker databases. Archiving may be performed after successive intervals using similar averaging methods.

The collected statistics may be viewed in a variety of ways via tracking tools in the administrative interface of the broker . As illustrated in for example the administrative interface may include a dashboard for displaying a variety of statistical data in summary form. The dashboard may provide for example pie charts indicating domain and group allocations of engines measured statistics for the clients and engines and platform alerts generated according to a comparison of the measured statistics to service level agreements SLAs defined in the service level policies. In addition the dashboard may provide links for viewing domains wizards for configuring various components of the platform and links to other frequently used pages of the administrative interface.

For example as illustrated in a web page of the administrative interface illustrates a thread count over time for a selected engine.

At step the resources are provisioned according to the policy. Engines are assigned to domains by the broker and configured by downloading and installing associated application server and application software in the engines. Once configured engine instances are also started in response to the receipt of service requests and stopped upon task completion.

At step the broker periodically collects averaged performance statistics from one or more of the clients and the engines and compares the averaged statistics with SLAs defined in service level policies. The statistics may provide for example measures of throughput response time CPU occupancy memory occupancy and other attributes that may preferably be defined as JMX attributes. The policy is then again re applied at step and the resources are re allocated at step . In addition at step alerts indicating violation of the SLAs may preferably be reported to administrators via a dashboard of the administrative interface of the broker .

The reallocation step is further described in an exemplary manner with reference to . In reallocation process begins at step with the creation of an empty resource allocation map. The resource allocation map is a data structure which is used for example by the broker for recording assignments of resources e.g. computing engines to resource users e.g. domains during the reallocation process . At step the broker determines a number of expected or desired resource for each domain based on a predetermined policy for the domain SLAs for the domain and current performance statistics reported to the broker by one or more of engines and clients assigned to the domain . The predetermined policy for the domain for example may specify a minimum and maximum number of engines to be assigned to the domain a priority for the domain and other associated rules. The other rules may constrain the types of engines that may be assigned to the domain for example according to type of operating system and further specify rules pertaining to the SLAs.

Once the expected number of resources for each domain is determined at step and recorded in the allocation map the reallocation process proceeds at step to prepare a set of resource assignments assigning specific computing engines to domains . Assignments of computing engines to domains are made in an order reflective of the priorities specified for the domains and are then recorded in the allocation map.

At step a current fitness value is calculated for each assignment of computing engines to a domain and by means of one or more conventional constraint programming methods the assignments made at step are adjusted fitness values are recalculated for the adjusted assignments and the adjusted assignments are maintained and recorded in the allocation map when the fitness values for the adjusted assignments improve over the fitness values for the assignments made at step .

At step based on the assignment information currently in the allocation map the broker proceeds to release and re acquire computing engines that are to be reassigned to among the domains in order to provision the computing engines to the domains . At step after a predetermined time period for example in the range of three to five seconds the reallocation process resumes at step by preparing an empty allocation map to be used in the subsequent reallocation steps.

At step a current demand is computed for each domain for example as a function of SLAs defined in the policy for the domain and performance statistics collected for the domain see Policy and Resource Allocation supra . If there is a positive demand i.e. the statistics indicate that performance falls below the thresholds established by the SLAs and the demand exhibits stability i.e. as may be indicated according to a normalized variance in demand among engines currently assigned to the domain the expected number of engines is increased. For example where a stable positive demand is indicated the expected number of engines may be increased by a fixed number i.e. by one engine . At step the expected number of engines is finally set to be the lesser of a the expected number of engines as may have been increased due to demand and b the maximum number of engines which has been set according to the domain policy . This final expected number of engines is recorded in the allocation map at step . A pseudocode representation of the process at step is illustrated in and a pseudocode representation of the process at steps is illustrated in .

At step for each identified domain a selection rule is determined. For example the selection rule may only allow selecting the engine that is currently assigned to a particular allocation map entry for the domain same entry selection . Alternatively the selection rule may allow the selection of an engine that is already assigned to the domain same domain selection may allow the selection of an engine so along as it is not required by another domain rule selection or may allow the selection of any available engine always selection . Based on the policy for the identified domain a single selection rule may be identified for the domain or more than one selection rule may be selected in a predefined sequence.

At step it is determined whether an unassigned engine is available for the identified domain that meets the current selection rule. If so the available engine is assigned to the identified domain at step . If no eligible engine is available the process proceeds to step to determine whether the selection round has been completed. If not completed the process returns t step to identify a next domain in the selection sequence that is looking for an available unassigned computing engine . Once the current selection round is completed the process returns to step to decrement the priority i. At step if it is determined that i is zero the process terminates at step . Otherwise the process begins a next selection round.

At step a number of iterations N is selected for carrying out the improvement process of step . Alternatively the process may continue until a performance objective is reached for example reaching no more than M unsatisfied entries in the allocation map .

At step a domain having an unsatisfied allocation table entry is identified. This may be accomplished by selecting entries in the table in a pre established order by random selection or by some other scheme for example as a function of fitness for the entry time since the entry was last selected and the like . Once the unsatisfied allocation table entry is identified an engine that is not currently assigned to the identified allocation table entry is identified and selected at step and is assigned to the allocation table entry at step . The engine assigned to the allocation table entry may preferably be selected from a set of unassigned engines or alternatively be selected to be reassigned from another allocation table entry for example having an allocation of engines that currently satisfies its expected number of allocations. In the latter case a conventional constraint programming based method may preferably be employed to efficiently identify engines for re allocation.

At step the fitness value for the allocation table is recomputed in view of the reassigned engine . At step it is determined whether or not the recomputed fitness value is greater than the current fitness value. If the recomputed value is greater at step the reassignment of engine is maintained the fitness value is set equal to the recomputed fitness value N is decremented by 1 and the process returns to step to determine whether N is greater than 0. If the recomputed fitness value is less than or equal to the current fitness value at step the reassignment of engine is discarded i.e. the current assignment of engine is maintained N is decremented by 1 and the process returns to step to determine whether N is greater than 0. At step if N is equal to zero the process terminates at step . presents a pseudocode representation for a preferred method for the process at step .

Thus while there have been shown described and pointed out fundamental novel features of the invention as applied to a preferred embodiment thereof it will be understood that various omissions substitutions and changes in the form and details of the devices illustrated and in their operation may be made by those skilled in the art without departing from the spirit and scope of the invention. For example it is expressly intended that all combinations of those elements and or steps which perform substantially the same function in substantially the same way to achieve the same results are within the scope of the invention. Substitutions of elements from one described embodiment to another are also fully intended and contemplated. It is also to be understood that the drawings are not necessarily drawn to scale but that they are merely conceptual in nature. It is the intention therefore to be limited only as indicated by the scope of the claims appended hereto.

All references publications pending and issued patents are herein each incorporated by reference in their entirety.

