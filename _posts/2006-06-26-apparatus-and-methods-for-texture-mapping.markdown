---

title: Apparatus and methods for texture mapping
abstract: The invention provides texture mapping techniques that facilitate interactive painting of a three-dimensional virtual surface by a user in object space, without requiring global parameterization. The texture mapping techniques feature rendering texture for a given virtual object using a plurality of composite textures, each formed by blending collapsible texture layers. Texture coordinates in texture space are derived using information determined at the time of surface mesh generation. The invention features dynamic texture allocation and deallocation, allowing a user to interactively modify the shape of a painted, three-dimensional model. Finally, the invention features an architecture for combined graphical rendering and haptic rendering of a virtual object, allowing a user to experience force feedback during the painting of the object in object space.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07400331&OS=07400331&RS=07400331
owner: SensAble Technologies, Inc.
number: 07400331
owner_city: Woburn
owner_country: US
publication_date: 20060626
---
This application is a divisional application of U.S. patent application Ser. No. 10 697 548 filed on Oct. 30 2003 and issued on Aug. 22 2006 as U.S. Pat. No. 7 095 418 which is related to commonly owned U.S. patent application Ser. No. 10 697 174 filed on Oct. 30 2003 each of which is hereby incorporated by reference in its entirety.

This invention relates generally to graphical rendering. More particularly in certain embodiments the invention relates to texture mapping techniques for the graphical rendering of a virtual object.

Certain computer graphics applications graphically render the surface of a three dimensional virtual object. The surface of a three dimensional virtual object is generally represented as a mesh of polygonal surface elements for example triangles. Attributes such as color intensity are assigned to surface elements of the virtual object which are then displayed to the user.

The resolution of the surface mesh is typically chosen according to the three dimensional complexity of the object. For example rendering a virtual object having a complex geometry may require a tight mesh of many small surface elements whereas rendering a virtual object of simpler shape may be performed with a looser mesh of fewer larger surface elements.

It is typically not possible to achieve sufficient realism by assigning color values to vertices of each surface element particularly if the surface elements are large. This problem may be overcome by representing three dimensional surface properties of the object using a texture in two dimensional space. Texture mapping permits improved resolution of surface properties such as color values within each surface element and allows certain operations to be performed on the three dimensional object as if it were flat.

Mapping methods are used to relate points on the surface of a three dimensional virtual object to corresponding points of a two dimensional surface. For example mapping methods can be used to relate points on the surface of a three dimensional sphere such as the Earth to corresponding points of a two dimensional map. Certain graphics applications perform texture mapping for a three dimensional virtual object by establishing a global parameterization that links every surface element in the three dimensional object space to an element in two dimensional texture space. The mapping process may not be automatic and may require manual input from the user. A goal of these mapping schemes is to produce a coherent two dimensional texture whose elements are arranged in such a way that the distortion of the object surface is acceptably low. For many complex virtual objects this poses a problem that is either computationally difficult or intractable.

Furthermore current graphics applications require a user to paint the surface of a virtual object in two dimensional texture space before applying the texture on the virtual object in three dimensional object space. This results in a less interactive less intuitive experience for the user.

Moreover current methods do not allow a user to modify the shape of the object after its surface has been painted without losing surface data from unmodified portions of the object. This is due in part to the need to re mesh and re parameterize the entire model following any modification of the underlying three dimensional model.

A method of texture painting has recently been introduced to allow texture mapping without global parameterization. M. Foskey et al. ArtNova Touch Enabled 3D Model Design 2002 pp. 119 126 March 2002 .

However there remains a need for mapping methods that allow a user to modify the shape of an object after its surface has been painted without losing the surface data from unmodified portions of the object. There also exists a need for a more efficient graphical rendering method that is able to support the rendering of complex virtual objects while still allowing a user to interactively paint directly onto the object in object space. Furthermore there is a need for a method of blending textures while maintaining the interactivity of painting without creating graphical artifacts.

The invention provides improved methods of graphically rendering virtual objects. More specifically the invention provides improved texture allocation and texture rendering techniques for graphically representing the surface of a three dimensional virtual object.

The improved methods allow a user to paint directly onto the surface of a three dimensional virtual object. The methods also allow a user to interactively modify the shape of a painted three dimensional object without losing surface data from unmodified portions of the model. For example the improved methods permit a user to paint an object then carve portions of the object without losing the painted surface data from unmodified portions of the model. The improved methods also permit a user to easily switch back and forth between a painting mode and a sculpting mode without having to reallocate texture for unmodified portions of the object.

Additionally the invention provides techniques for blending a brush stroke into a surface texture without creating artifacts in the overlapping segments of the stroke and without diminishing the interactivity of the user s painting experience.

Furthermore the invention features improved methods for the combined graphical and haptic rendering of a virtual object thereby permitting a user to experience force feedback via a haptic interface device during the painting of the object in object space. In this way a user can feel the virtual object as the user paints its surface while at the same time the user observes a display of the object in object space.

Texture mapping methods of the invention include texture allocation methods and texture rendering methods. Texture allocation refers to the process of allocating elements in texture space to corresponding surface elements in object space. Texture rendering refers to the process by which data in the texture space is sent to a graphics card and or graphics application for display. Texture rendering also involves sending information to the graphics application that allows the application to correctly relate the texture data to corresponding portions of the surface of the virtual object. Texture rendering methods of the invention are able to interface with any commercially available standard for three dimensional rendering and or three dimensional hardware acceleration including cross platform standards.

In one embodiment the invention provides an improved method for graphically rendering a virtual object by using information produced during mesh generation. In the process of generating a surface mesh for a voxel based virtual object an index is produced for each resulting jack where a jack is a surface containing voxel and a voxel is a volumetric element in object space. Each jack contains a certain configuration of surface elements. There are a finite number of possible configurations of surface elements within each jack and the number of possible configurations depends on the mesh generation scheme employed. The index for each jack corresponds to one of the finite number of surface element configurations. A first lookup table is created by determining a local configuration of texture elements for each of the known set of surface element configurations. The first lookup table is preferably computed prior to object rendering. Thus graphical rendering of a given virtual object proceeds by using the indices for the jacks of the virtual object to generate coordinates of texture elements in texture space corresponding to the surface elements of the virtual object.

Thus in one embodiment the invention provides a method of graphically rendering a virtual object including the steps of 1 using an index corresponding to each of a plurality of jacks of a voxel based virtual object to identify texture elements to which surface elements of the virtual object are mapped and 2 generating texture coordinates in texture space for each of the identified texture elements. The index may be for example a marching cubes index derived from an implementation of a marching cubes algorithm that is used to generate a surface mesh for the virtual object. Alternatively the index may be for example a marching tetrahedra index derived from an implementation of a marching tetrahedra algorithm used to generate a surface mesh for the virtual object.

It is found that dividing the surface of a virtual object into texture regions may overcome hardware limitations in rendering complex virtual objects. Thus in one embodiment the texture space in the graphical rendering method summarized above includes a plurality of texture regions. Moreover in addition to steps 1 and 2 above the rendering method may further include the steps of 3 binding to a graphics application a blended texture corresponding to one of the plurality of texture regions and 4 transmitting to the graphics application the texture coordinates for each of a plurality of surface elements associated with the blended texture. The blended texture may be a contiguous texture formed by blending together a plurality of texture layers as discussed in more detail hereinbelow.

The index produced for each jack as a result of the mesh generation procedure can be used to create any number of lookup tables. In one embodiment the graphical rendering method includes creating two lookup tables using a first lookup table to determine to which of a plurality of texture elements a given surface element is mapped and or using a second lookup table to determine to which of a plurality of positions within a texture element a given surface element is mapped. For example where either zero one or two triangular surface elements in object space are mapped to a quadrilateral texture element in texture space a first lookup table is used to determine to which quadrilateral a given triangle is mapped and the second lookup table is used to determine to which of two positions within the quadrilateral the triangle is mapped. More lookup tables may be used in more complex embodiments for example where all of the surface elements of a given jack are mapped to a single texture element.

The invention also includes methods of dynamic texture allocation and deallocation allowing a user to interactively modify the shape of a painted three dimensional model without losing texture data associated with unmodified portions of the object. Thus the invention provides a method of mapping texture onto a virtual object that includes allocating texture for at least one newly created jack of a virtual object following an object modification and or de allocating texture in the texture space for at least one newly eliminated jack of the virtual object following an object modification.

In one embodiment the method proceeds by stepping through contiguous blocks of jacks of the model in render order to determine whether texture allocation is needed therein and by keeping texture corresponding to a given jack block together within the same texture region. This dynamic allocation method provides improved efficiency since new texture is only created for the modified jacks and since there is no global parameterization required. Advantages are achieved by allocating texture in render order and by keeping texture corresponding to a given jack block together within the same texture region. This promotes efficient binding and results in a more efficient texture rendering process. In one embodiment texture is allocated so as to minimize the number of texture binds required during rendering.

The invention also provides for the compact storage of texture information for a virtual object. Since many texture elements may contain a uniform value it is efficient to store this information as a single value instead of storing values for all texels of every texture element. It is not necessary to store a full contiguous texture for a given texture region since the user does not need to see the texture space at any time as all edits may be performed by the user in object space. Accordingly the invention provides a method of creating a blended texture for use in the rendering of a virtual object the method including the step of blending two or more texture layers where at least one of the texture layers is a grid of pointers indicating at least two of i uniform texture elements ii nonuniform texture elements and iii the location of the nearest free texture element in the grid.

A blended texture may be created by combining scratch textures stencil textures and or paint textures associated with one or more brush strokes. A scratch texture indicates one or more intensity values of pixels associated with each brush stroke and a paint texture indicates one or more color values associated with each brush stroke.

The methods of blending texture presented herein are compatible with a method of stenciling in which a user may specify a maximum amount by which selected portions of an image are allowed to change over the course of a series of brush strokes. A first type of stencil texture indicates a level of protection to apply to a given region of an image and a second type of stencil texture contains brush strokes that are accumulated and are modified according to the protection levels of the first type of stencil texture prior to blending into the image.

Methods of the invention include blending texture layers of at least two of the three types listed above scratch texture layers paint texture layers and stencil texture layers in the order in which the brush strokes are performed. Enhanced interactivity is achieved since texture data is blended into the image pixel by pixel in discrete time slices without interrupting the user s application of brush strokes. Additional model complexity can be handled since texture layers are blended into composite textures for only those texture regions affected by the brush strokes. Furthermore one embodiment stores the texture layers in a collapsed form that includes both uniform and nonuniform texture elements and then combines them to form a contiguous blended texture suitable for binding to a graphics application.

By combining the various texture allocation texture rendering and texture blending methods disclosed herein the invention provides a complete graphics application feature that allows a user to paint directly on the surface of a virtual object in object space. Accordingly the invention provides a method of interactively representing application by a user of at least one brush stroke directly onto a virtual object in object space the method comprising the steps of a allocating a plurality of texture elements in two dimensional texture space for a plurality of jacks of a virtual object b graphically rendering the allocated texture in real time as a user applies at least one brush stroke onto the virtual object wherein rendering includes creating at least one blended texture for binding to a graphics application and c updating the blended textures according to the at least one brush stroke applied by the user wherein the method involves one or more of the following i using an index corresponding to each of a plurality of jacks of the virtual object to identify texture elements to which surface elements of the virtual object are mapped ii dynamically allocating texture in the texture space and iii blending a set of texture layers corresponding to a first of a plurality of texture regions in the texture space and binding the blended texture to the graphics application during rendering of the first texture region.

Finally the invention features an architecture for combined graphical rendering and haptic rendering of a virtual object allowing a user to experience force feedback during the painting of the object in object space.

The invention provides improved methods of graphically rendering the surface of a three dimensional virtual object. The invention relates to a method of texture mapping that allows a user to switch between a paint mode and a sculpt mode without losing data. The method also provides for accurate and efficient rendering without requiring global parameterization.

Texture mapping is a process by which points on the surface of a three dimensional virtual object are related to points on a two dimensional surface. Texture mapping allows certain operations to be performed on the three dimensional object as if it were flat. The three dimensional virtual object is generally represented in object space for example as a system of elements and or points in a Cartesian x y z coordinate system. The surface elements of the object are mapped to texture elements in two dimensional texture space. The texture is then rendered by relating texels or pixels in texture space to corresponding points in object space and displaying them to a user. Additional effects such as lighting shadowing manipulation of orientation and or size animation and other effects may be performed once the surface of the object is initially rendered.

Because embodiments of the invention allow a user to paint directly on the object in object space the texture space need not be coherent. There is no need to display the texture space to the user. Accordingly mapping methods of the invention do not require global UV parameterization.

Texture mapping includes texture allocation and texture rendering. Texture allocation refers to the process of allocating elements in texture space to corresponding elements in object space.

The method of proceeds by stepping through jacks in the object space in the order in which the object is rendered. Texture rendering and rendering order is discussed in more detail hereinbelow. Texture allocation proceeds from jack to jack in render order by allocating texture elements for the surface elements in the jack.

Texture allocation proceeds such that a plurality of texture regions are defined for the virtual object being rendered. The organization of allocated texture into texture regions is important in the rendering methods described herein since it allows binding and rendering texture from one texture region at the time providing faster more efficient rendering of complex virtual objects. illustrates the partitioning of texture elements for example references and associated with a three dimensional virtual object into texture regions. Although later figures portray texture regions as boxes that divide up the virtual object into neat segments as seen at reference a texture region is not necessarily so neatly partitioned since its extent is based on how texture is allocated to the jacks in render order. For example texture regions may divide up the virtual object roughly into the portions indicated at references and .

Furthermore jacks may be organized into jack blocks. For example a jack block may be an 8 8 8 contiguous block of voxels although any other number or configuration of voxels may be used. The voxels within a given jack block may or may not include surface containing voxels jacks . illustrates a volume in object space encompassing the jack blocks that contain all the object surface elements that are mapped to a given texture region. One of the jack blocks is shown at reference . The surface of the virtual object that intersects the volume is shown at reference . The jack block at reference contains 8 8 8 512 voxels. A single jack is shown at reference . Jack contains three object surface elements .

The allocation method produces a list for example the Texture Mapper depicted in the system architecture of and . The list provides a map identifying texture elements corresponding to the jacks of the virtual object. The list may be a hash map identifying each texture element corresponding to surfaces in each of a plurality of jacks. More preferably the list is a hash map of hash maps identifying each texture element corresponding to surface s in each jack of each jack block. The Texture Mapper stores all the texture element identifiers owned by a particular jack. For example illustrates a hash map of hash maps identifying each texture element Q Q Q Q within a given texture region TR where each texture element is mapped to a jack Local Jack within a jack block Block .

The texture allocation method of begins by considering the first jack of the first jack block of the virtual object in render order and determining in step whether texture has been allocated for this jack. If not step directs that a first texture region be created if none currently exist or alternatively proceeds to the current texture region. Step determines whether there is enough space in the current texture region to contain the surface elements in the current jack. The computation in step may involve requiring a margin of extra texture elements in each texture region to accommodate possible surface expansion in a jack block due to edits that change the amount of surface of the virtual object in a given jack block.

If there is enough space in the current texture region for the current jack step of directs that a sufficient number of texture elements needed for the current jack be allocated. In an embodiment where texture elements are quadrilaterals quads and surface elements are triangles step may involve pairing surface elements that share a common edge and mapping each pair to an available quad. If there is not enough space in the current texture region for the current jack step of directs that a new texture region be created and that all texture elements corresponding to jacks within the current jack block be moved into the new texture region. Thus in this instance the entire jack block s texture elements are moved as a unit to a new texture region where more texture elements are available. Then entries for the transferred texture elements are updated in the Texture Mapper accordingly.

Step of proceeds if texture has previously been allocated for the current jack or alternatively following the allocation of texture for the current jack in step . Step determines whether the current jack is the last jack in the current jack block. If not step proceeds to the next jack in the current jack block and the allocation process starts again at step with the new jack. If the current jack is the last jack in the current jack block step determines if there is a jack block remaining. If no jack block remains the allocation process is complete. If there is a jack block remaining step proceeds to the first jack of the next jack block and the process starts again at step with the new jack.

Texture allocation methods of the invention support dynamic texture allocation and deallocation that is the creation and or elimination of texture elements corresponding to edited portions of the object without affecting texture previously allocated for texture elements corresponding to unedited portions of the object. In this way the invention supports a quick transition from a sculpting mode or other object editing mode to a painting mode or other surface editing mode and vice versa. The allocation method of allocates new texture elements when new jacks are created as a result of object edits. The allocation method deallocates frees erases texture elements when their associated jacks are destroyed. When the surface within a voxel changes for example due to surface based editing such as tugging or any operation involving rasterization a slightly modified method is performed. First texture previously allocated to the edited jack is preserved by caching it then the old texture is deallocated while the new texture is reallocated according to the method of . Finally the cached texture is resampled into the new texture where the surface elements have not changed significantly.

In addition to texture allocation texture mapping involves the process of texture rendering. While texture allocation need only be performed if texture has not yet been allocated for a given virtual object or when there has been a change that affects the amount of surface of the virtual object texture rendering is performed once for every frame that is graphically rendered. For example texture rendering may take place up to about 30 times per second or more depending on the complexity of the virtual object being rendered and the capability of the computer system and graphics application used. Texture rendering involves sending data representing the contents of each texture element to a graphics rendering interface such as a graphics card and or graphics application. Thus the texture rendering methods of the invention may optionally include using a commercially available platform for graphical rendering and hardware acceleration. Moreover the texture rendering methods of the invention may optionally include the use of a commercially available graphics application programming interface. Along with sending data representing the contents of each texture element texture rendering methods of the invention send texture coordinates to the graphics rendering interface application in order to correctly relate the texture data to corresponding portions of the surface of the virtual object.

Steps and of show the order in which texture space coordinates are determined for elements within a given texture region. Step is performed for each jack of the current jack block then for each jack of the next jack block within the current texture region. The process continues until step determines that the last jack of the last jack block in the current texture region has been reached. Then step determines whether the current texture region is the last region allocated for the virtual object. If so the rendering process has completed its cycle. If not step indicates that the process returns to step with the blended composite texture for the next texture region. The method proceeds until all jacks have been rendered.

In another embodiment the method of texture rendering proceeds jack block by jack block irrespective of texture regions. Here unlike the method shown in jack blocks are not rendered in an order according to the texture region in which they lie. As rendering proceeds from jack block to jack block the texture region in which the current jack block lies is first bound to the graphics application before texture space coordinates are determined for surface elements in each jack of the current jack block. A single texture region may be bound multiple times depending on the jack block render order. The render order may be adjusted to reduce the number of texture region bindings required.

The method illustrated in proceeds by using the Texture Mapper to determine the identification of all texture elements that are mapped to surface elements within a given jack. This is performed for each jack of the virtual model according to the method illustrated in and as indicated at reference of . For example the jack in contains three surface elements labeled Tri Tri and Tri that have been allocated two texture elements here quadrilaterals or quads labeled and in the current texture region. The texture elements were allocated according to the texture allocation method illustrated in .

The rendering method of proceeds by performing steps 2 3 and 4 for each surface element within the current jack as indicated by reference . Step 2 uses the first lookup table to determine in which texture element the current surface element is mapped step 3 uses the second lookup table to determine to which position within the texture element the current surface element is mapped and step 4 determines texture coordinates within the current blended composite texture to which the current surface element is mapped.

The results of the method of can be seen in . Since Tri and Tri share a common edge they are paired into a single quad Quad of 2 in which is Quad of the current texture region. Tri shares a common edge with Tri but since Tri is already paired with Tri Tri is allocated its own texture element Quad of 2 in which is Quad of the current texture region.

More sophisticated surface element to texture element mapping schemes are possible. For example in one embodiment where there are a finite number of surface element configurations within a jack that are created during mesh generation texture elements indicative of each possible surface element configuration within a jack can be pre computed so that a single texture element is mapped to all the surfaces within a given jack.

When the user paints a virtual object in object space values are assigned to corresponding texels in texture space. The user paints texture elements in essence via the link between surface elements of the virtual object in object space and corresponding texture elements in texture space. This process is invisible to the user who only sees the effects of the painting operation in object space. However the process of blending brush strokes occurs in texture space using two dimensional texture compositing techniques. Graphical user input fills texture layers corresponding to a given texture region then the texture layers are combined into a blended composite texture for that texture region. The blended composite texture for each texture region is bound one at a time to a graphics application during texture rendering as described in more detail elsewhere herein.

A scratch texture indicates one or more intensity values of pixels and or texels associated with each brush stroke. A scratch texture may be thought of as a template describing the brush characteristics for example the scratch texture may contain intensity values that reflect brush size and or edge effects. The brush may be assigned a certain width a varying width along the length of a stroke a certain shape characteristic of the end of the brush and or a falloff or transition region along a portion of the brush such as the edges of the brush. The intensity values in the scratch texture may be used to determine the intensity of a selected color at a given pixel within the brush stroke. For example a scratch texture comprising values representing a given brush stroke may represent a falloff region of the brush stroke by assigning intensity values from 1 full intensity at the center or near to the center of the stroke down to 0 no intensity at points at the edges of the stroke. Thus a blended composite of the scratch texture with a paint texture containing a single monochromatic color value would portray a paint stroke with the most intense color at the center of the stroke falling off to no color at the very edges of the stroke.

As used herein a brush stroke is an operation performed on a collection of pixels in a texture and or image. Brush strokes include for example paint strokes erase strokes pen strokes lines characters and text. The manner in which a brush stroke operates on a collection of pixels may be determined interactively by a user as in the performance of a paint or erase stroke using a graphical interface device or non interactively for example in batch without any user input. Thus brush strokes include for example batch deletions batch pastes and flood fills. The pixels texels on which a brush stroke operates may be either contiguous or non contiguous.

The texture layers portrayed in may also include stencil textures. Stenciling allows a user to more accurately control the editing of an image by specifying a maximum amount by which selected portions of the image are allowed to change over the course of a series of brush strokes. Stencil textures are described in more detail herein for example in the descriptions of and .

Texture layers may be stored in collapsed form as shown in thereby requiring less memory and improving the efficiency of the rendering process. As shown in the collapsed textures are combined to form a contiguous blended texture suitable for binding to a graphics application. Alternatively the blended texture may be stored in collapsed form.

A representative contiguous texture is shown in . The contiguous texture contains quadrilateral texture elements. Other shapes may be used alternatively. All texels of each of the elements of the contiguous texture are represented in normal expanded form. Where a given texture element contains limited data for example a single color value it is not necessary to store this value for each of the texels of the given element. Thus a collapsible texture can save memory by representing uniform texture elements with the limited data for example the single color value applied to all texels of the element.

The collapsible texture in is a grid of elements indicating uniform texture elements non uniform texture elements and locations of the nearest free texture element in the grid. Here an element of the grid may be a value of any bit length i.e. 32 bit that represents for example the color value of a uniform collapsed texture element the location of the next free grid element or the location of a non uniform expanded texture element as shown in the legend of . For each collapsible texture there may be a shadow texture that is used to interpret what kind of information the values of the grid represent. For example a shadow texture may comprise codes corresponding to the elements of the grid that indicate whether a grid element is a uniform quad value a location or identification number of a free quad or a pointer to a non uniform quad.

Texture layers are combined in discrete time slices to form the blended composite image in a pixel by pixel manner without interrupting application of additional brush strokes by the user. Each brush stroke within a given texture region may be represented using a scratch texture. An individual brush stroke is divided into a series of stroke segments that are separately blended into the scratch texture. The invention provides a method that prevents double blending of overlapping portions of segments of the individual brush stroke thereby avoiding undesired artifacts at the segment ends.

The blending method uses a scratch texture to describe the size and shape of the brush. By assigning a new pixel value to the scratch texture only if it exceeds the existing value at that pixel the double blending artifact is avoided. The blending method includes the steps of 1 receiving brush stroke data from a graphical user interface 2 for each of a plurality of pixels of a scratch texture comparing a received pixel value to a value previously written at the corresponding pixel of the scratch texture and assigning the received value to the corresponding pixel of the scratch texture only if it exceeds the existing value and 3 blending the scratch texture into the target image. Here the scratch texture is a texture having one or more intensity values of pixels and or texels associated with each brush stroke. The blending step may be performed substantially upon completion of the performance of the paint stroke by the user. Each scratch texture is emptied or deleted after its contents are blended so that each new brush stroke fills an empty scratch texture.

In order to enhance interactivity texture layers are blended in the order in which the brush strokes they represent are performed. Texture data is blended pixel by pixel in discrete time slices without interrupting the user s application of additional brush strokes. Thus multiple scratch textures layers may be blended together where each scratch texture represents an individual brush strokes within a given texture region. This technique is demonstrated in .

The texture layers that are combined to form a blended composite texture for a given texture region may include stencil textures. Stencil textures are used to protect a selected region of an image from subsequent editing. The methods of blending texture are compatible with stenciling methods that allow a user to more accurately control the editing of an image by specifying a maximum amount by which selected portions of the image are allowed to change over the course of a series of brush strokes.

The stenciling methods involve protecting an image using a first texture and a second texture rather than a single texture alone. is a block diagram featuring a method of blending brush strokes into a texture layer protected by application of a stencil. The first texture includes texels with values indicating levels of protection to be applied to corresponding texels of the protected texture . For example the first texture may be a map of values indicating one or more regions of the texture to be protected from editing by subsequent paint strokes. The level of protection may be from 0 to 100 where 0 indicates no protection from subsequent edits and 100 indicates full protection from subsequent edits. A level between 0 and 100 indicates partial protection and may correspond to a minimum opacity above which to maintain at least a portion of the protected region throughout the application of subsequent brush strokes.

Overlapping portions may result from multiple overlapping brush strokes and or from a single brush stroke that overlaps itself. Despite the presence of any overlapping portion s and despite the number of brush strokes applied following activation of the stencil methods of the invention can prevent the opacity of an initial version or initial layer of the selected region s from decreasing below a specified minimum in any subsequent composite.

The stenciling method illustrated in proceeds by directing graphical input for example brush strokes into a second texture rather than directly blending the graphical input into the protected texture . The second texture acts as a buffer accumulating graphical input. The protected texture may be combined along with other texture layers into a blended composite texture for the given texture region or alternatively the protected texture may in fact be the blended composite texture for a given texture region.

The interactivity of the user s image editing experience may be preserved by use of a display texture . In one embodiment texels of the protected texture are copied directly into a display texture while texels of the second texture are modified according to the first texture then blended into the display texture .

User interactivity is preserved by modifying texels of the second texture and blending the modified texels into the display image on a texel by texel basis. In this way the user sees the resulting image emerge subject to the user specified protection as the user continues to apply brush strokes.

The display texture can reflect real time user brush strokes as well as preserve a minimum opacity of the original texture layer within a protected region regardless of the number of brush strokes that follow. This is because in a preferred embodiment each update of the display texture is performed by 1 re copying texel values of the original protected texture layer into the display texture texels and then 2 compositing the modified second texture texels with the display texture texels. The display texture may be updated at a rate of up to about 30 times per second or more depending on the complexity of the image and the computational speed for graphical rendering. The update rate may be less for more complex images or for slower machines for example from about 10 times per second to about 20 times per second.

The use of a display texture is optional. Whether or not a display texture is used methods of the invention can preserve a minimum opacity of the original image layer within a protected region by accumulating graphical input in the second texture modifying the second texture using the first texture and subsequently blending the modified second texture into the protected texture .

The user may provide one or more signals indicating the beginning and or ending of the period of time in which brush strokes are accumulated in the second texture. The user provides a first signal such as a button click to indicate the beginning of the application of a stencil. Alternatively the stencil may self activate once the user defines the first texture. The step of defining the first texture may include indicating 1 one or more regions of the surface of a virtual object to be protected and or 2 one or more levels of protection to apply within the one or more regions. The surface elements within the region indicated by the user in object space are mapped to corresponding texture elements in texture space.

Once the stencil is active graphical input representing brush strokes by the user are directed into the second texture . When the user has completed one or more brush strokes the user may provide a second signal to deactivate the stencil. In one embodiment once the stencil is deactivated the second texture modified by the first texture is blended into the protected texture .

Real time display of erase strokes requires modification of paint strokes applied both before and after activation of the stencil. is a block diagram featuring a stenciling method in which erase strokes are blended into a protected texture . Generally the second texture contains data from paint strokes applied after activation of the stencil but not before. Therefore the step of modifying a value of one or more texels of the protected texture is performed prior to copying texels of the protected texture into the display texture and compositing the modified second texture texels with the display texture texels. Texel values of the protected texture are modified according to the level s of protection indicated in the first texture .

In one embodiment a minimum opacity of an original texture layer may be preserved despite repeated erase strokes within the protected region where overlapping erase strokes result in the attenuation of a texel value of the protected texture down to a minimum value but no further. The minimum value is determined from the protection level of that texel as indicated in the first texture . In cases where texels are represented by RGBA quadruples the first texture may be used to derive a minimum alpha channel value below which the texel values of the protected texture are not allowed to fall. Pixel values and or texel values include values of any bit depth where bit depth generally ranges from 1 to 64 bits per pixel. Pixel values include grayspace values RGB colorspace values RGBA colorspace values or any other colorspace values such as HSL HSV CMY CMYK CIE Lab and R Y B Y. Preferred methods of the invention are performed using 24 bit RGBA colorspace pixels although any bit depth and or colorspace format may be used.

The display methods discussed herein work where a user performs paint strokes erase strokes or both paint and erase strokes while the stencil is active. Additionally these display methods preserve the interactivity experienced by the user during the editing process while maintaining the protection offered by the stenciling methods described herein.

Methods of the invention involve the modification of paint colors of images and or textures as well as the blending of paint colors between two or more images and or textures. For example in one embodiment pixels of the second texture are modified using the first texture where the first texture is a map of values indicating protection levels for the protected texture and the second texture contains accumulated graphical input. A texel of the second texture may be modified by attenuating its color value according to the protection level in the first texture corresponding to that texel.

Blending of images and or textures may be performed using one or more compositing operations. For example in one embodiment texels of the second texture are blended into the protected texture . This may be done by performing a compositing operation such as an overlay operation in RGBA colorspace between the second texture and the protected texture .

Because texture is dynamically allocated a user may seamlessly switch between an object modification mode for example a sculpt mode and a surface paint mode without losing paint information for unaffected surfaces of the virtual object. is a block diagram featuring a method of texture painting in which texture space is dynamically allocated following modification of the virtual object. may represent part or all of a graphics thread for graphically rendering the virtual object. Throughout the process depicted in the user may apply any number of brush strokes directly onto the three dimensional object in object space using for example a haptic interface device. The user may also switch from the painting feature to a sculpting feature and back again. For example the method of may be initiated every time the user enters the painting feature for example by clicking an icon or button or by providing some other signal.

Step of the painting method illustrated in allocates texture space for the virtual object according to methods described herein for example the texture allocation method depicted in . Step describes the creation and rendering of blended composite textures for each of a plurality of texture regions as shown for example in . Step may be performed multiple times per second for example up to about 40 times per second or more. For more complex virtual objects step is performed at a slower rate for example from about 10 Hz to about 30 Hz.

Step of performs a set of substeps for each of a plurality of texture regions as indicated at reference . The substeps include updating texture layers according to user brush strokes combining the texture layers into blended composite textures binding the composite texture to a graphics application where the graphics application provides hardware and or software for display of the virtual object in object space and transmitting texture coordinates to the graphics application . After one or more render cycles of step the method determines in step whether the user has modified the virtual object such that any surface is destroyed or new surface is created. If not the creation and rendering of blended composite textures of step continues. If surface is created or destroyed the surface mesh for the virtual object is updated according to the user modification. For example if the user has sculpted the object and has re entered the painting feature step updates the surface mesh by remeshing at least a portion of the virtual object. The mesh generation step may employ a marching cubes algorithm for example if the model is a voxel based model. Then the method of proceeds to step where texture is allocated for example according to the method of which prevents reallocation of texture for surface elements in unmodified jacks. The creation and rendering of blended textures in step then continues as before.

An embodiment of the painting method of allows a user to paint with brush strokes whose characteristics are reflected in corresponding scratch textures. For example each brush stroke may include a falloff region or transition region near the edges of the brush stroke such that the paint appears to fade into the background color at the edges of the brush. Each stroke is divided into segments that link positions of a graphical interface device such as a stylus or other painting tool. The positions are recorded at successive frames as the user moves the graphical interface device in real space and preferably while the user views a graphical rendering of the virtual object in object space. The display may represent the virtual object using a Cartesian coordinate system or any other coordinate system. Surface elements of the object which fall within a volume of influence of the tool are painted.

For each texture region there is an interface labeled IComposite Color Texture Region in the architecture of that represents a stack of texture layers for the texture region. This interface is implemented by a texture that blends and stores paint layers and or brush stroke layers labeled Composite Color Texture Region . This texture contains a texture storing color per texel labeled Color Texture Region Component in as well as multiple textures storing paint layer data labeled Color Texture Region Layer . The Color Texture Region Component is a contiguous texture. A contiguous texture may be needed for proper binding of a blended composite texture with a computer graphics application for graphical rendering display.

The Texture Region Component in the architecture of is a template for a contiguous texture class. The Quad Texture Region Component is a template for a collapsible texture class which can be instantiated as a Color Quad Texture Region Component the texture storing color per texel in collapsed form.

Any of the methods described herein for graphically rendering a virtual object may be combined with haptic rendering of the virtual object. For example an embodiment of the invention haptically renders the virtual object in real time as the user applies a brush stroke onto the surface of the virtual object in object space. The haptic rendering process includes determining a force feedback corresponding to a position of a haptic interface device held by the user as the user applies a brush stroke using the device. The force is delivered to the user via the haptic interface device. A haptic rendering process is described for example in U.S. Pat. No. 6 552 722 by Shih et al. the text of which is hereby incorporated by reference in its entirety.

A combined haptic and graphical rendering method of the invention performs haptic rendering at a substantially faster rate than graphical rendering. This may be necessary to provide realistic force feedback to the user. In one embodiment graphical rendering is performed within a range from about 5 Hz to about 150 Hz while haptic rendering is performed within a range from about 700 Hz to about 1500 Hz. In another embodiment haptic rendering is performed at about 1000 Hz while graphical rendering is performed at up to about 40 Hz. Haptic and graphical rendering of a virtual object may be performed by different threads of an overall rendering process.

The sampling structure in a marching tetrahedra approach is a tetrahedron. Samples are at the vertices on a rectangular grid where a mesh cell is made up of eight samples of the grid and the mesh cell is split into six tetrahedra that tile the cell. FIG. shows a mesh cell that is split into six tetrahedra where vertices of the tetrahedra coincide with vertices of the cube. The configuration of triangular surface elements through each tetrahedron is determined by a lookup table. The index into the lookup table for a given tetrahedron is determined from values at the four vertices of the tetrahedron where each value indicates whether the vertex is interior or exterior to the isosurface of the virtual object being meshed. The sum of all triangular surface elements for all tetrahedra of a given cube tile the cube. The sum of all triangular surface elements for all the cubes tile the object space.

A computer hardware apparatus may be used in carrying out any of the methods described herein. The apparatus may include for example a general purpose computer an embedded computer a laptop or desktop computer or any other type of computer that is capable of running software issuing suitable control commands receiving graphical user input and recording information. The computer typically includes one or more central processing units for executing the instructions contained in software code that embraces one or more of the methods described herein. The software may include one or more modules recorded on machine readable media where the term machine readable media encompasses software hardwired logic firmware object code and the like. Additionally communication buses and I O ports may be provided to link any or all of the hardware components together and permit communication with other computers and computer networks including the internet as desired.

While the invention has been particularly shown and described with reference to specific preferred embodiments it should be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention as defined by the appended claims.

