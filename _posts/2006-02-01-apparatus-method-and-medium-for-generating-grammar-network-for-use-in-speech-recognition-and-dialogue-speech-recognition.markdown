---

title: Apparatus, method, and medium for generating grammar network for use in speech recognition and dialogue speech recognition
abstract: A method, apparatus, and medium for generating a grammar network for speech recognition and a dialogue speech recognition are provided. A method, apparatus, and medium for employing the same are provided. The apparatus for generating a grammar network for speech recognition includes: a dialogue history storage unit storing a dialogue history between a system and a user; a semantic map formed by clustering words forming each dialogue sentence included in a dialogue sentence corpus depending on semantic correlation, and generating a first candidate group formed of a plurality of words having the semantic correlation extracted for each word forming a dialogue sentence provided from the dialogue history storage unit; a sound map formed by clustering words forming each dialogue sentence included in the dialogue sentence corpus depending on acoustic similarity, and generating a second candidate group formed of a plurality of words having an acoustic similarity extracted for each word forming the dialogue sentence provided from the dialogue history storage unit and each word of the first candidate group; and a grammar network construction unit constructing a grammar network by combining the first candidate group and the second candidate group.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07606708&OS=07606708&RS=07606708
owner: Samsung Electronics Co., Ltd.
number: 07606708
owner_city: Suwon-Si
owner_country: KR
publication_date: 20060201
---
This application claims the benefit of Korean Patent Application No. 10 2005 0009144 filed on Feb. 1 2005 in the Korean Intellectual Property Office the disclosure of which is incorporated herein in its entirety by reference.

The present invention relates to speech recognition and more particularly to an apparatus and method for adaptively and automatically generating a grammar network for use in speech recognition based on contents of previous dialogue and an apparatus and method for recognizing dialogue speech by using the grammar network for speech recognition.

Among grammar generation algorithms used in a decoder among elements of a speech recognition apparatus such as a virtual machine and a computer well known methods such as an n gram method a hidden Markov model HMM method a speech application programming interface SAPI a voice eXtensible markup language VXML and a speech application language tags SALT method are used. In the n gram method real time discourse information between a speech recognition apparatus and a user is not reflected in utterance prediction. In the HMM method each moment of utterance by a user is assumed as an individual probability event completely independent from other utterance moments of the user or a speech recognition apparatus. Meanwhile in the SAPI VXML and SALT methods a predefined grammar in a simple prefixed discourse is loaded on predefined time points.

As a result when the content of utterance by a user falls outside of a predefined standard grammar structure it becomes difficult for the speech recognition apparatus to recognize the utterance of the user and therefore the speech recognition apparatus prompts the user to utter again. In conclusion the time taken by the speech recognition apparatus to recognize the utterance of the user becomes longer such that the dialogue between the speech recognition apparatus and the user becomes unnatural as well as tedious.

Furthermore a grammar network generation method of the n gram method using a statistical model may be appropriate to a grammar network generator of a speech recognition apparatus for dictation utterance but it is not appropriate to that for a speech recognition apparatus for conversational utterance due to a drawback that real time discourse information is not utilized for utterance prediction. In addition grammar network generation methods of the SAPI VXML and SALT methods that employ a context free grammar CFG using a computational language model may be appropriate to a grammar network generator of a speech recognition apparatus for command and control utterance but these are not appropriate for conversational utterance due to a drawback that the discourse and speech content of the user cannot go beyond a pre designed fixed discourse.

Additional aspects features and or advantages of the invention will be set forth in part in the description which follows and in part will be apparent from the description or may be learned by practice of the invention.

The present invention provides an apparatus method and medium for adaptively and automatically generating a grammar network for speech recognition based on contents of previous dialogue.

The present invention also provides an apparatus method and medium for performing dialogue speech recognition by using a grammar network for speech recognition generated adaptively and automatically based on contents of previous dialogue.

According to an aspect of the present invention there is provided an apparatus for generating a grammar network for speech recognition including a dialogue history storage unit storing a dialogue history between a system and a user a semantic map formed by clustering words forming each dialogue sentence included in a dialogue sentence corpus depending on semantic correlation and generating a first candidate group formed of a plurality of words having the semantic correlation extracted for each word forming a dialogue sentence provided from the dialogue history storage unit a sound map formed by clustering words forming each dialogue sentence included in the dialogue sentence corpus depending on acoustic similarity and generating a second candidate group formed of a plurality of words having an acoustic similarity extracted for each word forming the dialogue sentence provided from the dialogue history storage unit and each word of the first candidate group and a grammar network construction unit constructing a grammar network by combining the first candidate group and the second candidate group.

According to another aspect of the present invention there is provided a method of generating a grammar network for speech recognition including forming a semantic map by clustering words forming each dialogue sentence included in a dialogue sentence corpus depending on semantic correlation forming an acoustic map by clustering words forming each dialogue sentence included in the dialogue sentence corpus depending on acoustic similarity activating the semantic map and generating a first candidate group formed of a plurality of words having the semantic correlation extracted for each word forming a dialogue sentence included in a dialogue history performed between a system and a user activating the acoustic map and generating a second candidate group formed of a plurality of words having an acoustic similarity extracted for each word forming the dialogue sentence included in the dialogue history and each word of the first candidate group and generating a grammar network by combining the first candidate group and the second candidate group.

According to another aspect of the present invention there is provided an apparatus for speech recognition including a feature extraction unit extracting features from a user s voice and generating a feature vector string a grammar network generation unit generating a grammar network by activating a semantic map and an acoustic map by using contents of a dialogue most recently spoken whenever the user speaks a loading unit loading the grammar network generated by the grammar network generation unit and a searching unit searching the grammar network loaded in the loading unit by using the feature vector string and generating a candidate recognition sentence formed of a word string matching the feature vector string.

According to another aspect of the present invention there is provided a method of speech recognition including extracting features from a user s voice and generating a feature vector string generating a grammar network by activating a semantic map and an acoustic map by using contents of a dialogue most recently spoken whenever the user speaks loading the grammar network and searching the loaded grammar network by using the feature vector string and generating a candidate recognition sentence formed of a word string matching the feature vector string.

According to another aspect of the present invention there is provided at least one computer readable medium storing instructions that control at least one processor for executing a method of generating a grammar network for speech recognition wherein the method includes forming a semantic map by clustering words forming each dialogue sentence included in a dialogue sentence corpus depending on semantic correlation forming an acoustic map by clustering words forming each dialogue sentence included in the dialogue sentence corpus depending on acoustic similarity activating the semantic map and generating a first candidate group formed of a plurality of words having the semantic correlation extracted for each word forming a dialogue sentence included in a dialogue history performed between a system and a user activating the acoustic map and generating a second candidate group formed of a plurality of words having an acoustic similarity extracted for each word forming the dialogue sentence included in the dialogue history and each word of the first candidate group and generating a grammar network by combining the first candidate group and the second candidate group.

According to another aspect of the present invention there is provided at least one computer readable medium storing instructions that control at least one processor for executing a method of speech recognition wherein the method includes extracting features from a user s voice and generating a feature vector string generating a grammar network by activating a semantic map and an acoustic map by using contents of a dialogue most recently spoken whenever the user speaks loading the grammar network and searching the loaded grammar network by using the feature vector string and generating a candidate recognition sentence formed of a word string matching the feature vector string.

According to another aspect of the present invention there is provided a method of speech recognition including extracting features from a user s voice and generating a feature vector string generating a grammar network by activating a semantic map and an acoustic map by using contents of a dialogue spoken by a user and searching the grammar network by using the feature vector string and generating a candidate recognition sentence formed of a word string matching the feature vector string.

According to another aspect of the present invention there is provided at least one computer readable medium storing instructions that control at least one processor for executing a method of speech recognition wherein the method includes extracting features from a user s voice and generating a feature vector string generating a grammar network by activating a semantic map and an acoustic map by using contents of a dialogue spoken by a user and searching the grammar network by using the feature vector string and generating a candidate recognition sentence formed of a word string matching the feature vector string.

Reference will now be made in detail to exemplary embodiments of the present invention examples of which are illustrated in the accompanying drawings wherein like reference numerals refer to the like elements throughout. Exemplary embodiments are described below to explain the present invention by referring to the figures.

Referring to the dialogue history storage unit stores a dialogue history between a virtual machine or computer having a speech recognition function hereinafter referred to as a system and a user as dialogue progresses up to and including a preset number of times the source system or user of the dialogue changes. According to this the dialogue history stored in the dialogue history storage unit can be updated as a dialogue between the system and the user progresses. For example the dialog history includes at least one combination among a plurality of candidate recognition results of a user s previous voice input provided from a searching unit of a final recognition result of the user s previous voice input provided from an utterance verification unit of a reutterance requesting message provided from a reutterance request unit of and a system s previous utterance sentence.

The semantic map is a map formed by clustering word like units depending on semantic correlation. The semantic map is activated by word like units forming a latest dialogue sentence in the dialogue history stored in the dialogue history storage unit . The semantic map extracts at least one or more word like units having high semantic correlations for each word like unit in the latest dialogue sentence and generates a first candidate group formed of a plurality of word like units extracted for each word like unit in the latest dialogue sentence.

The acoustic sound map is a map formed by clustering word like units depending on acoustic similarity. The sound map is activated by word like units activated by the semantic map and the word like units forming a latest dialogue sentence in the dialogue history stored in the dialogue history storage unit . The acoustic map extracts at least one or more acoustically similar word like units for each word like unit in the latest dialogue sentence and generates a second candidate group formed of a plurality of word like units extracted for each word like unit in the latest dialogue sentence.

In the semantic map and the acoustic map a dialogue sentence of the user recognized most recently by the computer and a dialogue sentence uttered most recently by the computer among the dialogue history stored in the dialogue history storage unit may be received after being separated into respective word like units.

The grammar network construction unit builds a grammar network by combining randomly the word like units included in the first candidate group provided by the semantic map and the word like units included in the second candidate group provided by the acoustic map or by extracting from a corpus using a variety of methods the word like units included in the first candidate group provided by the semantic map and the word like units included in the second candidate group provided by the acoustic map .

The dialogue sentence corpus stores all dialogue contents that can be used between a system and a user or between persons by arranging the contents as sequential dialogue sentences or partial sentences in a database. At this time it is also possible to form dialogue sentences for each domain and store the sentences. Also a variety of usages of each word may be included in the forming of a dialogue sentence. Here the word like unit is a word formed of one or more syllables or a string of word. The word like unit serves as a basic element forming each dialogue sentence and the word like unit is comprised of a single meaning and a single pronunciation. Accordingly unless the meaning and pronunciation is maintained the word like unit cannot be divided further or cannot be combined with other elements. Also only one pair of an identical meaning and an identical pronunciation is defined. Meanwhile when words having identical pronunciation have meanings even slightly different from each other for example homonyms homophones homographs and polysemies all of the words are arranged and defined as different elements. Also when words having the same meaning have pronunciations even slightly different from each other for example dialectics and abbreviations all are arranged and defined as different elements.

The semantic map generation unit selects one dialogue sentence sequentially in relation to the dialogue contents stored in the dialogue sentence corpus . The semantic map generation unit sets at least one dialogue sentence positioned at a point of time previous to the selected dialogue sentence and at least one dialogue sentence positioned at a point of time after the selected dialogue sentence as training units. In relation to the set training units it is determined that word like units occurring adjacent to each word like unit have high semantic correlations. By considering semantic correlations clustering or classifier training for all dialogue sentences included in the dialogue sentence corpus semantic map generation is performed so that a semantic map is generated. At this time for the clustering or the classifier training a variety of algorithms such as a Kohonen network vector quantization a Bayesian network an artificial neural network and a Bayesian tree can be used.

Meanwhile a method of quantitatively measuring a semantic distance between word like units in the semantic map generation unit will now be explained. Basically a co occurrence rate is employed for distance measuring that is used when a semantic map is generated from the dialogue sentence corpus through the semantic map generation unit . The co occurrence rate will now be explained further. When taking a sentence or part of a sentence from the dialogue sentence corpus referring to a current point in time t as a center a window is defined to include a sentence in t 1 to a sentence in t 1 including the sentence in t. In this case one window includes three sentences. Also t 1 can be t n and t 1 can be t n. At this time n may be any value from 1 to 7 but is not limited to these numbers. The reason why the maximum number is 7 is that the limit of the short period memory of a human being is 7 units.

Word like units co occurring in one window are counted respectively. For example a predetermined sentence Ye Kuraeyo is included in a window. Since this sentence includes two word like units Ye yes and Kuraeyo right and Ye yes Kuraeyo right is counted once and also Kuraeyo right Ye yes is counted once. The frequencies of these co occurrences are continuously recorded and then finally counted in relation to the entire contents of the corpus. That is a counting operation identical to the above is performed each time with moving the window of a constant size in relation to the entire contents of the corpus by one step with respect to time. If the counting operation in relation to the entire contents of the corpus is finished the count value integer value in relation to each pair of the entire plurality of word like units is obtained. If this integer value is divided by the total sum of all count values each pair of word like units will have a fractional value between 0.0 and 1.0. The distance between a predetermined word like unit A and another word like unit B will be a predetermined fractional value. If this value is 0.0 it means that the two word like units never occurred together and if this value is 1.0 it means that only this pair exists in the entire contents of the corpus and other possible pairs have never occurred. As a result the values for most pairs will be arbitrary values less than 1.0 and greater than 0.0 and if values of all pairs are added the result will be 1.0.

The co occurrence rate described above corresponds to what is obtained by converting all important semantic relations defined in ordinary linguistics into quantitative amounts. That is antonyms synonyms similar words super concept words sub concept words and part concept words are all included and even interjections frequently occurring are included. Especially in the case of interjections they have bigger values of semantic distance for a bigger variety of word like units. Meanwhile in the case of articles they will occur adjacent to only predetermined sentence types. That is in the case of the Korean language articles will occur only after nouns. In conventional technology linguistic knowledge can be defined one by one manually. However according to the present invention if dialogue sentences are correctly collected in the dialogue sentence corpus words will be automatically arranged and the quantitative distance can be measured. As a result a grammar network appropriate to the flow of a dialogue that is the discourse is generated so that utterance by a user can be predicted.

The acoustic map generation unit selects one dialogue sentence sequentially in relation to the dialogue sentences stored in the dialogue sentence corpus . The acoustic map generation unit matches each word like unit included in the selected dialogue sentence with at least one or more word like units having identical pronunciation but having different meaning according to usage or at least one or more word like units having a different pronunciation but having identical meaning. Then with respect to acoustic similarity semantic or pronunciation indexes are given to the at least one or more word like units matched with one word like unit and then by performing clustering or classifier training an acoustic map is generated. The acoustic map is generated by performing clustering or classifier training in the same manner as in the semantic map generation unit . As an example of a method of quantitatively measuring an acoustic distance between word like units in the acoustic map generation unit a method is disclosed in Korean Patent Laid Open Application No. 2001 0073506 title of the invention A method of measuring a global similarity degree between Korean character strings .

An example of a semantic map generated in the semantic map generation unit and an acoustic map generated in the acoustic map generation unit will now be explained assuming that the dialogue sentence corpus includes the usage examples as the following Table 1 

By using the word like units shown in Table 2 an acoustic map containing relations between pronunciations and polymorphemes as the following Table 3 and a semantic map containing relations between polymorphemes as shown in Table 4 are generated.

In Table 3 indicates a pronunciation and in Table 4 indicates an adjacent relation indicates a relation that has nothing to do with an utterance order and . . . indicates a relation that may be adjacent or may be skipped.

Referring to the characteristic extraction unit receives a voice signal from a user and converts the voice signal into a feature vector string useful for speech recognition such as a Mel frequency Cepstral coefficient.

The grammar network generation unit receives the dialogue history most recently generated and generates a grammar network by activating the semantic map of and the acoustic map of using the received dialogue history. The dialog history includes at least one combination among a plurality of candidate recognition results of a user s previous voice input provided from a searching unit a final recognition result of the user s previous voice input provided from an utterance verification unit a reutterance requesting message provided from a reutterance request unit and a system s previous utterance sentence. The detailed structure and related specific operations of the grammar network generation unit are the same as described above with reference to .

The loading unit expresses phoneme combination information in relation to phonemes included in the grammar network generated in the grammar network generation unit in a structure such as a context free grammar and loads it into the searching unit .

The searching unit receives the feature vector string in relation to the currently input voice signal from the feature extraction unit and performs a Viterbi search for the grammar network formed of phoneme models extracted from the acoustic model based on the phoneme combination information loaded from the loading unit in order to find candidate recognition sentences N Best formed of matching word strings.

The utterance verification unit performs utterance verification for the candidate recognition sentences provided by the searching unit . At this time without using a separate language model the utterance verification can be performed by using the grammar network generated according to an exemplary embodiment of the present invention. That is if similarity calculated in relation to one among the candidate recognition sentences by using the grammar network is equal to or greater than a threshold it is determined that the utterance verification of the current user voice input is successful. If each similarity calculated in relation to all the candidate recognition sentences is less than the threshold it is determined that the utterance verification of the current user voice input is failed. In relation to the utterance verification the method disclosed in the Korean Patent Application No. 2004 0115069 which corresponds to U.S. patent application Ser. No. 11 263 826 title of the invention method and apparatus for determining the possibility of pattern recognition of a time series signal can be applied.

When utterance verification is failed for all candidate recognition sentences in the utterance verification unit the user reutterance request unit may display text requesting the user to utter again on a display not shown such as an LCD display or may generate a system utterance sentence requesting the user to utter again through a speaker not shown .

Referring to a dialogue history most recently generated is received in operation . The dialogue history includes a first dialogue sentence that is spoken most recently by the user and recognized by the system and a second dialogue sentence that is spoken most recently by the system. The first dialogue sentence includes at least one combination of a plurality of candidate recognition results of a user s previous voice input provided from a searching unit and a final recognition result of the user s previous voice input provided from an utterance verification unit . The second dialogue sentence includes at least one combination of a reutterance requesting message provided from a reutterance request unit and a system s previous utterance sentence.

In operation the semantic map of and the acoustic map of are activated by using the dialogue history received in operation and a grammar network is generated by combining randomly or in a variety of ways extracted from the corpus a plurality of word like units included in a first candidate group provided by the semantic map and a plurality of word like units included in a second candidate group provided by the acoustic map .

In operation phoneme combination information in relation to phonemes included in the grammar network generated in operation is expressed in a structure such as a context free grammar and is loaded for a search such as a Viterbi search.

In operation the Viterbi search is performed for the grammar network formed of phoneme models extracted from the acoustic model based on the phoneme combination information loaded in operation in relation to the feature vector string for the current voice signal which is input in operation and by doing so candidate recognition sentences N Best formed of matching word strings are searched for.

In operation it is determined whether or not there is a candidate recognition sentence among the candidate recognition sentences for which utterance verification is successful according to the search result of operation .

In operation if the determination result of the operation indicates that there is a candidate recognition sentence whose utterance verification is successful the recognition sentence is output of the system and in operation if there is no candidate recognition sentence whose utterance verification is successful the user is requested to utter again.

In addition to the above described exemplary embodiments exemplary embodiments of the present invention can also be implemented by executing computer readable code instructions in on a medium e.g. a computer readable medium. The medium can correspond to any medium media permitting the storing and or transmission of the computer readable code.

The computer readable code instructions can be recorded transferred in on a medium in a variety of ways with examples of the medium including magnetic storage media e.g. ROM floppy disks hard disks etc. optical recording media e.g. CD ROMs or DVDs random access memory media and storage transmission media such as carrier waves. Examples of storage transmission media may include wired or wireless transmission such as transmission through the Internet . The medium media may also be a distributed network so that the computer readable code instructions is stored transferred and executed in a distributed fashion. The computer readable code instructions may be executed by one or more processors.

According to the present invention as described above dialogue speech recognition is performed by using a grammar network for speech recognition adaptively and automatically generated by reflecting the contents of previous dialogues such that even when the user utters outside a standard grammar structure the contents can be easily recognized. Accordingly dialogue can be smoothly and naturally performed.

Furthermore as a grammar network generator of a conversational or dialogue driven speech recognition apparatus the present invention can replace the n gram SAPI VXML and SALT methods that are conventional technologies and in addition it enables a higher dialogue recognition rate through a user speech prediction function.

Although a few exemplary embodiments of the present invention have been shown and described it would be appreciated by those skilled in the art that changes may be made in these exemplary embodiments without departing from the principles and spirit of the invention the scope of which is defined in the claims and their equivalents.

