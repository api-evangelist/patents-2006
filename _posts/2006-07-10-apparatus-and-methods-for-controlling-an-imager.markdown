---

title: Apparatus and methods for controlling an imager
abstract: A method of controlling an imager in a portable data collection device. A plurality of data structures are created with each containing a set of values for controlling an exposure process of an imager in a portable data collection device. One of the plurality of data structures is selected and the values therein are applied to the imager. Thereafter, a frame is captured by the imager and outputted.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07798408&OS=07798408&RS=07798408
owner: Hand Held Products, Inc.
number: 07798408
owner_city: Skaneateles Falls
owner_country: US
publication_date: 20060710
---
The term Portable data terminal PDT refers to data collection devices used to collect process and transfer data to a larger data processing system. Most PDTs are ruggedized to some extent for use in industrial environments. The tougher the environment the more robust the PDT. PDT s are available from several sources including the assignee of the present application HAND HELD PRODUCTS. INC.

A PDT generally comprises a mobile computer a keypad and a data acquisition device. The mobile computer generally comprises a hand held or pocket computing device such as those available from INTEL. PALM HEWLETT PACKARD and DELI. Keypads come in a variety of alpha numeric and numeric configurations. The data acquisition device generally comprises a device that captures data from for example radio frequency IDs RFID images and bar codes. Data may also be captured via keypad entry and utilization of a touch pad associated with the mobile computer.

The handle extending from a bottom surface of the body incorporates a trigger . In use the user may actuate either the scan key or the trigger to initiate a frame capture via the image engine . The captured frame may either be processed as an image or as a data carrier. In the first case the captured frame may undergo some post capture image processing such as de speckling or sharpening and then stored as an image file e.g. a bitmap jpeg of gif file and possibly displayed. In the second case the captured frame also undergoes some post capture image processing but the image is then analyzed e.g. decoded to identify data represented therein. The decoded data is stored and possibly displayed on the PDT . Additional processing of the image or data may take place on the PDT and or a data processing resource to which the data is transmitted via any available transport mechanism on the PDT . Some examples of known transport mechanisms utilized by PDT s include Bluetooth WiFi. GSM CDMA USB. IrDA removable FLASH memory parallel and serial ports including for example. RS 232 .

Imagers have a plurality of settings that may be adjusted. These settings including gain and shutter speed affect the image acquisition process and typically affect the image captured. A variety of functions designed to modify captured images are often provided in software or firmware associated with the imager. Examples of these functions include sharpness and edge algorithms. Between the settings and functions the user of an imager based PDT is faced with large number of choices any of which may dramatically affect the final image outputted by the system. PDTs with other data capture devices such as RFID or magstripe readers may also be faced with a similar array of choices. The present inventors have recognized a need to simplify control of parameters associated with controlling a data capture process on a PDT.

Reference will now be made in detail to the present invention examples of which are illustrated in the accompanying drawings wherein like reference numerals refer to like elements throughout. The following description will use nomenclature associated with an imager based PDT however those of ordinary skill in the art will recognize that the present invention is applicable to a variety of portable devices including RF or magstripe based PDTs personal data assistants PDAs bar code scanners and consumer electronics for example digital cameras cellular phones and the like. It is anticipated that many such portable devices would benefit from the present invention including the embodiments thereof described herein.

A method is here and generally conceived to be a sequence of steps or actions leading to a desired result and may be implemented as software. While it may prove convenient to discuss such software as if it was embodied by a single program most implementations will distribute the described functions among discrete and some not so discrete pieces of software. These pieces are often described using such terms of art as programs. objects. functions. subroutines libraries .dlls. APIs. and procedures. While one or more of these terms may find favor in the present description there is no intention to limit the invention to the described configurations.

In general the sequences of steps in the present methods require physical manipulation of physical quantities. These quantities take the form of optical electrical or magnetic signals capable of being stored transferred combined compared or otherwise manipulated. Those of ordinary skill in the art conveniently refer to these signals as bits values elements symbols characters images terms numbers or the like. It should be recognized that these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities.

With respect to the software described herein those of ordinary skill in the art will recognize that there exist a variety of platforms and languages for creating software for performing the methods outlined herein. Embodiments of the present invention can be implemented using MICROSOFT VISUAL STUDIO or any number of varieties of C. However those of ordinary skill in the art also recognize that the choice of the exact platform and language is often dictated by the specifics of the actual system constructed such that what may work for one type of system may not be efficient on another system. It should also be understood that the methods described herein are not limited to being executed as software on a computer or DSP Digital Signal Processor but can also be implemented in a hardware processor. For example the methods could be implemented with HDL Hardware Design Language in an ASIC.

In the present description an element number followed by a letter generally indicates multiple occurrences of similar either in structure or function elements. Further the use of an italicized n e.g. n associated with an element number generally denotes either an unspecified one of such elements or a partial or complete group of such elements the meaning of which is to be drawn from the context of such use.

A central processing unit CPU receives data from and outputs data to other sub systems for storage transmission and additional processing. CPU may be implemented using any number of off the shelf solutions including embedded processors such as an XSCALE processor available from INTEL general purpose processors such as a PENTIUM 4 available from INTEL or any number of custom solutions including pre configured field programmable gate arrays FPGAs and application specific integrated circuits ASICs . Overall operation of the CPU is controlled by software or firmware typically referred to as an operating system stored in one or more memory locations including RAM and FLASH memory . Examples of suitable operating systems for PDT include WINDOWS MOBIL WINDOWS CE. WINDOWS XP LINUX PALM and OSX.

In general communication to and from the CPU and the various sub components takes place via one or more ports or busses including a main system bus IC busses and a plurality of Universal Asynchronous Receivers Transmitter UART ports a Universal Serial Bus USB and an RS 232 port .

The illustrated CPU also includes a liquid crystal display LCD controller for controlling an LCD . A touch sensitive panel which may be in communication with one or more of the CPU and an auxiliary processor via the IC bus may be associated with the LCD for receipt of data thereon. The combination of the LCD and the touch sensitive panel is often referred to as a touch screen. 

A variety of secondary processors may be provided to perform general and application specific functions. The example illustrated in provides two such processors a field programmable gate array FPGA and the auxiliary processor . The FPGA may comprise any number of FPGA including the Virtex 4 family available from XILINX. The auxiliary processor may comprise any number of embedded or general purpose processors including the PICmicro family of microcontrollers available from MICROCHIP TECHNOLOGY.

The auxiliary processor may interface with and control a variety of data input devices including for example the touch panel a keyboard and a scan button . By way of example the PDT may be configured so that displayed menu options are selected by physically depressing a key on the keyboard or activating the touch screen with use of a finger or stylus. The scan button may be used for initiating and controlling the various data collection systems such as an image signal generating system an RFID sensing system or a magnetic stripe reader .

The data collection systems e.g. the image signal generating system the RFID sensing system and the magnetic stripe reader may be controlled by one or more of the CPU the auxiliary processor and the FPGA . In this case the FPGA initiates and controls the operation of the data collection systems and accumulates data received there from prior to depositing such data in memory . Possible configurations of FPGA are illustrated in U.S. Pat. No. 6 947 612 incorporated herein by reference.

The image signal generating system generally comprises a two dimensional solid state image sensor utilizing such technologies as CCD CMOS and CID for capturing an image containing data e.g. a bar code or signature. Two dimensional solid state image sensors generally have a plurality of photo sensor picture elements pixels which are formed in a pattern including a plurality of rows and a plurality of columns of pixels. The image signal generating system further includes an imaging optics not shown focusing an image onto an active surface of the image sensor . Image sensor may be incorporated on an image sensor IC chip having disposed thereon image sensor control circuitry image signal conditioning circuitry and an analog to digital converter. FPGA manages the capture and transfer of image data into RAM . Decoding may be performed by the CPU or any suitable secondary processor. Examples of devices suitable for use as the imaging assembly include an IMAGETEAM 5x00VGA 5x00MPX imaging module of the type available from Hand Held Products assignee of the present application. A variety of alternatives including dedicated laser barcode scanners may also be utilized.

One use of the image signal generating system is for reading and interpreting bar codes such as bar code on an item . For this operation when the scan button is actuated the CPU causes the appropriate control signals to be sent to the image sensor . In response thereto the image sensor outputs digital image data including hopefully an adequate representation of the bar code symbol . The digital image data is streamed to the FPGA where it is collected and subsequently deposited in memory . In accordance with a decoding program not specifically illustrated an attempt may be made to decode the bar code represented in the captured electronic image representation. The capture and decoding of image data may occur automatically in response to a trigger signal being generated usually by activation of the scan button or a pre selected key on keyboard . For example the CPU may be configured typically through execution of a program resident in memory to continuously capture and decode bar code symbols represented therein as long as scan button is actuated. The cycle may be terminated upon successfully decoding the bar code symbol or by timing out after a number of unsuccessful attempts.

In addition to having a decode operation the image signal generation system may also be configured for an image capture operation. In an image capture operation control circuit captures an electronic image representation in response to the scan button being actuated without attempting to decode a decodable symbol represented therein. The captured electronic image representation may be one or more of i stored into a designated memory location of memory ii transmitted to an external spaced apart device or iii displayed on LCD . This mode may be used to capture for example an image of a signature or damage to a package.

In an image capture operation the image signal generation system may be operated in two distinct stages aiming and final capture. During the aiming stage frames output by the image signal generation system are displayed on the LCD display . These frames are not saved. Once a user is satisfied with the content of the image displayed on the LCD display he or she initiates the final capture stage. In final capture stage a frame either the frame currently in the buffer or a next frame is saved and typically displayed on the LCD . Generally the aiming stage is initiated by pressing a designated button such as a scan button with the final capture stage being initiated by releasing the designated button. It is generally desirable to display frames as quickly as possible in the aiming stage to ensure that the user is viewing a recently outputted fame. Otherwise there is a danger that the frame the user views when deciding to initiate capture is outdated and does not accurately reflect what the image signal generating system is currently outputting and what will be captured in final capture stage .

The RFID reader unit includes an RF oscillation and receiver circuit and a data decode processing circuit . RFID reader unit may be configured to read RF encoded data from a passive RFID tag such as tag which may be disposed on article .

Where the RFID reader unit is configured to read RF encoded data from a passive RFID tag the RF oscillation and receiver circuit transmits a carrier signal to the passive tag which in turn converts the carrier energy to voltage form and actuates a transponder not shown to transmit a radio signal representing the encoded tag data. The RF oscillator and receiver circuit in turn receives the radio signal from the tag and converts the data into a digital format. The data decode processing circuit typically including a low cost microcontroller IC chip decodes the received radio signal information received by RF oscillator and receiver circuit to decode the encoded identification data originally encoded into RFID tag.

RFID reader unit may for example operate in a selective activation mode or in a continuous read operating mode. In a selective activation mode RFID reader unit broadcasts radio signals in an attempt to activate a tag or tags in its vicinity in response to an RFID trigger signal being received. In a continuous read mode RFID reader module continuously broadcasts radio signals in an attempt to actuate a tag or tags in proximity with unit automatically without module receiving a trigger signal. PDT may be configured so that the CPU recognizes a trigger signal under numerous conditions such as 1 the trigger is actuated 2 an RFID trigger instruction is received from a remote device or 3 the CPU determines that a predetermined condition has been satisfied.

Still further the PDT may include a card reader unit for reading data from a card . Card reader unit generally comprises a signal detection circuit and a data decode circuit . In operation the signal detection circuit detects data from for example a magnetic strip on a card . Subsequently the data decode circuit decodes the data. The decoded data may be transmitted to the CPU for further processing via the FPGA . The card reader unit can be selected to be of a type that reads card information encoded in more than one data format. For example the card reader unit may comprise a Panasonic ZU 9A36CF4 Integrated Smart Reader capable of reading any one of magnetic stripe data smart card or Integrated circuit card IC card data and RF transmitted data.

A power circuit supplies power to the PDT . The power circuit generally comprises a series of power supplies that regulate the power supplied to the various components of the PDT . The power supplies each generally comprise step up or step down circuits which are in turn connected to each of the various components in the PDT that require the particular voltage output by that power supply

The power supplies receive current from a power bus which is in turn supplied by one of a battery a first power input or a connector that includes a second power input. The first power input may comprise a DC power jack for example a 2.5 mm coaxial DC power plug which receives 9.5 volts from a conventional AC DC transformer. The connector may comprise any number of known connection technologies such as the D Series of circular plastic connectors or the HCL D sub derivative design data transfer connector available from HYPERTRONICS INC. Certain pins of the connector may be dedicated to receiving DC power for example 9.5 volts while other pins are dedicated to one or more communication paths. e.g. RS 232 and USB. It may also prove advantageous to provide DC power out for example from a power supply so as to power tethered accessories such as external magnetic stripe or RFID readers not shown . It may prove further advantageous to add circuitry to insulate the first power input from the second power input on the connector and other components in the PDT in the event that a user attempts to supply power to both power inputs.

The battery may be selected from any of a variety of battery technologies including fuel cell NiMh. NiCd Li Ion or Li Polymer. The battery is charged by a charge circuit which receives power from either the first power input or the second power input on the connector . The charge circuit may comprise any of a number of available circuits. In the example shown in control is provided to the CPU which may modify the charging behavior of the charge circuit based on information generated by the auxiliary processor . In this example the auxiliary processor monitors battery chemistry such as gas content via known interfaces such as the SMART battery interface as specified by the Smart Battery System Implementers Forum. A switch isolates the battery based upon the presence of power from the first power input or the second power input on the connector . Thus when an external power supply is connected to either the power input or the second power input on the connector the battery is isolated from the power supplies and may be charged via the charge circuit . Once power is removed from the power input and the connector the battery is connected to the power supplies

The PDT may further include a plurality of wireless communication links such as an 802.11 communication link an 802.16 communication link a communication link for communication with a cellular network such as a network in accordance with the Global System for Mobile Communications GSM an IR communication link and a Bluetooth communication link . Each of these links facilitates communication with a remote device and may be used to transfer and receive data.

An application programming interface API is a set of routines that a computer system library or application provides to allow requests for service from other computer programs and or to facilitate the exchange of data. Generally an API is designed to simplify use of abstract or extend a lower level entity. Many times this simplification takes the form of collecting and ordering a set of lower level commands to accomplish a function. Thus referring to the architecture illustrated in the scan driver API provides a set of routines that simplifies use of the imaging hardware . In turn the imaging API provides a set of routines that extend use of the scan driver API .

The imaging hardware generally comprises the image generating system including the image sensor . The imaging hardware is generally responsive to the contents of registers and the voltage level applied to a set of pins. For example illumination of LEDs associated with the image signal generation system may be adjusted based on a signal supplied to a selected pin. By way of another example gain applied to the output of the charge couple devices forming the imager corresponding to an ISO setting may be responsive to values stored in a register. It is to be understood that different manufactures of different imagers will provide different capabilities with varying settings and functions used to access those capabilities.

The scan driver API provides a software interface to imaging hardware . In other words the scan driver API provides software callable routines for setting the registers and supplying voltage to pins used to control the imaging hardware . The scan driver API may for example provide routines that turns illumination on or off turns an aimer on or off initiates image capture and retrieves an image. Table 1 sets forth an example list of routines that may be provided in a scan driver API .

The imaging API provides a set of libraries and tools to help software developers create applications that utilize the PDT s image generation system for capturing manipulating and saving images. Developers of applications interface with the imaging API the scan driver API and the imaging hardware by using the calls provided by the imaging API . Functionally the imaging API provides a set of routines that facilitate the capture and manipulation of one or more images.

More to the point the imaging API provides access to a variety of different types of settings and functions useful for the capture and post processing of frames. The examples discussed herein will focus on three types of settings and functions exposure settings aimer illumination settings and post capture image processing functions hereinafter referred to as image functions . Exposure aimer and illumination settings provide access to settings within the imaging hardware that affect the capture of one or more images also referred to as frames . In particular aimer and illumination settings generally comprise indications of whether illumination generally comprising LEDs on the imaging hardware is to be utilized and whether an aimer perhaps comprising LEDs with a diffraction screen or a laser is to be projected. Exposure settings generally refer to values that affect the exposure process of the imaging hardware . Image functions are a suite of routines that manipulate an existing image and include such functions as de speckle and sharpen.

A representative group of image based settings and functions are described herein below. It is to be recognized that depending on the imaging hardware other settings and functions may be available. It is also to be recognized that a similar set of settings and functions may be provided for decoding operations.

Table 2 sets forth an example list of routines that may be provided in an imaging API for adjusting settings related to the capture and display of frames.

In the example illustrated in Table 2 exposure settings are set using the imgSetExposureSettings call. Exposure settings are generally dictated by the collection of possible settings allowed by particular imaging hardware and which of those settings are exposed by the scan driver API . Thus the available parameters may vary between different imaging hardware. Table 3 sets forth an example list of exposure settings that may be provided in association with an imaging API . In this example the imager may operate in one of two modes automatic or manual set using the imgSetExposureMode call .

Image functions generally comprise image manipulation methods applied to a captured frame. While image functions may be physically provided in a variety of forms and memory locations it is convenient to think of them as being logically part of the imaging API . Table 4 sets forth one possible set of image functions 

Any given set of settings and functions along with parameters thereof may be assembled into a data structure termed herein an image profile. An image profile may include indications of illumination aimer settings exposure settings and a list of image functions. The list of image functions describes an image processing sequence which may include multiple instances of any given image function. Image profiles may be implemented within the imaging API . In the present embodiment the imaging API is extended with routines for storing retrieving and loading image profiles in a profile database . Image profiles comprise one or more data structures representing a collection of settings for use of the imaging hardware and instructions for executing image function on an image captured by the imaging hardware . The collection of the settings and instructions in a data structure facilitates the use of a single call for example imgInitCamera to implement all of the settings and instructions contained within a data structure. This facilitates the creation of plural profiles each directed toward a situation experienced by the user of the system. For example one profile may be created for sunny situations while another profile may be created for dark situations. Each of these profiles may be loaded a process described with respect to by using the imgInitCamera call and passing a profile name. Table 5 illustrates some possible profiles 

The use of a data structure to store aimer illumination settings exposure settings and image functions simplifies storage and retrieval and facilitates the provision of solutions to various imaging challenges. Once the image profiles have been constructed a single call will load an indicated image profile. By way of additional example a reoccurring PDT technical support situation involves a user complaining about the performance of an imager in a PDT. Many times the complaints arise from a particular set of circumstances in which the PDT is used for example scanning under fluorescence lights as opposed to sunlight or the darkness of a delivery truck. The customer service representative can attempt to solve the issue by creating a profile and providing same to the customer without requiring the customer to set each setting or call each function individually.

Image profiles may utilize any number of data structures including HTML XML comma delineated files text files records or any number of common database file formats. By using a hierarchical document format such as XML multiple image profiles can easily be organized and stored in a single document. Table 6 provides an example of a document in XML format containing a plurality of image profiles. The profiles illustrated in Table 6 contains profiles corresponding to the example profiles described in Table 5. i.e. Low Light Document Distant Signature BW Signature GS and Normal.

The data structure illustrated in Table 6 is organized into sections separated by tags with each top level sections corresponding to an image profile. Each image profile is further divided into three sections a first for exposure settings Automatic or Manual Exposure Control a second for image functions Processing and a third for aimer and illumination settings Settings .

The exposure settings section will indicate a desired mode fixed or automatic in the illustrated examples of exposure control and provide a series of keys corresponding to parameter settings therefore. It is to be noted that the modes and parameters therefore will be dictated by the imaging hardware utilized and the calls made available by any APIs such as a scan driver API and or an imaging API . The overall purpose of the exposure control section is to control the total amount of light allowed to fall on the image sensor during the process of capturing an image.

The image function section contains an ordered list of post capture image functions to be applied to captured frames. The processing section is divided into sub sections one for each instance of an image process to be applied in the order in which they are to be applied . Each image process sub section may contain keys corresponding to parameter settings for each image process. A flag may also be included indicate whether the image process described by that section is to be executed during the aiming stage or whether the image process is to be executed only as part of the final capture stage. It is to be noted that the availability of any particular image process may vary from device to device and between suppliers of imaging hardware and software.

The illumination and aimer settings section contains a first entry indicating whether illumination is to be used and perhaps a configuration thereof . A second entry indicates whether an aimer is to be projected and perhaps a configuration thereof .

In step a check is made to determine whether a button has been pressed to initiate an image capture operation. In the simplest use case the button is the scan button . It is to be noted that any designated button may be used as may soft keys or menu items. As described hereinabove in an image capture operation the image signal generation system may be operated in two distinct stages aiming and final capture. During the aiming stage frames output by the image signal generation system are displayed on the LCD display but not saved. Once a user is satisfied with the content of the image displayed on the LCD display he or she initiates the final capture stage to save a frame to a memory location.

If the user has not pressed the scan button the method proceeds to step and a determination is made as to whether a new profile has been selected. If a new profile has not been selected the method will return to step . If a new profile has been selected the method proceeds to step and a de initialize command is issued. Thereafter the method returns to step in which the new profile is retrieved.

Once a scan button press is sensed in step the method proceeds to step in . In step aimer and illumination settings are applied. Next in step a frame is pulled from an imager buffer in the image signal generating system using for example the imgCaptureImage command. This frame should have been captured using the exposure settings applied in step . Thereafter in step a quick image size reduction method is applied to the frame pulled in step .

A quick image size reduction method is one that emphasizes speed over versatility. In general most imagers used in PDT are capable of producing images having more pixels than the LCD display is capable of displaying. For example the typical image may have a resolution of 640 480 pixels or even 752 480 or 1280 960 while a typical display on a PDT may only have a resolution of 240 by 320 pixels. Therefore for the user to view the whole image the frame must be resized. To keep the frame rate high a quicker resize method may be preferable for example simply selecting one out of every three pixels for display. While there are a variety of versatile resizing methods that produce superior images they tend to consume processor cycles which may slow the frame rate during the aiming stage.

Next in step image functions that have been flagged for use during the aiming phase are processed. Using the example profiles set forth in Table 6 each image processing section includes a Flag key which may be set to 1 or 0. If the flag is set to 1 the image process is designated for use during the aiming stage and the final image stage . If the flag is set to 0 the image process is designated for use only during the final image stage. By running only select image functions the frame rate of the display during the aiming stage may be increased thereby ensuring that the images the user sees at any instance are closely related to the image produced should the user select that instance to produce a final image. Further certain image functions may interfere with or confuse the processes of aiming. e.g. flipping horizontally or vertically would only confuse the user during the aiming stage.

Thereafter in step the frame as processed in steps and is displayed. In step a determination is made as to whether the button. e.g. the scan button has been released indicating a desire on part of the user to initiate the final capture stage. If the button has not been released. i.e. the user is still aiming the method returns to step and the next frame is pulled. If the button has been released i.e. the user has indicated that he or she desires a final frame capture the method proceeds to step .

The final capture stage starts in step wherein the aimer is turned OFF. This is to avoid any ill effect that the inclusion of reflected aimer light in a captured frame may produce. Thereafter in step a final frame is pulled. Next in step the illumination is turned OFF. In step each image function listed in the processing section is sequentially performed in order. This may include performing selected image functions more that one time wherein each time may utilize a different set of parameters.

Next in step the final frame as modified by the applied image functions is returned to a calling application. At this point the final frame is typically saved to a more persistent memory location. Thereafter in step the image is resized for display on the PDT. As frame rate is no long a concern a resize function that emphasizes versatility or quality over speed may be utilized. For example a variable resize method e.g may be utilized. Thereafter in step the resized frame is displayed on the PDT.

The method starts in step . In step a dynamic profile is generated. The dynamic profile may be implemented as a data structure in a memory on the PDT containing a set of parameters indicative of illumination aimer settings exposure settings and image functions. The dynamic profile may be based on a set of default illumination aimer and exposure settings. It may prove preferable to leave the image process section empty. Step may be considered as compiling a profile similar in manner to step and set forth in utilizing a set of default values.

In step a user is presented with a blank screen upon which he or she may select one of four tabs. Referring to the illustrated tabs are a VIEW tab an IMAGE tab and an EXPOSURE tab and an A I tab . If the user selects the VIEW tab or if the method defaults to the VIEW tab upon startup the method proceeds to the steps illustrated in . If the user selects the IMAGE tab the method proceeds to step . If the user selects the EXPOSURE tab the method proceeds to step . If the user selects the A I tab the method proceeds to the steps illustrated in .

When the VIEW tab is first selected the viewing method starts with C at step wherein current exposure settings from the dynamic profile are applied. Next in step a determination is made as to whether a button e.g. the scan button or other button or menu item used to initiate the aiming phase has been pressed. Once the button is pressed a timer t is started in step .

The time is used to determine which of two modes a user wishes to implement for the aiming stage. The first mode termed the normal mode is as described hereinabove with reference to . In the normal mode the aiming stage is maintained for as long as the user presses the button. To initiate the final capture stage the user releases the button. As may be appreciated it may prove difficult for many users to maintain pressure on the button while simultaneously modifying settings and functions not to mention the various parameters thereof . To assist with generation of a profile a new mode of imager operation hereinafter termed the automatic mode. To enter the automatic mode the user presses and quickly releases the button for example within 100 ms. In the automatic mode the imager is maintained in the aiming stage until the user indicates a desire to exit for example by pressing and releasing the button or selecting a menu entry. It is to be recognized that alternative methods may be used to enter the automatic aiming mode including the pressing of a designated key to the activation of a menu item.

In either mode of operation once the button has been pressed current aimer and illumination settings from the dynamic profile are applied in step . Next in step an image frame is pulled from the imager buffer. The image frame should have been generated using the current exposure settings contained within the dynamic profile. Thereafter in step a quick image size reduction method is applied to the frame pulled in step . As noted hereinabove one possible quick image size reduction method comprises simply selecting one out of every three pixels for display.

Next in step image processing functions that are currently selected and flagged for use during the aiming phase are executed. Thereafter in step the frame as processed in step and is displayed as an image within the display

In step a determination is made as to whether a button release event has issued either indicating a desire to enter the automatic mode or to enter the final capture stage. If no button release event has issued the method returns to step wherein the next frame is pulled using the then current exposure settings as stored in the dynamic profile . If a button release has occurred a determination must be made as to whether the user is indicating a desire to enter the automatic mode or if the user desires to enter the final capture stage. In step the timer t is compared against a pre selected value in the illustrated example 100 ms. If the timer is less than the pre selected value the user has indicated a desire to enter the automatic mode to be exited upon subsequent pressing and release of the button. To ensure that the user has not quickly indicated entry and exit of the automatic mode a check is made in step to determine if button release event is the second button release event. If the button release event is not the second button release event the user has indicated a desire to enter the automatic mode and the method returns to step . If either t is greater than the pre selected value or the button release event is a second button release event the method enters the final capture stage by going to step .

During either aiming mode automatic or normal a user may select another tab or to dynamically adjust exposure and image processing options. During such adjustments the view method may continue to run as a background process or it may be suspended until the user re selects the view tab . If the view method is suspended reentry may be made at C step . This allows a user to immediately see the effects of his or her choices on the image .

Once the user has initiated the final capture mode the method proceeds to step wherein the aimer is turned OFF. This is to avoid any ill effect that the inclusion of reflected aimer light may produce. Thereafter in step a final frame is pulled. Next in step the illumination is turned OFF. In step the selected image functions are sequentially performed in order. As noted this may include performing selected image functions more than once perhaps with varying parameters . Next in step the image is resized for display on the PDT. As frame rate is no long a concern a high quality resize function may be utilized. Thereafter in step the resized frame is displayed on the display of the PDT as an image within the display . While not explicitly illustrated the display is maintained until replaced with another frame or a display associated with another tab. Thereafter the method returns to step to await another button press.

During or after final image capture a user may select another tab or to dynamically adjust exposure and image processing options. During such adjustments the final frame may be maintained in a buffer until the user re selects the view tab . Reentry may be made at C step in which all selected image functions are applied. This allows a user to immediately see the effects of his or her choices on the image . As may be appreciated it may be preferable to store an unmodified copy of the final frame such that the new regiment of image functions may be applied to the original frame as opposed to being applied to a previously modified frame. In this case the stored unaltered frame may be loaded into the frame capture buffer prior to returning at C.

At any time if the user selects the IMAGE tab the method proceeds to step wherein referring to an IMAGE display is generated. The display generally comprises a main window an add button a delete button an indication of a currently selected parameter and modification box in which a value associated with the currently selected parameter may be set. A determination is made in step as to a desired action adding a process indicated by selecting the add button modifying a parameter indicated by selecting a parameter or deleting a process indicated by selecting the delete button .

If the user selects the add button the method proceeds to step and a list of available image functions is presented to the user. Once the user selects an available image process the process is added to the dynamic profile with default parameter values in step . Thereafter in step the display is updated to add the new image process and associated parameters to the main window .

If in step the user chooses to modify a parameter for example by selecting a parameter displayed in the main window the method proceeds to step . In step a modification box is displayed permitting user modification of the value associated with the selected parameter in step . Thereafter in step the dynamic profile is updated with the new value.

If the user selects the delete button the method proceeds to step wherein a selected image process is deleted from the dynamic profile and the main window of the display

After completion of the steps associated with adding modifying or deleting functions the method waits for an indication from the user of a next action to take. e.g. add or delete a process modify a parameter or switch tabs. If the user selects the view tab it may prove beneficial to maintain the display of the indication of a currently selected parameter and the associated modification box in addition to the normal content of the view tab . This will allow the user to adjust the value of the parameter and dynamically view the results on the image .

At any time if the user selects the EXPOSURE tab the method proceeds to step wherein with reference to an EXPOSURE display is generated. The display generally comprises a main window an exposure mode selection box an indication of a currently selected parameter and modification box in which a value associated with the currently selected parameter may be set.

A determination is made in step as to a desired exposure mode the illustrative examples have described two such modes automatic and fixed. Once the exposure mode has been selected either by the user or by default the method proceeds either to step for the fixed exposure mode or to step for the automatic exposure mode. Both branches have similar steps. First a display of parameters is created steps and . Once a parameter has been selected steps and a modification box is displayed permitting user modification of the value associated with the selected parameter. A new value is received in step or . Thereafter in step or the dynamic profile is updated with the new value. Thereafter the method waits for an indication from the user of a next action to take e.g. modify a new parameter switch exposure modes or even switch tabs. It may prove beneficial to maintain the display of the indication of a currently selected parameter and the modification box for a currently selected parameter when the user returns to the view tab . This will allow the user to adjust the value of the parameter and dynamically view the results on the image .

At any time if the user selects the A I tab the method proceeds to step in wherein with reference to an A I display is generated. The display generally comprises an aimer mode selection check box and an Illumination mode selection checkbox .

In step a determination is made as to whether a parmeter has been changed e.g. a box has been checked or unchecked. If a change has been made the method proceeds to step and the aimer and illumination settings are compiled. Thereafter in step the aimer and illumination settings are applied. Thereafter the method waits for an indication from the user of a next action to take. e.g. modify a new parameter or switch tabs. It may prove beneficial to maintain the display of the check boxes and when the user returns to the view tab . This will allow the user to adjust the aiming and illumination and observe the results.

At any time during the illustrative method the user may jump from tab to tab and within tabs the user may jump to any of the desired actions. e.g. add delete or modify. The method ends when the user indicates a desire to end for example by exiting the program or shutting down the PDT.

Although some embodiments of the present invention have been shown and described it will be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the invention the scope of which is defined in the claims and their equivalents. The embodiments described herein focus on the preparation and use of image profiles useful for an image capture operation. It is to be recognized that other types of profiles may be prepared and used for other data capture operations performed by portable data terminals. For example decode profiles could be prepared and used in a decoding operation wherein many of the parameters and processed used in image capture are implemented in addition to the decoding processes. RFID profiles could be used to configure an RFID reader unit for various operating environments.

