---

title: Visualizing camera position in recorded video
abstract: Disclosed is an arrangement () for displaying video footage captured by a controllable camera (), the arrangement comprising a memory () storing the captured footage, means for constructing a representation () of a field of view accessible by the camera (), means for retrieving, from the memory (), the stored footage () and parameters characterising the control state of the camera () when the footage was captured, and means for displaying the footage (), the representation () of the field of view, and an indicator () on the representation () dependent upon the parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07595833&OS=07595833&RS=07595833
owner: Canon Kabushiki Kaisha
number: 07595833
owner_city: Tokyo
owner_country: JP
publication_date: 20060227
---
The present invention relates generally to the area of video surveillance and in particular to visualizing in the context of recorded video footage the orientation of the viewpoint i.e. the controllable camera from which the footage was captured.

Many current surveillance and security systems use a number of controllable network cameras interconnected over an existing corporate local area network LAN or wide area network WAN . The network cameras also referred to as internet protocol IP cameras typically incorporate special purpose computers. These IP cameras constitute nodes in a computer network and can generally be remotely controlled and operated by a user from a suitable interconnected desktop computer. The controllable cameras generally have pan tilt and zoom capability and may also be controlled in regard to other camera attributes such as lens aperture infra red or night vision capability and so on. By using a suitable software application running on their desktop computer the user typically can control pan tilt and zoom aspects of the controllable camera and consequently can receive and view live images from the camera over the controllable field of view that is accessible by the camera.

Video surveillance systems of this type typically generate very large amounts of data. Storage servers which can be implemented using corresponding software applications running on desktop computers can be used to record this video footage to non volatile storage devices such as hard disk drives HDDs .

An arrangement is needed whereby large volumes of recorded surveillance data can be rapidly and conveniently viewed by the user. Furthermore there is a particular need to visualize the control state of the camera capturing the data where this control state relates most importantly but not necessarily exclusively to the orientation and zoom attributes of the camera as these attributes are associated to particular captured video footage. This enables the user to view the captured video footage and equally importantly to intuitively grasp the context of the viewed video within the accessible field of view of the camera.

Disclosed are arrangements hereinafter referred to as arrangements for viewpoint visualization which seek to satisfy the above need by displaying the stored video footage in conjunction with a representation of the field of view accessible by the camera which captured the video footage wherein upon the representation of the field of view an indicator is superimposed to indicate the control state of the camera this control state relating in particular to the pan tilt zoom parameters of the camera associated with the captured video material in question.

By this arrangement referred to as the viewpoint visualization arrangement the user can both review recorded video footage and equally important instantly gain an intuitive understanding of the viewpoint within the camera field of view from which the recorded footage was captured. The indicator depicting the camera orientation is automatically updated as and when the control states of the camera changes in the prefeffed arrangement. Alternately the indicator can be updated according to some other method such as by generating and displaying an indicator which represents the average orientation of the camera over a desired time period. The accessible field of view of the camera is also referred to in the present specification as a panorama or a panorama image .

In one arrangement the panorama image is the complete extent of coverage of the camera in question The panorama image can be generated by stitching together non overlapping images captured using different pan and tilt positions of the camera. In another arrangement the panoramic image can be an artificially generated line representation of the field of view that is accessible by the camera.

The indicator that is superimposed upon the panoramic image is in the preferred arrangement implemented as a rectangle. The position of the rectangle within the panoramic image indicates the camera s pan and tilt position and the size of the rectangle is an indication of the corresponding zoom setting of the camera. The indicator can take other forms however including an arrow an arbitrary geometric shape such as an ellipse or a polygon for example an arbitrary mark such as a cursor line for example a portal such as a shaded rectangle giving the impression of a portal through which the region of interest is viewed and so on.

Another aspect of the viewpoint visualization technique is to use the panorama image in conjunction with a timeline to relate the camera coverage on the panorama image with an indication of a time period on the timeline. This enables a user to visualize the time period during which the camera was focused at a particular region.

Yet another aspect of the viewpoint visualization arrangements is to use the panorama image as a search tool and display the search results on a timeline. The user can typically specify a region of interest in the panorama and visualize one or more time period indications on the time line showing the time s during which the camera was pointing anywhere within the region specified by the user.

Yet another aspect of the viewpoint visualization arrangements is to use the timeline as a search tool and display the search results on the panorama image. The user can typically specify a region of interest on the timeline representing a time period and visualize one or more camera position indications on the panorama showing the positions the camera was in during the specified time period.

According to a first aspect of the present invention there is provided a method for displaying one of a plurality of images stored in a storage server the images having been captured by a controllable camera the method comprising the steps of 

retrieving from the storage server the stored image and parameters characterising the control state of the camera when the image was captured and

According to another aspect of the present invention there is provided an apparatus for displaying one of a plurality of images stored in a storage server the images having been captured by a controllable camera the apparatus comprising 

means for retrieving from the memory the stored image and parameters characterising the control state of the camera when the image was captured and

According to another aspect of the present invention there is provided an apparatus for displaying one of a plurality of images stored in a storage server the images having been captured by a controllable camera the apparatus comprising 

code for retrieving from a memory the stored image and parameters characterising the control state of the camera when the image was captured and

According to another aspect of the present invention there is provided a computer program product including a computer readable medium having recorded thereon a computer program for directing a processor to execute a method for displaying one of a plurality of images stored by a storage server the images having been captured by a controllable camera said program comprising 

code for retrieving from a memory the stored image and parameters characterising the control state of the camera when the image was captured and

According to another aspect of the present invention there is provided a computer program for directing a processor to execute a method for displaying one of a plurality of images stored on a storage server the images having been captured by a controllable camera said program comprising 

code for retrieving from a memory the stored image and parameters characterising the control state of the camera when the image was captured and

Where reference is made in any one or more of the accompanying drawings to steps and or features which have the same reference numerals those steps and or features have for the purposes of this description the same function s or operation s unless the contrary intention appears.

Some portions of the description which follows are explicitly or implicitly presented in terms of algorithms and symbolic representations of operations on data within a computer memory. These representations are one way people skilled in data processing convey the substance of their work to others. An algorithm may be considered a self consistent sequence of steps leading to a desired result. The steps can be those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities may take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise processed. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

Unless specifically stated otherwise terms in the present specification such as displaying constructing retrieving characterising capturing combining and outputting refer to the actions and processes performed within a computer system or similar electronic device. In particular the computer system manipulates and transforms data represented as physical electronic quantities into other data. The data are stored within various registers and memories within the computer system.

The present specification also discloses apparatus for performing the operations of the viewpoint visualization methods. Such apparatus may be specially constructed for the required purposes or may comprise a general purpose computer or other device selectively activated or reconfigured by a computer program stored in the computer. The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general purpose machines may be used with programs in accordance with the teachings herein. Alternatively the construction of a more specialized apparatus to perform the required method steps may be appropriate. The structure of a conventional general purpose computer will appear from the description below.

In addition the present invention also implicitly discloses a computer program in that it would be apparent to the person skilled in the art that the individual steps of the preferred viewpoint visualization method described herein are to be put into effect by computer code which directs a processor to execute the viewpoint visualization method. The computer program is not intended to be limited to any particular programming language and implementation thereof. It will be appreciated that a variety of programming languages and coding thereof may be used to implement the teachings of the disclosure contained herein. Moreover the computer program is not intended to be limited to any particular control flow. There are many other variants of the computer program which can use different control flows without departing the spirit or scope of the invention. Furthermore one or more of the steps of the computer program may be performed in parallel rather than sequentially.

Such a computer program may be stored on any computer readable medium. The computer readable medium may include storage devices such as magnetic or optical disks memory chips or other storage devices suitable for interfacing with a general purpose computer. The computer readable medium may also include a hard wired medium such as exemplified in the Internet system or wireless medium such as exemplified in the GSM mobile telephone system. The computer program when loaded and executed on such a general purpose computer effectively results in an apparatus that implements the steps of the preferred viewpoint visualization method.

The camera supported by the system typically allows external software applications such as and to control the camera and to receive video signals captured by the camera over the network using HTTP. The Storage Server software Application and the Viewer software application use HTTP to communicate with the camera over the network . The Storage Server software Application can store images captured from the camera onto a video and camera database . The database is a software entity that is effected on a suitable hardware platform and may for example be effected as a suitable memory partition in a hard disk on a desktop computer see upon which the storage server application runs. The video and camera database in the described example comprises two components namely a video database component which stores the video data captured by the camera and a camera database which stores information identifying the camera i.e. the name or label used to designate the camera as well as IP address and port numbers by which the camera is attached to the network . The video and camera database is managed and maintained by the storage server .

The Storage Server Application also provides access for one or more Viewer Applications to recorded video information stored on the database . The images captured by the camera and stored on the database are typically in Joint Photographic Experts Group JPEG format however this is not intended to limit the types of formats which can be used. In this document these images are typically referred to as JPEG images or JPEG frames. The Viewer Application typically has a Graphical User Interface GUI enabling a user to view video footage stored on the database .

A sequence of JPEG frames is referred to as a video clip or simply as video. A video clip can be logically segmented into sub clips each comprising a contiguous subset of the frames of the video clip based on one or more criteria such as camera position. The Viewer Application GUI is capable of viewing recorded images recorded video clips recorded video sub clips and or successive video sub clips.

As noted the Viewer Application typically communicates with the Storage Server Application using HTTP. This communication is used by the Viewer Application to learn which cameras such as are known to the Storage Server Application and to access video data recorded on the database from the camera . The Viewer Application enables a user of the system to visualize the control state in particular the orientation that the camera was in when a particular recorded image from that camera being viewed was captured. This is typically done in conjunction with a panorama image which may be either stored in a memory in the camera or elsewhere. The orientation of the camera can be described in terms of the control state of the camera at the time the image was captured where the control state is defined in terms for example of a time of capture of the image a pan attribute a tilt attribute and a zoom attribute.

The panorama image represents the complete available range also referred to as the field of view accessible by the camera . The Storage Server typically stores video data captured from the cameras into flat files stored on a hard disk which may be located for example on a dedicated computer such as in . The recorded video database in typically comprises video data files and video index files. The camera database in is typically a file containing information about camera names IP address and port numbers.

The instructions may be formed as one or more code modules each for performing one or more particular tasks. Some of the software modules may also be divided into two separate parts in which a first part performs the viewpoint visualization methods and a second part manages a user interface between the first part and the user. The software modules may be stored in a computer readable medium including the storage devices described below for example. The software modules are loaded into the computers from the respective computer readable media and then executed by the respective computers. A computer readable medium having such software or computer program recorded on it is a computer program product. The use of the computer program products in the computers of preferably effects an advantageous apparatus for viewpoint visualization.

The computer system is formed by the computers and as well as the hidden computers in the cameras and input devices such as a keyboard and mouse output devices including a printer a display device and loudspeakers . A Modulator Demodulator Modem transceiver device is used by the computer for communicating to and from a communications network for example connectable via a telephone line or other functional medium. The modem can be used by the computer to obtain access via the Internet and other network systems such as a Local Area Network LAN or a Wide Area Network WAN to the network and the devices applications connected thereto. The modem may be incorporated into the computer in some implementations.

In the example of the computer runs the viewer application shown running in the memory and the computer runs another viewer application . The storage server application runs on the computer upon which the video and camera database is also located. The camera upon which a network camera software application runs and another camera upon which a network camera software application runs are also connected to the network .

The computer typically includes at least one processor unit and the memory unit for example formed from semiconductor random access memory RAM and read only memory ROM . The module also includes a number of input output I O interfaces including an audio video interface that couples to the video display and loudspeakers an I O interface for the keyboard and mouse and optionally a joystick not illustrated and an interface for the modem and printer . In some implementations the modem may be incorporated within the computer for example within the interface . A storage device is provided and typically includes a hard disk drive and a floppy disk drive . A magnetic tape drive not illustrated may also be used. A CD ROM drive is typically provided as a non volatile source of data. The components to of the computer typically communicate via an interconnected bus and in a manner which results in a conventional mode of operation of the computer known to those in the relevant art. Examples of computers on which the described arrangements can be practised include IBM PC s and compatibles Sun Sparcstations or alike computer systems evolved therefrom.

Typically the viewer application program is resident on the hard disk drive and is read and controlled in its execution by the processor . Intermediate storage of the program and any data fetched from the network may be accomplished using the semiconductor memory as shown in possibly in concert with the hard disk drive . In some instances the viewer application program may be supplied to the user encoded on a CD ROM or floppy disk and read via the corresponding drive or or alternatively may be read by the user from the network via the modem device . Still further the software can also be loaded into the computer from other computer readable media. The term computer readable medium as used herein refers to any storage or transmission medium that participates in providing instructions and or data to the computer for execution and or processing. Examples of storage media include floppy disks magnetic tape CD ROM a hard disk drive a ROM or integrated circuit a magneto optical disk or a computer readable card such as a PCMCIA card and the like whether or not such devices are internal or external of the computer . Examples of transmission media include radio or infra red transmission channels as well as a network connection to another computer or networked device and the Internet or Intranets including e mail transmissions and information recorded on Websites and the like.

The method of viewpoint visualization may alternatively be implemented in dedicated hardware such as one or more integrated circuits performing the functions or sub functions of viewpoint visualization. Such dedicated hardware may include graphic processors digital signal processors or one or more microprocessors and associated memories.

The HTTP Interface module is based upon the HTTP protocol. This module serves as the external interface of the storage server and is used to communicate with the Viewer Application . This interface module implements a web server function which supports the HTTP protocol in handling requests from the Viewer Application . The interface module implements the necessary functionality to handle the HTTP commands supported by the Storage Server . The HTTP requests received by the storage server application via the interface module are typically in the form of a URL having the following general form http nvr 1 where the URL parameters in 1 are defined as follows 

The Video access module deals with recorded video information which is typically organized as a sequence of JPEG images in chronological order in one or more files in the database see . According to one arrangement the aforementioned files comprise video data files such as in and associated video index files such as in . The respective filenames and of the video data file and the index file have camera name embedded in them this forming the association between the recorded files and the corresponding camera with which the files were generated. Other file arrangements can also be used.

The video index files such as provide a mechanism for fast access to the associated video data files such as . These index files typically have one entry record such as for every frame in the data file also referred to as a video image record such as . Each such entry typically contains a timestamp e.g. in which represents the time of image capture and a file offset e.g. in which is typically the location of the associated image in the video data file. The timestamps typically have at least millisecond precision. show respectively the format of the video data file and the format of the video index files. Each record for an image in the video data file has a header component e.g. in which is typically a JPEG header followed by an image data component e.g. in .

The Video Access module provides the functionality necessary to open the video data file associated with a particular camera based on the camera name in the filename . Furthermore the video access module can seek i.e. can search for a particular frame such as in the video data file by searching the associated video index file on the basis of for example a particular start time date stored in the corresponding video index record . After completing the seek operation the video access module can start retrieving the corresponding image frame such as . The video index file is thus used to implement a particularly efficient seek mechanism. Once the video data file is opened the user can retrieve video frames such as one at a time until end of the file is reached.

Although the arrangement described in relation to B and stores PTZ parameters on a per image basis other arrangements can equally be used. Thus for example information relating to N images can be stored as one information block this information enabling PTZ parameters for each of the N images to be derived. This approach can be used for example if video information is stored in MPEG rather than JPEG format.

Returning to the Video Recording module implements the functionality of recording images from the network cameras such as and storing the recorded images in video data files such as . The corresponding video index files such as are also created and updated by this module .

The Operating system services module is the Application Programming Interface API provided by the operating system or the platform such as the computer in on which the storage server application runs. The various functional aspects of the Storage Server Application are described in regard to the following figures.

If the command is GetCameraList then the process is directed from the step via an arrow to a step in which the storage server returns a list of cameras stored by the storage server in the video and camera database . This is described in detail in regard to . Returning to the step if the command is GetVideo then the process follows an arrow to a step in which the storage server returns recorded video from for instance the video data file back to the Viewer Application . This is described in detail in regard to . Typically the Storage Server starts a new thread to process GetVideo requests so that the storage server can handle multiple requests from one or more Viewer Applications such as concurrently.

Returning to the step if the command is GetAvailableVideo then the process follows an arrow to a step in which the storage server returns the time periods during which video was available for the specified range of camera positions. This is described in detail in regard to . Typically the storage server starts a new thread to handle this command.

Returning to the step if the command is GetCameraCoverage then the process follows an arrow to a step in which the storage server returns a list of pan tilt and zoom positions of the camera which indicates the various positions the camera was in during a particular recording period. Typically the storage server starts a new thread to handle this command. This is described in more detail in regard to .

After commands are successfully processed in appropriate ones of the steps and the process is directed as depicted by the symbol back to the step in which the Storage Server waits for the next HTTP request from a Viewer Application.

Returning to the step once the end of file is reached or the end date time is reached on the video file the process is directed by a YES arrow to a step in which the storage server sends the HTTP response back to the Viewer application . The response body is line oriented and contains one set of pan tilt and zoom values per line. The process then terminates with an END step .

Then in a step the process reads a frame from the video data file commencing with the frame having the correct offset as determined in the step . A following step determines if an end of file indication has been detected in the video data file . If this is not the case then the process follows a NO arrow to a step in which the frame that is read in the step is sent back to the viewer application in a HTTP response message each such frame being sent as multi part data. The multi part data contains the image data and the timestamp which represents the time of capture of the image from the camera. The process then is directed back to the step . Returning to the step if the step detects an end of file indication then the process follows a YES arrow to a step in which the HTTP response is terminated and the connection to the Viewer Application is closed. The process then terminates in an END step .

A following step reads a record such as see from the index file . A following step determines if an end of file indication has been detected. If this is not the case then the process follows a NO arrow to a step which determines if the pan and tilt range parameters extracted from the corresponding image header of the extracted record are within the specified range read in the step . If this is the case then the process follows a YES arrow and a following step adds the timestamp associated with the record to a list of timestamp ranges to be sent back in the response. Timestamps are stored in sorted order for building up the timestamp ranges and consecutive timestamps are grouped together to form a range with a start and end provided that the difference between consecutive timestamps is within a threshold typically determined by the lowest frame rate supported by the cameras. The process is then directed back to the step .

Returning to the step if the pan and tilt extracted from the header is not in the range then this frame is skipped the process is directed according to a NO arrow back to the step and the Storage Server proceeds with the next frame. Returning to the step once all records in the index file are scanned an end of file indication is detected by the step which then directs the process via a YES arrow to a step . The step returns the list of accumulated time periods back to the viewer application in the body of a HTTP response message. Each line of the body will typically comprise a start and an end timestamp. The process then terminates in an END step .

Turning from the storage server application to the camera it is noted that the camera runs the network camera application see in order to support a HTTP based protocol for receiving camera control commands and for transmitting captured image information. These camera HTTP commands have the following general form http 2 where 

Returning to it is noted that the panorama image represents in one arrangement the complete extent of camera coverage. This image can according to one arrangement be created by panning and tilting the camera to point at all possible non overlapping regions in the camera Field of View and capturing one image at each one the aforementioned positions. These individual images are then typically attached to one another to reflect their spatial positions and presented as a single panorama image.

In addition to the above GUI elements two other GUI elements are displayed by the viewer application . These elements are shown in and and comprise the following elements.

Panorama Window The panorama window e.g. in displays the panorama image captured from the camera . The panorama window also displays camera control state information such as camera position and zoom angle indication typically as a rectangular region. There is one such indication for every video window that is displaying a frame captured from the camera and recorded on the storage server . There is typically one panorama window for a camera whose images are cuffently being displayed. If the Show Trail option is selected before the PLAY button is clicked or the timeline is double clicked with the mouse then there will typically be one or more semi transparent rectangular regions e.g. in displayed on the panorama window in which indicate camera coverage in the recorded video. The double clicking operation as applied to a particular graphical control such as the timeline is refeffed to more generally as designating the noted control. The panorama window e.g. in is also used to display camera coverage search results such as when the user selects the associated time period of interest on the timeline and clicks the search button . This aspect of the display is described in relation to in .

When more than one panorama window e.g. in is open in the Viewer Application the one of the panorama windows is designated as the active panorama window. This active state can be changed by the user clicking using the mouse on a panorama window which is not currently active to make it active. The active panorama window is typically identified by its title bar. The title bar of the active one typically has the word Active appended see in . The timeline display is always associated with the active panorama window and all indications on the timeline are with respect to the active panorama window. When the active panorama window changes as a result of user action typically clicking on another not currently active panorama window the timeline is also updated and refreshed accordingly.

Video Window A video window e.g. in displays the stored image captured from the camera and recorded on the Storage Server . Along with the image display a timestamp representing the time of image capture is displayed below the image display . Every time the user selects a camera using specifies a start date and time using and respectively and clicks the PLAY button a new video window such as is opened to display frames from the specified start time. Another way of creating a video window is by double clicking using the mouse on the timeline in an area which indicates available video this will be described in more detail in regard to .

The camera coverage indication on the panorama is typically shown as semi transparent labelled rectangular regions and for time periods previous to 10 Dec. 2004 at 04 30 04. Each of these displayed regions has a corresponding representation and respectively on the top half of the timeline. These timeline representations are in the present example rectangular regions with the same respective sequence number labels and colours. The rectangular regions on the timeline represent the respective time periods for which the camera was in the corresponding region displayed on the panorama image.

In addition to the aforementioned labelled rectangular regions on the panorama and on the timeline there is also an unlabelled rectangular region on the panorama and a corresponding unlabelled rectangular region on the timeline which correspond to the time period for the camera position .

From a terminology perspective the term recorded periods refers to the fact that for a first time period say 10 Dec. 2004 02 30 00 to 10 Dec. 2004 03 15 00 camera was pointing at the region 1 i.e. in the panorama . Thereafter for a second time period say 10 Dec. 2004 03 15 10 to 10 Dec. 2004 04 05 00 camera was pointing at the region 2 i.e. in the panorama . Thereafter for a third time period say 10 Dec. 2004 04 05 10 to 10 Dec. 2004 04 30 04 camera was pointing at the region in the panorama . All the aforementioned recorded periods are historic in the sense that all the video information presented by the system is made up of video sub clips derived from previously recorded captured video information however the aforementioned first time period occurred prior to the second time period which in turn occurred prior to the third time period.

Each trail region such as on the panorama window can be displayed for example for a predetermined time see after the associated video images have been displayed in the video window after which time the display of the trail region i.e. display of the sub clips associated with the region ceases to be displayed. Alternately the trail region can be continuously displayed until the user operates a CLEAR control such as in .

Further the user has subsequently chosen Camera from the pick list selected a different start date of 19 Dec. 2004 and a different start time prior to 06 23 44 and clicked on the PLAY button again. The viewer application consequently opens a panorama window for Camera and a video window for displaying recorded video information relating to the specified start date and time. A region on the panorama view indicates the control state of Camera during the time period associated with the display . The end result is that there is a composite representation consisting of the two panorama windows and and the associated two video windows and that are opened one for Camera and another for Camera respectively.

In the example shown in the user has chosen Camera from the pick list has specified a start date of 10 Dec. 2004 and a start time prior to 06 00 04 and has clicked on the PLAY button . The viewer application opens the panorama window for Camera and a video window for displaying video from the specified start date and time. Further the user also specified the rectangular region this being the region of interest previously referred to on the Panorama window and clicked on the SEARCH button .

The Viewer Application determines available video indication s from the Storage Server for the designated region and displays the results in the bottom half of the time line as shown by the shaded rectangular regions . These regions indicate time periods for which recorded video is available for the user specified shaded region in the panorama image .

Returning to and particularly to the playback session management module it is noted that whenever the user clicks on a PLAY button a new playback session is created. This session manages the communication between the Viewer Application and the Storage Server Application . A video window such as which displays the recorded video frame is associated with each playback session. All video windows showing recorded video of the same camera such as Camera are associated with a single panorama window such as displaying a panorama image from the camera whose recorded video is being viewed.

Typically a unique colour is associated with each playback session and this colour is used to paint the borders as depicted by and in of the video window e.g. the windows and in as well as to paint rectangular regions such as and in on the timeline and on the panorama window such as and in . The reason for associating a unique colour with a video window a corresponding region on a timeline and a corresponding region on a panorama window is to create a visual association between the video window displaying a recorded frame with its corresponding position or range indicator on the panorama. Further the aforementioned use of colour coordination also serves to distinguish multiple such position indications corresponding to different video windows on a single panorama image.

In order to correlate rectangular regions within panorama windows indicating camera coverage with their corresponding regions in the timeline indicating time periods sequence numbers such as and for the panorama window and and for the timeline in are used to label the rectangular regions. These sequence numbers are displayed whenever a camera moves to a new position.

When the Show Trail option is used the playback session module maintains all the data necessary to show indications of time periods on the time line. The data related to available video indications is stored in the memory in along with the panorama image and shared among all playback sessions associated with the same panorama image.

Returning to the Storage Server communication module deals with communication between the viewer application and the Storage server . This involves sending HTTP requests to the Storage Server and processing the received HTTP responses from the storage server .

The Camera communication module handles all aspects of communicating between the viewer application and a camera such as in order to retrieve a panorama image and associated information from the camera.

The Image decoder module is typically a JPEG decoder that is used to render JPEG images on the display device .

The Platform GUI support module is in the present example the GUI support infrastructure provided by the software operating system of the computer in . This module is used to develop the GUI components of the Viewer Application.

The Operating system services module represents the Application Programming Interface provided by the operating system or platform of the computer on which the Viewer Application runs.

In a following step the Viewer Application waits for some user action. The Viewer Application is typically implemented as an event driven application where user actions such as selection of a GUI control are reported to the application asynchronously as events occur. When a user action occurs in a subsequent step then in a following step the Viewer Application processes the user input and the process returns via an arrow to the step .

The Viewer Application thus has an event ioop comprising the steps and the loop which waits for events and dispatches them appropriately. The user action will typically include retrieving recorded video available video indications or camera coverage indications from the Storage Server Application . The Viewer Application responds to user action by retrieving recorded video available video indications or camera coverage indications from the Storage server . This is described in detail in regard to . After processing the current user input the Viewer Application waits for more user input.

If the PLAY button is pressed then the process follows a PLAY arrow to a step in which the Viewer Application retrieves the camera name its IP address and port number as well as the start date and time from the respective text boxes in the GUI . In a further step the Viewer Application creates a playback session to get video as described in relation to . The process is then directed to an END step where the process terminates.

Returning to the step if the SEARCH button is pressed then the process follows a SEARCH arrow to a step in which the Viewer Application determines whether the user is searching using the timeline or the panorama Window. If panorama window based searching is being used then the process follows an arrow to a step in which the Viewer Application searches for available video as described in relation to . The process is then directed to the END step . Returning to the step if timeline based searching is being used then the process follows an arrow to a step in which the Viewer Application retrieves the start and end time s designated by the user on the timeline e.g. see in . In a following step the Viewer Application retrieves the camera coverage in a manner that is described in relation to the process in . The process is then directed to the END step .

Returning to the step if the user presses the EXIT button then the process follows an EXIT arrow to a step which exits the viewer application . The process is then directed to the END step .

Returning to the step if the CLEAR button in is pressed then the process follows an arrow to a step which clears all indications from the active panorama window and from the timeline. These indications include the trail indications such as in the available video indication in and the camera coverage indication in .

Returning to the step if the user double clicks with the mouse on the timeline then the process follows an arrow to a step in which the Viewer Application gets the camera name associated with the active panorama window and the date and time corresponding to the location where the user double clicked from the timeline. In a following step the Viewer Application creates a playback session to get video as described in regard to . It is noted that both the steps and implement the process described in relation to .

Returning to the step if an area in the panorama is selected and the SEARCH button is pressed then the Viewer Application proceeds to doing a search for available video as described in flowchart of .

In a following step the Viewer Application sends the GetAvailableVideo command to the Storage Server with the camera name and pan and tilt coordinates corresponding to the rectangular region indicated by the user. Thereafter in a step the Storage Server returns an HTTP response that contains as set out in a following statement time ranges which indicate video available for that camera when the camera was in the region the user specified earlier. In a subsequent step the Viewer Application updates the timeline to indicate available video as one or more rectangular regions spanning across the timeline in the bottom half of the timeline using the time periods returned in the HTTP response see in . The process then terminates with an END step .

A following step determines if a panorama window already exists. If this is not the case then the process follows a NO arrow to a step in which the Viewer Application retrieves and displays the panorama window as described in relation to . In a following step the Viewer Application creates a new video window for showing recorded video for the selected camera. The video window for displaying recorded frames is displayed with the chosen border colour. In a following step the Viewer Application starts retrieving frames from the Storage Server as described in relation to . Thereafter in a step the Viewer Application processes the received frames and displays them as described in relation to . Returning to the step if a panorama window does exist then the process follows a YES arrow to the step .

The received video frames are thus processed one frame at a time till there are no more frames to be processed. Each frame is displayed in the video window one after another in the order they are received. Along with the display of the video frame the timestamp associated with the video frame which represents the time of capture of the frame from the camera is also displayed. The camera position indication is continually updated in the panorama window and the timeline is also updated if necessary. Details of how the panorama and timeline are updated are described in relation to .

Returning to the step if the pan tilt and zoom values are different from the previous frame then the process follows a YES arrow to a step which determines if the show trail function is active. If Show Trail is on for the playback session then the process follows an ON arrow to a step which changes the rectangle corresponding to the pan tilt and zoom settings of the previous frame into a semi transparent rectangular region which is labelled with the current value of the sequence number for the session.

In a following step the timeline is also updated to indicate a rectangular region with the same sequence number label to show the time period the camera was in the previous position. The time period is determined by using the saved timestamp corresponding to the first frame in the previous camera position and the previous frame s timestamp which happens to be the last frame in the previous camera position. The semi transparent rectangular regions drawn previously to this one are made progressively more transparent. If a region becomes fully transparent and hence invisible the corresponding indication on the timeline erased.

In a following step the timestamp for the current frame is saved and later used to draw the rectangle in the timeline. A subsequent step increments the sequence number for the session by 1. Returning to the step if the Show trail option is off for the playback session then the process follows an OFF arrow to a step in which the rectangle corresponding to the pan tilt and zoom settings of the previous frame is erased. Thereafter in a step a new rectangle is drawn corresponding to pan tilt and zoom values of current recorded frame. Alternatively the rectangle indication on the panorama rather than being just the current camera position could be implemented as some function such as union or average of the last few distinct camera positions. The process then terminates at the END step . Returning to the step after the sequence number is incremented the process is directed to the step .

The Storage Server returns in a subsequent step an HTTP response that contains pan tilt and zoom values indicating the various positions the camera was in during the specified period. In a following step the Viewer Application updates the panorama window to show rectangular regions indicating camera position using the pan tilt and zoom values returned in the response. The pan tilt and zoom values are in camera coordinates specified in 1 100degree units and they are converted to pixel coordinates using the transformation matrix in before being displayed. The process then terminates with an END step .

The pan and tilt settings extracted from the JPEG header of the recorded video frame are in Camera coordinate system which is expressed in 1 100degree units.

When this transformation matrix is applied to pan and tilt values extracted from the header the corresponding center of the rectangular region in pixel coordinates is obtained. The width and height of the rectangle are determined as follows. image aspect ratio image width image height rectangle width frame zoom Sx rectangle height rectangle width image aspect ratio

It is apparent from the above that the arrangements described are applicable to the image processing and surveillance industries.

The foregoing describes only some embodiments of the present invention and modifications and or changes can be made thereto without departing from the scope and spirit of the invention the embodiments being illustrative and not restrictive.

The aforementioned preferred viewpoint visualization method s comprise a particular control flow. There are many other variants of the preferred viewpoint visualization method s which use different control flows without departing the spirit or scope of the invention. Furthermore one or more of the steps of the preferred method s may be performed in parallel rather sequential.

