---

title: Insertion of standard text in transcriptions
abstract: A computer program product, for automatically editing a medical record transcription, resides on a computer-readable medium and includes computer-readable instructions for causing a computer to obtain a first medical transcription of a dictation, the dictation being from medical personnel and concerning a patient, analyze the first medical transcription for presence of a first trigger phrase associated with a first standard text block, determine that the first trigger phrase is present in the first medical transcription if an actual phrase in the first medical transcription corresponds with the first trigger phrase, and insert the first standard text block into the first medical transcription.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08286071&OS=08286071&RS=08286071
owner: eScription, Inc.
number: 08286071
owner_city: Needham
owner_country: US
publication_date: 20060629
---
Healthcare costs in the United States account for a significant share of the GNP. The affordability of healthcare is of great concern to many Americans. Technological innovations offer an important leverage to reduce healthcare costs.

Many Healthcare institutions require doctors to keep accurate and detailed records concerning diagnosis and treatment of patients. Motivation for keeping such records include government regulations such as Medicare and Medicaid regulations desire for the best outcome for the patient and mitigation of liability. The records include patient notes that reflect information that a doctor or other person adds to a patient record after a given diagnosis patient interaction lab test or the like.

Record keeping can be a time consuming task and the physician s time is valuable. The time required for a physician to hand write or type patient notes can represent a significant expense. Verbal dictation of patient notes offers significant time savings to physicians and is becoming increasingly prevalent in modern healthcare organizations.

Over time a significant industry has evolved around the transcription of medical dictation. Several companies produce special purpose voice mailbox systems for storing medical dictation. These centralized systems hold voice mailboxes for a large number of physicians each of whom can access a voice mailbox by dialing a phone number and putting in his or her identification code. These dictation voice mailbox systems are typically purchased or shared by healthcare institutions. Prices can be over 100 000 per voice mailbox system. Even at these prices these centralized systems save healthcare institutions vast sums of money over the cost of maintaining records in a more distributed fashion.

Using today s voice mailbox medical dictation systems when a doctor completes an interaction with a patient the doctor calls a dictation voice mailbox and dictates the records of the interaction with the patient. The voice mailbox is later accessed by a medical transcriptionist who listens to the audio and transcribes the audio into a text record.

The medical transcriptionist s time is less costly for the hospital than the doctor s time and the medical transcriptionist is typically much more familiar with the computerized record keeping systems than the doctor is so this system offers a significant overall cost saving to the hospital.

To reduce costs further health care organizations have deployed speech recognition technology. Some efforts have been made to utilize speech recognition technology for the purpose of producing written documents. Such efforts have met with limited success however since producing a literal transcription of a dictation has not resulted in a document sufficiently close to the desired final document.

Until recently most deployed automatic speech recognition systems were front end or real time systems. In these applications the speaker interacts directly with the speech recognition device which hypothesizes the spoken words and outputs them to the computer terminal with a short delay. The speaker may then be required to correct the output either using voice commands or by typing.

In an application of background speech recognition to medical transcription the automatic speech recognition ASR process is run off line without real time clinician interaction. The speaker dictates normally and the speech recognition process is run in batch mode at a later time. Draft transcriptions produced by the ASR process may then be edited by the clinician or by a Medical Transcriptionist MT before being added to the medical record. An example of this type of ASR application is the EditScript product from eScription.

In background speech recognition the speaker does not have access to the text as s he dictates. As such the speaker cannot interact with the speech recognition device in order to improve the appearance of the document. Moreover the use of such verbal directives is counter productive to the efficiency of the dictation process. Health care clinicians are used to simply dictating the medical information in the way that they feel comfortable and assuming that the final documented will be formatted according to generally accepted standards.

A hybrid of the front end and background speech recognition process is also possible. In these near real time applications the speaker dictates for some period of time before indicating to the speech recognition device that the dictation has been completed. At this point the speech recognition device completes its processing on all of the audio received and outputs the entire transcription to the computer terminal for editing either with voice or typing by the user. In general front end speech recognition software is resident on the computer at which the speaker is speaking whereas background speech recognition runs on a high end server which is often remote from the dictation device. Near real time speech recognition may be run in either of these modes or in a combination scenario where some of the speech recognition processing is done on the speaker s computer and some is done on a remote high end server.

Often health care clinicians perform procedures and examinations which are similar to those they have performed previously. For example a Urologist may perform several routine vasectomies each day or a Radiologist may examine dozens of normal chest x rays during a shift. In cases such as this the medical record for the incidence of service is nearly if not completely identical to the document for all other such services. Accordingly clinicians often dictate words to the effect that a certain standard document should be inserted as the transcription for the dictation. Sometimes this standard document is the entire desired transcription. For example a Urologist may say Please use my normal vasectomy template indicating that the entire standard vasectomy description should be inserted as the transcription. In other circumstances the standard text may comprise a subset of the desired final transcription in which case the clinician will continue with the remainder of the dictation in the usual fashion. Clinicians may dictate several such standard sub sections within the course of a dictation and may also include standard dictation. The MT analyzes the dictation to determine whether standard text at least for that speaker can be inserted and obtains and inserts the standard text as appropriate.

In these circumstances the medical transcriptionist may have access to the text that is indicated by the dictation. In general the MT will use the transcription device to access a list or menu of files each file representing standard text. The appropriate file is then selected and the standard text inserted into the transcription document. Selection and insertion of standard texts into transcription documents requires experience and depending on how large the list of potential files can be very time consuming. In addition managing standard documents is challenging for health care institutions particularly when MTs are dispersed geographically and their access to the transcription system is not synchronous with changes to the documents. If the MT does not have access to the most recent version of a standard document the transcription may need to be reviewed and edited by a transcription supervisor. This workflow is especially costly.

Embodiments of the invention are directed to the use of speech recognition to insert standard text into medical transcriptions as well as the system workflow needed to support this behavior.

In general in an aspect the invention provides a computer program product for automatically editing a medical record transcription the computer program product residing on a computer readable medium i.e. a computer readable storage medium and including computer readable instructions for causing a computer to obtain a first medical transcription of a dictation the dictation being from medical personnel and concerning a patient analyze the first medical transcription for presence of a first trigger phrase associated with a first standard text block determine that the first trigger phrase is present in the first medical transcription if an actual phrase in the first medical transcription corresponds with the first trigger phrase and insert the first standard text block into the first medical transcription.

Implementations of the invention may include one or more of the following features. The computer program product further includes instructions for causing the computer to insert text from the first transcription of the dictation proximate to the actual phrase corresponding to the first trigger phrase into the first standard text block. The instructions for causing the computer to insert text are configured to cause the computer to replace at least a portion of the first standard text block with the text proximate to the actual phrase corresponding to the first trigger phrase. The instructions for causing the computer to insert text are configured to cause the computer to fill a placeholder portion of the first standard text block with the text proximate to the actual phrase corresponding to the first trigger phrase. The computer program product further includes instructions for causing the computer to prompt a user for at least one user selected trigger phrase prompt the user for user selected standard text corresponding to the user selected trigger phrase and store the user selected trigger phrase in association with the user selected standard text for use in determining that the user selected trigger phrase is present in the first transcription. The computer program product further includes instructions for causing the computer to compare multiple edited medical transcriptions corresponding to multiple dictations identify similar portions of the multiple medical transcriptions determine an automatically determined standard text block corresponding to the similar portions and store at least one indication of texts from transcriptions of the multiple dictations corresponding to the similar portions as at least one automatically determined trigger phrase corresponding to the automatically determined standard text block. The computer program product further includes instructions for causing the computer to determine presence of a second standard text block in an edited medical transcription determine a second trigger phrase in a second medical transcription associated with the edited medical transcription the second trigger phrase corresponding to the second standard text block and store the second trigger phrase for use in determining presence of the second trigger phrase in another transcription. The instructions for causing the computer to determine that the first trigger phrase is present in the first transcription cause the computer to so determine if the actual phrase in the first transcription is within a threshold likeliness of being a possible form of the first trigger phrase. The computer program product further includes instructions for causing the computer to obtain the first trigger phrase based upon at least one of speaker and worktype associated with the dictation. The computer program product further includes instructions for causing the computer to display a list indicative of available standard text blocks including the first standard text block and providing descriptions of content of the available standard text blocks.

In general in another aspect the invention provides a language processor module for processing a medical dictation transcription the module being configured to compare words of the transcription with a trigger phrase associated with a standard text block determine that the transcription includes the trigger phrase and replace if the transcription includes the trigger phrase the content of the transcription corresponding to the trigger phrase with the standard text block in the transcription.

Implementations of the invention may include one or more of the following features. The module is further configured to insert text from the transcription proximate the text corresponding to the trigger phrase into the first standard text block. To insert text from the transcription that is proximate the text corresponding to the trigger phrase into the first standard text block the module is configured to replace at least a portion of the standard text block with the text proximate to the text corresponding to the trigger phrase. To insert text from the transcription that is proximate the text corresponding to the trigger phrase into the first standard text block the module is configured to fill a placeholder portion of the standard text block with the text proximate to the text corresponding to the trigger phrase. To determine that the transcription includes the trigger phrase the module is configured to determine if the actual phrase in the transcription is within a threshold likeliness of being a possible form of the trigger phrase. The module is further configured to retrieve the trigger phrase from storage based upon at least one of speaker and worktype associated with the dictation.

In general in another aspect the invention provides a language processor module for processing a medical dictation transcription the module being configured to prompt a user for at least one user selected trigger phrase prompt the user for user selected standard text corresponding to the user selected trigger phrase and store the user selected trigger phrase in association with the user selected standard text for retrieval and use in determining that the user selected trigger phrase is present in a medical dictation transcription.

Implementations of the invention may include one or more of the following features. The module is further configured to prompt the user for at least one of a speaker and a worktype to be associated with the user selected standard text and the user selected trigger phrase and store the at least one of speaker and worktype in association with the user selected standard text and the user selected trigger phrase.

In general in another aspect the invention provides a language processor module for processing a medical dictation transcription the module being configured to compare multiple edited medical transcriptions corresponding to multiple dictations identify similar portions of the multiple medical transcriptions determine an automatically determined standard text block corresponding to the similar portions and store an indication of at least one portion of text from at least one of the transcriptions of the multiple dictations corresponding to the similar portions of the edited medical transcriptions as an automatically determined trigger phrase corresponding to the automatically determined standard text block for retrieval and use in determining that the automatically determined trigger phrase is present in another medical dictation transcription.

Implementations of the invention may include one or more of the following features. To determine the automatically determined standard text block the module is configured to determine that the similar portions are above a threshold amount of being identical. The module is further configured to verify the similar portions by comparing at least one of the similar portions to at least one other transcription for a speaker of the multiple dictations to determine presence of another text portion similar to the at least one of the similar portions.

In general in another aspect the invention provides a language processor module for processing a medical dictation transcription the module being configured to determine presence of a standard text block in an edited medical transcription determine a trigger phrase in a literal medical transcription portion associated with the edited medical transcription the trigger phrase corresponding to the standard text block and store the trigger phrase for use in determining presence of the trigger phrase in another transcription.

Implementations of the invention may include one or more of the following features. The module is configured to store a plurality of automatically determined trigger phrases corresponding to the automatically determined standard text block. The module is further configured to store the automatically determined trigger phrase in association with at least one of speaker and worktype.

In general in another aspect the invention provides a method of processing a medical record transcription the method including obtaining a medical transcription of a dictation the dictation being from medical personnel and concerning a patient analyzing the medical transcription for presence of stored trigger phrases associated with standard text blocks determining that a particular trigger phrase from the stored trigger phrases is present in the medical transcription if an actual phrase in the medical transcription has at least a threshold level of similarity to the particular trigger phrase and replacing the content of the transcription corresponding to the trigger phrase with the standard text block if the transcription includes the trigger phrase.

Implementations of the invention may include one or more of the following features. The replacing results in an edited medical transcription and the method further includes transmitting the edited transcription to the medical personnel before further editing if any by a medical transcriptionist if the edited medical transcription comprises at least a predetermined level of standard text from the standard text blocks. The method further includes providing a list of the standard text blocks to at least one of a medical transcriptionist and the medical personnel wherein the list provides descriptions of content of the standard text blocks.

Various aspects of the invention may provide one or more of the following capabilities. Time and cost of generating medical transcription documents can be reduced. Transcriptionist editing time can be reduced. Transcriptionist fatigue in editing transcribed documents can be reduced. Stress associated with typing editing including physical stress can be reduced. Consistency in medical documentation can be improved. Efficiency of dictating can be improved. Requiring clinicians to explicitly dictate formatting instructions can be reduced or eliminated. The format of standard documents may be made uniform for a clinician or across a health care institution. Management of transcription workflow can be streamlined. Further in a speech recognition assisted medical transcription system the speech recognition devices can have access to the latest version of standard text and documents for each clinician. Standard text can be pre inserted into the draft transcription prior to review and editing by the MT.

These and other capabilities of the invention along with the invention itself will be more fully understood after a review of the following figures detailed description and claims.

Embodiments of the invention provide techniques and a workflow for using automatic speech recognition of trigger phrases to insert standard text into medical transcription documents. Embodiments of the workflow include manual and automatic registering of speech triggers and output text as well as techniques for improving the accuracy with which the appropriate triggers are detected. Embodiments of the invention may be applied to e.g. background and front end speech recognition assisted transcription systems. In embodiments of the invention verbal trigger phrases are used as indicators that portions of pre defined text are to be inserted into a transcription at a given location. In some embodiments a trigger phrase specifies the entire content of the desired transcription. In other embodiments a trigger phrase refers to a subset of the final document and regular dictation is used to indicate the rest of the text. In other embodiments a trigger phrase is used to indicate substantially all of either the entire document or a section of the final document having blanks to fill in by subsequent dictation. Other embodiments are within the scope of the invention.

Referring to a system for transcribing audio and editing transcribed audio includes a speaker person a communications network an administrative console a real time ASR device a voice mailbox system an editing device a communications network a database server a communications network a reviewing computer a file server an automatic transcription device an automatic standard text finder and an automatic trigger finder . Embodiments of the invention may have systems with more or fewer elements than the system e.g. without the ASR device as indicated by dotted lines. Here the network is preferably a public switched telephone network PSTN although other networks including packet switched networks could be used e.g. if the speaker uses an Internet phone for dictation. The network is preferably a packet switched network such as the global packet switched network known as the Internet. The network is preferably a packet switched local area network LAN . Other types of networks may be used however for the networks or any or all of the networks may be eliminated e.g. if items shown in are combined or eliminated.

Preferably the voice mailbox system the administrative console the real time ASR device and the editing device are situated at the health care facility remotely from the hosting facility where the database server and the automatic transcription device are located. These systems devices however could be located at the same site with communications between them taking place e.g. over a local area network. Similarly it is possible to locate the automatic transcription device at the health care facility and have the device communicate with the database server over the network .

The network is configured to convey dictation from the speaker to the voice mailbox system . Preferably the speaker dictates into an audio transducer such as a telephone and the transduced audio is transmitted over the telephone network into the voice mailbox system such as the Intelliscript product made by eScription of Needham Mass. The speaker may however use means other than a standard telephone for creating the digital audio file for each dictation. For example the speaker may dictate into a handheld PDA device that includes its own digitization mechanism for storing the audio file. Or the speaker may use a standard dictation station such as those provided by many vendors or via a microphone attached to a personal computer or other device. Still other devices may be used by the speaker for dictating and possibly digitizing the dictation and sending it to the voice mailbox system .

The voice mailbox system is configured to digitize audio from the speaker to produce a digital audio file of the dictation. For example the system may use the Intelliscript product made by eScription.

The voice mailbox system is further configured to prompt the speaker to enter an identification code and a workType code. The speaker can enter the codes e.g. by pressing buttons on a telephone to send DTMF tones or by speaking the codes into the telephone. The mailbox system is further configured to store the identifying code and the workType code in association with the dictation. The identification code can associate the dictation with a particular speaker and or an entity associated with the speaker e.g. the speaker s employer or affiliate hospital etc. . Speakers with multiple affiliations e.g. to different entities such as hospitals preferably have multiple identification codes with each identification code corresponding to a respective one of the affiliated entities. The system preferably prompts the speaker to provide the workType code at least for each dictation related to the medical field. The workType code designates a category of work to which the dictation pertains e.g. for medical applications this could include Office Note Consultation Operative Note Discharge Summary Radiology report etc. The workType code may be used to define settings such as database fields and or to refine settings such that settings may be specific to the workType of dictations provided by the speaker and or to other parameters or indicia.

The voice mailbox system is further configured to transmit the digital audio file and speaker identification code and workType code over the network to the database server for storage. This transmission is accomplished by the system product using standard network transmission protocols communicating with the database server .

The database server is configured to store the incoming data from the voice mailbox system as well as from other sources in a database . The database server may include the EditScript database product from eScription. Software of the database server is configured to produce a database record for the dictation including a file pointer to the digital audio data and a field containing the identification code for the speaker . If the audio and identifying data are stored on a PDA the PDA may be connected to a computer running the HandiScript software product made by eScription that will perform the data transfer and communication with the database server to enable a database record to be produced for the dictation. Preferably all communication with the database server is intermediated by a servlet application that includes an in memory cached representation of recent database entries. The servlet is configured to service requests from the voice mailbox system the automatic transcription device the editing device and the administrative console reading from the database when the servlet s cache does not contain the required information. The servlet includes a separate software module that helps ensure that the servlet s cache is synchronized with the contents of the database . This enables the database to be off loaded of much of the real time data communication and to grow to be much larger than otherwise possible. For simplicity however the below discussion does not refer to the servlet but all database access activities may be realized using the servlet application as an intermediary.

The automatic transcription device may access the database in the database server over the data network for transcribing the stored dictation. The automatic transcription device uses an automatic speech recognition ASR device e.g. software to produce a draft transcription for the dictation. An example of ASR technology is the AutoScript product made by eScription that also uses the speaker and worktype identifying information to access speaker worktype dependent ASR models with which to perform the transcription. The device can transmit the draft transcription and or intermediate results over the data network to the database server for storage in the database and to be accessed along with the digital audio file by the editing device .

The automatic trigger finder is configured to access the database in the database server and to use data stored in the database to determine standards triggers used by particular speakers. For example the automatic trigger finder may access literal transcriptions and corresponding edited transcriptions as well as registered standard texts for a speaker or speaker workType combination. The automatic trigger finder is configured to determine verbal triggers that are used by speakers to indicate that standard text is to be inserted e.g. by identifying similar words and or phrases in dictations that correspond to standard text in final edited document versions. Triggers are stored in association with the speaker workType or speaker workType combination in the database .

The automatic standard text finder is configured to access the database in the database server and to use data stored in the database to determine unregistered standard text used by particular speakers. For example the automatic standard text finder may access edited transcriptions for a speaker or speaker workType combination. The automatic standard text finder identifies occurrences of identical or nearly identical text in multiple edited transcriptions that have not been registered by a user and alerts the user that the occurrences of such text exist in association with the speaker workType or speaker workType combination in the database . The text finder can request registration of the repeated text and identify possible trigger words phrases and request other triggers.

The editing device is configured to be used by a transcriptionist to access and edit the draft transcription stored in the database of the database server . The editing device is configured to access standards in the database that are specific to the speaker worktype of the document being edited and to insert the standard text into the document e.g. in place of a trigger word phrase. The editing device includes a computer e.g. display keyboard mouse monitor memory and a processor etc. an attached foot pedal and appropriate software such as the EditScript Client software product made by eScription. The transcriptionist can request a dictation job by e.g. clicking an on screen icon. The request is serviced by the database server which finds the dictation for the transcriptionist and transmits the corresponding audio file and the draft transcription text file as stored in the database.

The transcriptionist edits the draft using the editing device and sends the edited transcript back to the database server . For example to end the editing session the transcriptionist can click an on screen icon button to instruct the editing device to send the final edited document to the database server via the network .

With the data sent from the editing device the database in the server contains at least for each dictation a speaker identifier a workType identifier the digital audio signal the literal text document the draft document and the edited text document.

The edited text document can be transmitted directly to a customer s medical record system or accessed over the data network from the database by the administrative console . The console may include an administrative console software product such as Emon made by eScription.

Referring also to the automatic transcription device includes an ASR module memory and a processor for reading software code stored in the memory and or in the ASR module and for executing instructions associated with this code for performing functions described below. The ASR module downloads a digital audio file from the database . The ASR module also obtains information related to the dictation such as the speaker workType etc. The ASR module downloads acoustic and language models from the database . Preferably the acoustic and language models are specific to the speaker or speaker worktype of the dictation.

The ASR module is configured to create a literal transcription or literal text file from the audio file . The ASR module is further configured to obtain standards from the database and store the standards in the memory . A standard comprises a trigger phrase or phrases and standard text . The standards see and associated text are stored in the database to be accessed in conjunction with a particular dictation e.g. in association with a speaker a workType or a combination of speaker and workType. A speaker or a speaker workType may have one or many standards which is downloadable by the ASR module .

The ASR module is configured to search the literal transcription for words and or phrases corresponding to e.g. matching a standard trigger for example using a pattern comparison technique. The ASR module replaces a spoken word phrase with the corresponding standard text when the spoken words phrases correspond to e.g. match or match within a threshold of confidence a trigger . The formatted text or output draft transcription is comprised in general of literal text optionally processed by the formatting models and software and inserted standard text . The output draft transcription may be comprised entirely of one or more inserted standard texts with all of the literal text replaced. Or if no triggers are found the output draft transcription will contain the literal text optionally processed by the formatting models and software.

The ASR module uploads the literal text and output draft transcription to the database . The output draft is accessed by an MT who edits the draft and produces the final document. The literal text is used for the alignments used in the process which automatically creates and adapts standards triggers see and accompanying text .

Referring also to the administrative console is configured to register standards that are used by the ASR module to insert standard text into transcriptions. Standards are registered via the administrative console . For example standards may be manually entered into the system . A user interface includes a speaker field a workType field a text field a description field and trigger fields . The user interface further includes a filename browser and a submit button . The user interface prompts a user e.g. a clinician transcription manager health information systems director etc. to input at least one speaker name or workType a description text at least one trigger phrase and the name of a file that contains the standard text to be associated with the trigger phrase s . The file can be for example on a file server that is connected to the database or a file on a user s computer that is uploaded to the database for storage either in the database or on a file server connected to the database .

After entry of the requested information the user clicks the submit button . The information is uploaded to the database and the relevant database records are populated with fields representing the association between the trigger phrase s the description and the standard text file . If text has been entered into the text field then in response to actuation of the submit button a new file is generated on the file server that contains the text in the field . Referring to a database table stores the description trigger standard text file triples each with an index . Each triple submitted through the registration process has an entry in the database table i.e. if either the trigger phrase description or standard text differs a new record with a new index is added to the table .

Referring to a speaker workType standards table stores a speaker ID a workType and standards . The standards are listed according to the index . Every speaker workType using the system has an associated list of standards field . The system can use information about a speaker and workType for a dictation under analysis and the table to limit the trigger phrases searched for in the dictation for possible replacement with standard text.

The administrative console is configured to check the database table to determine if the submitted standard identified by its index already exists e.g. a standard having the same trigger phrase and output text . If so the standards index is used to represent that entry in the standards table . If not the administrative console is configured to add a new record to the database table with the trigger phrase description and standard text file or the text file created as a result of text entry triple and an index is generated and used to represent that entry in the database table . For each speaker workType in the speaker workType standards table that matches the standards index is added to the list of standards field . For example multiple speakers or even all speakers with a given workType may share a particular standard text and associated description or use identical trigger phrases to indicate that they should be inserted by the ASR module see and related text . The standard text files in the database table may be used by MTs at the editing device when they are typing transcriptions from the audio with or without speech recognition drafts. This may be accomplished at the editing device by for example clicking on a button or typing a hot key sequence which indicates that a menu of standards for the appropriate speaker worktype should appear with each menu item displayed as the description for the associated standard text file. When the MT clicks on a given description the contents of the standard text file are inserted in the transcription document at the current cursor location.

Trigger phrases in the database table may be encoded as regular expression grammars. For example a trigger phrase may be written as 

where parentheses indicate choices and square brackets indicate options. For example any of the following language matches the trigger phrase in the databse table 

During the standards registration process using the user interface portions of the standard text which may be filled in as a result of a trigger phrase can be marked using for example XML tags such as 

Referring to FIGS. and the administrative console is further configured to modify or update existing standard texts. Initially the administrative console presents a user with a speaker worktype selection screen . The screen prompts the user to enter the speaker in a speaker window and or the worktype in a worktype window . In response to entry of information by the user into the appropriate window s and actuation of a submit button icon the administrative console displays a standard selection update screen for the user. The screen presents the user with a list of standard text files and their associated descriptions corresponding to the speaker and or worktype entered using the screen . The user can select one of the standard text files as indicated by an X and the administrative console will display the corresponding standard text in an editing updating region . The console is configured to prompt the user to edit update the text in the region as desired e.g. by adding and or removing text displayed in the region and or by changing the text file corresponding to a description . The trigger s preferably remain the same for a given description . The revised text can be accepted by actuation of a submit button icon causing the standard text in the table to be replaced with the new text in the region .

Referring to A B and in addition to standards registration and updating the literal and edited versions of a transcriptionmay be used by the automatic trigger finder to produce standard triggers for the speaker or workType for a given standard text. The literal and edited versions of transcriptions associated with their respective standard text speaker and workType identifiers are stored in the database . The automatic trigger finder accesses the database in the database server to use data stored in the database to determine verbal triggers used by particular speakers to indicate that the given standard text is to be inserted. The automatic trigger finder uses the literal and the edited transcriptions for each speaker or workType or combination of both speaker and workType to build standards triggers for the speaker and or speaker and workType . These triggers are stored in the database for access and use by the automatic transcription device to indicate that standard text is to be inserted in a document.

The automatic trigger finder is configured to develop the triggers that are stored in the database for access by the ASR module . The automatic trigger finder includes an automatic trigger finder module and a memory . The automatic trigger finder module includes memory storing software code and a processor for reading this software code and executing instructions associated with this code to perform functions described below. The memory of the module and the memory may be portions of a single physical memory. The memory includes a literal text file an edited text file a triggers file and a reference standard text . The literal text file includes literal transcriptions that are produced from the dictated audio by the ASR module . The edited transcriptions file includes formatted text associated with a draft transcription that has been edited by a transcriptionist and stored in the database . The triggers file includes triggers extracted from a comparison of the literal text to the edited text with reference to the standard text which is passed in as a parameter of the process. As with the manual trigger entry process automatically found triggers are used by the ASR device to map verbal directives from the speaker into standard text segments.

The automatic trigger finder module is configured to discover standards triggers based on the literal text in the literal text file in comparison with the formatted text including standard text from the transcriptionist formatted text file for corresponding transcriptionist edited documents.

The automatic trigger finder module is configured to align the literal text file with the formatted text file for a set of dictations hereinafter referred to as a parallel text set and to segment this alignment using the standard text to develop the triggers . A parallel text set could include multiple literal and formatted text files corresponding to multiple dictations. The module is configured to align the literal text and the transcriptionist edited text of the parallel text set to determine what portions of the literal text can be automatically replaced by standard text with minimal interaction from a transcriptionist. Alignment is accomplished using for example a standard technique such as reducing possibly minimizing the Levenshtein distance between the literal text and the edited text using a modified Levenshtein distance that weights certain substitution errors more or less than normal based on task specific knowledge etc. The module is configured to determine the literal triggers for each portion of the alignment where the edited text matches the standard text . In general a parallel text set comprising multiple dictations will produce multiple segmentations which correspond to the standard text and will therefore produce multiple triggers to store in the triggers file .

Referring also to an exemplary alignment table illustrates the alignment of literal text to edited text along with the segmentation by reference to the standard text for producing a trigger . The alignment table includes automatic speech recognition columns and formatted entries columns . A literal text statement is represented as the ASR entries and is transcribed from the audio dictation. The formatted text entries represent the formatted document that results from editing the literal text in the ASR field . Here the region between lines and has been demarcated as it corresponds to a given standard text. The alignment of the columns with the columns shows that the clinician used the phrase use my normal exam template here to indicate that standard text as shown in the columns was to be inserted.

The automatic trigger finder may find triggers which are not exactly the spoken language but are representative of typical errors made by the ASR device when producing the literal transcription of the audio. For example the ASR column may contain the sequence use the normal exam macrophage instead of use my normal exam macro here but the misrecognized phrase is added as a trigger phrase .

Referring to the automatic standard text finder includes a memory and an automatic standard text finder module . The automatic standard text finder module includes memory storing computer readable software code and a processor for reading this software code and executing instructions associated with this code to perform functions described below. The processor can be dedicated to the text finder or may be shared with other apparatus such as the trigger finder . The memory of the module and the memory may be portions of a single physical memory. The memory includes a formatted text file that contains formatted texts and a standard text file that contains standard texts. The standard text finder module is configured to align formatted texts in the file with each other. The module is configured to identify and demarcate similar to identification and demarcation shown in regions of similar e.g. identical near identical etc. aligned text. The module will add one of the similar regions of text to the standard text file . The module is configured to compare the standard texts in the text file with the formatted texts in the formatted text file to determine the number of occurrences absolute or relative e.g. frequency of occurrences per number of texts reviewed of each standard text in the file in the reviewed formatted texts. The module verifies approves of standard texts exceeding a corresponding threshold e.g. for quantity and or frequency . The module is further configured to upload verified approved standard texts from the file to the database table with an index. One or more triggers can be provided for and associated with the standard texts automatically or manually as discussed herein.

Referring to with further reference to a process for developing a trigger using the automatic trigger finder includes the stages shown. The process however is exemplary only and not limiting. The process can be altered e.g. by having stages added removed or rearranged. The process is preferably performed for each occurrence of known standard text in the standards table for a given speaker or speaker workype appearing in the final formatted transcription and is preferably performed for each occurrence of a speaker worktype in the table .

At stage the automatic trigger finder module queries the database for text that has been received into the system . For example the automatic trigger finder module may query for a set of all literal and final transcriptions related to a particular speaker workType or speaker workType pair for which a particular standard text occurs in the final transcription.

At stage for each set of literal and final transcriptions an alignment is made. The literal and final texts are put into columns e.g. the columns of the table with one word or a null per row. Similar words in the two columns are put in common rows with nulls inserted in the columns as appropriate to align the similar words.

At stage the location of standard text is demarcated to identify the trigger. At stage the trigger is identified as the sequence of non NULL tokens in the draft columns of the alignment that aligns with the section marked as standard text in the formatted columns .

In embodiments of the invention the process may discover cases where standard text is being dictated fully without the use of a trigger . For example the alignment in these instances would largely comprise identical entries in the draft and edited columns of . From this clinicians may be alerted that they can save time by using an existing or newly registered trigger phrase to indicate the insertion of the standard text and can register manual trigger phrases using the administrative console interface shown in to correspond with the standard text.

In embodiments of the invention the process may discover cases where standard text is being triggered but has not been registered using the interface shown in . For example the process may be invoked for registered standard texts that occur in the database table independent of their speaker worktype association. In this case the database is queried for documents for a speaker or speaker worktype that contain the given standard text. The automatic trigger finder searches for triggers and if any triggers are discovered they are added to the database table with a new index into the table and are associated with the given standard text file. An entry is added to the standard list in the row of the table corresponding to the speaker worktype or a new row is added to the table if the speaker worktype does not currently exist in the table .

At stage triggers are collected and added to the regular expression trigger in the table . New entries may be added to the database table where the standard text is the same as an existing entry but with the new trigger and the index for this entry in the standards table may be added to the speaker workType standards table entry in the standards table . Alternatively existing triggers may be extended to include the new triggers using well known regular expression grammar notation such as Backus Naur form.

Referring to with further reference to and a process for discovering standard text automatically using the automatic standard text finder includes the stages shown. The process however is exemplary only and not limiting. The process can be altered e.g. by having stages added removed or rearranged. Further the process may be performed before and or after the process for developing a trigger e.g. such that the process can develop triggers for standards discovered during the process .

At stage for each speaker or speaker workype a sample of final edited transcriptions is collected from the database . For example 100 transcriptions for a particular speaker can be collected from the database .

At stage the sample transcriptions are aligned with each other. During alignment text blocks that match exactly or nearly exactly within a desired tolerance are collected as standard text that a clinician may register as a standard having a trigger. For example text blocks of about 50 words may be analyzed although other block sizes may be used but are at least large enough such that the use of a trigger phrase represents a time savings for the clinician. Also as a match between two transcriptions may not be identical a threshold for how much identical matching of the text between transcriptions will cause designation as standard text is used. For example matches of language of greater than about 90 of all of the words in text blocks can result in a text block being labeled as standard text. In an alternative embodiment a clinician s final edited text documents or a sample thereof may be compared with the registered standard texts from other clinicians in the Standard table.

At stage similar portions of aligned texts are demarcated and designated as possible standard texts. Text portions that are more than a threshold amount e.g. about 90 of being identical are marked as possible standard texts. The portions identified at stage as being possible standard texts are marked or otherwise identified by the standard text finder module in the aligned texts. The standard text finder module selects one of the identified text portions and stores this selected text portion in the standard text file for verification as standard text.

At stage a verification is performed. A search is performed in preferably all of the clinician s final documents not just the subset sample selected at stage for standard texts. The text finder module compares the possible standard texts in the text file with the formatted texts to find text portions similar e.g. about 90 or more identical to the possible standard texts in the text file . The automatic standard text finder can verify standard texts and preferably does so only for standard texts that occur in a given fraction of all the documents and that would be the best candidates for registration.

At stage the standard texts are registered. The standard texts are presented to the clinicians that are using these texts either by dictating them fully or by triggering them. When registered the standard texts become entries in the standards table and triggers are created for these entries.

Referring to with further reference to a process for inserting standard text into a transcribed document includes the stages shown. The process however is exemplary only and not limiting. The process can be altered e.g. by having stages added removed or rearranged.

At stage a dictation is obtained from the database . The speaker dictates text that is conveyed through the network to and stored in the voice mailbox . The dictation is conveyed through the network the database server and the LAN to the automatic transcription device . The dictation is associated with a speaker and or workType an indication of which is stored in association with the dictation in the database .

At stage a literal transcription is created from the dictation. The ASR device transcribes the speech of the speaker to produce a literal transcription and stores this transcription locally for analysis regarding standard text portions.

At stage a trigger is obtained by the ASR device for use in searching for standard texts. The trigger is found using information regarding the speaker workType or speaker workType combination parameter that is associated with the selected dictation.

At stage the literal transcription is searched for matches to the trigger to replace the trigger literal text with the standard text . To apply the standard text the literal text file is searched for a literal portion of text that corresponds to a registered standard trigger . If a match within acceptable tolerance confidence is made the standard text is applied such that the literal text portion is replaced with the standard text . Triggers are registered for example according to processes described in . Triggers are also registered by manual entry of triggers and corresponding standard text for example by a clinician or a manager. An auto formatted text document is developed from the application of the standards to the literal text file . At stage the formatted transcription and the literal text transcription are uploaded to the database for storage.

Other embodiments are within the scope and spirit of the appended claims. For example due to the nature of software functions described above can be implemented using software hardware firmware hardwiring or combinations of any of these. Features implementing functions may also be physically located at various positions including being distributed such that portions of functions are implemented at different physical locations. For example the translation model builder may be disposed wholly or partially elsewhere such as at the database server .

How and whether trigger literal text is replaced with the appropriate standard text may depend on the type of standard as determined during the registration process. The literal transcription is searched for except triggers e.g. except but however etc. . If an except trigger is found then the standard text replaces the trigger literal text except that the portion of the standard text to which the except trigger is applicable is replaced with the literal text associated with the except trigger. Each replacement field in standard text has associated with it a set of potential except triggers. If an acceptable match is found to the except trigger then the value for the replacement field is filled in to the draft transcription the blank or pre existing standard text is removed and the literal text following the except trigger potentially formatted e.g. as numeric quantities is inserted and the trigger literal text is removed. Further if the standard text includes blanks e.g. empty fields or placeholders for certain information e.g. temperature pulse blood pressure etc. then the literal text near the trigger phrase may be used to fill in the missing information. For example a normal exam standard text may have placeholders for the patient s temperature pulse and blood pressure. The literal text Use my normal checkup with 140 for weight 98 point 4 degrees for temperature pulse and BP 120 over 90 may result in the following output draft transcription 

The output draft transcription may be encoded as a token alignment file that may contain invisible records for annotation purposes. This file would comprise a set of token records with each record preferably containing a token a begin index and an end index. The token comprises a character or a sequence of characters that are to appear on the screen during a word processing session or one or more sounds that may or may not appear as text on a screen. A begin index comprises an indication of the beginning of a standard text block and the end index comprises an indication of the end of the standard text block. As an alternative the end index may not exist separately if second standard text block follows a first standard text block with it being assumed that the starting point of the second text block is also the ending point of the previous text block. The transcription device can store the token alignment file in the database . The token alignment file may be encoded with the locations at which standard text was inserted using invisible markup such as . . . where the particular Standard is indicated by the index in these tags. This may be used as part of the standards updating process for example as an aid to definitively demarcate the portion of the alignment associated with a standard and therefore to better produce the automatic triggers .

The ASR device may be configured so that when certain standards are inserted the transcription goes directly to the clinician for signing. For example this may be done if substantially all of the output transcription resulted from the insertion of standard text. The output transcription may still be sent to the database but its state marked as Ready for Signing instead of the usual Ready for Editing. At a later time the draft may be accessed by a dictating clinician at the clinician s own computer terminal for review and signing prior to being uploaded as the final signed document into the database . The computer at which the signing takes place may also have editing capabilities so that the clinician may update the document prior to signing. Several means are available for this editing process e.g. standar PC based editors textual tokens or real time speech recognition and these means may be employed in various combinations. Standard PC based editors may be used to modify the text by keyboard and mouse. Certain textual tokens in the draft transcription may have associated with them several options from which the speaker now editor may easily select by for example clicking a mouse over the item which causes a menu of the options to be presented and then choosing the particular option by clicking the mouse again. This means may be particularly useful for editing drafts in which standards except have been inserted in the event that the ASR device was unable to determine which option was indicated verbally. This may happen for example either because the speaker did not indicate the choice at the original dictation time or because the literal transcription was erroneous so that no match was made against the clinician s standard trigger phrases. In this case the choices may be included in the hidden records of the draft transcription using for example HTML or other well known markup languages. Real time speech recognition means may be provided at the signing computer and well known interactive voice editing means may then be employed to edit the document as desired.

In some embodiments of the invention the ASR process is accomplished at a real time ASR device. The ASR software may reside on a computer that is directly connected to the dictating device and the ASR process may run in parallel to the dictation. Thus the literal words appear on the screen as they are dictated. As the literal words are decoded on the screen the pattern matching search for standards is on going. When a standard is triggered the literal trigger is erased and replaced by the appropriate standard text. This may facilitate signing of the transcription soon if not immediately after the draft transcription is produced with no intermediate database transaction performed.

In still other embodiments the ASR device resides on a local area network with the speaker s dictating device and the audio data is quickly transmitted to the ASR device. Downloading of standards begins as the clinician begins dictating as identifying information speaker and or workType is sent to the ASR device prior to the audio stream. Replacement of standard text occurs on the ASR device in parallel to the incoming audio stream. When the clinician signals that the clinician is done dictating for example by pressing a button on a dictation device the ASR device completes its processing and the output draft transcription is sent to the computer terminal at the dictation station.

In embodiments involving real time or near real time ASR where the speaker is potentially involved in the editing of the final document a user interface may be provided to enable the speaker to manually insert standard text into the document. This may be used for example if the literal transcription fails to match one of the standards triggers . In this case the speaker may press a button on the dictating device e.g. a microphone itself and this will cause the menu of standard descriptions associated with the speaker or speaker worktype to appear on the computer screen at which point the speaker may select the appropriate standard description from the menu either by keyboard or voice interaction with the menu.

While the description above focused on medical transcriptions the invention is not limited to medical transcriptions. The invention may be applied to formatting dictations for non medical applications such as legal dictations psychological evaluations etc. Further while the discussion above refers to the invention more than one invention may be disclosed.

