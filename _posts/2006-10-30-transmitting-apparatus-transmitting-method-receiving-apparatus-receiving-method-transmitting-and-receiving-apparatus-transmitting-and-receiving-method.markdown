---

title: Transmitting apparatus, transmitting method, receiving apparatus, receiving method, transmitting and receiving apparatus, transmitting and receiving method, record medium, and signal
abstract: On the transmission side, a background picture and objects # to # are transmitted at a transmission rate R/4 each. On the reception side, a picture composed of the objects # to # and the background picture is displayed with a particular spatial resolution and a particular temporal resolution. Thus, on the reception side, when the object # is dragged at particular time t, on the transmission side, the transmission of the background picture and the objects # and # is stopped. Only the object # is transmitted at the transmission rate R of the transmission path. Therefore, a picture of which the spatial resolution of the object # dragged is improved is displayed at the sacrifice of the temporal resolution of the picture.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07760156&OS=07760156&RS=07760156
owner: Sony Corporation
number: 07760156
owner_city: Tokyo
owner_country: JP
publication_date: 20061030
---
This is a division of application Ser. No. 11 125 781 filed May 10 2005 now U.S. Pat. No. 7 486 253 which is a continuation of application Ser. No. 09 807 114 filed Jun. 15 2001 pursuant to 35USC 371 as a National Phase Application of International Application PCT JP00 05319 now U.S. Pat. No. 7 009 579 which is entitled to the priority filing date of Japanese Applications 11 225020 filed in Japan on Aug. 9 1999 2000 127657 filed in Japan on Apr. 24 2000 and 2000 21437 filed in Japan on Jul. 14 2000 the entirety of which are incorporated herein by reference.

The present invention relates to a transmitting apparatus a transmitting method a receiving apparatus a receiving method a transmitting and receiving apparatus a transmitting and receiving method a record medium and a signal. In particular the present invention relates to a transmitting apparatus a transmitting method a receiving apparatus a receiving method a transmitting and receiving apparatus a transmitting and receiving method a record medium and a signal that allow for example picture data to be transmitted at a limited transmission rate with a limited transmission band and a picture with a high spatial resolution to be displayed.

For example a related art reference of Japanese Patent Laid Open Publication No. HEI 10 112856 discloses a picture transmitting apparatus. In the picture transmitting apparatus a transmission side transmits picture data of a particular area of a picture and picture data of the other area of the picture are transmitted with different information amounts corresponding to a command issued by a reception side. The reception side displays the picture in the area that contains a designated point with a higher spatial resolution the resolution in the spatial direction and the picture in the other area with a lower spatial resolution.

In other words when the transmission side transmits picture data to the reception side through a transmission path the transmission side cannot transmit picture data at a higher data rate than that of the transmission path. Thus when the reception side displays a picture on a real time basis the transmission side should transmit picture data to the reception side at a transmission rate corresponding to the transmission path. As a result if the transmission rate is not sufficient the spatial resolution in the spatial direction of a picture displayed on the reception side totally deteriorates.

To solve such a problem in the picture transmitting apparatus of Japanese Patent Laid Open Publication No. HEI 10 112856 picture data in one area of a picture and picture data in other area of the picture are transmitted with different information amounts. The picture in the area that contains a designated point and the picture in the other area are displayed with a high spatial resolution and a low spatial resolution respectively on the reception side.

In other words in the picture transmitting apparatus of Japanese Patent Laid Open Publication No. HEI 10 112856 the spatial resolution of a portion that the user wants to see in detail is improved at the sacrifice of the spatial resolution of the other portion.

However in the picture transmitting apparatus of Japanese Patent Laid Open Publication No. HEI 10 112856 since the spatial resolution of the portion that the user wants to see in detail is improved at the sacrifice of the spatial resolution of the other portion the spatial resolution of the portion that the user wants to see in detail is improved for only the sacrificed special resolution.

In addition when the transmission rate of the transmission path is very low if the spatial resolution of the portion that the user wants to see in detail is improved at the sacrifice of the spatial resolution of the other portion the spatial resolution of the other portion terribly deteriorates. In the worst case the user cannot clearly see the other portion.

The present invention is made from the above described point of view. An object of the present invention is to allow the spatial resolution of a picture to be more improved corresponding to a preference of the user.

A first transmitting apparatus of the present invention is a transmitting apparatus for transmitting data to a receiving apparatus comprising a receiving means for receiving control information transmitted from the receiving apparatus a controlling means for controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and a transmitting means for transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus.

A receiving apparatus of the present invention is a receiving apparatus for receiving data transmitted from a transmitting apparatus comprising a transmitting means for transmitting control information to the transmitting apparatus that controls resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data corresponding to the control information a receiving means for receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and an outputting means for outputting the data received by the receiving means.

A transmitting and receiving apparatus of the present invention is a transmitting and receiving apparatus having a transmitting apparatus for transmitting data and a receiving apparatus for receiving the data wherein the transmitting apparatus comprises a control information receiving means for receiving control information transmitted from the receiving apparatus a controlling means for controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and a data transmitting means for transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus and wherein the receiving apparatus comprises a control information transmitting means for transmitting the control information a data receiving means for receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and an outputting means for outputting the data received by the data receiving means.

A second transmitting apparatus of the present invention is a transmitting apparatus for transmitting data to a receiving apparatus comprising a receiving means for receiving control information transmitted from the receiving apparatus a categorizing means for categorizing the data corresponding to the control information and a transmitting means for transmitting the data to the receiving apparatus corresponding to the categorized result of the data.

A first transmitting method of the present invention is a transmitting method for transmitting data to a receiving apparatus comprising the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus.

A receiving method of the present invention is a receiving method for receiving data transmitted from a transmitting apparatus comprising the steps of transmitting control information to the transmitting apparatus that controls resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data corresponding to the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the receiving step.

A transmitting and receiving method of the present invention is a transmitting and receiving method having a process of a transmitting apparatus for transmitting data and a process of a receiving apparatus for receiving the data wherein the process of the transmitting apparatus comprises the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus and wherein the process of the receiving apparatus comprises the steps of transmitting the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the data receiving step.

A second transmitting method of the present invention is a transmitting method for transmitting data to a receiving apparatus comprising the steps of receiving control information transmitted from the receiving apparatus categorizing the data corresponding to the control information and transmitting the data to the receiving apparatus corresponding to the categorized result of the data.

A first record medium of the present invention is a record medium for recording a program that causes a computer to perform a transmitting process for transmitting data to a receiving apparatus the transmitting process comprising the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus.

A second record medium of the present invention is a record medium for recording a program that causes a computer to perform a receiving process for receiving data transmitted from a transmitting apparatus the receiving process comprising the steps of transmitting control information to the transmitting apparatus that controls resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data corresponding to the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the receiving step.

A third record medium of the present invention is a record medium for recording a program that causes a computer to perform a transmitting process of a transmitting apparatus for transmitting data and a receiving process of a receiving apparatus for receiving the data wherein the transmitting process of the transmitting apparatus comprises the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus and wherein the receiving process of the receiving apparatus comprises the steps of transmitting the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the data receiving step.

A fourth record medium of the present invention is a record medium for recording a program that causes a computer to perform a transmitting process for transmitting data to a receiving apparatus the transmitting process comprising the steps of receiving control information transmitted from the receiving apparatus categorizing the data corresponding to the control information and transmitting the data to the receiving apparatus corresponding to the categorized result of the data.

A first signal of the present invention is a signal for containing a program that causes a computer to perform a transmitting process for transmitting data to a receiving apparatus the transmitting process comprising the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus.

A second signal of the present invention is a signal for containing a program that causes a computer to perform a receiving process for receiving data transmitted from a transmitting apparatus the receiving process comprising the steps of transmitting control information to the transmitting apparatus that controls resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data corresponding to the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the receiving step.

A third signal of the present invention is a signal for containing a program that causes a computer to perform a transmitting process of a transmitting apparatus for transmitting data and a receiving process of a receiving apparatus for receiving the data wherein the transmitting process of the transmitting apparatus comprises the steps of receiving control information transmitted from the receiving apparatus controlling the resolutions in at least two directions of the temporal direction the spatial direction and the level direction of the data transmitted to the receiving apparatus corresponding to the control information and transmitting the data of which the resolutions in at least two directions have been controlled corresponding to the control information to the receiving apparatus and wherein the receiving process of the receiving apparatus comprises the steps of transmitting the control information receiving the data transmitted from the transmitting apparatus the resolutions of the data having been controlled in at least two directions of the data and outputting the data received at the data receiving step.

A fourth signal of the present invention is a signal for containing a program that causes a computer to perform a transmitting process for transmitting data to a receiving apparatus the transmitting process comprising the steps of receiving control information transmitted from the receiving apparatus categorizing the data corresponding to the control information and transmitting the data to the receiving apparatus corresponding to the categorized result of the data.

According to the first transmitting apparatus the first transmitting method the first record medium and the first signal of the present invention control information transmitted from a receiving apparatus is received. Corresponding to the control information the resolutions in at least two directions of the temporal direction the spatial direction and the level direction are controlled. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted to the receiving apparatus.

According to the receiving apparatus the receiving method the second record medium and the second signal of the present invention control information is transmitted to a transmitting apparatus that controls the resolutions in at least two directions of the temporal direction the spatial direction and the level direction corresponding to the control information. In addition data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted from the transmitting apparatus received and output.

According to the transmitting and receiving apparatus the transmitting and receiving method the third record medium and the third signal a transmitting apparatus receives control information transmitted from a receiving apparatus. Corresponding to the control information the resolutions in at least two directions of the temporal direction the spatial direction and the level direction are controlled. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted to the receiving apparatus. In addition the receiving apparatus transmits control signal to the transmitting apparatus. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted from the transmitting apparatus received and output.

According to the second transmitting apparatus the second transmitting method the fourth record medium and the fourth signal of the present invention control signal transmitted from a receiving a apparatus is received. Corresponding to the control information data is categorized. Corresponding to the categorized result of the data data is transmitted to the receiving apparatus.

The transmitting system is composed of at least two terminal units and . In the relation between the terminal units and one is a transmitting apparatus and the other is a receiving apparatus. A picture picture data is transmitted from the transmitting apparatus to the receiving apparatus through a transmission path .

According to the embodiment of the present invention for example it is assumed that the terminal unit is a transmitting apparatus and the terminal unit is a receiving apparatus and that picture data is transmitted and received therebetween. Hereinafter the terminal unit or may be referred to as transmitting apparatus or receiving apparatus respectively.

In this case the transmitting apparatus transmits picture data to the receiving apparatus through the transmission path . The receiving apparatus receives picture data from the transmitting apparatus . The picture data is displayed on a picture outputting portion see that will be described later. The picture outputting portion is composed of for example a liquid crystal display or a CRT Cathode Ray Tube . In addition the receiving apparatus transmits control information for controlling the spatial resolution in the spatial direction and the temporal resolution in the temporal direction of the picture displayed by the picture outputting portion to the transmitting apparatus through the transmission path .

The transmitting apparatus receives the control information from the receiving apparatus and controls the transmission of the picture data corresponding to the control information so that the spatial resolution and the temporal resolution of the picture displayed by the receiving apparatus are changed while a predetermined condition is satisfied.

As the transmitting apparatus and the receiving apparatus terminal units such as PHS Personal Handy phone System trademark units and portable terminal units such as portable telephone units can be used. When the PHS units are used the transmission path has a frequency band of 1895.1500 to 1905.9500 MHz and the transmission rate thereof is 128 kbps Bit Per Second .

According to the embodiment shown in the transmission path shown in is composed of a radio base station or and an exchange station that is for example a telephone station that connects the radio base stations and . The radio base station or transmits and receives a radio signal to from the terminal unit or . Between the terminal units and each of them can transmit a signal to the other through the transmission path composed of the radio base stations and the charging server and so forth and receive a signal from the other. The type of the base station may be the same as or different from the type of the base station .

Referring to the terminal unit comprises a video camera portion a displaying portion a key portion a speaker and a microphone . The video camera portion has an image pickup device and an optical system that can photograph a moving picture. The displaying portion can display characters symbols pictures and so forth. The key portion is operated when a telephone number a character a command or the like is input. The speaker outputs a sound. The microphone inputs a sound. Likewise the terminal unit comprises a video camera portion a displaying portion a key portion a speaker and a microphone that have the same structures as the video camera portion the displaying portion the key portion the speaker and the microphone respectively.

Between the terminal units and audio signals collected by the microphones and are transmitted and received. In addition picture data photographed by the video camera portions and can be transmitted and received. Thus the displaying portion of the terminal unit can display picture data obtained by the video camera portion of the terminal unit . Likewise the displaying portion of the terminal unit can display picture data obtained by the video camera portion of the terminal unit .

In other words along with necessary information such as a frame rate picture data photographed by the video camera portion of the transmitting apparatus is transmitted to the receiving apparatus through the transmission path composed of the base stations and and the exchange station . The receiving apparatus receives picture data from the transmitting apparatus and displays a picture corresponding to the received picture data on the displaying portion composed of for example a liquid crystal display. On the other hand the receiving apparatus transmits control information for controlling the spatial resolution and the temporal resolution of a picture displayed on the displaying portion to the transmitting apparatus through the transmission path . The transmitting apparatus receives control information from the receiving apparatus and controls the transmission of the picture data corresponding to the control information so that the spatial resolution and the temporal resolution of the picture displayed by the receiving apparatus are changed while a predetermined condition is satisfied.

A picture inputting portion corresponds to the video camera portion shown in . The picture inputting portion photographs a particular object and outputs the picture thereof to a pre process portion . The pre process portion is composed of a background picture extracting portion an object extracting portion and an additional information calculating portion . The pre process portion performs the pre process for the picture that is input from the picture inputting portion and supplies the resultant picture to a transmitting process portion .

In other words the background picture extracting portion extracts a so called background picture from the picture supplied from the picture inputting portion and supplies the extracted background picture to the transmitting process portion . In addition the background picture extracted by the background picture extracting portion is also supplied to the object extracting portion and the additional information calculating portion .

As a method for extracting the background picture the appearance frequencies of pixel values of pixels at the same spatial position of a plurality of successive frames for example the current frame and the past 10 frames are obtained. A pixel value with the highest frequency may be treated as a background picture at the position. Alternatively the average value moving average value of pixel values at the same position of a plurality of frames may be obtained as a background picture at the position.

The object extracting portion performs for example a subtraction of the background picture extracted by the background picture extracting portion from the picture supplied from the picture inputting portion obtains a so called foreground picture and supplies the foreground picture to the transmitting process portion . When a picture that is input from the picture inputting portion contains a plurality of substances as foreground pictures the object extracting portion extracts the foreground picture corresponding to each substance and supplies the extracted foreground picture to the transmitting process portion . In addition the foreground picture extracted by the object extracting portion is also supplied to the additional information calculating portion . Hereinafter a foreground picture corresponding to each substance may be referred to as object.

The additional information calculating portion detects a background picture moving vector and an object moving vector. The background picture moving vector represents the motion of a background picture extracted by the background picture extracting portion the motion of a background picture corresponds to the motion of the photographing direction of the picture inputting portion . The object moving vector represents the motion of an object extracted by the object extracting portion . In addition the additional information calculating portion supplies position information and so forth of an object in a frame as additional information supplied from the object extracting portion to the transmitting process portion . In other words when the object extracting portion extracts an object the object extracting portion also extracts information about the object such as position information and so forth of the object and supplies the information to the additional information calculating portion . The additional information calculating portion also outputs the position information and so forth as additional information.

The transmitting process portion multiplexes the background picture extracted by the background picture extracting portion the object extracted by the object extracting portion and the additional information obtained by the additional information calculating portion and transmits the resultant multiplexed data to the receiving apparatus through the transmission path at a data rate thereof. The transmitting process portion receives control information transmitted from the receiving apparatus through the transmission path and controls the transmission of the background picture the object and the additional information corresponding to the control information so that the spatial resolution and the temporal resolution of the picture displayed by the receiving apparatus are changed while a predetermined conditions is satisfied.

Next with reference to a flow chart shown in the process of the transmitting apparatus shown in will be described in brief.

A picture that is output from the picture inputting portion is supplied to the pre process portion . At step S the pre process portion performs the pre process for the picture. In other words at step S the background picture extracting portion or the foreground picture extracting portion extracts a background picture or an object from the picture that is input from the picture inputting portion respectively and supplies the extracted background picture or the extracted object to the transmitting process portion . In addition at step S the additional information calculating portion obtains the above described additional information from the picture that is input from the picture inputting portion and supplies the obtained additional information to the transmitting process portion . The transmitting process portion transmits the background picture the foreground picture and the additional information through the transmission path . Thereafter the flow returns to step S. Thereafter the transmitting apparatus repeats the similar process.

Multiplexed data is transmitted from the transmitting apparatus through the transmission path . The multiplexed data is received by the receiving process portion . The receiving process portion separates the multiplexed data into a background picture an object and additional information and supplies them to the combining process portion .

The combining process portion combines the background picture the object and the additional information received from the receiving process portion into the original picture and supplies the combined picture to the picture outputting portion . The combining process portion changes the spatial resolution and the temporal resolution of the picture that is combined corresponding to high resolution information and so forth that will be described later.

The picture outputting portion is composed of for example a liquid crystal display or a CRT. The picture outputting portion displays a picture that is output from the combining process portion .

A control information inputting portion outputs control information to the combining process portion and a control information transmitting portion . In other words the control information inputting portion composes the key portion . The control information inputting portion is composed of for example a pointing device such as a track ball. When the user designates a particular position of a picture displayed by the picture outputting portion with the control information inputting portion it detects the position as a considered point that the user is considering places the coordinates of the considered point in the control information and outputs the resultant control information. Alternatively the control information inputting portion is composed of for example a video camera. When the user photographs and recognizes a picture the control information inputting portion detects a point that the user is considering as a considered point places the coordinates of the considered point in the control information and outputs the resultant control information. The control information inputting portion may be structured so that the user can directly input the spatial resolution and the temporal resolution of a picture displayed by the picture outputting portion as control information.

When the control information transmitting portion receives the control information from the control information inputting portion the control information transmitting portion transmits the control information to the transmitting apparatus through the transmission path .

Next with reference to a flow chart shown in the process of the receiving apparatus shown in will be described in brief.

In the receiving apparatus the receiving process portion receives multiplexed data from the transmitting apparatus through the transmission path . At step S the receiving process portion performs a receiving process for separating the multiplexed data into a background picture an object and additional information. The receiving process portion supplies the background picture the object and the additional information as the result of the receiving process to the combining process portion . At step S the combining process portion combines the background picture the object and the additional information to the original picture and supplies the combined picture to the picture outputting portion . The picture outputting portion displays the combined picture. Thereafter the flow returns to step S. Thereafter the receiving apparatus repeats the similar process.

In the receiving apparatus when the user designates a considered point of a picture displayed by the picture outputting portion with the control information inputting portion the coordinates of the considered point are placed in the control information. The resultant control information is supplied to the control information transmitting portion . The control information transmitting portion transmits the control information to the transmitting apparatus through the transmission path . When the transmitting apparatus receives the control information as was described above the transmitting process portion controls the transmission of the background picture the object and the additional information so that the spatial resolution and the temporal resolution of the picture displayed by the receiving apparatus can be changed while a predetermined condition is satisfied. Thus thereafter since the background picture the object and the additional information that have been controlled are transmitted from the transmitting apparatus to the receiving apparatus a picture of which the spatial resolution and the temporal resolution have been changed while a predetermined condition has been satisfied is displayed by the receiving apparatus .

Next shows an example of the structure of the transmitting process portion of the transmitting apparatus shown in .

A background picture an object and additional information are supplied from the pre process portion see to the encoding portion and the controlling portion . The encoding portion encodes the background picture the object and the additional information and supplies the resultant encoded data to an MUX multiplexer . The MUX selects encoded data of the background picture the object and the additional information received from the encoding portion under the control of the controlling portion and supplies the selected encoded data as multiplexed data to a transmitting portion . The transmitting portion modulates the multiplexed data received from the MUX and transmits the modulated data to the receiving apparatus through the transmission path . A data amount calculating portion monitors the multiplexed data that the MUX outputs to the transmitting portion calculates the data rate of the multiplexed data and supplies the calculated data rate to the controlling portion .

The controlling portion controls the output of the multiplexed data of the MUX so that the data rate of the data amount calculating portion does not exceed the transmission rate of the transmission path . In addition the controlling portion receives the control information transmitted from the receiving apparatus through the transmission path and controls the selection of the encoded data of the MUX corresponding to the control information.

A background picture is supplied to a difference calculating portion B. The difference calculating portion subtracts a background picture of the immediately preceding frame that has been processed from a background picture of the current frame that is processed hereinafter this frame may be referred to as considered frame and supplies difference data of the background pictures as the subtracted result to a hierarchically encoding portion B. The hierarchically encoding portion B hierarchically encodes the difference data of the background pictures received from the difference calculating portion B and supplies the encoded result to a storing portion B. The storing portion B temporarily stores the hierarchically encoded result received from the hierarchically encoding portion . The hierarchically encoded result stored in the storing portion B is supplied as encoded data of background pictures to the MUX see .

The hierarchically encoded result stored in the storing portion B is supplied to a local decoder B. The local decoder B decodes the hierarchically encoded result to the original background picture and supplies the decoded background picture to the difference calculating portion B. The background picture decoded by the local decoder B is used by the difference calculating portion B. The difference calculating portion B uses the decoded background picture to obtain the difference data of a background picture of the next frame.

An object is supplied to a difference calculating portion F. The difference calculating portion F a hierarchically encoding portion F a storing portion F and a local decoder F perform the same processes as the above described difference calculating portion B the hierarchically encoding portion B the storing portion B and the local decoder B. Thus in the same manner as the background picture the object is hierarchically encoded and supplied to the MUX see . When there are a plurality of objects the difference calculating portion F the hierarchically encoding portion F the storing portion F and the local decoder F hierarchically encode the plurality of objects in the above described manner.

Additional information is supplied to a VLC Variable Length Coding portion . The VLC portion encodes the additional information corresponding to variable length code encoding method and supplies the encoded additional information to the MUX see .

Next with reference to hierarchical encoding decoding performed by the encoding portion shown in will be described.

Now it is assumed that the average value of four pixels of 2 2 pixels horizontal vertical of a lower hierarchy is treated as a pixel pixel value of a higher hierarchy and that in three hierarchical levels a picture is encoded. In this case as a picture in the lowest hierarchical level considering 8 8 pixels as shown in A the average value m of four pixels h h h and h of an upper left portion of 2 2 pixels is calculated. The average value m is treated as one pixel of an upper left portion of the second hierarchical level. The average value m of four pixels h h h and h of an upper right portion of the lowest hierarchical level is calculated. The average value m of four pixels h h h and h of a lower left portion of the lowest hierarchical level is calculated. The average value m of four pixels h h h and h of a lower right portion of the lowest hierarchical level is calculated. The average values m m and m are treated as pixels at an upper right portion a lower left portion and a lower right portion of the second hierarchical level respectively. In addition the average value q of four pixels m m m and m of 2 2 pixels of the second hierarchical level is calculated. The average value q is treated as a pixel of the third hierarchical level that is the highest hierarchical level.

According to the above described hierarchical encoding the spatial resolution of a picture in the highest hierarchical level is the lowest. The spatial resolution of a picture is inversely proportional to the hierarchical level. In other words the spatial resolution of a picture in the lowest hierarchical level is the highest.

The data amount in the case that all the pixels h to h h to h h to h h to h m to m and q are transmitted is larger than the data amount in the case that only a picture of the lowest hierarchical level is transmitted by the pixels m to m and q of the higher hierarchical levels.

Thus as shown in B the pixel q of the third hierarchical level is transmitted instead of for example the pixel m at a lower right position of the pixels m to m of the second hierarchical level.

In addition as shown in C the pixel m of the second hierarchical level is transmitted instead of the pixel h at a lower right position of the lowest hierarchical level. Likewise the remaining pixels m m and q of the second hierarchical level are transmitted instead of the pixels h h and h of the first hierarchical level. Although the pixel q is not a pixel of the second hierarchical level it is transmitted instead of the pixel m directly obtained from the pixels h to h. Thus the pixel q is transmitted instead of the pixel m instead of the pixel h.

Thus as shown in C the number of pixels that are transmitted becomes 4 4 pixels 16 pixels. Thus the number of pixels that are transmitted is the same as the case that only pixels of the lowest hierarchical level shown in A are transmitted. Thus in this case the amount of data that is transmitted can be prevented from increasing.

The pixel m transmitted instead of the pixel q and the pixels h h h and h transmitted instead of the pixels m to m can be decoded in the following manner.

In other words since q is the average value of m to m the expression q m m m m 4 is satisfied. Thus the pixel m of the second hierarchical level can be obtained decoded with the pixel q of the third hierarchical level and the pixels m to m of the second hierarchical level corresponding to the expression m 4 q m m m .

In addition since m is the average value of h to h the expression m h h h h 4 is satisfied. Thus corresponding to the expression h 4 m h h h the pixel h of the first hierarchical level can be obtained with the pixel m of the second hierarchical level and the pixels h to h of the first hierarchical level. In the same manner h h and h can be obtained.

Thus a pixel that is not transmitted in a particular hierarchical level can be decoded with pixels that are transmitted in the particular hierarchical level and a pixel of the immediately higher hierarchical level.

Next with reference to a flow chart shown in the transmitting process of the transmitting process portion shown in will be described.

At step S in the transmitting process portion the controlling portion determines whether or not a control signal has been transmitted from the receiving apparatus . When the determined result at step S represents that the control signal has not been transmitted from the receiving apparatus namely the controlling portion has not received the control signal the flow advances to step S. The controlling portion controls the MUX to select encoded data of a background picture an object and additional information and multiplex them so that the receiving apparatus can display a picture with a regular temporal resolution for example a default temporal resolution .

When the regular temporal resolution is for example 30 frames sec the MUX selects encoded data of a background picture an object and additional information multiplex the encoded data and outputs the multiplexed data so that the picture is displayed with the maximum spatial resolution of which the multiplexed data is transmitted at the transmission rate of the transmission path .

In reality for example in the case that hierarchical encoding is performed in three hierarchical levels when data of only the third hierarchical level is transmitted at the transmission rate of the transmission path encoded data of a background picture an object and additional information is selected so that a picture of the third hierarchical level is displayed. Thus in this case the receiving apparatus displays a picture with a spatial resolution that is times in the horizontal direction and the vertical direction each lower than that of the original picture of the first hierarchical level and a temporal resolution of 30 frames sec.

Thereafter the flow advances to step S. At step S the transmitting portion transmits the multiplexed data that is output from the MUX through the transmission path . Thereafter the flow returns to step S.

When the determined result at step S represents that a control signal has been transmitted from the receiving apparatus namely the controlling portion has received the control signal the flow advances to step S. The controlling portion operates the control information inputting portion see corresponding to the control signal and thereby recognizes a designated considered point. Thereafter the flow advances to step S.

At step S the controlling portion designates an area such as a rectangle having a predetermined size around a considered point the rectangle has parallel sides in the horizontal direction and the vertical direction of a frame and has the considered point at the center of gravity thereof as a priority range in which the spatial resolution is improved with priority and detects a background picture an object and additional information that compose the picture in the priority range.

Thereafter the flow advances to step S. At step S the controlling portion controls the MUX to select and multiplex encoded data of a background picture an object and additional information and multiplex the selected encoded data so that the receiving apparatus can display the picture in the priority range with a higher spatial resolution.

In other words when the controlling portion receives a control signal from the receiving apparatus the controlling portion controls the MUX to improve the spatial resolution of the picture in the priority range at the sacrifice of the temporal resolution.

Thus the MUX selects encoded data of a background picture an object and additional information necessary for displaying a picture of the third hierarchical level and a picture of the second hierarchical level with priority multiplexes the selected encoded data and outputs the multiplexed data.

In addition at step S the controlling portion controls the MUX to insert information of the position of the priority range the size thereof and so forth hereinafter may be referred to as high resolution information into the additional information selected as multiplexed data. Thereafter the flow advances to step S.

At step S as was described above the transmitting portion transmits the multiplexed data that is output from the MUX through the transmission path . Thereafter the flow returns to step S.

For simplicity assuming that encoded data of a background picture an object and additional information for displaying a picture of the third hierarchical level is continuously selected for a picture of the third hierarchical level as a picture in the non priority region at step S the data amount of the multiplexed data is larger than that in the case at step S by the data of the second hierarchical level for the picture in the priority range. According to the embodiment of the present invention as was described above to display a picture at 30 frames second data of only the third hierarchical level is transmitted at the transmission rate of the transmission path . Thus the multiplexed data obtained at step S cannot be transmitted so that the picture is displayed at 30 frames second. Thus at step S in the extreme case the multiplexed data obtained at step S is transmitted with a temporal resolution of 0 frames sec.

Thus in this case for a picture in the priority range the receiving apparatus displays a picture of which the spatial resolution in each of the horizontal direction and the vertical direction is as low as that of the original picture of the first hierarchical level . In other words the receiving apparatus displays a picture of the second hierarchical level of which the spatial resolution in each of the horizontal direction and the vertical direction is twice as high as that of a picture of the third hierarchical level. However the temporal resolution is 0 frame second. In other words the receiving apparatus displays a still picture.

After data of the second hierarchical level is transmitted for a picture in the priority range when the determined result at step S represents that the control signal has been transmitted again from the receiving apparatus namely the user continues to operate the control information inputting portion and designates the same considered point the flow advances to step S. At step S the controlling portion recognizes the same considered point. Thereafter the flow advances to step S. At step S the controlling portion designates the same priority range. Thereafter the flow advances to step S.

At step S the controlling portion controls the MUX to select encoded data of a background picture an object and additional information and multiplexes the selected encoded data so that the receiving apparatus can display the picture in the priority range with a higher spatial resolution.

In this case for a picture in the priority range encoded data of a background picture an object and additional information of the third hierarchical level and the second hierarchical level is selected with priority. In this case encoded data of a background picture an object and additional information of the first hierarchical level is selected with priority and output as multiplexed data. In addition at step as was described above high resolution information is inserted into the additional information. Thereafter the flow advances to step S. At step S the transmitting portion transmits the multiplexed data that is output from the MUX through the transmission path . Thereafter the flow returns to step S.

Thus in this case for a picture in the priority range the receiving apparatus displays a picture with a spatial resolution that is the same as that of the original picture of the first hierarchical level . In other words the receiving apparatus displays a picture of the first hierarchical level with a spatial resolution in each of the horizontal direction and the vertical direction that is four times higher than that of the picture of the third hierarchical level. However the temporal resolution is for example 0 frames second. In other words the receiving apparatus displays a still picture.

Thus when the user continues to operate the control information inputting portion and designate the same considered point for a picture in the priority range that contains the considered point data for improving a spatial resolution is transmitted with priority at the sacrifice of the temporal resolution of the picture. Thus although the temporal resolution of the picture deteriorates the spatial resolution of the picture in the priority range that contains the considered point gradually improves. Thus the picture in the priority range is more clearly displayed. In other words the picture of the portion that the user is considering is more clearly displayed.

Thus the transmission of picture data is controlled so that the spatial resolution and the temporal resolution of a picture in a particular priority range that contains a considered point are changed in the range of a resolution of picture data transmitted at the transmission rate of the transmission path . In other words the transmission of picture data is controlled so that the spatial resolution of a picture in the priority range improves and the temporal resolution of the picture deteriorates. Thus the improved spatial resolution and the deteriorated temporal resolution is obtained with picture data transmitted at the transmission rate of the transmission path . As a result at a limited transmission rate the spatial resolution of a picture displayed by the receiving apparatus can be more improved.

Multiplexed data is received by a receiving portion through the transmission path . After the multiplexed data is demodulated it is supplied to a DMUX demultiplexer . The DMUX separates the multiplexed data received from the receiving portion into encoded data of a background picture an object and additional information and supplies the separated data to a decoding portion . The decoding portion decodes the encoded data of the background picture the object and the additional information into their original data and outputs them to the combining process portion see .

Hierarchically encoded difference data as encoded data of a background picture is supplied to an adding device B. In addition a background picture of the immediately preceding frame that has been decoded and stored in a storing portion B is supplied to the adding device B. The adding device B adds the difference data of background pictures and the background picture of the immediately preceding frame received from the storing portion B so as to decode a background picture of a desired hierarchical level. The decoded background picture is supplied to the storing portion B. The storing portion B stores the background picture received from the adding device B. The decoded background picture is supplied to the adding device B and the combining process portion see .

Hierarchically encoded difference data as encoded data of an object is supplied to an adding device F. The adding device F and a storing portion F perform the similar processes to those of the adding device B and the storing portion B. Thus in the same manner as the background picture the difference data of objects is decoded to an object of a desired hierarchical level and then supplied to the combining process portion see . When there are a plurality of objects the adding device F and the storing portion F decode hierarchically decode the difference data of the plurality of objects.

Additional information that has been encoded with variable length code as encoded data of additional information is supplied to an inverse VLC portion . The inverse VLC portion decodes the additional information with variable length code. Thus the original additional information is obtained and supplied to the combining process portion .

The local decoder B shown in is structured as the adding device B and the storing portion B. Likewise the local decoder F is structured as the adding device F and the storing portion F.

A background picture that is output from the decoding portion see is supplied to a background picture writing portion . An object that is output from the decoding portion is supplied to an object writing portion . Additional information that is output from the decoding portion is supplied to the background picture writing portion the object writing portion and a combining portion .

The background picture writing portion successively writes background pictures to a background picture memory . When a picture is photographed while the video camera is panned or tilted a background picture is moved. At that point the background picture writing portion aligns the background picture and then writes the aligned background picture to the background picture memory . Thus the background picture memory can store a picture that is spatially wider than a picture of one frame. The background picture is aligned corresponding to a background picture moving vector contained in the additional information.

When the background picture writing portion writes a background picture with a high spatial resolution to the background picture memory the background picture writing portion changes the value of a background picture flag stored at an address of a background picture flag memory corresponding to the pixel of the background picture from 0 to 1. When the background picture writing portion writes a background picture to the background picture memory the background picture writing portion references the background picture flag memory . The background picture writing portion does not write a background picture with a low spatial resolution to a pixel whose background picture flag is 1 that represents that the pixel storing a background picture with a high spatial resolution. Thus basically whenever a background picture is supplied to the background picture writing portion it is written to the background picture memory . However the background picture writing portion does not write a background picture with a low spatial resolution to a pixel that stores a background picture with a high spatial resolution. As a result whenever a background picture with a high spatial resolution is supplied to the background picture writing portion the range of a high spatial resolution becomes wide in the background picture memory .

The object writing portion successively writes supplied objects to an object memory . When there are a plurality of objects the object writing portion writes each object to the object memory . When the object writing portion writes the same object assigned the same label to the object memory the object writing portion substitutes the old object with the new object that is newly supplied to the object writing portion .

In addition when the object writing portion writes an object with a high spatial resolution to the object memory the object writing portion changes a background picture flag stored at an address of an object flag memory corresponding to the pixel of the object from 0 to 1. When the object writing portion writes an object to the object memory the object writing portion references the object flag memory . The object writing portion does not write an object with a low spatial resolution to the object memory that stores an object with a high spatial resolution object flag 1 . Thus in the same manner as the background picture memory whenever an object is supplied to the object writing portion the object is written to the object writing portion . However the object writing portion does not write an object with a low spatial resolution to a pixel that stores an object with a high spatial resolution. As a result whenever an object with a high spatial resolution is supplied to the object writing portion the number of objects with a high spatial resolution increases in the object memory .

The background picture memory stores a background picture supplied from the background picture writing portion . The background picture flag memory stores the above described one bit background picture flag at an address of the background picture memory . The background picture flag memory represents whether or not a background picture with a high spatial resolution has been stored at an address of the background picture memory . The object memory is composed of at least one memory portion that stores each object supplied from the object writing portion . The object flag memory stores the above described one bit object flag that represents whether or not an object with a high spatial resolution has been stored in the object memory .

In this case for simplicity the background picture flag and the object flag are one bit flags. Alternatively the background picture flag and the object flag may be multi bit flags. In that case the background picture flag and the object flag can represent resolutions in more levels. In other words a one bit flag represents only two levels that are a high resolution and a low resolution. However a multi bit flag represents resolutions in more levels.

The combining portion reads a background picture of the current frame this frame may be referred to as considered frame stored in the background picture memory corresponding to a background picture moving vector contained in the additional information. In addition the combining portion combines the background picture and an object stored in the object memory corresponding to an object moving vector contained in the additional information. As a result the combining portion generates a picture of the considered frame and supplies the picture to a display memory .

In addition when the combining portion receives control information from the control information inputting portion see the combining portion reads an object at the considered point contained in the control information from the object memory and supplies the object to a sub window memory .

The display memory functions as a so called VRAM Video Read Only Memory . The display memory temporarily stores the picture of the considered frame supplied from the combining portion .

A superimposing portion reads the stored content of the display memory and supplies the stored content to the picture outputting portion see . The picture outputting portion displays the stored content. When necessary the superimposing portion opens a sub window that will be described later on the picture outputting portion reads the stored content of the sub window memory and displays the content on the sub window.

Next with reference to the process combining process performed by the combining process portion shown in will be described.

First of all at step S the background picture writing portion or the object writing portion writes a background picture or an object that is supplied from the decoding portion see to the relevant memory corresponding to the background picture flag stored in the background picture flag memory or the object flag stored in the object flag memory respectively in the above described manner.

In other words the background picture writing portion references the background picture flag memory and writes the supplied background picture to an address of the background picture memory when the background picture flag of a pixel corresponding to the address is 0. In contrast if the spatial resolution of the supplied background picture is high the background picture writing portion writes the background picture to an address of the background picture memory when the background picture flag of a pixel corresponding to the address is 1.

Likewise when the object flag of the object memory is 0 the object writing portion writes the supplied object to the object memory . When the object flag of the object memory is 1 if the spatial resolution of the supplied object is high the object writing portion writes the supplied object to the object memory .

When the background picture writing portion writes a background picture to a particular address of the background picture memory if the address has stored a background picture the background picture writing portion overwrites the background picture to the address. This operation applies to the object memory .

Thereafter the flow advances to step S. At step S the background picture writing portion and the object writing portion determine whether or not the additional information contains high resolution information. When the determined result at step S represents that the additional information contains the high resolution information namely the user has operated the control information inputting portion see the resultant control information has been transmitted to the transmitting apparatus and then the transmitting apparatus has transmitted a background picture and an object with a high spatial resolution for a picture in the priority range the flow advances to step . At step S the background picture writing portion or the object writing portion changes the background picture flag of the background picture flag memory or the object flag of the object flag memory to 1.

In other words when the transmitting apparatus transmits a background picture and an object with a high spatial resolution for a picture in the priority range at step S the background picture writing portion and the object writing portion write the background picture and object with the high spatial resolution to the background picture memory and the object memory respectively. Thus at step S the background picture flag and the object flag for a pixel that composes the background picture and the object with the high spatial resolution are changed to 1.

Thereafter the flow advances to step S. The combining portion reads an object in the priority range from the object memory and writes the object to the sub window memory .

In other words when the determined result at step S represents that the additional information contains high resolution information the user has operated the control information inputting portion see the control information has been transmitted to the transmitting apparatus and then the transmitting apparatus has transmitted a background picture and an object with a high spatial resolution for a picture in the priority range. The control information that is transmitted to the transmitting apparatus is also supplied to the combining portion . Thus when the combining portion receives the control information at step S the combining portion recognizes the priority range corresponding to the coordinates of the considered point contained in the control information reads an object with a high spatial resolution in the priority range that has been transmitted from the transmitting apparatus from the object memory and writes the object to the sub window memory .

Thereafter the flow advances to step S. At step S the combining portion reads a background picture of the current frame that is displayed this frame is referred to as considered frame from the background picture memory corresponding to a background picture moving vector contained in the additional information. In addition the combining portion reads an object that is displayed on the considered frame from the object memory . The combining portion combines the background picture of the considered frame and the object that is read from the object memory corresponding to the object moving vector contained in the additional information and writes the combined picture of the considered frame to the display memory . In other words the combining portion writes a background picture to for example the display memory and then overwrites an object to the display memory . As a result the combining portion writes a picture of which a background picture and an object are combined as a picture of the considered frame to the display memory .

In such a manner a picture of the considered frame written to the display memory and an object written to the sub window memory are supplied to the picture outputting portion see . The picture outputting portion displays the supplied picture and object.

In the transmitting apparatus a so called soft key may be contained in for example additional information. In this case the combining portion combines an object and a background picture using the soft key.

In contrast when the determined result at step S represents that the additional information does not contain high resolution information namely the user has not operated the control information inputting portion see FIG. the flow advances to step S skipping steps and . As was described above the combining portion reads a background picture of the considered frame from the background picture memory . In addition the combining portion reads a required object from the object memory and combines the background picture of the considered frame and the object that is read from the object memory corresponding to the additional information. As a result a picture of the considered frame is generated and written to the display memory . Thereafter the flow returns to step S. Thereafter the combining process portion repeats the similar process.

In the above described combining process when the user does not operate the control information inputting portion see namely the control information inputting portion that is composed of a pointing device such as a mouse is not dragged or clicked as shown in A a picture with a low spatial resolution is displayed with a default temporal resolution on the picture outputting portion see . In A an object with a low spatial resolution is being moved on a background picture with a low spatial resolution.

When the user operates the control information inputting portion see moves the cursor to an object and drags the cursor at the position of the object as was described above control information is transmitted to the transmitting apparatus . The transmitting apparatus transmits data necessary for displaying a picture with a high spatial resolution at the sacrifice of a temporal resolution for a picture in the priority range. As a result as shown in B although the temporal resolution is for example 0 frames second a picture of which the spatial resolution of an object and a background picture in the priority range around the dragged position is gradually improved is displayed on the picture outputting portion see . In other words corresponding to the dragging time or the number of clicks the spatial resolution of a picture in the priority range is gradually improved.

In this case on the picture outputting portion see as shown in B a sub window is opened. An object in the priority range around the dragged position is displayed in such a manner that the spatial resolution of the object is gradually improved.

Thereafter when the user stops the dragging operation with the control information inputting portion see as was described above at step S the combining portion reads a background picture of the considered frame from the background picture memory reads an object from the object memory combines the background picture of the considered frame and the object that is read from the object memory corresponding to additional information and writes the combined picture to the display memory . As was described above since the object with a high spatial resolution as a result of the dragging operation is stored in the object memory the picture outputting portion see displays a picture of which an object with a high spatial resolution as a result of the dragging operation is pasted at a relevant position of the considered frame with a regular temporal resolution as shown in C .

Thereafter the picture outputting portion see displays a picture of which an object with a high spatial resolution is being moved corresponding to the additional information with a regular temporal resolution.

Thus when the user performs the dragging operation at the position of an object that he or she wants to see in detail he or she can see the object with a high spatial resolution. In other words the user can see an object in detail.

When the user performs the dragging operation a background picture with a high spatial resolution in the priority range is stored to the background picture memory . Thus even if the user stops the dragging operation the background picture with the high spatial resolution stored in the background picture memory is displayed. Thus when the user performs the dragging operation since the spatial resolution of a background picture in the priority range including the dragged position is improved whenever the user performs the dragging operation at each position on the display screen of the picture outputting portion see a background picture with a high spatial resolution gradually widens in a mosaic pattern. Finally the picture outputting portion displays all the background picture with a high spatial resolution.

In addition according to the embodiment as was described above since a background picture is stored in the background picture memory the transmitting apparatus does not need to transmit a background picture with a low spatial resolution that has been already transmitted. Thus the transmission band transmission rate for the background picture can be assigned to an object and a background with a higher spatial resolution.

In the above described case an object with a high spatial resolution as a result of the dragging operation is stored to the object memory . After the dragging operation is stopped the object with the high spatial resolution is pasted to a background picture. Thus the spatial resolution of an object displayed by the receiving apparatus becomes high. However the state of an object photographed by the transmitting apparatus is not affected to an object displayed by the receiving apparatus .

To solve such a problem after the dragging operation is stopped an object with a high spatial resolution stored in the object memory can be substituted with an object stored in the storing portion F of the decoding portion see ignoring the object flag. In other words objects that are transmitted from the transmitting apparatus are successively stored to the storing portion F of the decoding portion see . Thus when the objects are written to the object memory the objects of a picture displayed on the picture outputting portion are affected by the state of the objects photographed by the transmitting apparatus however the spatial resolution of the objects displayed is low .

The MUX shown in that composes the transmitting process portion of the transmitting apparatus places the presence absence of high resolution information a frame rate temporal resolution and a spatial resolution in a priority range corresponding to the high resolution information and a frame rate and a spatial resolution in the non priority range to a header or the like of multiplexed data under the control of the controlling portion . The receiving apparatus recognizes the presence absence of the high resolution information the frame rate and spatial resolution in the priority range and the frame rate and spatial resolution in the non priority range corresponding to information placed in the header hereinafter this information is referred to as header information .

In the transmitting apparatus the header information may contain for example the coordinates of a considered point contained in control information transmitted from the receiving apparatus . In this case the combining portion shown in can recognize an object at the position of a considered point corresponding to the header information transmitted from the transmitting apparatus . In other words in the above described case the combining portion recognizes an object at the position of a considered point contained in the control information corresponding to the control information supplied from the control information inputting portion see reads the object from the object memory and supplies the object to the sub window memory . However when the header information contains a considered point the combining portion recognizes an object at the position of the considered point corresponding to the header information. In this case in the control information inputting portion does not need to supply the control information to the receiving apparatus .

Next with reference to the relation between a spatial resolution and a temporal resolution of a picture transmitted from the transmitting apparatus to the receiving apparatus through the transmission path will be described.

Now it is assumed that the transmission rate of the transmission path is R bps and that a picture composed of a background picture and three objects to is transmitted. For simplicity in this example additional information is not considered. In addition it is assumed that to display the background picture and the objects to with a particular spatial resolution each of them requires the same data amount.

In this case when the user does not perform the dragging operation in the transmitting apparatus as shown in A each of the background picture and the objects to is transmitted at R 4 bps of which the transmission rate R is divided by 4. When the regular temporal resolution is 1 T frames second the transmitting apparatus can transmit data of one frame of each of the background picture and the objects to in at most T seconds. Thus in this case the receiving apparatus displays the background picture and the objects to with a spatial resolution obtained with data of T R 4 bits per frame.

When the user perform the dragging operation at the position of for example the object as shown in A the transmitting apparatus stops transmitting the background picture and the objects and and transmits only the object at all the transmission rate R of the transmission path . Thereafter at time t of which time period 4T has elapsed from time t when the user stops the dragging operation the transmitting apparatus transmits the background picture and the objects to at the transmission rate R 4 each.

Thus while the user is performing the dragging operation the transmitting apparatus transmits data of 4T R bits for the object . Thus assuming that while the user is performing the dragging operation the temporal resolution is 0 frames second the receiving apparatus displays the object with a spatial resolution obtained with data of 4T R bits per frame. In other words when the horizontal spatial resolution and the vertical spatial resolution are improved for the same amount in the receiving apparatus although the temporal resolution becomes 0 frames second the receiving apparatus displays the object with a spatial resolution in each of the horizontal direction and the vertical direction that is four times 4T R T R 4 bits higher than that in the case that the user does not perform the dragging operation.

In other words the spatial resolution can be more improved at the sacrifice of the temporal resolution. In addition in comparison with the case that the temporal resolution is sacrificed the spatial resolution of a portion that the user is considering can be quickly improved.

In the above described case while the user performing the dragging operation for the object all data of the background picture and the other objects and is not transmitted. However as shown in B a higher transmission rate can be assigned to the data of the object while a low transmission rate can be assigned to data of the background picture and the other objects and .

Alternatively even if the dragging operation is performed the transmission rate assigned to each of the background picture and the objects to may not be changed from R 4. In other words in this case since the spatial resolution is improved at the sacrifice of the temporal resolution for example although it takes a long time to display the data the spatial resolution can be improved without need to change the assignment of the transmission rate.

According to the embodiment as was described above an object with a high spatial resolution as a result of the dragging operation is stored to the object memory . After the dragging operation is stopped the object with the high spatial resolution is pasted on a background picture. However the position of the background picture to which the object with the high spatial resolution is pasted depends on an object moving vector contained in the additional information about the object that is transmitted from the transmitting apparatus .

Thus the receiving apparatus should recognize what object of a particular frame corresponds to what object of an adjacent frame. Thus when the object extracting portion of the transmitting apparatus see extracts an object the object extracting portion adds information that allows the receiving apparatus to perform such an recognizing operation to the additional information.

A picture that is output from the picture inputting portion and a background picture that is output from the background picture extracting portion are supplied to a subtracting portion . The subtracting portion subtracts the background picture that is output from the background picture extracting portion from the picture that is output from the picture inputting portion and obtains a foreground picture as an object. The foreground picture obtained by the subtracting portion is supplied to a frame memory and an initial area dividing portion .

The frame memory temporarily stores the foreground picture supplied from the subtracting portion . The initial area dividing portion performs an initial area dividing process using the foreground picture of the current frame that is processed this frame is referred to as considered frame that is supplied from the subtracting portion and the foreground picture of the immediately preceding frame stored in the frame memory this foreground picture is referred to as foreground picture of the preceding frames .

In other words the initial area dividing portion categorizes each pixel that composes the foreground picture of the considered frame as a class corresponding to the pixel value. In reality when a pixel value is represented by RGB Red Green and Blue the initial area dividing portion categorizes each pixel as a class depending on the relation between a vector composed of elements of R G and B values this vector may be referred to as color vector and a plurality of small areas in the RGB space. In addition the initial area dividing portion categorizes each pixel that composes the foreground picture of the immediately preceding frame stored in the frame memory as a class in the same manner.

When the considered frame is for example the n th frame the initial area dividing portion divides the foreground picture of the n th frame and the foreground picture of the n 1 th frame the immediately preceding frame into areas that are temporally or spatially adjacent areas and that are composed of pixels categorized as the same class.

In other words for example it is assumed that each pixel that composes the foreground picture of the n th frame and each pixel that composes the foreground picture of the n 1 th frame are categorized as classes as shown in . In also in a set of a character c and a numeral contained in a square represents the class of a pixel.

In the case shown in when the foreground picture of the n th frame and the foreground picture of the n 1 th frame are divided into areas composed of pixels categorized as the same class initial areas as denoted by dotted lines shown in are formed.

The initial areas obtained by the initial area dividing portion are supplied to an area merging portion shown in .

The area merging portion performs an area margining process for margining the initial areas supplied form the initial area dividing portion .

In other words the area merging portion reads object information about an object contained in the n 1 th frame from an object information memory and recognizes the position and the range of the object contained in the n 1 th frame. In addition the area merging portion recognizes pixels that compose the object contained in the n 1 th frame and merges the initial areas that contain the pixels.

In reality for example assuming that a particular object Obj is contained in a range denoted by solid lines a box shown in A the object Obj is composed of pixels categorized as classes c c c and c. The initial areas containing these pixels are merged. Thus in this example initial areas composed of pixels of the classes c c c and c hereinafter the initial areas composed of pixels of the classes c i are referred to as initial areas c i are merged as hatched areas shown in B .

In addition the area merging portion calculates the distance between the merged initial area hereinafter may be referred to as merged area and an initial area adjacent to the merged area. In this example the distance between a merged area and an initial area adjacent thereto hereinafter may be referred to as adjacent initial area may be the distance of the average values of the pixel values colors of the pixels that compose two areas the merged area and the adjacent initial area this distance may be referred to as distance in the RGB space or the continuity of pixel values colors of pixels in the vicinity of the boundary of the two areas.

When the distance between the merged area and the adjacent initial area is smaller than or equal to a predetermined threshold value the area merging portion merges the merged area and the adjacent initial area and generates a new merged area. The area merging portion calculates the above described distance until there is no adjacent initial area that can be merged to the merged area and repeatedly merges the adjacent initial area and the merged area.

Thus with the merged area shown in B for example a merged area shown in C is formed. In C since the distance between the initial areas c and c is close they are merged to the merged area shown in B . In contrast since the distance between the initial areas c and c is far they are not merged to the merged area.

When there is no adjacent initial area that can be merged to the merged area as shown in C the area merging portion extracts a portion composed of pixels that compose the foreground picture of the n th frame as an object corresponding to the object Obj of the n 1 th frame this object may be referred to as corresponding object assigns the same label as the label of the object Obj of the n 1 th frame and outputs the object to the merged area process portion and the separated area process portion .

In other words according to the embodiment objects that correspond in individual frames are assigned the same label. The receiving apparatus recognizes what object of a particular frame corresponds to what object of the adjacent frame corresponding to the label.

The label assigned to the object Obj of the n 1 th frame is contained in the object information and stored in the object information memory . With reference to the object information memory the area merging portion recognizes the label assigned to the object Obj of the n 1 th frame.

In addition after the area merging portion extracts objects of the n th frame corresponding to all objects of the n 1 th frame in the above described manner the area merging portion extracts an area of which each initial area of the n th frame and another initial area adjacent thereto are merged as an object and assigns a new label other than any label assigned to objects of the n 1 th frame to the extracted object and outputs the extracted object to the merged area process portion and the separated area process portion .

The merged area process portion and the separated area process portion perform a merged area process and a separated area process respectively. The merged area process is performed when objects are merged. The separated area process is performed when a merged object is separated.

In other words for example considering three successive frames of the n 1 th frame the n th frame and the n 1 th frame as shown in in the n 1 th frame objects A and B approach each other. In the n th frame the objects A and overlap. In other words in the n th frame the objects A and B may be merged as one object. In this case the objects A and B that have been merged as one object continue to move in their directions. In the n 1 th frame the merged object is separated into the two objects A and B.

In this case in the area merging process of the area merging portion the merged object of the n th frame corresponds to both the objects A and B in the n 1 th frame. In contrast the objects A and B separated in the n 1 th frame correspond to one merged object in the n th frame. According to the embodiment it is assumed that one object of a particular frame corresponds to one object of the immediately preceding frame. Thus as was described above it is not preferred to correlate two objects with one object. In contrast it is not preferred to correlate one object with two objects.

Thus the merged area process portion performs a merged area process for correlating one merged object of the n th frame with one of the objects A and B of the n 1 th frame. The separated area process portion performs a separated area process for correlating one of two objects A and B of the n 1 th frame with one merged object of the n th frame.

In other words the merged area process portion assigns the same label as one of the objects A and B of the n 1 th frame to one merged object of the n th frame. On the other hand the separated area process portion assigns the same label as the label of the merged object of the n th frame to one of the two separated objects A and B of the n 1 th frame and assigns a new label to the other separated object of the n 1 th frame.

The object extracted result as the result of the merged area process performed by the merged area process portion and the object extracted result as the result of the separated area process performed by the separated area process portion are merged by the area merging portion and supplied to a new area process portion .

When the object extracted results of the merged area process portion and the separated area process portion contain a new object the new area process portion performs a new area process for the new object.

There are three types of objects that are assigned new labels in the object extracted results of the merged area process portion and the separated area process portion . The first type is an object of which since the motion of an object is fast and the object does not spatially overlap in the considered frame and the immediately preceding frame the area merging portion does not extract the object of the considered frame as the corresponding object of the immediately preceding frame. The second type is an object of which since the corresponding object of the immediately preceding frame is merged with another object the separated area process portion cannot correlate the object of the considered frame with the corresponding frame of the immediately preceding frame. The third type is an object of which since a new object takes place in the considered frame a new label is assigned thereto.

Among those three types of objects a new label should be assigned to an object of the third type. Thus for objects of the first and second types the new area process portion detects a corresponding object from the immediately preceding frame and re assigns the same label as the object of the considered frame to the corresponding object of the immediately preceding frame.

In reality the new area process portion references the object information memory recognizes objects of several past frames of the considered frame and obtains the distance between each of the recognized objects and the considered object of the considered frame the considered object being assigned a new label. As the distance between objects the distance between feature amounts of the objects can be used. Examples of a feature amount of an object are an area of the object a histogram in the tangent direction of the contour line composed of each pixel of the object for example a histogram in each of eight directions of up down left right upper left lower left upper right and lower right and a moving vector of the object.

The new area process portion obtains the minimum value of the distances between the recognized objects and the considered object. When the minimum value is smaller than or equal to a predetermined threshold value the new area process portion treats an object with the minimum distance to the considered object as an object corresponding to the considered object assigns the same label as the label of the obtained object to the considered object and outputs the considered object. When the minimum value of the distances between the recognized objects and the considered object is not smaller than the predetermined threshold value namely there is no object whose distance to the considered object is small in the past frames the new area process portion treats the considered object as an object that newly takes place in the considered frame assigns a new label to the considered object and outputs the considered object.

An output of the new area process portion is supplied to the additional information calculating portion see and the transmitting process portion see . In addition the output of the new area process portion is supplied to the object information memory . The object information memory temporarily stores an object the position and size contour of the object pixel values of pixels that compose the object and so forth and a label assigned thereto as object information.

Next with reference to a flow chart shown in the object extracting process for extracting an object from a picture will be described. The object extracting process is performed by the object extracting portion shown in .

A picture that is output by the picture inputting portion and a background picture that is output by the background picture extracting portion are supplied to the subtracting portion . At step S the subtracting portion subtracts the background picture that is output from the background picture extracting portion from the picture that is output from the picture inputting portion and obtains a foreground picture as an object. The foreground picture obtained by the subtracting portion is supplied to the frame memory and the initial area dividing portion . The frame memory stores the foreground picture that is output from the subtracting portion .

On the other hand at step S the initial area dividing portion references a foreground picture of the immediately preceding frame of the considered frame performs the initial area dividing process described with reference to obtains initial areas and supplies the obtained initial areas to the area merging portion . At step S the area merging portion references object information of the immediately preceding frame stored in the object information memory performs the area merging process as described with reference to for the initial areas that are output from the initial area dividing portion and extracts an object of the considered frame.

The object extracted by the area merging portion is supplied to the merged area process portion and the separated area process portion . At step S the merged area process portion or the separated area process portion performs the merged area process or the separated area process as described with reference to and outputs the processed result to the new area process portion .

At step S the new area process portion performs the above described new area process for the outputs of the merged area process portion and the separated area process portion . Thus the new area process portion outputs the final object extracted result of the considered frame. The extracted result of the object is supplied to the additional information calculating portion see and the transmitting process portion see . In addition the extracted result of the object is supplied to the object information memory and stored therein.

Thereafter the flow returns to step S. At the step the next frame is designated as a new considered frame. Thereafter the object extracting portion repeats the similar process.

Next with reference to a flow chart shown in the area merging process performed by the area merging portion at step S of will be described in detail.

In the area margining process first of all at step S the area merging portion references object information about an object contained in the immediately preceding frame preceding frame of the considered frame and treats the object of the preceding frame as a considered object. At step S using the considered object as shown in the area merging portion merges initial areas that are output from the initial area dividing portion and forms a merged area.

Thereafter the flow advances to step S. At step S the area merging portion searches an initial area adjacent to the merged area this initial area may be referred to as adjacent initial area . Thereafter the flow advances to step S. At step S the area merging portion calculates the distance between the merged area and the considered initial area. Thereafter the flow advances to step S. At step S the area merging portion determines whether or not the distance between the areas is smaller than a predetermined threshold value.

When the determined result at step S represents that the distance between the merged area and the considered initial area is smaller than the predetermined threshold value the flow advances to step S. At step S the area merging portion merges the considered initial area to the merged area and thereby forms a new merged area. Thereafter the flow advances to step S.

In contrast when the determined result at step S represents that the distance between the merged area and the considered initial area is not smaller than the predetermined threshold value the flow advances to step S skipping step S. In other words the area merging portion does not merge the considered initial area to the merged area. At step S the area merging portion determines whether or not all initial areas adjacent to the merged area have been searched. When the determined result at step S represents that all the initial areas adjacent to the merged area have not been searched the flow returns to step S. At step S the area merging portion searches an adjacent initial area that has not been searched. Thereafter the area merging portion repeats the similar process.

When the determined result at step S represents that all initial areas adjacent to the merged area have been searched the flow advances to step S. At step S the area merging portion determines whether or not each of all objects contained in the preceding frame has been designated as the considered object. When the determined result at step S represents that each of all objects contained in the preceding frame has not been designated as the considered object the flow returns to step S. At step S the area merging portion designates one of objects that are contained in the preceding frame as the considered object and repeats the similar process for the newly considered object.

In contrast when the determined result at step S represents that each of all the objects contained in the preceding frame has been designated as the considered object the flow returns to the called process.

Next with reference to a flow chart shown in the merged area process performed by the merged area process portion at step S shown in will be described in detail.

First of all at step S the merged area process portion designates a frame that is processed as a considered frame references the object information memory recognizes the number of objects contained in the immediately preceding frame preceding frame namely the number of objects of the preceding frame of the considered frame in the condition that the objects of the preceding frame spatially overlap with the considered object of the considered frame and sets the number of objects to a variable N.

Thereafter the flow advances to step S. At step S the merged area process portion determines whether or not the variable N is 2 or larger. When the variable N is smaller than 2 namely no object that spatially overlaps with the considered object is contained in the preceding frame or the number of the objects is one the flow advances to step S skipping steps S and S.

In contrast when the determined result at step S represents that the variable N is 2 or larger namely two or more objects that spatially overlap with the considered object are contained in the preceding frame the flow advances to step S. At step S the merged area process portion calculates the distance between the considered object and each of two or more objects of the preceding frame that spatially overlap with the considered object. Thereafter the flow advances to step S.

At step S the merged area process portion selects an object with the minimum distance to the considered object from the objects obtained at step S and assigns the same label as the label of the selected object to the considered object.

Thereafter the flow advances to step S. At step S the merged area process portion determines whether or not each of all objects contained in the considered frame has been designated as the considered object. When the determined result at step S represents that each of all objects contained in the considered frame has not been designated as the considered object the merged area process portion designates one of those objects as the considered object. Thereafter the flow returns to step S. At step S the merged area process portion repeats the similar process.

On the other hand when the determined result at step S represents that each of all the objects contained in the considered frame has been designated as the considered object the flow returns to the called process.

Next with reference to a flow chart shown in the separated area process performed by the separated area process portion at step S shown in will be described in detail.

The separated area process portion references the object information memory and designates one of objects contained in the immediately preceding frame preceding frame of the considered frame as a considered object. In addition at step S the separated area process portion recognizes the number of objects of the considered frame corresponding to the considered object the recognized objects are referred to as corresponding objects and sets the number of objects to the variable N.

Thereafter the flow advances to step S. At step S the separated area process portion determines whether or not the variable N is 2 or larger.

When the determined result at step S represents that the variable N is not larger than 2 namely no object that spatially overlaps with the considered object is contained in the considered frame or the number of objects is one the flow advances to step S skipping steps S to S.

In contrast when the determined result at step S represents that the variable N is 2 or larger namely two or more objects that spatially overlap with the considered object are contained in the considered frame objects corresponding to the considered object the flow advances to step S. At step S the separated area process portion calculates the distance between each of those objects and the considered object. Thereafter the flow advances to step S.

At step S the separated area process portion selects an object with the minimum distance to the considered object from those objects and assigns the same label as the label of the selected object to the considered object.

Thereafter the flow advances to step S. At step S the separated area process portion assigns a new label to one of the objects that are not selected at step S namely objects except for an object with the minimum distance to the considered object . Thereafter the flow advances to step S.

At step S the separated area process portion determines whether or not each of all objects contained in the preceding frame has been designated as the considered object. When the determined result at step S represents that each of all the objects contained in the preceding frame has not been designated as the considered object the separated area process portion designates one of those objects as the considered object. Thereafter the flow returns to step S. At step S the separated area process portion repeats the similar process.

When the determined result at step S represents that each of all the objects contained in the preceding frame has been designated as the considered object the flow returns to the called process.

In the above described case when the user designates a considered point with the control information inputting portion the transmitting apparatus controls the transmission of data so that the spatial resolution of a picture in a priority range containing the considered point is improved at the sacrifice of the spatial resolution of the picture. Alternatively the transmitting apparatus may learn a preference of the user detect an object or the like that the user tends to see with a high spatial resolution corresponding to the learnt result and control the transmission of data so that the object is displayed with a high spatial resolution.

A priority range designating portion receives a control signal transmitted from the receiving apparatus designates a priority range in the above described manner and supplies the designated priority range to a selection controlling portion and a feature amount extracting portion .

The selection controlling portion controls the selection of data of a background picture an object and additional information of the MUX see . In other words when the selection controlling portion receives the priority range from the priority range designating portion the selection controlling portion controls the MUX see to improve the spatial resolution of the picture in the priority range at the sacrifice of the temporal resolution of the picture. In addition when the selection controlling portion receives a label from an object detecting portion the selection controlling portion controls the MUX see to improve the spatial resolution of an object with the label at the sacrifice of the temporal resolution of the picture.

The data amount calculating portion see supplies the data rate of the multiplexed data that is output from the MUX to the selection controlling portion . The selection controlling portion controls the selection of data of the MUX so that the data rate of the multiplexed data does not exceed the transmission rate of the transmission path .

A background picture an object and additional information that are output by the pre process portion see and a priority range that is output by the priority range designating portion are supplied to the feature amount extracting portion . The feature amount extracting portion extracts a feature amount of a picture in the priority range that is output from the priority range designating portion . In other words the feature amount extracting portion extracts a feature amount of an object contained in the priority range so that the feature amount reflects the tendency of the picture that the user is considering.

In reality for example as shown in the feature amount of an object of a particular person extracted by the feature amount extracting portion represents that an object is a person the motion of the object is uniform the position in the depth direction of the object depth is foreground the position of the object on the display is center the object is moving the object is a portion that is moving the area of the object contains eyes a nose and a mouth the area of the object is composed of eyes a nose and a mouth the pattern of the object is a stripe pattern the object is a stripped portion the color of the object is red the object is a red portion .

The feature amount extracting portion obtains a vector having elements of feature amounts of an extracted object the vector may be referred to as feature amount vector and increments the frequency of the histogram of the obtained feature amount vector stored in the histogram storing portion by 1.

A histogram storing portion stores the histogram of the feature amount vector as the learnt result of the preference of the user.

The object detecting portion detects an object from those supplied from the preprocess portion see so that a feature amount vector with the maximum frequency of the histogram is obtained from the histogram storing portion . In other words the object detecting portion obtains a feature amount vector for an object supplied from the pre process portion see in the same manner as the feature amount extracting portion . In addition the object detecting portion references the histogram stored in the histogram storing portion and determines whether or not a feature amount vector of an object supplied from the pre process portion see is contained in a predetermined range of the feature amount vector space around the feature amount vector with the highest frequency. When the feature amount vector is contained in the predetermined range the object detecting portion designates the object as an object that the user tends to consider and supplies the label of the object to the selection controlling portion .

Next with reference to a flow chart shown in the controlling process of the MUX see will be described. The controlling process is performed by the controlling portion shown in .

First of all at step S the priority range designating portion determines whether or not a control signal has been transmitted from the receiving apparatus . When the determined result at step S represents that a control signal has been transmitted from the receiving apparatus the flow advances to step S. At step S the priority range designating portion designates a priority range in the above described manner corresponding to the control signal and supplies the priority range to the selection controlling portion and the feature amount extracting portion .

At step S the selection controlling portion controls the MUX see to improve the spatial resolution of a picture an object and a background picture in the priority range supplied from the priority range designating portion at the sacrifice of the temporal resolution of the picture.

At step S the feature amount extracting portion extracts the feature amount of the object in the priority range supplied from the priority range designating portion and obtains a feature amount vector having elements composed of each feature amount of the object. At step S the feature amount extracting portion increments the frequency of the histogram of the feature amount vector stored in the histogram storing portion by 1. Thereafter the flow returns to step S.

In the loop from step S to step S the histogram storing portion forms a histogram of a feature vector of an object that the user tends to consider. In other words the histogram storing portion learns the preference of the user.

In addition the feature amount extracting portion can quantized the obtained feature amount vector and increment the frequency of code corresponding to the quantized result of the feature amount vector. In this case the histogram storing portion temporarily stores the histogram of the code.

In contrast when the determined result at step S represents that the control signal has not been transmitted from the receiving apparatus the flow advances to step S. At step S the object detecting portion obtains a feature amount vector of the object supplied from the pre process portion see in the same manner as the feature amount extracting portion . In addition at step S the object detecting portion references the histogram stored in the histogram storing portion and determines whether or not a feature amount vector of the object supplied from the pre process portion see is contained in a predetermined range of the feature amount vector space around the feature amount vector with the highest frequency. In other words at step S the object detecting portion determines whether or not the distance between the feature amount vector with the highest frequency and the feature amount vector of the object supplied from the pre process portion is equal to or smaller than a predetermined value.

As was described above when the histogram storing portion stores the histogram of the code as the vector quantized result the object detecting portion quantizes the obtained feature amount vector. At step S the object detecting portion determines whether or not the code as the vector quantized result matches the code of the highest frequency of the histogram stored in the histogram storing portion .

When the determined result at step S represents that the distance between the feature amount vector with the highest frequency and the feature amount vector of the object supplied from the pre process portion is not smaller than the predetermined value namely the object supplied from the pre process portion is an object that the user does not tend to consider due to his or her tendency the flow advances to step S. At step S the selection controlling portion controls the MUX see so that the receiving apparatus displays a picture with a regular temporal resolution and a regular spatial resolution. Thereafter the flow returns to step S.

In contrast when the determined result at step S represents that the distance between the feature amount vector with the maximum frequency and the feature amount vector of the object supplied from the pre process portion is equal to or smaller than the predetermined value namely the object supplied from the pre process portion is an object that the user tends to consider due to his or her tendency the object detecting portion outputs the label of the object supplied from the pre process portion to the selection controlling portion . Thereafter the flow advances to step S.

At step S the selection controlling portion controls the MUX see to improve the spatial resolution of the object with the label supplied from the object detecting portion at the sacrifice of the temporal resolution. Thereafter the flow returns to step S.

Thus in this case the receiving apparatus displays an object with a label that is output from the object detecting portion so that the spatial resolution becomes high at the sacrifice of the temporal resolution. Thereafter the receiving apparatus continues to display the object with the high spatial resolution.

As a result the receiving apparatus automatically displays an object that the user tends to consider so that the spatial resolution of the object becomes high without necessity of the intervention of the user for the control information inputting portion . Thereafter the receiving apparatus continues to display the object with the high spatial resolution however in this case as was described above the temporal resolution of the picture deteriorates .

The histogram of the feature amount vector stored as the learnt result of the preference of the user in the histogram storing portion can be reset periodically non periodically or corresponding to a request from the user of the receiving apparatus .

In the above described case the spatial resolution of an object that has a feature amount vector that matches or that is similar to a feature amount vector with the highest frequency of the histogram is improved. Alternatively spatial resolutions of all objects having feature amount vectors that match or that are similar to a feature amount vector whose frequency in the histogram exceeds a predetermined value may be improved.

The priority range is a predetermined range of which a considered point is at the center of gravity in the above described case the priority range is a rectangular range . However it can be said that an area of a picture in a particular range containing a considered point is a picture area that the user wants to see with interest hereinafter this area is referred to as interested object area .

On the other hand a moving picture displayed by the receiving apparatus has a moving picture area hereinafter this area may be referred to as moving area and a still picture area hereinafter this area may be referred to as still area .

To improve the spatial resolution of the interested object area it is necessary to recognize designate an interested object area that the user is considering in both the moving area and the still area of the picture. When the interested object area that the user is considering can be designated a picture area that the user is not considering for example a background picture can be obtained.

Even if an interested object area that the user is considering can be designated at a particular time thereafter it may be changed. Thus when a picture area that the user is considering is changed to another picture area it is necessary to recognize the new picture area as the interested object area.

In addition there may be a plurality of interested object areas that the user is considering. In this case it is necessary to separately recognizes those interested object areas.

Thus shows an example of a second structure of the picture transmitting system shown in in the case that portable terminal units are used as the transmitting apparatus and the receiving apparatus shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words the structure of the picture transmitting system shown in is basically the same as the structure of the picture transmitting system shown in .

In the embodiment shown in all information necessary for controlling a spatial resolution and a temporal resolution such as the coordinates of a considered point that the user is considering the spatial resolution and the transmission rate is transmitted as control information from the receiving apparatus to the transmitting apparatus . In contrast according to the embodiment shown in as will be described later information of a considered point of a picture displayed on the displaying portion that is operated clicked by the user with the key portion of the receiving apparatus is transmitted as control information hereinafter information at a considered point may be referred togas click data .

When the transmitting apparatus receives click data from the receiving apparatus the transmitting apparatus designates a picture area interested object area that the user is considering from a picture displayed by the receiving apparatus the picture is photographed by the video camera portion of the transmitting apparatus corresponding to the click data and controls the information amount of the picture data that is transmitted to the receiving apparatus so that the spatial resolution and the temporal resolution of the designated picture area are changed while a predetermined condition is satisfied.

Next shows an example of the structure of the transmitting apparatus shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In the transmitting apparatus shown in a background picture extracting portion an object extracting portion and a transmitting process portion are disposed instead of the background picture extracting portion the object extracting portion and the transmitting process portion respectively. In addition click data transmitted from the receiving apparatus is supplied to not only the transmitting process portion corresponding to the transmitting process portion but the preprocess portion . Except for those points the structure of the transmitting apparatus shown in is basically the same as the structure of the transmitting apparatus shown in . However in the transmitting apparatus shown in an output of the background picture extracting portion is not supplied to the object extracting portion . In contrast in the transmitting apparatus shown in an output of the background picture extracting portion is supplied to the object extracting portion . In addition in the transmitting apparatus shown in an output of the object extracting portion is supplied to the background picture extracting portion . In contrast in the transmitting apparatus shown in an output of the object extracting portion is not supplied to the background picture extracting portion .

Click data is supplied to the pre process portion . In the preprocess portion the click data is supplied to the object extracting portion . The object extracting portion extracts designates a picture area interested object area that the user of the receiving apparatus is considering from a picture photographed by the picture inputting portion and supplies picture data corresponding to the extracted designated interested object area to the transmitting process portion . When there are a plurality of interested object areas that the user of the receiving apparatus is considering in the picture photographed by the picture inputting portion the object extracting portion supplies picture data of the plurality of interested object areas to the transmitting process portion . In addition the picture data of an interested object area extracted by the object extracting portion is also supplied to the additional information calculating portion .

As an example of an interested object area that the user is considering is an object such as a substance. Next the case that an object hereinafter referred to as object picture is extracted as an example of an interested object area by the object extracting portion will be described. It should be noted that an interested object area is not limited to an object. Instead an interested object area may be a picture area other than an object a picture area in an object or a background picture portion that will be described later . However according to the embodiment as an example the case that an interested object area is an object will be described. The object extracting process interested object area designating process performed by the object extracting portion will be described later.

The background picture extracting portion extracts a signal hereinafter referred to as background picture data corresponding to a background picture portion that is a picture area other than an interested object area hereinafter the background picture portion is referred to as background picture of the picture from picture data supplied from the picture inputting portion corresponding to the object extracted result of the object extracting portion and supplies the extracted background picture data to the transmitting process portion and the additional information calculating portion . In this example a plane picture area whose activity is low namely that does not have a significance as a picture is treated as a background picture. Of course as well as a picture that does not have a significance a background picture may be an object in which the user is not interested. In this example for simplicity the above described plane picture area will be described as a background picture.

The additional information calculating portion detects a background picture moving vector that represents the motion of background picture corresponding to background picture data supplied from the background picture extracting portion the motion of the background picture corresponds to the motion in the photographing direction of the picture inputting portion . In addition the additional information calculating portion detects an object moving vector that represents the motion of an object corresponding to picture data of an object picture hereinafter this picture data is referred to as object picture data supplied from the object extracting portion . The additional information calculating portion supplies the detected moving vector as a part of the additional information to the transmitting process portion . Moreover the additional information calculating portion supplies information about the object such as the position and contour of the object of the picture frame photographed by the picture inputting portion corresponding to the object picture data supplied from the object extracting portion as additional information to the transmitting process portion . In other words when the object extracting portion extracts an object picture from picture data the object extracting portion also extracts information about the object such as the position and contour of the object and supplies the information to the additional information calculating portion . The additional information calculating portion outputs information about the object as additional information.

The transmitting process portion encodes the object picture data supplied from the object extracting portion the background picture data supplied from the background picture extracting portion and the additional information supplied from the additional information calculating portion corresponding to the click data supplied from the receiving apparatus so that while the spatial resolution of the object picture of the picture displayed by the receiving apparatus is improved the condition of the data rate of the transmission path is satisfied. Thereafter the transmitting process portion multiplexes the encoded object picture data the encoded background picture data and the encoded additional information and transmits the multiplexed data the frame rate information and so forth to the receiving apparatus through the transmission path .

Next with reference to a flow chart shown in the process performed by the transmitting apparatus shown in will be described.

At step S the transmitting apparatus inputs picture data obtained by the picture inputting portion to the preprocess portion .

Thereafter at step S the transmitting apparatus receives click data transmitted from the receiving apparatus and inputs the click data to the pre process portion .

At step S the pre process portion that has received the picture data and the click data performs a pre process for extracting a background picture an object and additional information and supplies the background picture data object picture data and additional information obtained in the pre process to the transmitting process portion .

At step S the transmitting process portion calculates the data amounts of the object picture data background picture data and additional information so that the condition of the data rate of the transmission path is satisfied. Thereafter the transmitting process portion encodes the object picture data background picture data and additional information corresponding to the data amounts and then multiplexes them. Thereafter along with the frame rate information and so forth the transmitting process portion transmits the multiplexed data to the receiving apparatus through the transmission path .

Thereafter the flow returns to step S. At step S the transmitting apparatus repeats the similar process.

Next shows an example of the structure of the receiving apparatus shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words in the receiving apparatus shown in a combining process portion is disposed instead of the combining process portion . In addition a click data inputting portion and a click data transmitting portion are disposed instead of the control information inputting portion and the control information transmitting portion respectively. Except for those points the structure of the receiving apparatus shown in is basically the same as the structure of the receiving apparatus shown in .

Multiplexed data transmitted from the transmitting apparatus through the transmission path is received by the receiving process portion . The receiving process portion separates the received multiplexed data into encoded background picture data encoded object picture data and encoded additional information data and decodes the separated data. Thereafter the receiving process portion supplies the decoded background picture data object picture data and additional information to the combining process portion .

The combining process portion combines the decoded background picture data object picture data and additional information and supplies the combined picture signal to the picture outputting portion . In addition the combining process portion controls the spatial resolution and temporal resolution of the picture that is combined corresponding to click data supplied from the click data inputting portion .

The click data inputting portion generates click data that represents the click portion coordinate position and the click time corresponding to the operation of the key portion by the user. The key portion functions as a pointing device for designating the coordinate position of a picture displayed on the picture outputting portion corresponding to the displaying portion of the receiving apparatus see . In other words when the user clicks the key portion for a desired picture portion interested object area of a picture displayed on the picture outputting portion the click data inputting portion generates click data that represents the coordinate information of the click position and the click time. The click data generated combining process portion and the click data transmitting portion .

When the click data transmitting portion receives the click data from the click data inputting portion the click data transmitting portion transmits the click data to the transmitting apparatus through the transmission path .

Next with reference to a flow chart shown in the process performed by the receiving apparatus shown in will be described in brief.

First of all at step S the receiving apparatus receives multiplexed data transmitted from the transmitting apparatus through the transmission path .

At step S the receiving process portion separates the multiplexed data into encoded background picture data encoded object picture data and encoded additional information data and decodes the separated encoded data. The decoded background picture data object picture data and additional information are sent to the combining process portion .

At step S in the receiving apparatus the click data inputting portion obtains click data corresponding to a click operation of the key portion by the user and supplies the click data to the combining process portion and the click data transmitting portion . Thus the click data is transmitted from the click data transmitting portion to the transmitting apparatus .

At step S the combining process portion combines a picture and controls the spatial resolution and the temporal resolution of the combined picture corresponding to the background picture data object picture data and additional information supplied from the receiving process portion and the click data supplied from the click data inputting portion . The transmitting apparatus can place the click data transmitted from the receiving apparatus in header information of the multiplexed data and transmit the resultant header information to the receiving apparatus . In this case the combining process portion of the receiving apparatus can obtain the click data from the header information. Thus it is not necessary to supply the click data from the click data inputting portion to the combining process portion .

At step S the picture outputting portion displays the picture combined by the combining process portion on a liquid crystal display or the like of the picture outputting portion .

Thereafter the flow returns to step S. At step S the receiving apparatus repeats the similar process.

Next shows a real example of the structure of the transmitting process portion of the transmitting apparatus shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words the structure of the transmitting process portion shown in is basically the same as the structure of the transmitting process portion shown in except that the transmitting process portion shown in supplies click data as part of control information rather than the whole control information to the controlling portion .

In background picture data object picture data and additional information are supplied from the preprocess portion shown in to the transmitting process portion . The background picture data object picture data and additional information are input to the encoding portion and the controlling portion . The encoding portion hierarchically encodes the supplied background picture data object picture data and additional information in the above described manner and supplies the obtained encoded data to the MUX . The MUX selects the encoded background picture encoded data encoded object picture encoded and encoded additional information data under the control of the controlling portion and supplies the selected data as multiplexed data to the transmitting portion . The transmitting portion modulates the multiplexed data supplied form the MUX corresponding to the transmission standard of the transmission path as a downstream portion and transmits the modulated data to the receiving apparatus through the transmission path .

On the other hand the controlling portion controls an output of the multiplexed data supplied from the MUX so that the data rate supplied from the data amount calculating portion does not exceed the transmission rate of the transmission path . In addition the controlling portion receives click data transmitted from the receiving apparatus through the transmission path and controls the MUX to select and a multiplex the encoded data corresponding to the lick data.

Next with reference to a flow chart shown in the transmitting process performed by the transmitting process portion shown in will be described.

First of all at step S the controlling portion of the transmitting process portion determines whether or not click data has been transmitted from the receiving apparatus . When the determined result at step S represents that the click data has not been transmitted from the receiving apparatus namely the controlling portion has not received click data the flow advances to step S. At step S as with the case at step S shown in the controlling portion controls the MUX to select encoded background picture data encoded object data and encoded additional information data and multiplex the selected data so that the receiving apparatus can display a picture with a regular temporal resolution.

Thereafter the flow advances to step S. At step S the transmitting process portion transmits the multiplexed data supplied from the MUX from the transmitting portion through the transmission path . Thereafter the flow returns to step S.

When the determined result at step S represents that click data has been transmitted from the receiving apparatus namely the controlling portion has received click data the flow advances to step S. At step S the controlling portion recognizes the coordinates click position and click time of a considered point that the user has designated with the key portion of the receiving apparatus corresponding to the click data.

Thereafter at step the controlling portion designates an interested object area that the user of the receiving apparatus side has considered corresponding to the coordinates click position and the click time of the considered point in the manner that will be described later designates the interested object area as a priority range for a picture whose spatial resolution is improved with priority and detects a picture in the priority range and additional information thereof. In this case a picture in the priority range is an object picture. A picture in the non priority range is for example a picture such as a background picture in a non interested object area.

Thereafter at step S the controlling portion controls the MUX to select encoded data of a picture in the priority range object picture a picture in the non priority range background picture and additional information and multiplex them. In other words when the controlling portion receives click data from the receiving apparatus as in the case at step S shown in the controlling portion controls the MUX so that the spatial resolution of the picture in the priority range is improved at the sacrifice of the temporal resolution.

In addition at step S the controlling portion controls the MUX to insert high resolution information as information of the position and size of the priority range into the additional information selected as multiplexed data. Thereafter the flow advances to step S.

At step S the transmitting portion transmits the multiplexed data that is output by the MUX through the transmission path . Thereafter the flow returns to step S.

As was described above in the transmitting process shown in the similar process to the process shown in is performed. Thus when the user of the receiving apparatus continuously operates the click data inputting portion for example he or she continuously designates the same considered point for a picture in the priority range that contains a considered point an interested object area and an object picture data for improving the spatial resolution is transmitted with priority. Thus the spatial resolution of the picture in the priority range that contains the considered point is gradually improved. As a result the picture in the priority range is more clearly displayed. In other words a picture an interested object area and an object picture that the user on the receiving apparatus side is considering is more clearly displayed.

As described above the transmission of picture data is controlled so that the spatial resolution and the temporal resolution of the picture in the priority range an interested object area and an object picture are changed in the range of the resolutions corresponding to the transmission rate of the transmission path . Thus in a limited transmission rate the spatial resolution of an object picture corresponding to a considered point displayed by the receiving apparatus can be more improved. In other words since the spatial resolution of the object picture in the priority range is improved at the sacrifice of the temporal resolution of the picture the object picture displayed on the receiving apparatus can be more clearly displayed at the limited transmission rate namely the spatial resolution can be more improved .

Next shows an example of the structure of the combining process portion shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words the background picture flag memory is not disposed in the combining process portion . A combining portion rather than the combining portion is disposed in the combining process portion . In addition click data rather than control information is supplied to the combining portion . Except for those points the structure of the combining process portion shown in is basically the same as the structure of the combining portion shown in .

Referring to background picture data that is output from the receiving process portion see is input to a background picture writing portion . Object picture data that is output from the receiving process portion is input to an object writing portion . Additional information that is output from the receiving process portion is input to the background picture writing portion the object writing portion and the combining portion .

The background picture writing portion successively writes the supplied background picture data to a background picture memory . However in the embodiment shown in the background picture flag memory of the embodiment shown in is not disposed. Thus in when the background picture writing portion writes background picture data to the background picture memory the background picture writing portion does not reference a background picture flag.

The combining portion reads a background picture of the frame that is displayed at present time current frame from the background picture data stored in the background picture memory corresponding to a background picture moving vector contained in the additional information combines an object picture stored in an object memory and the background picture corresponding to an object moving vector contained in the additional information and supplies the combined picture of the current frame to a display memory .

In addition when the combining portion receives click data from the click data inputting portion shown in the combining portion reads object picture data that contains the coordinate position of a considered point contained in the click data from an object memory and supplies the obtained object picture data to a sub window memory .

Next with reference to a flow chart shown in the process combining process performed by the combining process portion shown in will be described.

First of all at step S the object writing portion writes object picture data supplied form the decoding portion shown in in the above described manner corresponding to an object flag stored in the object memory .

Thereafter the flow advances to step S. The object writing portion determines whether or not the additional information contains high resolution information. When the determined result at step S represents that the additional information contains high resolution information namely the user of the receiving apparatus has operated the key portion the click data has been transmitted to the transmitting apparatus and then for a picture in the priority range object picture data with a high spatial resolution has been transmitted from the transmitting apparatus the flow advances to step S. At step S the object writing portion sets a relevant object flag of the object flag memory to 1 .

In other words when object picture data with a high spatial resolution for a picture in the priority range has been transmitted from the transmitting a apparatus at step S the object picture data with the high spatial resolution is written to the object memory . Thus at step S the object flag of the pixel that composes the object picture with the high spatial resolution is set to 1 .

Thereafter the flow advances to step S. At step S the combining portion reads the object picture data in the priority range from the object memory and writes the obtained object picture data to the sub window memory .

In other words when the determined result at step S represents that the additional information contains the high resolution information as was described above the use has operated the key portion the click data has been transmitted to the transmitting apparatus and then object picture data with a high spatial resolution for a picture in the priority range has been transmitted from the transmitting apparatus . The click data transmitted to the transmitting apparatus is also supplied to the combining portion . When the combining portion receives the click data at step S the combining portion recognizes the priority range corresponding to the coordinates and click time of the considered point contained in the click data reads an object with a high spatial resolution in the priority range that has transmitted from the transmitting apparatus from the object memory and writes the obtained object to the sub window memory . In addition as was described above when the header information transmitted from the transmitting apparatus contains click data the combining portion can recognize the priority range from the click data contained in the header information.

Thereafter the flow advances to step S. At step S the combining portion reads background picture data of the current frame from the background picture memory corresponding to a background picture moving vector contained in the additional information. In addition the combining portion reads object picture data of the current frame that is displayed from the object memory . Thereafter the combining portion combines the background picture data of the current frame and the object picture data that has been read from the object memory corresponding to an object moving vector contained in the additional information and writs the combined picture of the current frame to the display memory . In other words the combining portion writes the background picture data to the display memory and then overwrites the object picture data to the display memory . As a result the combining portion writes picture data of the current frame of which a background picture and an object picture have been combined to the display memory .

In the above described manner the picture data of the current frame written to the display memory and the object picture data written to the sub window memory are supplied to the picture outputting portion shown in and displayed thereon.

In contrast when the determined result at step S represents that the additional information does not contain high resolution information namely the user of the receiving apparatus has not operated the key portion the flow advances to step S skipping steps S and S. As was described above at step S the combining portion reads background picture data of the current frame from the background picture memory reads required object picture data from the object memory and combines the background picture of the current frame and the object picture that has been read from the object memory corresponding to the additional information. As a result picture data of the current frame is formed and written to the display memory . Thereafter the flow returns to step S. At step S the combining portion repeats the similar process.

According to the above described combining process in the same manner as the case described with reference to a picture with a high spatial resolution that the user is considering as an object is displayed. The combining process portion shown in does not have the background picture flag memory shown in . Thus the background picture writing portion shown in always writes supplied background picture data to the background picture memory . Thus in the combining process shown in the spatial resolution of the background picture is not improved unlike in the case described with reference to .

Next a method for extracting an object picture interested object area corresponding to click data supplied from the receiving apparatus will be described. This method is performed by the an object extracting portion shown in .

In picture data supplied from the picture inputting portion shown in is stored to a picture memory . The picture data is read from the picture memory and supplied to a common terminal of a still area and moving area determining portion an object picture extracting portion and a selecting switch . The picture memory stores picture data of at least several frames necessary for the still area and moving area determination of the still area and moving area determining potion as a downstream portion of the picture memory .

In addition click data transmitted from the receiving apparatus through the transmission path is stored to a click data memory . The click data is read from the click data memory and supplied to a common terminal of a still area and moving area determining portion a continuous click determining portion and a selecting switch . The click data memory stores click data for a predetermined time period for example longer than 500 to 700 msec necessary for the continuous click determination performed by the continuous click determining portion as a downstream portion of the click data memory .

The still area and moving area determining portion determines whether a picture area of a local small block of for example 16 16 pixels around the click position coordinate value on a picture represented by the current click data sent from the receiving apparatus is a moving area or a still area. In other words the still area and moving area determining portion obtains the difference between the picture area of the current frame and the picture area of a past frame that precedes the current frame by several frames hereinafter this past frame is referred to as past frame for 16 16 pixels around the click position. When the difference between the frames is equal to or smaller than a predetermined threshold value the still area and moving area determining portion determines that the picture area is a still area. In contrast when the difference is more than the predetermined threshold value the still area and moving area determining portion determines that the picture area is a moving area. When a color picture is handled the still area and moving area determining portion obtains the difference between the picture area of the current frame and the picture area of the past frame for a picture of 16 16 pixels for each of R G and B. When the average value of the absolute values of the frame differences obtained for R G and B is equal to or smaller than a predetermined threshold value for example equal to or less than 10 the still area and moving area determining portion determines the picture area is a still area. In contrast when the average value is larger than the predetermined threshold value the still area and moving area determining portion determines that the picture area is a moving area. When the still area and moving area determining portion determines that the picture area is a still area the still area and moving area determining portion determines that the current click data that is output from the click data memory is a still click a click in a still area . When the still area and moving area determining portion determines that the picture area is a moving area the still area and moving area determining portion determines that the current click data that is output from the click data memory is a moving click a click in a moving area . Thereafter the still area and moving area determining portion sends information that represents a still click or a moving click as a still area and moving area determined result to a process determining portion .

The continuous click determining portion determines whether or not the user of the receiving apparatus has continuously performed the click operation corresponding to the click time of the click data sent from the receiving apparatus . In other words the continuous click determining portion obtains the time difference between the click time of the current click data sent from the receiving apparatus and the click time of the immediately preceding click data namely the click time interval . When the time difference is equal to or smaller than a predetermined threshold value the continuous click determining portion determines that the user has not continuously performed the click operation. When the continuous click determining portion determines that the use has continuously performed the click operation the continuous click determining portion treats the current click data that is output form the click data memory as a continuous click. In contrast when the continuous click determining portion determines that the user has not continuously perform the click operation namely the time difference between the current click time and the immediately preceding click time is equal to or larger than the predetermined threshold value the continuous click determining portion treats the current click data that is output from the click data memory as a non continuous click. Thereafter the continuous click determining portion sends information that represents a continuous click or a non continuous click as a continuous click determined result to the process determining portion .

The process determining portion controls the selecting switch the selecting switch and a selecting switch corresponding to the still area and moving area determined result of the still area and moving area determining portion and the continuous click determined result of the continuous click determining portion .

In other words for example corresponding to the still area and moving area determined result and the continuous click determined result when the current click data that is output from the click data memory is a still click and a continuous click the process determining portion controls the selecting switch so that the current click data that is output from the click data memory is sent to a still object connecting process portion . In addition the process determining portion controls the selecting switch so that the picture data that is output from the picture memory is sent to the still object connecting process portion . Moreover the process determining portion controls the selecting switch so that the immediately preceding click data that is output from an object extracted result memory that will be described later an object number that corresponds to the above described label and that categorizes identifies an object assigned to the click data and object picture data corresponding to the object number are sent to the still object connecting process portion .

In addition corresponding to the still area and moving area determined result and the continuous click determined result when the current click data that is output from the click data memory is a moving click and a continuous click the process determining portion controls the selecting switch so that the current click data that is output from the click data memory is sent to a moving object connecting process portion . In addition the process determining portion controls the selecting switch so that picture data that is output from the picture memory is sent to the moving object connecting process portion . Moreover the process determining portion controls the selecting switch so that the immediately preceding click data that is output from the object extracted result memory that will be described later the object number assigned to the click data and the object picture data corresponding to the object number are sent to the moving object connecting process portion .

In addition corresponding to the still area and moving area determined result and the continuous click determined result when the current click data that is output from the click data memory is a still click and a continuous click the time difference of the current click time and the immediately preceding click time is equal to or larger than the predetermined threshold value the process determining portion controls the selecting switch so that the current click data that is output from the click data memory is sent to an object number assigning portion . In addition the process determining portion controls the selecting switch so that the picture data that is output from the picture memory is sent to the still object connecting process portion . At that point the selecting switch controls the selecting switch so that the immediately preceding click data that is output from the object extracted result memory the object number and the object picture data are not sent to the still object connecting process potion in this case for example the selecting switch is opened .

In addition corresponding to the still area and moving area determined result and the continuous click determined result when the current click data that is output from the click data memory is a moving click and a non continuous click the time difference between the current click time and the immediately preceding click time is equal to or larger than the predetermined threshold value the process determining portion controls the selecting switch so that the current click data that is output from the click data memory is not sent to the object number assigning portion . In addition the process determining portion controls the selecting switch so that the picture data that is output from the picture memory is sent to the moving object connecting process portion . At that point the process determining portion controls the selecting switch so that the immediately preceding click data that is output from the object extracted result memory the object number and the object picture data are not sent to the moving object connecting process portion for example the selecting switch is opened .

The object number assigning portion assigns a new object number to click data as a non continuous click other than continuous clicks that are processed as a connecting process by the still object connecting process portion and the moving object connecting process portion that will be described later and sends the object number and the click data to an object number memory .

When the process determining portion determines that the current click data that is output from the click data memory is a moving click and a continuous click the moving object connecting process portion determines whether the immediately preceding click data is a moving click and the feature of the picture in the vicinity of the current click position is contained in the feature of the area of the moving object picture with the object number assigned to the immediately preceding click data or they are similar to each other. When the determined result is true the moving object connecting process portion determines that the current click is a click for the same object picture. Thus the moving object connecting process portion performs a moving object connecting process for assigning the same object number as the immediately preceding click data to the current click data and sends the object number and the click data to the object number memory .

When the determined result of the process determining portion represents that the current click data that is output from the click data memory is a still click and a continuous click the still object connecting process portion determines whether the immediately preceding click is a still click and the current click position is contained in the area of the still object picture with the object number assigned to the immediately preceding click data or the current click position is close to the area. When the determined result of the still object connecting process portion is true the still object connecting process portion determines that the current click is a click for the same object picture as the immediately preceding click. Thus the still object connecting process portion performs a still object connecting process for assigning the same object number as the immediately preceding click data to the current click data and sends the object number and the click data to the object number memory .

The object number memory stores click data for a plurality of past frames to which the object number assigning portion the moving object connecting process portion and the still object connecting process portion have assigned object numbers and sends the stored click data and object numbers to the object picture extracting portion .

The object picture extracting portion extracts a still object picture a moving object picture a background picture and so forth from the picture data supplied from the picture memory corresponding to click data of the plurality of past frames that have been assigned object numbers and that have been supplied from the object number memory and supplies the extracted result to the object extracted result memory .

In other words the object picture extracting portion obtains a dominant object number from a picture portion of click data with a high click data density as still clicks corresponding to click data of the plurality of past frames that have been assigned object numbers and that have been supplied from the object picture extracting portion . The object picture extracting portion forms the shape of an object corresponding to the distribution of the click data assigned with the dominant object number and extracts a picture in the shape of the formed object as an object picture from the picture data.

In addition the object picture extracting portion performs a pattern matching operation for pictures of the frames in the vicinity of the click position assigned the same object number in click data determined as a moving click and performs a motion compensation for the pictures corresponding to the matching result. Moreover the object picture extracting portion obtains a dominant object number of a picture area with a high click density from a picture area determined as a similar picture area namely a picture area that has been aligned by the motion compensation . The object picture extracting portion forms the shape of an object corresponding to the distribution of the click data assigned the dominant object number and extracts a picture in the formed shape as an object picture from the picture data.

In addition the object picture extracting portion designates a picture portion with a low still click density or a low moving click density as a background picture.

Along with click data object number and so forth the object extracted result memory stores object picture data extracted by the object picture extracting portion . When necessary the object extracted result memory supplies the object picture data to the background picture extracting portion the additional information calculating portion and the transmitting process portion shown in .

Next with reference to a flow chart shown in a process for extracting an object picture interested object area that the user of the receiving apparatus is considering from a picture that is being photographed corresponding to click data transmitted from the receiving apparatus will be described. The process is performed by the object extracting portion shown in .

First of all at step S the picture memory stores picture data of a frame that is input from the picture inputting portion frame picture data is input whenever transmitted . The picture memory stores picture data of at least several frames necessary for the still area and moving area determining process performed at step S.

At step S when click data is transmitted from the receiving apparatus through the transmission path the click data memory stores the click data. The click data memory stores click data form at least a predetermined time period for example longer than 500 to 700 msec necessary for the continuous click determining process performed at step S that will be described later .

Thereafter the flow advances to step S. At step S the object extracting portion determines whether or not the click data memory stores click data that has been transmitted from the receiving apparatus and that has not been processed. When the determined result at step S represents that the click data memory does not store click data that has not been processed the flow returns to step S. At step S the object extracting portion waits for picture data and click data that are input. In contrast when the determined result at step S represents that the click data memory stores click data that has not been processed the flow advances to step S. At step S the object extracting portion designates the oldest click data that has not been processed as the current click data. The still area and moving area determining portion the continuous click determining portion and the process determining portion perform the still area and moving area determining process and the continuous click determining process for the current click data.

In other words at step S the still area and moving area determining portion performs the still area and moving area determining process for determining whether a picture area as a local small block around a click position is a moving area or a still area using click position picture coordinate value information contained in the current click data transmitted from the receiving apparatus .

Next the still area and moving area determining process at step S shown in performed by the still area and moving area determining portion will be described in more reality. As shown in a flow chart shown in at step S the still area and moving area determining portion performs reads picture data and click data for several frames from the picture memory and the click data memory respectively. When a color picture is handled as shown in A the still area and moving area determining portion reads picture data of several frames for R Red G Green and B Blue . In addition the still area and moving area determining portion reads picture data of several past frames containing a frame corresponding to the current click data and click data corresponding to clicks performed for the several frames from the picture data memory and the click data memory respectively.

Thereafter at step S the still area and moving area determining portion calculates the difference between a picture area of the current frame and a picture area of a past frame that precedes the current frame for several frame this past frame is referred to as past frame for a local small block composed 16 16 pixels in the horizontal direction and the vertical direction around the click position of the current click data. When a color picture is handled at step S as shown in B and C the still area and moving area determining portion obtains the difference between the frames for a picture composed of 16 16 pixels for each of R G and B and obtains the average value of the absolute values of the differences for each of R G and B.

Thereafter at step S the still area and moving area determining portion determines whether or not the difference between the frames calculated at step S is equal to or smaller than a predetermined threshold value. Thereafter the flow advances to step S. When the difference between the frames is equal to or smaller than the predetermined threshold value the still area and moving area determining portion determines that a small block that contains the click position of the current click data this small block may be referred to as current block is a still area. In contrast when the difference between the frames is larger than the predetermined threshold value the still area and moving area determining portion determines that the current block is a moving area. In addition when the determined result of the still area and moving area determining portion represents that the current block is a still area the still area and moving area determining portion designates click data corresponding to the picture area of the current block as a still click. In contrast when still area and moving area determining portion represents that the current block is a moving area the still area and moving area determining portion designates click data corresponding to the picture area of the current block as a moving click. The still area and moving area determining portion outputs the determined result as a still area and moving area determined result.

In the case that a color picture is handled at step S as shown in D when the average of the absolute values of the differences between the frames for each block of 16 16 pixels for each of R G and B is equal to or smaller than a predetermined threshold value for example 10 the still area and moving area determining portion sets a predetermined flag to for example 0 . In contrast when the average value is larger than the predetermined threshold value the still area and moving area determining portion sets the predetermined flag to for example 1 . At step S as shown in E when all the flags for R G and B for the current block of 16 16 pixels are 0 the still area and moving area determining portion determines that the current block is a still area and designates the click data corresponding to the picture area of the current block as a still click. In contrast when one of the flags is 1 the still area and moving area determining portion determines that the current block is a moving area and designates the click data corresponding to the picture area of the current block as a moving click. The still area and moving area determining portion outputs information of a still click or a moving click as a still area and moving area determined result.

Returning to at step S the continuous click determining portion performs a continuous click determination for determining whether or not the click operation performed by the user of the receiving apparatus is a continuous click operation corresponding to click time contained in the click data transmitted from the receiving apparatus .

Next the process of the continuous click determining portion performed at step S shown in will be described. With reference to a flow chart shown in at step S the click data memory reads click data stored in the click data memory .

Thereafter at step S the continuous click determining portion calculates the time difference click interval between the click time of the current click data transmitted from the receiving apparatus and the click time of the immediately preceding click data preceding time .

Next at step S the continuous click determining portion determines whether or not the time difference is equal to or smaller than a predetermined threshold value. When the determined result at step S represents that the time difference is equal to or smaller than the predetermined threshold value the continuous click determining portion determines that the current click data is a continuous click. In contrast when the determined result at step S represents that the time difference is larger than the predetermined threshold value the continuous click determining portion determines that the current click data is not a continuous click. Thereafter the flow advances to step S. At step S the continuous click determining portion outputs information that represents a continuous click or a non continuous click as the continuous click determined result.

In other words when the determined result at step S represents that the current click data is a continuous click the user of the receiving apparatus tends to continuously perform the click operation for one object picture. This is because when the user of the receiving apparatus requests the transmitting apparatus to transmit object picture data data in the interested object area with a high spatial resolution he or she tends to continuously click an object picture portion interested object area that the user wants to improve the spatial resolution thereof. Thus when the determined result of the continuous click determining portion represents that the current click operation is a continuous click operation the continuous click determining portion designates the current click data as a continuous click. In contrast when the determined result of the continuous click determining portion represents that the current click operation is not a continuous click operation namely the time difference between the click time of the current click and the click time of the immediately preceding click is equal to or larger than the predetermined threshold value the continuous click determining portion designates the current click data as a non continuous click. The continuous click determining portion outputs the continuous click determined result.

Returning to when the determined results of the still area and moving area determining portion and the continuous click determining portion at step S represent that the current click data is a still click and a continuous click the process determining portion controls the selecting switch the selecting switch and the selecting switch in the above described manner. Thus at step S the still object connecting process portion performs a still object connecting process. When the determined results represent that the current click data is a moving click and a continuous click the process determining portion controls the selecting switch the selecting switch and the selecting switch in the above described manner. Thus at step S the moving object connecting process portion performs a moving object connecting process. When the determined results represent that the current click data is a non continuous click the process determining portion controls the selecting switch the selecting switch and the selecting switch in the above described manner. At step S the moving object connecting process portion performs the moving object connecting process. When the determined results represent that the current click data is a non continuous click the process determining portion controls the selecting switch in the above described manner. Thus at step S the object number assigning portion performs a new object number assigning process.

In other words when the determined result at step S represents that the current click data is a non continuous click the flow advances to step S. At step S the object number assigning portion assigns a new object number to the current click data. Thereafter the flow returns to step S.

In more reality as shown in A when an object number assigned to the immediately preceding click data CL denoted by a solid X mark is for example 0 if the current click data CL denoted by a dotted X mark in A namely click data that has not assigned an object number is determined as a non continuous click the object number assigning portion assigns a new object number to the current click data CL denoted by a solid X mark in B in this example the new object number is 1 .

In contrast when the determined result at step S represents that the current click data is a continuous click and a still click if the immediately preceding click is a still click and the current click position is contained in a picture area corresponding to an object number assigned to the immediately preceding click data or the current click position is close to the picture area the still object connecting process portion determines that the current click is a click for the same object picture as the immediately preceding click. Thus at step S the still object connecting process portion performs a still object connecting process for assigning the same object number as the immediately preceding click data for the current click data.

In other words as shown in a flow chart shown in at step S the still object connecting process portion determines whether or not the immediately preceding click data is a continuous click and a still click. When the determined result at step S represents that the immediately preceding click data is a continuous click and a still click the flow advances to step S. In contrast when the determined result at step S represents the immediately preceding click is not a continuous click and a still click the flow advances to step S.

When the determined result at step S represents that the immediately preceding click data is not a continuous and still click at step S the still object connecting process portion assigns a new object number to the current click data in the same manner as was described with reference to A and B . Thereafter the flow advances to step S shown in .

In contrast when the determined result at step S represents that the immediately preceding click data is a continuous click and a still click the flow advances to step S. At step S the still object connecting process portion obtains the spatial distance between the current click position and the picture area corresponding to the object number assigned to the immediately preceding click data. When the current click position is contained in the picture area corresponding to the object number assigned to the immediately preceding click data or the current click position is close to the picture area the still object connecting process portion determines that the current click data is click data for the same object picture as the immediately preceding click. In contrast when the current click position is not contained in the object picture area corresponding to the object number assigned to the immediately preceding click data and the current click position is far from the object picture area the still object connecting process portion determines that the current click data is click data for a different object picture from the immediately preceding click. When the determined result at step S represents that the current click data is click data for the same object picture as the immediately preceding click the flow advances to step S. In contrast when the determined result at step S represents that the current click data is click data for a different object picture from the immediately preceding click the flow advances to step S.

When the determined result at step S represents that the current click data is click data for a different object picture from the immediately preceding click the flow advances to step S. At step S the still object connecting process portion assigns a new object number to the current click data. Thereafter the flow advances to step S shown in .

In contrast when the determined result at step S represents that the current click data is click data for the same object picture as the immediately preceding click at step S the still object connecting process portion performs a still object connecting process for assigning the same object number as the immediately preceding click data to the current click data.

In more reality as shown in C when an object number assigned to the immediately preceding click data CL denoted by a solid X mark is 0 if the current click data CL denoted by a dotted X mark shown in C namely the current click data has not been assigned an object number is determined as a continuous click and a still click the immediately preceding click is a still click and the current click position is contained in the picture area corresponding to an object number assigned to the immediately preceding click data or the current click position is close to the picture area the still object connecting process portion assigns the same object number in this example 0 as the immediately preceding click data to the current click data CL denoted by the solid X mark shown in D .

After the still object connecting process portion assigns the same object number as the immediately preceding click data to the current click data the flow advances to step S shown in .

When the determined result at step S represents that the current click data is a continuous click and a moving click the immediately preceding click is a moving click and the feature of the picture in the vicinity of the current click position is contained in the feature of the picture area 16 16 pixels corresponding to the object number assigned to the immediately preceding click or the former is close to the latter the moving object connecting process portion determines that the click is a click for the same object picture as the immediately preceding click. At step S the moving object connecting process portion performs a moving object connecting process for assigning the same object number as the immediately preceding click data to the current click data.

In other words when the determined result at step S represents that the current click data is a continuous click and a moving click as shown in at step S the moving object connecting process portion determines whether or not the immediately preceding click data is a continuous click and a moving click. When the determined result at step S represents that the immediately preceding click data is a continuous click and a moving click the flow advances to step S. In contrast when the determined result at step S is not a continuous click and a moving click the flow advances to step. S.

When the determined result at step S represents that the immediately preceding click data is not a continuous click and a moving click the flow advances to step S. At step S the moving object connecting process portion assigns a new object number to the current click data in the same manner described with reference to A and B . Thereafter the flow advances to step S shown in .

When the determined result at step S represents that the immediately preceding click data is a continuous click and a moving click the flow advances to step S. At step S the moving object connecting process portion obtains the feature of the picture area 16 16 pixels in the vicinity of the current click position and the feature of the picture area corresponding to the object number assigned to the immediately preceding click. When the feature of the picture area in the vicinity of the current click position is contained in the feature of the picture area corresponding to the object number assigned to the immediately preceding click or the former is close to the latter the receiving process portion determines that the click is a click for the same object picture as the immediately preceding click. In contrast when the feature of the picture area in the vicinity of the current click position is not contained in the feature of the picture area corresponding to the object number assigned to the immediately preceding click and the former is far from the latter the moving object connecting process portion determines that the current click data is click data for a different object picture from the immediately preceding click. In this case the feature of the picture area is for example a color an average color a typical color or the like a histogram and a pattern of the local area 16 16 pixels in the vicinity of a click position. When the same object number is assigned to a plurality of moving clicks it means that an object is tracked among those click data. When the determined result at step S represents that the current click data is click data for the same object picture as the immediately preceding click the flow advances to step S. In contrast when the determined result at step S represents that the current click data is clock data for a different object picture from the immediately preceding click the flow advances to step S.

When the determined result at step S represents that the current click data is click data for indifferent object picture from the immediately preceding click the flow advances to step S. At step S the moving object connecting process portion assigns a new object number to the current click data in the above described manner. Thereafter the flow advances to step S shown in .

When the determined result at step S represents that the current click data is click data for the same object picture as the immediately preceding click the flow advances to step S. At step S the moving object connecting process portion assigns the same object number as the immediately preceding click data to the current click data.

In more reality when an object number assigned to the immediately preceding click data CL denoted by a solid X mark shown in E is for example 0 if the current click data CL denoted by a dotted X mark shown in E is determined as a continuous click and a moving click and the feature of the picture in the vicinity of the current click position is contained in the feature of the object picture corresponding to the object number assigned to the immediately preceding click or the former is close to the latter the moving object connecting process portion assigns the same object number in this example 0 as the immediately preceding click data to the current click data CL denoted by the solid X mark shown in F .

After the moving object connecting process portion has assigned the same object number as the immediately preceding click data to the current click data at step S the flow advances to step S.

When the flow advances from step S to S shown in the object picture extracting portion extracts a still object picture a moving object picture and another background picture from input picture data corresponding to the click data of past several frames assigned object numbers and stored in the object number memory and picture data of past several frames stored in the picture memory . In other words it seems that a still object picture is contained in a picture portion with a high still click data density. At that point the object picture extracting portion obtains a still click data density corresponding to past several frames assigned object numbers obtains a dominant object number of a picture portion with the high still click density forms the shape of an object corresponding to the distribution of click data assigned the dominant object number and extracts a picture in the shape of the object as a still object picture from the picture data.

When the flow advances from step S to step S the object picture extracting portion performs a pattern matching operation for pictures of the frames in the vicinity of click positions of moving click data assigned the same object number performs a motion compensation for the pictures corresponding to the matching result obtains a dominant object number of the pattern matched picture area with a high click density forms the shape of an object corresponding to the distribution of click data assigned the dominant object number and extracts a picture in the shape of the object as a moving object picture from the picture data.

At step S the object picture extracting portion treats a picture portion with a low still click density or low moving click data as the current background picture. In other words the object picture extracting portion treats a picture portion other than the still object picture and the moving object picture that have been extracted from picture data as a background picture.

Next the process at step S will be described in detail with reference to a flow chart shown in . First of all at step S the object picture extracting portion captures click data of several past frames assigned object numbers and picture data corresponding thereto. Thereafter at step S the object picture extracting portion categorizes the click data as still clicks and moving clicks. When the flow advances from step S to step S in the flow advances from step S to step S in . In contrast when the flow advances from step S to step S in the flow advances from step S to step S in .

When the flow advances from step S to step S in the flow advances from step S to step S in . At step S the object picture extracting portion obtains a still click data density of each still click assigned an object number for each block of 16 16 pixels.

Thereafter at step S the object picture extracting portion determines whether or not the still click density of still clicks denoted by X marks shown in A for each block bk of 16 16 pixels denoted by a dotted box of the picture is equal to or larger than a predetermined value.

In a picture transmitted to the receiving apparatus a picture portion with a high still click density tends to contain a still object picture. Thus when the still click density of a particular block is equal to or larger than the predetermined value the flow advances to step S. In contrast when the still click density of a particular block is smaller than the predetermined value the flow advances to step S.

At step S when the still click density of the block exceeds the predetermined value as shown in E the object picture extracting portion obtains the most dominant object number from object numbers assigned to click data of the block. Thereafter the object picture extracting portion combines blocks BK BK BK and BK corresponding to dominant object numbers as shown in B and forms shapes of objects. The object picture extracting portion extracts pictures in the shapes of the objects as still object pictures from the picture data. After step S the flow advances to step S shown in .

On the other hand when the flow advances from step S to step S in the flow advances from step S to step S in . At step S as shown in C the object picture extracting portion performs a pattern machining operation for pictures of a plurality of past frames in the vicinity of click positions assigned the same object numbers of click data as moving clicks denoted by X marks shown in C and performs a motion compensation for the pictures corresponding to the matching result.

Thereafter at step S the object picture extracting portion obtains a moving click density in the pattern matched picture area.

Thereafter at step S the object picture extracting portion determines whether or not the moving click density of moving clicks denoted by X marks as shown in D of the picture is equal to or larger than a predetermined value.

A picture portion that has been motion compensated and that has a high moving click density tends to contain a moving object picture. Thus when the moving click density of a picture area that has been motion compensated is equal to or larger than the predetermined value the flow advances to step S. In contrast when the moving click density of a picture area that has been motion compensated is smaller than the predetermined value the flow advances to step S.

At step S the object picture extracting portion obtain the most dominant object numbers from object numbers assigned to click data for a picture area with a moving click density that is equal to or larger than the predetermined value. Thereafter as shown in D the object picture extracting portion combines blocks BK and BK corresponding to the dominant object numbers and forms shapes of objects. Thereafter the object picture extracting portion extracts pictures in the shapes of the objects as moving object pictures from the picture data. After step S the flow advances to step S shown in .

When the click density is smaller than the predetermined value at step S and step S the flow advances to step S. At step S the object picture extracting portion treats a picture portion with a low still click density or a low moving click density as a background picture area of the current picture. In other words the object picture extracting portion treats a picture portion other than a still object picture and a moving object picture that have been extracted from picture data as a background picture. After step S the flow advances to step S shown in .

After the object picture extracting portion has extracted a still object picture a moving object picture and a background picture from picture data the flow advances to step S shown in . At step S the object picture extracting portion determines whether or not the object extracting process is completed. When the determined result at step S is No the flow returns to step S. When the determined result at step S is Yes the object picture extracting portion completes the object extracting process.

In the above described process the object extracting portion of the transmitting apparatus shown in can extract a still object picture a moving object picture and a background picture corresponding to click data corresponding to the click operation performed by the user of the receiving apparatus .

In the embodiment shown in a plain picture area whose activity is small namely that does not have a significance as a picture is treated as a background picture. For the background picture the spatial resolution is not improved. Alternatively a background picture may be extracted corresponding to click data transmitted from the receiving apparatus so as to improve the spatial resolution thereof.

In such a case the background picture extracting portion shown in extracts a background picture corresponding to click data transmitted from the receiving apparatus . The transmitting process portion transmits the background picture so that the spatial resolution thereof is improved in the same manner that the spatial resolution of an object picture is improved.

In such a case as shown in the background picture flag memory shown in is added to the combining process portion shown in . The structure of the combining process portion shown in is the same as the structure of the combining process portion shown in except for the background picture flag memory . As in the structure shown in in the structure shown in when the background picture writing portion writes a background picture with a high spatial resolution to the background picture memory the background picture flag stored at an address of the background picture flag memory corresponding to each pixel that composes the background picture is changed from 0 to 1 . In if other words when the background picture writing portion writes background picture data to the background picture memory the background picture writing portion references the background picture flag memory . When the background picture flag is 1 namely when the background picture memory has stored background picture data with a high spatial resolution the background picture writing portion does not write background picture data with a low spatial resolution to the background picture memory . Whenever background picture data is supplied to the background picture writing portion the background picture data is written to the background picture writing portion . However when the background picture memory has stored background picture data with a high spatial resolution the background picture writing portion does not write background picture data with a low spatial resolution to the background picture memory . Thus whenever background picture data with a high spatial resolution is supplied to the background picture writing portion the number of background pictures with a high spatial resolution increases in the background picture memory .

In the example when the combining portion receives click data from the click data inputting portion shown in the combining portion reads object picture data and background picture data that contain the coordinate position of a considered point contained in the click data from the background picture memory and the object memory and supplies the obtained data to the sub window memory .

Next a technology for determining recognizing a change of an interested object area of the user of the receiving apparatus and categorizing each interested object area will be described.

Various types of pictures were analyzed to determine whether or not an interested object area of the user has changed and categorize each interested object area. The analyses show the following results.

First an area of an interested object of a person user is an area unit that has a significance for example an object .

Second when an interested object of the user is changed each area unit that has a significance is changed.

Third when an interested object of the user is changed the input time period necessary for designating the interested object of the user for example click operation tends to becomes long.

Fourth when an interested object of the user is changed the spatial distance between input positions at which the user designates an interested object area for example click operation tends to relatively become long.

Thus shows an example of the structure of the transmitting apparatus that obtains the input time interval and the input position distance corresponding to click data that is input by the user of the receiving apparatus determines whether or not an interested object area of the user of the receiving apparatus has changed in consideration of the analyzed results 1 to 4 and categorizes interested object areas. The transmitting apparatus shown in is a modification of the transmitting apparatus shown in . For simplicity in similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words the structure of the transmitting apparatus shown in is basically the same as the structure of the transmitting apparatus shown in except that a change determining and categorizing portion is newly disposed as a block that composes the pre process portion .

According to the embodiment shown in the change determining and categorizing portion is disposed in the preprocess portion . Alternatively the change determining and categorizing portion may be disposed in the object extracting portion or the background picture extracting portion of the pre process portion . Further alternatively the change determining and categorizing portion may be disposed independent from the pre process portion .

In this embodiment a position represented with click data is a considered point that the user is considering. A considered point of the user may be not click data. Instead a considered point of the user may be recognized by detecting the view direction of the user.

An input picture storing portion temporarily stores picture data that is output by the picture inputting portion . When necessary the input picture storing portion supplies the picture data to a click peripheral area extracting portion and a still area and moving area determining portion .

A click data obtaining portion temporarily stores click data transmitted from the receiving apparatus through the transmission path and supplies the stored click data to the click peripheral area extracting portion the still area and moving area determining portion an input time interval calculating portion and an input position distance calculating portion .

In this embodiment the input picture storing portion may be disposed in common with the picture memory shown in . In addition a click data storing portion may be disposed in common with the click data memory shown in .

The click peripheral area extracting portion extracts a picture area corresponding to click data supplied from the click data storing portion from the picture data supplied from the input picture storing portion the picture area is for example a local small block around the click position hereinafter the picture area may be referred to as click peripheral area . Data of the click peripheral area extracted by the click peripheral area extracting portion is sent to a click peripheral area storing portion . After the data is stored to the click peripheral area storing portion the data is sent to an interested object area categorizing portion .

In addition the still area and moving area determining portion performs a still area and moving area determination using the difference between frames in the same manner as the embodiment shown in corresponding to the picture data supplied from the input picture storing portion and the click data supplied from the click data storing portion .

The click peripheral area extracting process and the still area and moving area determining process can be accomplished by the same processes described with reference to . Thus the detailed description of those processes is omitted. In the embodiment shown in a result of which click data is determined as a still click or a moving click is output as a still area and moving area determination in the same manner as the above described embodiment. In addition for example a result of which a click peripheral area is determined as a still area or a moving area may be output. According to the embodiment shown in for simplicity as a result of a still area and moving area determination the case of which a still click or a moving click is output will be described.

The still area and moving area determined. result of the still area and moving area determining portion is sent to the input time interval calculating portion and the input position distance calculating portion .

When the still area and moving area determined result represents that click data is a still click the input time interval calculating portion calculates the time interval between the input time of the immediately preceding still click and the input time of the current still click. In this case the time interval is calculated regardless of whether or not for example a moving click takes place between the input time of the immediately preceding still click and the input time of the current still click. Data of the time interval calculated by the input time interval calculating portion is sent to an interest change determining portion .

When the still area and moving area determined result represents that click data is a still click the input position distance calculating portion calculates the spatial distance between the input click position coordinate position of the immediately preceding still click and the input click position coordinate position of the current still click. In this case the spatial distance is calculated regardless of whether or not there is an input position of for example a moving click between the input position of the current still click and the input position of the immediately preceding still click. The data of the spatial distance calculated by the input position distance calculating portion is sent to the interest change determining portion .

When the still area and moving area determined result represents that click data is a still click the interest change determining portion determines whether or not an interested object of the user has changed corresponding to the time interval calculated by the input time interval calculating portion and the spatial distance calculated by the position distance calculating portion . In other words the interest change determining portion performs a predetermined weighting process for the time interval and the spatial distance determines whether or not the weighted time interval exceeds a predetermined threshold value time and determines whether or not the weighted spatial distance exceeds a predetermined threshold value distance . When the weighted time interval exceeds the predetermined threshold value and or the weighted spatial distance exceeds the predetermined threshold value the interest change determining portion determines that the interested object of the user has changed. The interest change determining portion transmits the interested object change determined result to the interested object area categorizing portion .

When the determined result of the interest change determining portion represents that the interested object of the user has not changed the interested object area categorizing portion determines that the click peripheral area of the current still click is contained in the same picture area as an interested object area corresponding to the click peripheral area of the immediately preceding past still click categorizes the click peripheral area of the current still click as the same interested object area as the click peripheral area of the immediately preceding still click for example assigns the same category number to the click peripheral area of the current still click and outputs the categorized result. In other words when an interested object area is categorized for each object the same object number is assigned in the same manner as the above described embodiment.

In contrast when the determined result of the interest change determining portion represents that the interested object of the user has changed the interested object area categorizing portion determines that the click peripheral area of the current still click is not contained in the interested object area corresponding to the click peripheral area of the immediately preceding past still click outputs the stored data of the click peripheral picture of the current still click and resets the data that has been stored in the click peripheral area storing portion . Thereafter the interested object area categorizing portion categorizes the click peripheral area of the current still click as an interested object area that is different from the click peripheral area of the immediately preceding still click for example assigns a different category number to the click peripheral area of the current still click . In other words when an interested object area is categorized form each object a new different object number is assigned in the same manner as the above described case.

When the still area and moving area determined result represents that click data is a moving click likewise the input time interval calculating portion calculates the time interval between the input time of the immediately preceding moving click and the input time of the current moving click. In this case the time interval is calculated regardless of whether or not for example a still click takes place between the input time of the current moving click and the input time of the immediately preceding moving click. The data of the time interval calculated by the input time interval calculating portion is sent to the interest change determining portion .

In contrast when the determined result of the still area and moving area determined result represents that click data is a moving click likewise the in position distance calculating portion calculates the spatial distance between the input click position of the immediately preceding moving click and the input click position of the current moving click. In this case the spatial distance is calculated regardless of whether or not for example there is an input position of a still click between the input position of the current moving click and the input position of the immediately preceding moving click. The data of the spatial distance calculated by the input position distance calculating portion is sent to the interest change determining portion .

In addition the interest change determining portion determines whether or not the interested object of the user has changed corresponding to the time interval calculated by the input time interval calculating portion and the spatial distance calculated by the position distance calculating portion in the case that the still area and moving area determined result represents that the click data is a moving click. In other words the interest change determining portion performs a predetermined weighting process for the time interval and the spatial distance determines whether or not the weighted time interval exceeds a predetermined threshold value time and determines whether or not the weighted spatial distance exceeds a predetermined threshold value distance . When the weighted time interval exceeds the predetermined threshold value and or the weighted spatial distance exceeds the predetermined threshold value the interest change determining portion determines that the interested object of the user has changed. The interested object change determined result of the interest change determining portion is sent to the interested object area categorizing portion .

When the determined result of the interest change determining portion represents that the interested object of the user has not changed the interested object area categorizing portion determines that the click peripheral area of the current moving click is contained in the same picture area as the interested object area corresponding to the click peripheral area of the immediately preceding past moving click categorizes the click peripheral area of the current moving click as the same interested object area as the click peripheral area of the immediately preceding old moving click namely assign the same category number to the click peripheral area of the current moving click and outputs the categorized result. In other words when an interested object area is categorized for each object the same object number is assigned.

In contrast when the determined result of the interest change determining portion represents that the interested object of the user has changed the interested object area categorizing portion determines that the click peripheral area of the current moving click is not contained in the interested object area corresponding to the click peripheral area of the immediately preceding past moving click outputs the stored data of the click peripheral picture of the current moving click and resets the data that has been stored in the click peripheral area storing portion . Thereafter the interested object area categorizing portion categorizes the click peripheral area of the current moving click as an interested object area that is different from the click peripheral area of the immediately preceding moving click namely assigns a different category number to the click peripheral area of the current moving click . In other words when an interested object area is categorized for each object a new different object number is assigned.

Next with reference to a flow chart shown in the process of the change determining and categorizing portion shown in will be described.

At step S the change determining and categorizing portion receives picture data from the picture inputting portion and click data that has been input by the user of the receiving apparatus .

Thereafter at step S the picture data that is supplied from the picture inputting portion is stored to the input picture storing portion . The click data obtained by the click data obtaining portion is stored to the click data storing portion .

Thereafter at step S the click peripheral area extracting portion extracts a picture area click peripheral area corresponding to the click data from the picture that has been stored and read from the input picture storing portion . At step S the click peripheral area storing portion stores data of the click peripheral area that has been extracted.

Thereafter at step S the still area and moving area determining portion performs a still area and moving area determination using the difference between frames in the above described manner.

At step S when the determined result at step S represents that click data is a still click the flow advances to step S. In contrast when the determined result at step S represents that click data is a moving click the flow advances to step S.

When the determined result at step S represents that click data is a still click the flow advances to step S. At step S the input time interval calculating portion calculates the time interval between the input time of the immediately preceding still click and the input time of the current still click. The time interval is calculated regardless of whether or not there is for example a moving click between the input time of the current still click and the input time of the immediately preceding still click.

Thereafter at step S the input position distance calculating portion calculates the spatial distance between the input click position coordinate position of the immediately preceding still click and the input click position coordinate position of the current still click. In this case the spatial distance is calculated regardless of whether or not there is for example an input position of a moving click between the input position of the current still click and the input position of the immediately preceding still click.

At step S the interest change determining portion determines whether or not the interested object of the user has changed corresponding to the time interval calculated at step S and the spatial distance calculated at step . In other words as was described above the interest change determining portion performs a predetermined weighting process for the time interval and the spatial distance determines whether or not the weighted time interval exceeds a predetermined threshold value time and determines whether or not the weighted spatial distance exceeds a predetermined threshold value distance . When the weighted time interval exceeds the predetermined threshold value and or the weighted spatial distance exceeds the predetermined threshold value the interest change determining portion determines that the interested object of the user has changed. When the determined result at step S represents that the interested object has changed the flow advances to step S. When the determined result at step S represents that the interested object has not changed the flow advances to step S.

When the determined result at step S represents that the interested object of the user has not changed the flow advances to step S. At step S the interested object area categorizing portion determines that the click peripheral area of the current still click is contained in the picture area that is the same as the interested object area corresponding to the click peripheral area of the immediately preceding old still click and categorizes the click peripheral area of the current still click as the same interested object area as the click peripheral area of the immediately preceding still click namely assigns the same category number to the click peripheral area of the current still click . In other words when an interested object area is categorized for each object the same object number is assigned in the same manner as the above described embodiment. After step the flow advances to step S.

In contrast when the determined result at step S represents that the interested object of the user has changed the flow advances to step S. At step S the interested object area categorizing portion determines that the click peripheral area of the current still click is not contained in the interested object area corresponding to the click peripheral area of the immediately preceding old still click outputs the stored data of the click peripheral picture of the current still click and resets the stored data. Thereafter at step S the interested object area categorizing portion categorizes the click peripheral area of the current still click as a different interested object area from the click peripheral area of the immediately preceding still click for example assigns a different category number to the click peripheral area of the current still click . In other words when an interested object area is categorized for each object a new different object number is assigned in the same manner as the above described embodiment. After step S the flow advances to step S.

In contrast when the determined result at step S represents click data is a moving click the flow advances to step S. At step S the interest change determining portion calculates the time interval between the input time of the immediately preceding moving click and the input time of the current moving click. In this case the time interval is calculated regardless of whether or not there is for example a still click between the input time of the current moving click and the input time of the immediately preceding moving click.

Thereafter at step S the interest change determining portion calculates the spatial distance between the input click position of the immediately preceding moving click and the input click position of the current moving click. In this case the special distance is calculated regardless of whether or not there is for example an input position of a still click between the input position of the current moving click and the input position of the immediately preceding moving click.

Thereafter at step S the interest change determining portion determines whether or not the interested object of the user has changed corresponding to the time interval calculated at step S and the spatial distance calculated at step S. In other words the interest change determining portion performs a predetermined weighting process for the time interval and the special distance determines whether or not the weighted time interval exceeds a predetermined threshold value time and determines whether or not the weighted spatial distance exceeds a predetermined threshold value distance . When the weighted time interval exceeds the predetermined threshold value and or the weighted spatial distance exceeds the predetermined threshold value the interest change determining portion determines that the interested object of the user has changed. When the determined result at step S represents that the interested object has changed the flow advances to step S. When the determined result at step S represents that the interested object has not changed the flow advances to step S.

When the determined result at step S represents that the interested object of the user has not changed the flow advances to step S. At step S as was described above the interested object area categorizing portion determines that the click peripheral area of the current moving click is contained in the same picture area as the interested object area corresponding to the click peripheral area of the immediately preceding past moving click and categorizes the click peripheral area of the current moving click as an interested object area corresponding to the click peripheral area of the immediately preceding moving click for example assigns the same category number to the click peripheral area of the current moving click . In other words when an interested object area is categorized for each object the same object number is assigned in the same manner as the above described embodiment. After step S the flow advances to step S.

In contrast when the determined result at step S represents that the interested object of the user has changed the flow advances to step S. At step S the interested object area categorizing portion determines that the click peripheral area of the current moving click is not contained in an interested object area corresponding to the click peripheral area of the immediately preceding past moving click outputs the stored data of the click peripheral picture of the current moving click and resets the stored data. Thereafter at step S the interested object area categorizing portion categorizes the click peripheral area of the current moving click as an interested object area that is different from the click peripheral area of the immediately preceding moving click for example assigns a different category number to the click peripheral area of the current moving click . In other words when an interested object area is categorized for each object a new different object number is assigned in the same manner as the above described embodiment. After step S the flow advances to step S.

After steps S S S and S the flow advances to step S. At step S the change determining and categorizing portion determines whether or not all the process has been completed. When the determined result at step S is No the flow returns to step S. When the determined result at step S is Yes the change determining and categorizing portion completes the process shown in .

Next with reference to a flow chart shown in the interested object change determining process at steps S and S shown in will be described in detail.

At step S the interest change determining portion obtains information of the time interval. Thereafter at step S the interest change determining portion performs a predetermined weighting process for the time interval. At step S the interest change determining portion obtains information of the spatial distance. Thereafter at step S the interest change determining portion performs a predetermined weighting process for the spatial distance. The order of step S and step S may be changed. Likewise the order of step S and S may be changed. The weighting process for the time interval may be performed by compressing the time unit for example a compression of ms 10 . The weighting process for the spatial distance may be performed by compressing the pixel pitch in the horizontal direction and the vertical direction.

Thereafter the flow advances to step S. At step S the interest change determining portion generates a three dimensional vector using the weighted time interval t and the weighted spatial distance in the horizontal and vertical directions x coordinate and y coordinate and obtains the size of the three dimensional vector. The size of the three dimensional vector is obtained by calculating the Euclidean distance between the current input point and the immediately preceding input point in the three dimensional space of which the time axis t is added to the x coordinate axis and y coordinate axis of the input position of click data. After step S the flow advances to step S.

At step S the interest change determining portion determines whether or not the size of the three dimensional vector obtained at step S exceeds a predetermined threshold value. When the determined result at step S represents that the size of the three dimensional vector does not exceed the predetermined threshold value the flow advances to step S. At step S the interest change determining portion determines that the interested object of the user of the receiving apparatus has not changed. When the size of the three dimensional vector exceeds the predetermined threshold value the flow advances to step S. At step S the interest change determining portion determines that the interested object of the user has changed.

In the above described manner the change determining and categorizing portion accomplishes the user s interested object change determination and the categorization thereof corresponding to click data transmitted form the receiving apparatus .

In addition when an interested object area of the user of the receiving apparatus is categorized the categorized interested object area can be optimally processed. In other words an information amount assigned to each interested object area of the user may be varied. For example a large information amount may be assigned to a particular interested object area of the user. Alternatively data of an interested object area of the user may be transmitted with priority.

In addition a picture area that is read output for an interested object area from the click peripheral area storing portion can be transmitted so that the spatial resolution is improved as was described above.

In this case even if the user of the receiving apparatus mistakenly clicks a non interested object area it can be prevented from being incorrectly determined.

According to the embodiment even if one object that has a significance as an interested object area is spatially or temporally separated from another object they can be categorized as one object. In addition an area that has a particular significance other than an object such as a substance may be extracted.

In addition the embodiment described with reference to and the embodiment described with reference to may be combined. In this case at steps S and S a continuous click is determined for a still click for a continuous click in the above described manner. Likewise at steps S and S a continuous click is determined for a moving click for a continuous click in the above described manner.

Next shows an example of a third structure of the picture transmitting system shown in . In similar portions to those in are denoted by similar reference numerals and their description is omitted. In other words the structure of the picture transmitting system shown in is basically the same as the structure of the picture transmitting system shown in except that the exchange station has a charging server .

Although a service for transmitting click data or control information from the receiving apparatus to the transmitting apparatus and providing a picture having an improved spatial resolution corresponding to click data from the transmitting apparatus to the receiving apparatus hereinafter this service may be referred to as click service may be a free server the service may be a non free service. When the click service is a non free service the charging server performs a charging process for collecting a service fee for the click service from the user.

Predetermined information is supplied from the exchange station to a communication link establishment detecting portion . The communication link establishment detecting portion references the information supplied from the exchange station . As a result the communication link establishment detecting portion detects whether or not a communication link has been established between a terminal unit as a transmitting apparatus and a terminal unit as a receiving apparatus and supplies the resultant data to a terminal unit recognizing portion .

When the terminal unit recognizing portion receives information that represents that a communication link has been established between the terminal units such as the transmitting apparatus and the receiving apparatus hereinafter this information may be referred to as communication link establishment information the terminal unit recognizing portion references information supplied from the exchange station . As a result the terminal unit recognizing portion recognizes the terminal units that have been communication linked. In addition the terminal unit recognizing portion recognizes IDs assigned to the terminal units hereinafter the IDs may be referred to as terminal unit IDs and supplies the recognized terminal unit IDs to a click detecting portion .

The click detecting portion monitors data received through the exchange station detects click data transmitted from the terminal unit with a terminal unit ID received from the terminal unit recognizing portion and supplies the detected result and the terminal unit ID to a charging process portion .

In this case for example the receiving apparatus transmits click data along with the local terminal unit ID. The click detecting portion compares the terminal unit ID added to the click data received through the exchange station and the terminal unit ID supplied from the terminal unit recognizing portion recognizes the click data transmitted from the terminal unit that has been communication linked and detects the click data.

Hereinafter a set of a click data detected result of the click detecting portion and a terminal unit ID is referred to as click detection information.

When the charging process portion receives the click detection information from the click detecting portion the charging process portion updates the stored content of a charging database . In addition the charging process portion performs the charging process corresponding to the stored content of the charging database for example periodically for example once per month .

Next with reference to a flow chart shown in the process of the charging server shown in will be described.

The communication link establishment detecting portion monitors whether or not a communication link between terminal units has been established corresponding to information supplied from the exchange station . When the communication link establishment detecting portion detects that the communication link between the transmitting apparatus and the receiving apparatus has been established the communication link establishment detecting portion supplies communication link establishment information to the terminal unit recognizing portion .

When the terminal unit recognizing portion receives the communication link establishment information from the communication link establishment detecting portion at step S the terminal unit recognizing portion references the information supplied from the exchange station . As a result the terminal unit recognizing portion recognizes the terminal unit IDs of the terminal units for example the transmitting apparatus and the receiving apparatus that have been communication linked and supplies the terminal unit IDs to the click detecting portion .

When the click detecting portion receives the terminal unit IDs from the terminal unit recognizing portion the click detecting portion starts detecting click data that contains the terminal unit IDs.

Thereafter the flow advances to step S. At step S the charging process portion determines whether or not click data has been detected from a terminal unit that has been communication linked. When the determined result at step S represents that click data has not been detected from a terminal unit that has been communication linked namely when the click detection information has not been supplied from the click detecting portion to the charging process portion the flow advances to step S skipping step S.

In contrast when the determined result at step S represents that click data has been detected from a terminal unit that has been communication linked namely the click detection information has been supplied from the click detecting portion to the charging process portion the flow advances to step S. At step S the charging process portion updates the stored content of the charging database .

In other words the charging database stores information about clicks such as the number of clicks and click time hereinafter this information may be referred to as click information along with communication time at which a terminal unit originates a call and starts a communication. The charging database correlatively stores the click information and the terminal unit ID of the terminal unit. At step S the charging process portion updates the click information corresponding to the terminal unit ID contained in the click detection information corresponding to the click detection information.

After step S the flow advances to step S. At step S the terminal unit recognizing portion determines whether or not the communication link corresponding to the communication link establishment information supplied from the communication link establishment detecting portion has been disconnected.

In other words the communication link establishment detecting portion monitors not only the establishment of a communication link between terminal units but the disconnection thereof. When a communication link has been disconnected the communication link establishment detecting portion supplies the resultant information as communication link disconnection information to the terminal unit recognizing portion . At step S the terminal unit recognizing portion determines whether or not the communication link has been disconnected corresponding to the communication link disconnection information.

When the determined result at step S represents that the communication link has not been disconnected the flow returns to step S. At step S the charging server repeats the similar process.

In contrast when the determined result at step S represents that the communication link has been disconnected the terminal unit recognizing portion controls the click detecting portion to complete the monitoring of the click data of the terminal unit that has been communication linked. Thereafter the charging server completes the process.

Thereafter the charging process portion periodically references the charging database performs the charging process calculates the communication fee and the click service fee and transfers the fee from a bank account or the like of the user.

As a click service fee a unit fee per click may be designated. Corresponding to the number of clicks the click service fee may be calculated. Alternatively as a click service fee a unit fee per hour may be designated. Corresponding to the click time the click service fee may be calculated. Alternatively corresponding to the number of clicks and the click time the click service fee may be calculated.

The above described processes can be performed by hardware or software. When those processes are performed by software a program that composes the software is installed to a computer a general purpose computer or the like that is disposed in the transmitting apparatus the receiving apparatus and so forth as dedicated hardware apparatuses.

Thus shows an example of the structure of a computer in which the program for executing the above described processes has been installed.

The program can be prerecorded to a hard disk or a ROM as a record medium that is built in the computer.

Alternatively the program can be temporally or permanently stored recorded on a removable record medium such as a floppy disk a CD ROM Compact Disc Read Only Memory an MO Magneto optical disc a DVD Digital Versatile Disc a magnetic disc or a semiconductor memory. The removable record medium can be provided as a so called package software.

The program can be installed from the above described removable record medium to the computer. Alternatively the program can be wirelessly transferred from a download site to the computer through a digital satellite broadcast satellite. Further alternatively the program can be transferred to the computer through a network such as LAN Local Area Network or the Internet. In the computer the program is received by a communicating portion and installed to the hard disk .

The computer contains a CPU Central Processing Unit . An input output interface is connected to the CPU through a bus . When a command is input by the user with an input portion such as a keyboard a mouse a microphone and so forth to the CPU through the input output interface the program stored in a ROM Read Only Memory is executed. Alternatively the CPU loads the program stored in the hard disk to a RAM Random Access Memory and executes the program with the RAM . Further alternatively the CPU loads the program transferred from a satellite or a network and received by the communicating portion and installed to the hard disk or read from the removable record medium attached to a drive and installed to the hard disk to the RAM and executes the program with the RAM . Thus the CPU performs the processes corresponding to the flow charts shown in to to and . Alternatively the CPU performs the processes shown in the block diagrams of to to and . When necessary the CPU outputs the processed results from an output portion composed of an LCD Liquid Crystal Display a speaker and so forth through the input output interface . Alternatively the CPU transmits the processed results from the communicating portion or recorded to the hard disk .

In the specification process steps of the program that causes the computer to perform individual processes may not be always performed in the order of the flow charts. Alternatively process steps may be executed in parallel or discretely for example a parallel process or an object process may be performed .

The program may be processed by one computer. Alternatively the program may be distributed by a plurality of computers. Further alternatively the program may be transferred to a remote computer and executed therewith.

According to the embodiment of the present invention the transmitting apparatus performs hierarchical encoding. Depending on hierarchical data that is transmitted the temporal resolution and the spatial resolution of a picture that is displayed by the receiving apparatus are changed. Alternatively the temporal resolution and the spatial resolution of a picture displayed by the receiving apparatus may be changed depending on discrete cosine transform coefficients or quantized steps of a picture that are transmitted.

Alternatively the temporal resolution and the spatial resolution can be changed depending on an encoding method of the transmitting apparatus . In other words when a picture is displayed with a regular temporal resolution the encoding portion of the transmitting apparatus chain encodes the contour of an object thereof and obtains the average value of pixel values color that compose an object as a representative value. The receiving apparatus displays the area of the object with the color as the representative value. When a picture with an improved spatial resolution is displayed at the sacrifice of a temporal resolution as was described above the hierarchical encoding can be used.

According to the embodiment the spatial resolution is improved at the sacrifice of the temporal resolution of a picture. In contrast the temporal resolution may be improved at the sacrifice of the spatial resolution. Information representing the selection of the sacrificed improved resolution can be contained in control information such as click data and transmitted from the receiving apparatus to the transmitting apparatus .

According to the embodiment of the present invention the temporal resolution and the spatial resolution are handled. However according to the present invention the resolution in the level direction hereinafter this resolution may be referred to as level resolution may be handled. In other words when the number of bits assigned to data is increased or decreased the temporal resolution and the spatial resolution can be improved or deteriorated. In this case as the temporal resolution and the spatial resolution of a picture are changed the tone thereof is changed. The level resolution can be changed by changing the above described quantizing steps.

In addition according to the embodiment the spatial resolution of a partial area priority range of a picture is improved at the sacrifice of the temporal resolution. Alternatively the spatial resolution of the entire picture may be improved.

Alternatively the spatial resolution of a particular part of a picture can be improved at the sacrifice of the spatial resolution of the rest of the picture rather than the sacrifice of the temporal resolution namely the temporal resolution is maintained .

In addition according to the embodiment a picture is processed in such a manner that it is separated into a background picture and an object. Alternatively a picture may be processed without separating it.

In addition the present invention can be applied to not only picture data but audio data. In the case of audio data for example sampling frequency corresponds to the temporal resolution whereas the number of bits assigned to audio data corresponds to the level resolution.

In addition the process of the change determining and categorizing portion shown in may be applied to the case that a feature amount of a sound for example a pitch a desired part of a human voice or each musical instrument is extracted.

In addition the processes of the object extracting portions and and the change determining and categorizing portion can be applied to so called object encoding. In other words with the processes of the object extracting portions and and the change determining and categorizing portion since an object can be extracted the extracted object can be encoded along with information that represents the contour or the area thereof corresponding to object encoding process that obtains information that represents the motion of the object. The encoded data can be transmitted or recorded.

The receiving apparatus can perform the similar process to the process of the object extracting portion using click data so as to extract an object. In this case when an object extracted by the receiving apparatus is stored an object database can be formed.

According to the first transmitting apparatus the first transmitting method the first record medium and the first signal of the present invention control information transmitted from a receiving apparatus is received. Corresponding to the control information the resolutions in at least two directions of the temporal direction the spatial direction and the level direction are controlled. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted to the receiving apparatus. Thus for example the resolution in the spatial direction of a picture displayed by the receiving apparatus can be more improved.

According to the receiving apparatus the receiving method the second record medium and the second signal of the present invention control information is transmitted to a transmitting apparatus that controls the resolutions in at least two directions of the temporal direction the spatial direction and the level direction corresponding to the control information. In addition data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted from the transmitting apparatus received and output. Thus for example the spatial resolution of a picture that is output can be more improved.

According to the transmitting and receiving apparatus the transmitting and receiving method the third record medium and the third signal a transmitting apparatus receives control information transmitted from a receiving apparatus. Corresponding to the control information the resolutions in at least two directions of the temporal direction the spatial direction and the level direction are controlled. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted to the receiving apparatus. In addition the receiving apparatus transmits control signal to the transmitting apparatus. Data of which the resolutions in at least two directions have been controlled corresponding to the control information is transmitted from the transmitting apparatus received and output. Thus for example the resolution in the spatial direction of a picture displayed by the receiving apparatus can be more improved.

According to the second transmitting apparatus the second transmitting method the fourth record medium and the fourth signal of the present invention control signal transmitted from a receiving apparatus is received. Corresponding to the control information data is categorized. Corresponding to the categorized result of the data data is transmitted to the receiving apparatus. Thus for example an area of a picture that the user is considering can be transmitted to the receiving apparatus regardless of whether the area is moving or still.

