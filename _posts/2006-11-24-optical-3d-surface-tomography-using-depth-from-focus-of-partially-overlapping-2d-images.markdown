---

title: Optical 3-d surface tomography using depth from focus of partially overlapping 2-d images
abstract: A system and method of reconstructing a three-dimensional image of an object is provided. The system includes a single camera including a pinhole lens and having a surface defining an image plane. The single camera can be arranged to move along a linear path relative to the object and is configured to capture images at predetermined locations along the linear path such that at least a portion of the captured adjacent images overlap. The system includes a processor that can be programmed with an image processing logic that enables the processor to create a three-dimensional image of the object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07813529&OS=07813529&RS=07813529
owner: The United States of America as represented by the Secretary of the Navy
number: 07813529
owner_city: Washington
owner_country: US
publication_date: 20061124
---
The present teachings described herein may be manufactured and used by or for the Government of the United States of America for Governmental purposes without the payment of any royalties thereon or therefor.

The present teachings relate to a system and method for performing optical surface tomography. In particular the present teachings relate to a system and method for performing optical surface tomography which provides high quality images in low visibility conditions by processing a sequence of images taken from various locations by a single camera.

Three dimensional 3 D sensing and imaging has been the subject of research due to its diverse benefits and applications. Some exemplary applications of 3 D imaging include mapping and computer visualization. Presently 3 D information for purposes of mapping and computer visualization is obtained using photogrammetry. Photogrammetry is based on comparing two or more photographic images taken by one or more cameras from different positions with respect to an object being mapped. Common points are then identified on each image and a line of sight or ray is constructed from the camera location to the identified points on the object. The 3 D image and the range of the object can be determined using the intersection of these rays through the use of triangulation. Photogrammetry however does not allow for the generation of images in poor visibility environments such as turbid environments. Instead in poor visibility environments a 3 D image can be obtained using time gated imaging or laser scanning methods. However these methods require expensive specialized equipment that uses a specialized light source thereby limiting their practical range especially in daylight conditions.

Computer aided tomography CAT can also provide 3 D images. CAT is an imaging method that employs tomography in which digital geometry processing is used to generate a 3 D image of the internals of an object from a large series of two dimensional X ray images taken around a single axis of rotation. Although optical CAT is capable of providing high resolution 3 D images of convex objects its capability is limited with respect to occlusions and concave objects.

Accordingly a need exists for a system and method that can efficiently provide 3 D imaging of various shaped objects in all types of environmental conditions.

The present teachings disclose a system and method of reconstructing a 3 D image of an object using a single camera.

According to the present teachings the system includes a single camera including a pinhole lens and having a surface defining an image plane. The single camera is positionable at a distance away from a surface of an object to be imaged and is moveable along a linear path relative to the object. The single camera is configured to capture a volume spot projected into the camera to create a single pixel and to create a sequence of images whereby at least adjacent captured images in the sequence partially overlap. Moreover the system includes a processor programmed with an image processing logic that enables the processor to create a 3 D image of the object.

According to the present teachings the method includes capturing an image at each of a plurality of predetermined locations along a linear path by way of a single camera and creating a sequence of images whereby at least adjacent captured images in the sequence partially overlap. The method also includes mapping the plurality of images to create a 3 D image of the object.

Additional features and advantages of various embodiments will be set forth in part in the description that follows and in part will be apparent from the description or may be learned by practice of various embodiments. The objectives and other advantages of various embodiments will be realized and attained by means of the elements and combinations particularly pointed out in the description herein.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory only and are only intended to provide an explanation of various embodiments of the present teachings.

The present teachings are directed to a system and method for reconstructing a 3 D image of an object. As shown in the system of the present teachings includes a single camera including a pinhole lens and a surface defining an image plane . The single camera can be any type of camera such as a digital camera a CCD camera and the like.

The single camera is positionable at a distance away from a surface having the objects to be imaged and is capable of moving along a linear path relative to the objects . The single camera is configured to capture an image at predetermined locations A B C and D along the linear path to thereby create a sequence of images. The movement of the single camera along the linear path can be accomplished by placing the single camera on a track having a linearly moving device or in any other manner as would be appreciated by one of ordinary skill in the art. The single camera can be arranged to move continuously or non continuously along the linear path relative to the objects .

Predetermined locations A B C and D along the linear path are separated from one another by a distance . The distance can be a length that is pre selected such that at least a portion of each of the adjacent captured images in the sequence captured by the single camera overlap one another. For example the moving single camera at location A can capture an image that includes volumes and . When the moving single camera reaches location B it captures an image that includes volumes and . As the single camera moves further along the linear path to location C it captures an image that includes volumes and . Similarly when the moving single camera reaches location D it captures an image that includes volumes and . As a result the volumes and are an image of the same volume captured at two different angles due to the movement of the camera along the linear path . Similarly each of the volumes in each of the other four different volume sets i ii iii and iv are an image of the same volume captured at different angles due to the movement of the single camera along the linear path . Accordingly the images captured at locations A B C and D can produce a sequence of partially overlapping images.

The sequence of overlapping images can then be stored in a storage device. An image processing logic can then be used to retrieve the sequence of overlapping images from the storage device and create or reconstruct a 3 D image of the objects . As would be appreciated by one of ordinary skill in the art the image processing logic can be programmed and run by a processor such as one found in a general purpose computing device.

The image processing logic of the present teachings can include for example back projection process logic or focal plane projection process logic. Back projection process logic and focal plane projection process logic can utilize the attenuation data of the images captured from different angles corresponding to locations A B C and D for example.

An example of back projection process logic is shown in . At step images captured by the single camera at locations A B C and D can be collected or retrieved from a storage device. At step a depth H is selected and a scale factor M i.e. a magnification factor is determined at the selected depth H. Preferably the depth H is measured from the pinhole lens of a camera see . Additionally it is preferable that at the depth H at least a portion of the image of the object captured by the single camera is in focus. The scale factor M is the ratio of the depth H to a distance F i.e. M H F wherein the distance F is the distance from the pinhole lens to the image plane . Accordingly the size of an inversed mapped image MD can be determined by the following equation 

At step a layer of a single image captured at location A which corresponds to the selected depth H and scale factor M from step can be selected. At step a shift factor of zero is added to the selected layer because in this example the single camera at location A is stationary. At step the process at steps and are repeated for each of locations B C and D at which the single camera has captured an image. However given that the single camera is not stationary at locations B C and D the shift factor added at step for each of the selected images at locations B C and D is non zero. Accordingly when the process is repeated at step for an image captured at location B at step a layer of a single image at the depth H and scale factor M can be selected. At step a shift factor corresponding to the movement of the single camera from location A to location B is added to the selected layer of the image captured at location B.

Similarly for the image captured at location C a layer of a single image at the depth H and scale factor M can be selected. At step a shift factor corresponding to the movement of the single camera from location B to location C is added to the selected layer of the image captured at location C. For the image captured at location D a layer of a single image at the depth H and scale factor M can be selected. At step a shift factor corresponding to the movement of the single camera from location C to location D is added to the selected layer of the image captured at location D. Although in this exemplary embodiment the process involving steps and is repeated four times once for each of locations A B C and D one of ordinary skill in the art would appreciate that this process could be repeated as many times as necessary and for each location at which the single camera captures an image.

At step each of the single layers at the depth H and the scale factor M at locations A B C and D are then collected and can be inversely projected through the pinhole lens and onto a reconstruction image plane to create a single layer of an inversely mapped image of the object.

Each of the images which create the single layer of the inversely mapped image at step provides different information about the 3 D object. However in order to form a 3 D image of the object multiple layers of the object should be created. To create the multiple layers the entire process from step to step may be repeated as many times as necessary by selecting a new depth H and determining a new scale factor M at the end of each cycle as represented by step . Preferably each of the selected new depths H corresponds to an image. For example to create a second layer a second depth H is selected and a scale factor M is determined at the second selected depth H. Steps through are then repeated with steps and being repeated for each of locations A B C and D to create the second layer. To create a third layer a third depth H is selected and a scale factor M is determined at the third selected depth H. Steps through are then repeated with steps and being repeated for each of locations A B C and D to create the third layer. This process can continue until a sufficient number of a plurality of layers containing images at different depths H have been created. At step the layers are then collected to create multi layers of the captured images.

At step the multi layered image generated in step is subdivided into columns. Each of the columns can include all of the depths of a relatively small image or a portion of a larger image. At step the depth at which the image that is in focus in each of the columns is determined. Using the data of step the depth of the focused image in each of the individual columns the 3 D image of the object can then be reconstructed.

An example of focal plane projection process logic is shown in . Process steps and of the focal plane projection process logic are identical to process steps and respectively of the back projection process logic described above. Accordingly at step of the focal plane process logic the images captured by the single camera at locations A B C and D can be collected or retrieved from a storage device. At step a depth H is selected and a shift correction factor s is determined at the selected depth H. Depth H in the focal plane projection process logic is identical to the depth H in the back projection process logic described above. However given that in the focal plane projection process logic the image is reconstructed on the image plane of the moving single camera see a captured image of the object on the image plane appears as shifted from size d size of the image on the image plane at location A to size d the size of the image on the image plane at location B . Accordingly the shift correction factor s is the sum of dand d which can be defined by the following equation 

where S is the distance between each of locations A B C and D F is the distance from the pinhole lens to the image plane and H is the selected depth from pinhole lens .

At step a layer of a single image captured at location A which corresponds to the selected depth H and the shift correction factor s from step can be selected. At step a shift factor of zero is added to the selected layer because in this example the single camera at location A is stationary. At step the process at steps and are repeated for each of locations B C and D at which the single camera has captured an image. However given that the single camera is not stationary at locations B C and D the shift factor added at step for each of the selected images at locations B C and D is non zero. Accordingly when the process is repeated at step for an image captured at location B at step a layer of single image at the depth H and shift correction factor s can be selected. At step a shift factor corresponding to the movement of the single camera from location A to location B is added to the selected layer of the image captured at location B.

At step steps and of the process are repeated for the images captured by the single camera at locations C and D. Accordingly for the image captured at location C a layer of a single image at the depth H and shift correction factor s can be selected. At step a shift factor corresponding to the movement of the single camera from location B to location C is added to the selected layer of the image captured at location C. For the image captured at location D a layer of a single image at the depth H and shift correction factor s can be selected. At step a shift factor corresponding to the movement of the single camera from location C to location D is added to the selected layer of the image captured at location D. Although in this exemplary embodiment the process involving steps and is repeated four times once for each of locations A B C and D one of ordinary skill in the art would appreciate that this process could be repeated as many times as necessary and for each location at which the single camera captures an image.

At step each of the single layers at the depth H and the shift correction factor s at locations A B C and D are then collected and projected onto the image plane to create a single layer of mapped image of the object.

Each of the images which create the single layer of the mapped image at step provides different information about the 3 D object. However in order to form a 3 D image of the object multiple layers of the object should be created. To create the multiple layers the entire process from step to step may be repeated as many times as necessary by selecting a new depth H and determining a new shift correction factor s at the end of each cycle as represented by step . Preferably each of the selected new depths H corresponds to an image. For example to create a second layer a second depth H is selected and a shift correction factor s is determined at the second selected depth H. Steps through are then repeated with steps and being repeated for each of locations A B C and D to create the second layer. To create a third layer a third depth H is selected and a shift correction factor s is determined at the third selected depth H. Steps through are then repeated with steps and being repeated for each of locations A B C and D to create the third layer. This process can continue until a sufficient number of a plurality of layers containing images at different depths H have been created. At step the layers are then collected to create multi layers of the captured images.

As stated above steps and of the focal plane projection process logic are identical to the steps and of the back projection process logic respectively. Therefore as described above the multi layered image generated in step is subdivided into columns and the depth at which the image is in focus in each of the columns is determined. The 3 D image of the object can then be reconstructed.

Those skilled in the art can appreciate from the foregoing description that the present teachings can be implemented in a variety of forms. Therefore while these teachings have been described in connection with particular embodiments and examples thereof the true scope of the present teachings should not be so limited. Various changes and modifications may be made without departing from the scope of the teachings herein.

