---

title: Direct memory access-based multi-processor array
abstract: A direct memory access (“DMA”)-based multi-processor array architecture that may be implemented in a single integrated circuit is described. The integrated circuit includes a plurality of processing units. A first processing unit and a second processing unit of the plurality of processing units are topologically coupled via a first DMA block. The first DMA block includes a first dual-ported random access memory and a first decoder. A multiple-processor array is provided by topologically coupling the first processing unit and the second processing unit via the first direct memory access block.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07831801&OS=07831801&RS=07831801
owner: Xilinx, Inc.
number: 07831801
owner_city: San Jose
owner_country: US
publication_date: 20060830
---
One or more aspects of the invention relate generally to integrated circuits and more particularly to a direct memory access DMA based multi processor array architecture that may be implemented in a single integrated circuit.

Programmable logic devices PLDs are a well known type of integrated circuit that can be programmed to perform specified logic functions. One type of PLD the field programmable gate array FPGA typically includes an array of programmable tiles. These programmable tiles can include for example input output blocks IOBs configurable logic blocks CLBs dedicated random access memory blocks BRAMs multipliers digital signal processing blocks DSPs processors clock managers delay lock loops DLLs and so forth. Notably as used herein include and including mean including without limitation.

One such FPGA is the Xilinx Virtex FPGA available from Xilinx Inc. 2100 Logic Drive San Jose Calif. 95124. Another type of PLD is the Complex Programmable Logic Device CPLD . A CPLD includes two or more function blocks connected together and to input output I O resources by an interconnect switch matrix. Each function block of the CPLD includes a two level AND OR structure similar to those used in Programmable Logic Arrays PLAs and Programmable Array Logic PAL devices. Other PLDs are programmed by applying a processing layer such as a metal layer that programmably interconnects the various elements on the device. These PLDs are known as mask programmable devices. PLDs can also be implemented in other ways for example using fuse or antifuse technology. The terms PLD and programmable logic device include but are not limited to these exemplary devices as well as encompassing devices that are only partially programmable.

For purposes of clarity FPGAs are described below though other types of PLDs may be used. FPGAs may include one or more embedded microprocessors. For example a microprocessor may be located in an area reserved for it generally referred to as a processor block. Additionally or alternatively microprocessors may be implemented in programmable logic of an FPGA FPGA fabric . These microprocessors are generally referred to as soft processors in contrast to embedded microprocessors which are generally referred to as hard processors. Whether hard or soft microprocessors may be any of a variety of known architectures including a reduced instruction set computer RISC a complex instruction set computer CISC or a Zero Instruction Set Computer ZISC form.

Architectures associated with multi processor array MPA configurations have been based on a variety of infrastructures for communication between microprocessors. For example in some architectures a networking model is used for a Network on Chip NoC . In other architectures a hierarchical bus model is used for a System on Chip SoC . Furthermore in other architectures a data streaming via buffering model with first in first out buffers FIFOs is used for an MPA implemented in an FPGA.

In a bus based SoC implementation the convenience of abstracting away notions of clock signals hardware level concurrency and pipelining among other circuit based factors with the transaction level abstraction provided via an Application Programming Interface API comes at a price. With bus based communication well known performance degradation is exhibited as the number of clients is increased. This degradation in performance is rooted in a combination of bandwidth sharing and arbitration induced losses.

With respect to a streaming data approach microprocessors implemented in an FPGA communicate using directly connected FIFOs. Access to information in such FIFOs is not random and this may severely constrain performance in applications involving random access to such information. Moreover an intimate working knowledge of circuitry issues such as timing constraints pipelining and number of clock cycles among other known circuitry issues may be involved in parallel programming for such MPAs.

FPGA based NoC architectures have been proposed to overcome degradation due to an increase in the number of clients owing to the relative ease with which multiple concurrent connections are supported in such NoC architecture. However due to the distributed nature of NoC arbitration and routing mechanisms NoC remains significantly more complex. Furthermore in its serial form an NoC may have bandwidth limitations due to serial to parallel datapath conversion overhead. This additional overhead also increases complexity. Moreover a parallel form of NoC suffers from scalability limitations as network infrastructure is by nature highly consumptive of routing resources.

Additionally for FPGA based bus or network infrastructures there exist additional problems of synthesizing and mapping a hardware description language HDL representation to structures that are resource efficient. Moreover this inefficiency in addition to being based upon resource utilization may further be based upon inefficiencies associated with pipeline latency and overall speed.

Accordingly it would be both desirable and useful to provide an MPA architecture that is at least less susceptible to one or more of the above identified limitations.

One or more aspects of the invention generally relate to integrated circuits and more particularly to a direct memory access DMA based multi processor array architecture that may be implemented in a single integrated circuit.

An aspect of the invention provides an integrated circuit including a plurality of processing units. A first processing unit and a second processing unit of the plurality of processing units are topologically coupled via a first direct memory access block. The first direct memory access block includes a first dual ported random access memory and a first decoder. A multiple processor array is provided.

In the following description numerous specific details are set forth to provide a more thorough description of the specific embodiments of the invention. It should be apparent however to one skilled in the art that the invention may be practiced without all the specific details given below. In other instances well known features have not been described in detail so as not to obscure the invention. For ease of illustration the same number labels are used in different diagrams to refer to the same items however in alternative embodiments the items may be different.

Below a DMA based MPA architecture is described. While this DMA based MPA is described for an example implementation in an FPGA it should be appreciated that other forms of implementation may be used. For example an Application Specific Integrated Circuit ASIC may be used or a hybrid integrated circuit having both programmable logic and dedicated logic may be used. Thus generally it should be appreciated that a DMA based MPA architecture as described herein may be implemented in a single microchip chip .

In the following description MPA inter processor communication is described as being implemented using micro DMAs. The micro DMAs provide topological interconnects between processors. Thus an MPA employs a set of bilateral micro DMA instances. Notably as shall be appreciated from the following description this MPA topology is scalable and thus is not limited to the particular processor array sizes described in the examples that follow.

From the following description it should be appreciated that parallel processor performance dynamics of a micro DMA based MPA may be achieved over essentially any number of microprocessors that may be implemented in a single chip. This is because the number of microprocessors may be increased without correspondingly having much more complex arbitration as between such microprocessors.

As shall be appreciated from the following description the use of micro DMA instances does not need to involve arbitration at the DMA buffer level. In particular dual ported random access memory RAM resources may be used to avoid such arbitration. Thus DMA buffer access is made more independent of scale or topological connectivity as there is little to no concomitant complexity from arbitration as between microprocessors for access to shared memory. Moreover access to memory may be random in contrast to an MPA with a FIFO interconnect topology.

By providing support for micro DMA control mechanisms for each DMA buffer instance a highly repeatable constructive principle for hybrid processing structures is provided. Thus although the following description is in terms of an FPGA centric implementation using MPA arrays of RISC microprocessors it should be appreciated that a heterogeneous mix of microprocessors may be used. Such heterogeneous mix may include RISC processors digital signal processing DSP processors application specific processors cyclostatic structures finite state machines FSMs or CISC processors among other known types of processor structures.

In the following FPGA based MPA implementations RISC soft processors implemented in programmable logic are inter connected with micro DMA instances. These soft processors for example may be MicroBlaze soft processors. Notably although RISC soft processors are described it should be appreciated that RISC hard processors or a combination of hard and soft processors may be used. Furthermore it should be appreciated that the number of micro DMA instances used for such inter connection is generally dependent upon desired performance characteristics and available programmable logic resources FPGA fabric .

In the following description microprocessor interconnection is based upon micro DMA instances using dual ported BRAM using BRAM interconnect. Additionally there is associated control logic for such interconnect. Furthermore micro DMA instances may interface with cores namely micro DMA instances may be used to couple optional cores instantiated in programmable logic to an MPA implementations. It should be appreciated that such optional cores may form a basis for providing instruction or other form of control to an MPA or may be accelerators such as co processors or a combination thereof.

Processor to processor as well as processor to core communication may be structured as concurrent memory mapped buffered exchanges via topological micro DMA instances. Thus it should be appreciated that performance limitations associated with NoC and SoC interconnects as described above with respect to other MPA architectures may be substantially avoided.

It should further be appreciated that the DMA based MPA architecture described herein may be used as a processing resource for creation of useful SoC FPGA as Processor FPGAaP and Super Computer on Chip SCoC structures. Furthermore the DMA based MPA architecture as described herein for such SoC FPGAaP and SCoC applications may involve little to no change in known software tools and parallel programming software models.

In some FPGAs each programmable tile includes a programmable interconnect element INT having standardized connections to and from a corresponding interconnect element in each adjacent tile. Therefore the programmable interconnect elements taken together implement the programmable interconnect structure for the illustrated FPGA. Each programmable interconnect element also includes the connections to and from any other programmable logic element s within the same tile as shown by the examples included at the right side of .

For example a CLB can include a configurable logic element CLE that can be programmed to implement user logic plus a single programmable interconnect element . A BRAM can include a BRAM logic element BRL in addition to one or more programmable interconnect elements . Typically the number of interconnect elements included in a tile depends on the height of the tile. In the pictured embodiment a BRAM tile has the same height as four CLBs but other numbers e.g. five can also be used. A DSP tile can include a DSP logic element DSPL in addition to an appropriate number of programmable interconnect elements . An IOB can include for example two instances of an input output logic element IOL in addition to one instance of the programmable interconnect element . As will be clear to those of skill in the art the actual I O pads connected for example to the I O logic element are manufactured using metal layered above the various illustrated logic blocks and typically are not confined to the area of the I O logic element .

In the pictured embodiment a columnar area near the center of the die shown shaded in is used for configuration I O clock and other control logic. Vertical areas extending from this column are used to distribute the clocks and configuration signals across the breadth of the FPGA.

Some FPGAs utilizing the architecture illustrated in include additional logic blocks that disrupt the regular columnar structure making up a large part of the FPGA. The additional logic blocks can be programmable blocks and or dedicated logic. For example the processor block shown in spans several columns of CLBs and BRAMs.

Note that is intended to illustrate only an exemplary FPGA architecture. The numbers of logic blocks in a column the relative widths of the columns the number and order of columns the types of logic blocks included in the columns the relative sizes of the logic blocks and the interconnect logic implementations included at the right side of are purely exemplary. For example in an actual FPGA more than one adjacent column of CLBs is typically included wherever the CLBs appear to facilitate the efficient implementation of user logic. FPGA illustratively represents a columnar architecture though FPGAs of other architectures such as ring architectures for example may be used. FPGA may be a Virtex 4 FPGA from Xilinx of San Jose Calif.

Signaling between memory controller and RISC processor as well as instruction and data cache involves a chip select signal a write enable signal data signaling and address signaling. Separate address buses are used for handling instruction and data addresses however data for both instruction and data caching may be provided via a common data bus. Moreover separate write enable signals are used for instruction and data however a single chip select signal may be used for both instruction and data caching. As interfaces between memory controller RISC processor and instruction and data cache are known they are not described in unnecessary detail herein.

Micro DMA blocks through are coupled to memory controller and to left side RISC processor . Each of micro DMA blocks through include a buffer addressable space area a status and control data area and a decoder . Buffer area and status and control data area of each micro DMA block through may be separate address spaces of a dual ported BRAM. Notably status and control data area may be reserved memory address space namely reserved for status and control data for synchronizing states between right and left side RISC processors . Decoder which is described in additional detail below may be a separate block of circuitry from the BRAM used to provide buffer area and status and control data area and may be implemented in application specific circuitry or programmable logic.

Left side memory controller is coupled to each of micro DMA blocks through via signal buses through . Right side memory controller is coupled to micro DMA block via corresponding counterpart busing. Notably signals out of and to a memory controller are generally collectively referenced as signals . Bus may be an address bus. Bus may be a data bus. Bus may be a write enable bus. Bus may be a chip select bus. Notably although the term chip select is used it should be appreciated that micro DMA blocks through as well as memory controller and instruction and data cache may be implemented in a same integrated circuit. Thus the term chip select more generally may be thought of as a block select.

It should be appreciated that each processor is associated with another processor via a shared micro DMA block such as shared micro DMA block in this example. However each processor has a private instruction and data cache . Furthermore it should be appreciated that micro DMA blocks are bidirectional and thus may be coupled to separate processors. If for example left side RISC processor initiates an activity and thus the primary processor with respect to such activity a work unit may be placed into micro DMA block and more particularly into status and control data area . This work unit indicates that left side RISC processor is working on an activity which involves data stored in buffer area and this data may be identified with a particular address range or ranges. Responsive to a work unit being placed into micro DMA block decoder passes a token to right side RISC processor via an event signal associated with register space of such right side RISC processor . In other words this token may be passed to right side RISC processor via an event or events signal and stored in a register of registers of such right side RISC processor . Notably in this example event signals through are respectively provided from decoders of micro DMA blocks through for individual registers of registers of left side RISC processor and another event signal is associated with right side RISC processor for a shared micro DMA block . However it should be appreciated that other configurations for storing the indicators or flags for one or more events associated with a micro DMA instance may be used.

Memory controller associated with each RISC processor maps processor instruction and data cache memory and maps micro DMA memory associated with areas and . Notably memory controller maps such instruction and data into a composite address space. Thus memory and memories of micro DMA blocks through may be a composite address space which may or may not be contiguous and is mapped by memory controller . Thus it should be appreciated that transactions via micro DMA blocks may occur as memory reads or writes which simplifies the application program interface.

Activity associated with a micro DMA block is decoded by an associated decoder . More particularly accesses to status and control data area are decoded by decoder . Thus the processor initiating such activity may be considered the primary or initiating processor and the processor that shares the micro DMA block associated with such activity may be considered the secondary or attendant processor with respect to the activity. Additionally decoder decodes based on activity in buffer area . In particular a read from or write to an address space in buffer area is decoded by decoder and based on such decoded activity decoder sends an event vector to the processor not initiating the activity.

Thus it should be appreciated that micro DMA blocks may include dual ported BRAM and a conventional or simplified version of a DMA decoder adapted for use as bidirectional peer to peer inter processor communications resources. Random access block oriented transfer and support for a buffer partitioning may be implemented. Thus DMA buffer areas such as buffer areas may be instanced such that there is at least one shared DMA buffer area for each processor to processor coupling for providing at least approximately full bandwidth block oriented data control transfer between topologically adjacent processors. Bandwidth sharing in this implementation is cast in a form of RISC processing applied to a set of shared buffers and arbitration what little there is is cast in terms of an associated queue service paradigm.

In scatter gather processing in an MPA Locality of Reference LoR may be considered. LoR is less of an issue such as for example DSP butterfly transform and other types of closely connected activities. For LoR to an initiating processor it should be appreciated that one or more attendant processors may be coupled via a shared micro DMA block. It should be appreciated that using a micro DMA based topology for arraying processors such as in MPA for example eliminates much of the infrastructure associated with conventional bus and network multi processor topologies and thus reduces or eliminates associated performance limitations.

From the following descriptions it shall be appreciated how the leveraging of parallel processor acceleration and extension of programmable logic abstraction in the form of a parallel programming model using micro DMA based topology as a basis for datapath configuration may be obtained. Along those lines for purposes of clarity it shall be assumed that memory controller and instruction and data cache are part of RISC processor including associated busing to form a processor block . Furthermore in addition to the use of a processor block it shall be assumed that processor modules are formed by the inclusion of a processor block as well as least one shared micro DMA block.

Notably it should be appreciated that decoder of each micro DMA block through may be a conventional DMA decoder configured for managing two ports namely the dual ported BRAM used to provide buffer area and status and control data area . However conventional DMA decoders have more complexity than is needed for decoder and thus a much more simplified decoder may be implemented. Because a dual ported BRAM is implemented decoder may be simple in that it only has to manage the two ports of the dual ported BRAM.

Notably left side RISC processor may perform operations on memory associated with areas and of micro DMA block without interference from right side RISC processor and vice versa. Synchronization of state between left and right side RISC processors may be used to avoid degenerative conditions such as a read while writing or a write while reading of the same address space. Such synchronization may be implemented using finite state machines FSMs respectively associated with RISC processors . Such an FSM may be implemented as separate circuit coupled to registers such as may be implemented in dedicated or programmable logic. However for purposes of clarity by way of example and not limitation it shall be assumed that an FSM is implemented in RISC processor such as a software FSM.

Respective FSMs associated with left side and right side RISC processors may be synchronized with each other responsive to the status and control information stored in status and control data area . This information as well as knowledge of what tasks such processors have initiated may be provided to RISC processors via the combination of event signals. Moreover it should be appreciated that the addresses associated with memory of micro DMA block namely buffer area and status and control data area may be mapped to left and right side RISC processors . Thus such processors may have access to the same addresses. Alternatively addresses may be partitioned such that left and right side RISC processors have no address overlap or only partial address overlap with respect to address space of buffer area . For clarity by way of example and not limitation it shall be assumed that processors share the same address ranges as exchange of information may be done without any translation of addresses.

For example if left side RISC processor initiates a work unit an associated instruction for example written to buffer area is recorded in status and control data area . Decoder issues an event signal which is provided to right side RISC processor and registered in a register of registers thereof. This information along with whatever task initiated by left side RISC processor is used to coordinate access to shared micro DMA block via FSMs instantiated in software running using left and right side RISC processors .

Notably right side RISC processor may handle the task which is issued by left side RISC processor by using shared memory of micro DMA block as in situ scratch pad memory. Along those lines it should be appreciated that each memory respectively associated with micro DMA blocks through may have information for associated secondary processors where left side RISC processor is a primary processor. Accordingly information for secondary processes may be distributed for scatter gather MPA processing. Notably in the example embodiment of each RISC processor has a private instruction and data cache .

With simultaneous reference to MPA is further described. As noted above signals out of and to a memory controller are collectively referenced as signals . Signals are used to couple in this example four micro DMA blocks for each processor block of processor blocks through and thus common busing may be used within each processor module. Event signals through of a processor module are shown as going to respective registers or register banks of registers of each processor block. In some instances a micro DMA block as described above is shared as between processor blocks.

Although an alternating pattern of micro DMA blocks is shown such as a row of alternating micro DMA blocks and followed by a subsequent row of such alternating blocks though with the inverse order rows of same micro DMA blocks may be used. For example a row of micro DMA blocks may be followed by a row of micro DMA blocks which is then followed by another row of micro DMA blocks and so on. Likewise the same may be said with respect to columns of micro DMA blocks and . It should be appreciated that the relative position of a micro DMA block with respect to a processor block of a processor module may be relevant to addressing. For example if the micro DMA blocks through were associated with relative address positions through respectively then four sets of register of registers may have an association with addresses through respectively. Thus mapping of addresses between processors and micro DMA blocks may be simplified to avoid address translation. Moreover as addresses may follow the relative position of micro DMA blocks associated event signals may likewise correspond to particular registers as indicated by signals through respectively provided to registers through of registers of processor block .

The two dimensional mesh architecture of MPA or any other two dimensional MPA architecture as described herein may be used where addresses correspond to relative position of micro DMA blocks. However to avoid cross connecting processor modules some address translation may be implemented as described in additional detail with reference to .

With continuing reference to dual port BRAM instances for micro DMA blocks through are illustratively shown as a by four 4 configuration with respect to a RISC processor . However it should be appreciated that more or less than four micro DMA blocks may be implemented per processor and thus a processor may have as few as one micro DMA block associated with it for sharing with another processor. Notably even though an 4 representation is described it should be appreciated that some of such micro DMA blocks may be shared peer to peer connections for processor to processor coupling.

With continuing reference to it should be appreciated that a two by two micro DMA MPA is illustratively shown in the form of a two dimensional mesh architecture. By having consistent infrastructure topology for each micro DMA block architectural integrity is facilitated. Moreover with an ordering such as from 0 to 3 of micro DMA blocks BRAM address partitions of associated coupled processors may match each other. Thus processor to processor communication may employ the same memory addresses in an associated micro DMA buffer used to couple such processors. However this is not a requirement of the MPA architecture. Rather memory addresses of the MPA architecture described herein more generally are isomorphically mapped. Accordingly passing of addresses may involve address translation namely an offset addressing.

Cores through are external circuits with respect to MPA . However it should be appreciated that the same busing architecture associated with signals may generally be used for communicating between micro DMA blocks and MPA external cores. Cores through communicate with MPA via respective peripheral micro DMAs. For example peripheral micro DMAs blocks and of processor module are respectively coupled to cores and . Micro DMA blocks and of processor module are respectively coupled to cores and . Cores and are respectively coupled to micro DMA blocks and of processor module and cores and are respectively coupled to micro DMA blocks and of processor module . Accordingly devices external to MPA may be coupled using micro DMA blocks.

Instancing of micro DMAs on a per connection basis whether processor to processor or processor to MPA external device facilitates buffer exchange concurrency. This may result in generally high performance relative to minimal implementation cost. An MPA architecture as described herein is a parallel processor architecture and thus associated performance enhancements remain available within the context of applications developed for such parallel processing. Furthermore it should be appreciated that an MPA architecture as described herein may be used for a parallel program software representation. In other words the representational flexibility of an MPA as described herein may facilitate transfer of a datapath previously reserved to specialized hardware logic to software owing to the high performance capability of such an MPA. Additionally as interconnectivity may be generally described as reads and writes to random access memory a detailed knowledge of HDL implementation may be reduced or avoided which facilitates using software such as C Java and the like having less hardware dependence.

Furthermore it should be appreciated that an MPA as described herein with micro DMA instances may be implemented with hard or soft microprocessors. Accordingly such a micro DMA based MPA architecture may be leveraged as a building block for creation of extended datapath processing structures including being extended to peripheral cores as described with reference to or other devices such as for example FPGA external I O clients and memory among other types of FPGA external devices. Furthermore traditional bus network infrastructure may be appended to micro DMA MPA for connection of such FPGA external devices. Thus an MPA may be leveraged to extend to or be part of an SoC or NoC architecture where an MPA with micro DMA connectivity is used.

As indicated below in additional detail a micro DMA based MPA architecture may be extended to an FPGA in the form of a configurable high performance processor namely such as an FPGAaP or an SCoC. Furthermore by reducing inter processor communication as a system theoretic performance limit it should be appreciated that performance of a micro DMA based MPA architecture becomes more dependent upon microprocessor performance as well as performance of associated micro DMA instances. In other words performance is more directly coupled to the performance of the microprocessor and reads and writes to random access memory associated therewith.

With renewed reference to cores through in combination with MPA may be used to provide a bank of multiply accumulate units. Furthermore although a core is shown coupled to each peripheral micro DMA there may be a reduction in the number of such cores and correspondingly a reduction in the number of micro DMAs associated with such cores. Implementation of a bank of multiply accumulate units is merely one example of how MPA may be applied. Accordingly it should be appreciated that any other known uses of microprocessors where high performance is desirable are likewise suitable applications for MPA .

If one or both of buses and were an FPGA internal bus such bus or buses may be mapped directly to a processor block of MPA SoC as previously described with reference to use of micro DMA blocks. However for external busing it should be appreciated that such external buses generally may be coupled to a conventional bus hierarchy as is known.

One or more different types of devices or one or more same types of devices may be coupled to external buses such as buses and . In this example I O clients and are respectively shown coupled to external buses and . Furthermore in this example external memories and which may be for example DRAM or FLASH memories are illustratively shown coupled to external buses and respectively. Alternatively one or both of memories and may be another type of memory such as SRAM or other known type memory. Thus it should be appreciated that a micro DMA based MPA may form part of a larger architecture.

Accordingly it should be appreciated that micro DMA instances may be used as substantially ubiquitous building blocks for an MPA architecture. In this particular example I O device may be an interface to external I O devices and I O device may be external to or internal to FPGAaP . Moreover memory may be internal to or external to FPGAaP .

A task may be provided to central processor block and data for such task may be obtained from memory . The task may be issued from a device external to an FPGA associated with FPGAaP or may be a built in software application or any combination thereof. The task may be broken out or scattered among the processor blocks forming the periphery around central processor block namely processor blocks through and through .

In the scatter gather model the peripheral processors can obtain partial results which are gathered by the central processor block for providing a final result. It should further be appreciated that data associated with each of the peripheral processors may be provided via micro DMAs coupled between central processor block and horizontally or vertically neighboring processor blocks. For diagonally neighboring processor blocks in this architecture such data may be passed through a processor block to another processor block such as processor blocks and for such peripheral processing. Accordingly the reverse direction of flow back to central processor block may also be via an interim processor block.

By having a central processor block act as a server processor for scatter gather as architected there is little to no contention for memory access. The peripheral processors may enlist associated cores for completion of a partial result. The partial results provided back to the central processor block may be stored at least temporarily in memory . Accordingly it should be appreciated that an FPGA having sufficient programmable logic resources or dedicated processors or a combination thereof may be configured to provide an MPA as described herein. In effect the FPGAaP may be used as a CPU.

A useful balance is generally sought between inter processor communication bandwidth and computational LoR such that processor interconnect is not too significant a performance limitation. LoR may be defined as a condition where I O at any processor block boundary is generated or consumed by an immediately adjacent processor or peripheral I O process. Accordingly performance may be enhanced to the degree of spatial correlation of distributed tasks to their associated processors within an MPA. Notably there are many known useful algorithms which may schedule tasks such that LoR for a desired performance level may be satisfied. An example may be a DSP or discrete transform algorithm existing in the form of a synchronous dataflow.

Moreover the micro DMA architectures described herein facilitate meeting LoR as bandwidth sharing arbitration loss at an inter processor micro DMA buffer may be reduced or even eliminated. Again it should be appreciated that a micro DMA MPA therefore has a performance which is more closely indexed to individual processor performance characteristics and standard parallel processor physics as applied to the processor array in toto than it is to inter processor communication delayed by arbitration.

Coupled to an MPA of SCoC are address translation units through . Address translation units through are coupled to micro DMAs and respectively. It should be appreciated that each of these micro DMAs is associated with an address location as previously described as basically positions through going around a processor block. Thus address translation unit for example provides 2 to 0 or 0 to 2 address translation as does address translation unit for coupling processor block to processor block via a micro DMA block . Moreover address translation units and provide 0 to 2 and 2 to 0 address translation for coupling processor blocks and via a micro DMA block . Lastly with respect to the horizontal direction as illustratively shown address translation units and provide 0 to 2 and 2 to 0 address translation for communication between processor blocks and via a micro DMA block .

In the vertical direction the same applies however the address translation is from to and to as provided by the various sets of address translation units. Notably processor blocks and are coupled via address translation units and and a micro DMA block . Furthermore processor blocks and are coupled via address translation units and as well as a micro DMA block . Lastly processor blocks and are coupled via address translation units and as well as a micro DMA block .

Accordingly it should be appreciated that by coupling a right side to a left side and coupling a top side with a bottom side of an MPA effectively a toroidal processing block is provided. In this block information may be provided to a central processor block which information may include tasks and data as previously described with reference to .

Although address translation units are illustratively shown in it should be appreciated that if processor block were cross coupled to processor block rather than a more directionally direct coupling to processor block it may be that no address translation would be used. Furthermore it should be appreciated for example that if processor block were cross coupled to processor block rather than processor block it may be that no address translation would be used. Thus it should be appreciated that the right side and left side as well as top and bottom sides may be cross connected and providing that the number of connections on each side is even address translation may be avoided. Alternatively a combination of address translation and no address translation namely cross connecting and no cross connecting may be implemented. Moreover it may be that only top and bottom sides or only right and left sides of an MPA are coupled to one another to provide a tubular processor structure. Furthermore it may be that top and right sides or only bottom and left sides or any combination thereof of an MPA are coupled to one another to provide a processor structure. Thus while examples of two dimensional and three dimensional mesh or array processing architectures have been described it should be appreciated that other types of architectures that are known may be used such as H tree butterfly and pyramid architectures among other known types of architectures.

It should be appreciated that the dynamic signature of an MPA as described herein is very different from a conventional dynamic signature of arrayed processing. Rather than multi port expansion for having a central memory shared by multiple processors at a same time dual ported memories are implemented as a distributed memory. Thus it should be appreciated that in contrast to a conventional shared memory system the distributed shared memory system as described herein for a micro DMA MPA architecture may have all dual ported buffers active at the same time. Notably the distributed memory in the micro DMA MPA architecture is not one of a memory hierarchy other than to the extent that a processor of an MPA may be configured as a scatter gather server processor.

It should be noted that the use of Application Specific Modular Block ASMBL FPGAs from Xilinx may be an efficient basis for a micro DMA based MPA implementation. It should be appreciated that the degree to which processor blocks may be tiled and thus swapped or instantiated on a column by column basis may facilitate implementation in a columnar FPGA. Furthermore it should be appreciated that embedded processors may be considered ASMBL blocks for tiling an FPGA to provide a micro DMA based MPA. Notably the columns of BRAMs of a columnar architected FPGA likewise facilitate implementation of a micro DMA based MPA.

While the foregoing describes exemplary embodiment s in accordance with one or more aspects of the invention other and further embodiment s in accordance with the one or more aspects of the invention may be devised without departing from the scope thereof which is determined by the claim s that follow and equivalents thereof. Claim s listing steps do not imply any order of the steps. Trademarks are the property of their respective owners.

