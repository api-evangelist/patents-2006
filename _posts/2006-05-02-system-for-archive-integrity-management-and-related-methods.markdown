---

title: System for archive integrity management and related methods
abstract: A system for archive integrity management and related methods are disclosed. The invention includes one or more integrity manager applications, each of which monitor the integrity of an aspect of a data archive. Some integrity manager applications monitor the integrity of processes executed by the archive system, and other integrity manager applications monitor the integrity of communication paths in the archive system. A file input integrity manager application monitors the integrity of a plurality of processes associated with storing a new data file in the archive. A business content integrity manager application determines what documents are required for a transaction and monitors whether all of the required documents have been received by the archive system. Further, an event integrity manager application executes predetermined events triggered by characteristics of documents stored in the archive system and ensures that all events have been properly executed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07617261&OS=07617261&RS=07617261
owner: JP Morgan Chase Bank
number: 07617261
owner_city: New York
owner_country: US
publication_date: 20060502
---
This application is a continuation of U.S. patent application Ser. No. 10 912 819 filed on Aug. 6 2004 now U.S. Pat. No. 7 069 278 currently allowed which claims the benefit of U.S. Provisional Application No. 60 493 981 filed Aug. 8 2003. The entire disclosures of both applications are hereby incorporated herein by reference.

This invention relates to the field of data archiving systems and more specifically to ensuring the integrity of archive system operation. In particular the archive system according to the present invention ensures the integrity of file transfer data migration data destruction data retrieval and data input processes. The inventive archive system also ensures the integrity of communication paths and data retrieval paths. Further this invention discloses solutions for identifying necessary documents for predetermined transaction types and ensuring that all documents associated with an instance of a transaction type have been received. Additionally this invention reveals solutions for scheduling and executing events triggered by characteristics of the documents stored in an archive system according to the invention.

Digital archives are central information repositories often used by large corporations for storing or backing up critical business documents for extended periods. Because these archived digital documents support essential business operations it is imperative that their content be accurately maintained. Conventional schemes attempt to protect against corruption of data by performing a data integrity check at the point where data is received by the archive system. For instance when a data file is transferred to the archive system a cyclic redundancy check CRC may be performed to ensure that the file was received by the archive system successfully.

However errors may occur in the archive system at many other places in the archive system besides at the input interface and not all errors are data transfer errors. While a CRC may provide information about one type of error occurring at one point in the archive system it provides little or no information about non file transfer errors errors located at different points in the archive system or why errors occur. For instance an error may not have occurred at an input interface but may have occurred while storing the file to a storage medium. Further a CRC may detect an error that occurs at an input interface but does not detect what may be the cause of the error. Additionally a CRC fails to detect non file transfer errors such as an error that may occur when a document scheduled for destruction fails to be destroyed.

Because data integrity is of utmost importance in an archive system a need exists in the art for a comprehensive solution that ensures the integrity of all processes performed by an archive system.

This problem is addressed and a technical solution achieved in the art by a system for archive integrity management and related methods. The system includes one or more integrity manager applications each of which monitor the integrity of an aspect of the archive. Some integrity manager applications monitor the integrity of processes executed by the archive system such as file transfer document migration document destruction and document retrieval processes. Other integrity manager applications monitor the integrity of communication paths in the archive system such as communication lines and the document retrieval path. A file input integrity manager application monitors the integrity of a plurality of processes associated with storing a new data file in the archive. A business content integrity manager application determines which documents are required for a transaction and monitors whether all of the required documents have been received by the archive system. Further an event integrity manager application executes predetermined events triggered by characteristics of documents stored in the archive system and ensures that all events have been properly executed.

By monitoring the integrity of a wide range of aspects of an archive system the goal of ensuring complete data integrity in the archive system is thoroughly fulfilled.

The archive management system according to the present invention ensures that a data archive is functioning properly by monitoring a variety of different aspects of the operation of the data archive. By monitoring these different aspects more details about an error may be compiled such as the type of error that occurred where the error occurred and why it occurred.

Each box shown within the data archive system represents a computer program or application that instructs a computer to perform the functions associated with the box. Although shown separately one skilled in the art will appreciate that the applications may be implemented by a single program. Further although the archiving locations and the archive integrity system are depicted separately they may be integrated. For example the archive integrity system may be implemented using a single computer program operated on a single computer at each of the archiving locations where each computer includes a portion of the archive F. Alternatively the archive integrity system may be operated on a computer separate from computers executing the applications controlling archiving locations . In this situation the computer executing the archive integrity system may monitor operation of the computers executing the applications controlling the archiving locations remotely. Accordingly one skilled in the art will appreciate that the invention is not limited to the computer arrangement illustrated herein.

The archiving locations are shown in two parts archiving location A and archiving location B to illustrate that a single data archive may include one or more separate archiving locations. Each of the archiving locations include a portion of the total storage capacity of the single data archive. In the illustration of two archive portions F are shown that together make up the single data archive.

Further archiving location A and archiving location B may together represent a primary archive. Although not shown in one or more secondary archives having a structure the same as or similar to archiving locations A and B may also be used for redundancy and enhanced disaster protection. For example an archiving location AA and BB may exist which mirror or back up the contents of archiving locations A and B respectively.

The manner in which the archiving locations receive store and retrieve a data file will now be described. Customer site represents a customer location that has files to be archived. Some of these files may already be in a computer readable format such as in an electronic document format. Files that are not in a computer readable format such as a paper file are converted into a computer readable format by any data capture system known in the art such as a scanner. Although capturing is shown as occurring at a remote customer site one skilled in the art will appreciate that the invention is not limited to such an arrangement.

Once all of the files queued for archiving have been converted into a computer readable format they are transmitted to the data archive system using a File Transfer Agent FTA A. The customer site is communicatively connected to the archiving locations via a network which may include the Internet an intranet a virtual private network VPN a wide area network WAN or some other network connection known in the art. The File Transfer Agent A transfers the files by communicating via the network with a File Transfer Manager application FTM C of the archive system . The FTM C acts as an input interface to the a data archive system .

The FTA A can either be a generic industry product such as file transfer protocol FTP or a custom product for added file transfer integrity control. The FTA A includes logic instructing it to send files to a backup FTM C archiving location B instead of A for example if it cannot reach the default FTM C after several transmission attempts. In situations where a failed attempt occurs the FTA A stores information pertaining to the failed attempt in a local log file. This local log file is transmitted to the FTM C during the next successful transmission attempt.

The FTM C acts as a control server to the FTA A in managing the file transfer process. Prior to file transmission the FTM C authenticates the FTA A by verifying an ID and password. After authentication incoming files are stored in one or more storage locations sub directories assigned to the customer. These sub directories may be local to the FTM C archiving location A for example or remote archiving location B for example . The FTM C uses one or more error detection techniques such as a Cyclic Redundancy Check CRC to verify that the files are being transferred accurately. Files may be transferred in fixed size blocks to facilitate retransmission in the case of an error. The FTM C also collects and logs file transfer operation audit trails for downstream process monitoring including communication problems between the FTA A and the FTM C. As will be discussed the transmission log C in maintained by the FTM C is used by the File Transfer Integrity Manager H.

After the FTM C stores the incoming files into the appropriate sub directories one or more Routing and Distribution Manager applications RDM D located at each archiving location monitor the sub directories for new files. The RDMs may monitor the sub directories asynchronously according to their own time based polling scheme. When a new file is located in one of the sub directories an RDM D distributes the file to an Archive Loading Manager application ALM E responsible for adding the file to the archive. Multiple ALMs E may be located at each archiving location . However according to an exemplary embodiment each incoming file is serviced by a single ALM E.

Each ALM E has a queue to which the RDMs D add incoming files. The ALMs E may process their queues in a sequential manner and may add the files to local or remote archives F. Every time a file is added to the archive F by an ALM E the file is validated to ensure that it has been accurately stored such as by performing a CRC or a bitwise or other content comparison. When an incoming file to be stored is a computer generated report file it is parsed and indexed based upon pre defined indexing rules. Example indexing rules in this situation may include identifying the locations of the report title report date and section and page breaks. Other file types besides report files may also be indexed to identify the locations of titles section breaks page breaks or other document characteristics. Once indexed a document index database is updated with such information. The file itself is stored on one or more storage media such as a magnetic disk optical disk or magnetic tape of the archive F. The ALM E then updates an operation log file E as an audit trail that facilitates process integrity management and performance measurement.

An Archive Manager application AM F manages and maintains the index databases and the document storage on the various storage media making up the data archive F. Prior to the end of the useful lifetime of the storage media the AM F manages the migration from old storage media to new storage media. Such media migration may be initiated due to degradation of the physical or magnetic property of the storage media elapsing of the manufacturer s stated useful lifetime of the storage media or the storage media becoming obsolete. When the AM F performs a media migration it stores the details of such migration in a migration log file J as an audit trail discussed below with reference to . The AM F also conducts document destruction e.g. upon the end of a defined retention period.

Document retrieval from the archive is managed by a Retrieval and Output Distribution Manager application RODM G. The RODM G is responsible for outputting copies of selected files from the archive F. The RODM G validates the retrieved files to ensure that they are identical to the corresponding file stored in the archive F and updates an operation log file L as an audit trail.

Having described the process of capturing a document for archiving storing it in the archive F and retrieving it therefrom the archive integrity system will now be described. The File Transfer Integrity Manager application FTIM H of the archive integrity system will be described first with reference to . The FTIM H controls the processes and data objects shown in whose reference symbols begin with the letter C. The FTIM H monitors operation of the FTM C and validates the integrity of the document files C received from the FTA A.

Controlled by the FTIM H the FTM C receives document files C and stores them in their appropriate sub directories as discussed with reference to . For each document transfer or attempted transfer the FTM C updates the transmission log C as an audit trail. The transmission log C is frequently checked for new entries by a capture integrity control information process C. For each new entry in the transmission log C the process C retrieves an identifier for the FTA A and the FTM C involved in the file transfer associated with the entry a customer identifier a date and time of transfer initiation and completion the incoming file name the incoming file size in bytes the staging sub directory path name where the file was stored and the status of the transfer such as success or an error code. This information is then stored in a file transfer integrity database C. It should be noted that the term database is used to refer to a stored set of related data. For instance the file transfer integrity database C may comprise a relational database system supporting SQL commands or simply a text file comprising a series of records.

As a comparison to the data retrieved and stored by the process C another integrity control module C receives information from a Customer Relationship Management system CRM B. The CRM B may include a Web based input form that allows the customer to enter an expected input file transmission schedule for each FTA A. The expected input schedules may be manually generated generated from an automated system or created from the file transfer integrity database C using historical file transfer frequency patterns.

Information contained in the expected input schedules may include an identifier for the FTA A used for the transmission identifiers for the primary and secondary FTMs C the transmission frequency such as ad hoc hourly daily weekly etc. along with time of day day of week etc. a frequency predictability rating and information regarding the files to be transmitted such as name of file size of file etc. The predictability rating indicates an expected variance between the scheduled transmission frequency and the actual transmission frequency.

The expected schedule information is received by the process C and stored in the file transfer integrity database C. Any differences between the expected schedule information and the information from the transmission log C can result in a notification signal or an alert being transmitted via an output interface which may be connected to a user interface Z. In the exemplary embodiment the user interface is an Integrity Manager Dashboard Z described in detail below with reference to .

Turning now to the Document Migration Integrity Manager application DMIM J of will be described. The DMIM J controls the processes and data objects shown in whose reference symbols begin with the letter J. The DMIM J verifies that any migration event performed by the Archive Manager F occurs successfully. When it is determined that a document migration is to occur a migration schedule J is created. The migration schedule J may include an identification of the storage medium to be migrated old storage medium a file name and byte count for each file on the old storage medium the type of migration e.g. physical media migration and or file reformatting and other details about the migration. If the migration is a file format change then the original and target file types are specified such as TIFF 2.0 to TIFF 6.0.

The Archive Manager F accesses the migration schedule J and the archive storage system F to execute the migration event. Details of the event are stored in the migration log file J as an audit trail and to facilitate performance measurement. Each migration event is recorded in the log file J with information that may include an identification of the old storage medium an identification of the new storage medium a file name and byte count for each file on the new storage medium and a date and time that the migration was completed.

After the Archive Manager F completes a migration the DMIM J reconciles the migration schedule J and the migration log J as shown at J. The processing at J ensures that all storage media targeted for migration were migrated and that all document files targeted for migration were migrated successfully. Successful migration of document files may be verified by comparing the file sizes both before and after the migration if the file format remained the same.

The results from this reconcilement process are stored on the Media Migration Integrity Database J to support reporting. The information stored in the database J may include the information stored in the schedule J reconciled with the log J a migration status such as success or an error code and whether additional post migration quality assurance tasks J have been completed.

Additional post migration quality assurance tasks may include comparisons of document objects before and after migration. To perform these comparisons the quality assurance tasks interface with the archive storage system F. Such comparisons may include the extraction of plain text from each object both before and after the migration and then matching the plain text. Another comparison method may be the creation of bit maps for each object both before and after the migration and then matching the bit maps. Yet another comparison method be a side by side document display with a manual visual inspection.

Any number of methods or combinations of methods may be implemented at J to ensure that the migration was successfully performed. Migration quality assurance J may be based on a random sample of the migrated document objects or on all migration document objects. Results from the migration quality assurance process J are added to the Media Migration Integrity Database J. Any quality assurance failures either from the reconciliation process J or the quality assurance process J may result in a notification signal or an alert being transmitted via an output interface which may be connected to a user interface Z to notify an operator.

Turning now to the Document Destruction Integrity Manager application DDIM K from will be described. The DDIM K controls the processes and data objects shown in whose reference symbols begin with the letter K. The DDIM K ensures that documents scheduled for deletion are properly deleted.

Based on predetermined purge rules specifying how long documents of particular types should be retained prior to destruction a document retention schedule K is generated. Examples of purge rules include retaining images of bank checks for seven years from the date of check presentment or retaining loan documentation for a predetermined number of years from the date the loan is paid off. Examples of how the schedule K may be generated include using information associated with the storage location of the files such as all files in directory X will be retained until date Y an Enterprise Record Management system such as IBM DB2 CM Record Manager or an external system such as an input file of recently paid off loans.

The Archive Manager F interfaces with the schedule K and the archive storage system F when performing document destruction. Document destruction may be performed by deleting the index record s on an indexing database and the corresponding document object typically by writing over the storage area with data e.g. zeroes deleting only the index record s on the index database with additional control measures to prevent direct reading of the document objects or deleting the index records on the indexing database and physically destroying the storage media. For physical media destruction the operator may also have to sign on to the system to confirm execution of the media destruction event.

The Archive Manager F also records details of each document destruction event to a destruction log K. Such details may include an identification of the storage system involved the type of destruction performed as discussed above an identifier of the particular storage medium involved the name of the document destroyed the date and time of the destruction the status of the destruction e.g. successful or an error code and an identifier of the operator involved.

Any differences between the document retention schedule K and the destruction log K are reconciled as shown at K. In particular the data in the destruction log K is verified to ensure that document destruction has occurred according to the schedule K. The results of the reconcilement are stored in a document destruction integrity database K. Any differences between the schedule K and the log K may be communicated to an operator in the form of a notification signal or an alert displayed on a user interface Z.

Turning now to the Document Retrieval and Distribution Integrity Manager application DRDIM L from will be described. The DRDIM L controls the processes and data objects shown in whose reference symbols begin with the letter L. The DRDIM L ensures that documents retrieved from the archive storage system F via the Retrieval and Output Distribution Manager application G are retrieved properly.

A broad range of document retrieval applications G provide an end user with accessibility to documents stored in the archive storage system F. Such retrieval applications may include Internet and intranet Web browser applications for ad hoc document retrievals document workflow applications bulk retrieval applications that request document objects in large numbers that are delivered via bulk printing transmissions CD ROM DVD or magnetic tapes or other business applications that integrate digital document contents from the archive storage system F via Application Programming Interfaces APIs and Web Services such as XML SOAP WSDL and UDDI. Depending upon the storage medium on which a requested document is located a request may be satisfied within sub seconds seconds minutes or hours.

Each incoming request is recorded in a document request log L at the time of the request. The information recorded for each request may include an identifier of the retrieval application from which the request was received a date and time that the retrieval process is initiated an assigned unique retrieval tracking identifier an identifier of the archive storage subsystem that stores the requested file or files a customer identifier a user identifier an identifier of the document requested and whether the request indicates that the document format should be converted such as converting an AFP format to PDF format.

Upon execution of the retrieval by the Retrieval and Output Distribution Manager application G the document retrieval event is recorded on a Document Retrieval Log L as an audit trail. The information recorded for each retrieval event may include the identifier of the retrieval application that retrieved the requested document s a date and time that the retrieval process completed the assigned unique retrieval tracking identifier the identifier of the archive storage subsystem that stores the requested file or files the customer identifier an identifier of the document requested and a retrieval status such as successful or an error code.

The contents of the document request log L and the document retrieval log L are reconciled to ensure retrieval process integrity as shown at L. In particular each request record in the request log L is combined with each retrieval even L and stored in a document retrieval integrity database L. This combination process may execute on a periodic basis.

The combined data in the database L is scanned to verify the integrity of the retrieval process. For instance it is verified that each request in the request log L has a counterpart record having the same retrieval tracking identifier in the retrieval log L. Also a successful retrieval status for each retrieval event is verified. Further the time between retrieval initiation and retrieval completion is calculated to ensure that it is below a threshold level. If a request record is missing a counterpart retrieval record if any retrieval events failed or if any retrieval event took longer than expected an alert may be communicated to an operator via user interface Z.

Turning now to the Communication Line Integrity Manager application CLIM M from will be described. The CLIM M controls the processes and data objects shown in whose reference symbols begin with the letter M. Because one embodiment of the archive system according to the present invention involves many geographically distributed hardware and software components communicating via complex networks of routers and communication lines the CLIM M ensures that communication between these components occurs properly.

Communication Integrity Test Control Profile database M stores information regarding the communication tests to be performed. For each test the database M specifies between which points in the archive system is the test to be performed e.g. from point A to point B the type of test to be performed e.g. network point to point pings and the timing and frequency of test execution.

To perform a test from point A to point B a Line Test Control Message Generator LTCMG M generates a Communication Test Control Message M based on instructions from the database M. The control message M is transmitted to a Remote Line Test Control Module RLTCM M which is located at the test starting point i.e. point A. The control message M instructs the RLTCM M as to the test particulars which may include addresses the test starting and ending points e.g. IP addresses of the RLTCM M at point A and the component at point B the type of test to be performed e.g. ping and a location identifier for a Communication Line Test Result Log M to which test results are to be recorded. The control message M may also include other information such as the date and time the control message M was created a unique communication test control identifier for use in the log M and an identifier of the LTCMG M that generated the control message M. The LTCMG M records information pertaining to each generated control message M in a communication line test message log M. The information recorded in the log M may be the same as that contained within the message M.

The RLTCM M initiates a test upon receipt of the control message M. When the control message M is received the RLTCM M transmits a line test signal such as a ping to the test ending point point B in this example. The results of the test are stored in the Communication Line Test Result Log M. The information stored in the log M may include the date and time of test completion the unique communication test control identifier the identifier of the associated LTCMG M the test starting and ending points the test status such as success or an error code and for each router hop or line segment involved an address such as an IP address and a signal delay in milliseconds.

The data in the test result log M and the test message log M are reconciled or matched and combined at M to ensure integrity of the tested communication lines. This matching process may occur periodically. The combined records are then stored in a communication integrity manager database M.

The matching process at M verifies that a test occurred for each control message M generated by matching communication test control identifiers in each log M and the test message log M. Further it is determined whether each test was successful by checking the test statuses. Also it is determined whether any unacceptable test durations occurred by checking the signal delay fields from the test result log M. If any of these determinations indicate a test failure an alert may be communicated to an operator via a user interface Z.

Turning now to the Retrieval Path Integrity Manager application N RPIM from will be described. The RPIM N controls the processes and data objects shown in whose reference symbols begin with the letter N. The RPIM N ensures that the communication paths in the document retrieval path are working properly. The software components in N and N N may be installed at each archiving location in for example .

The Get Test Document Hitlist application N compiles a set of document identifiers e.g. document names and locations that will be used to test the retrieval path. Advantageously the set of document identifiers includes documents stored on various types of media that require different retrieval techniques to more thoroughly test all aspects of document retrieval. For instance a magnetic disk a magnetic tape and magneto optical disks are all accessed differently. Also it is advantageous to select a document that is located in cache memory to test another aspect of document retrieval. The compiled set of test documents is stored in a Test Hitlist file N.

Using the data in the hitlist file N several tests N N are performed. Tests N and N test the retrieval path with requests initiated from the Internet and tests N and N test the retrieval path with a requests initiated from an intranet. Therefore RPIM N tests the retrieval path by transmitting requests from different sources and by requesting documents stored on different types of media. One skilled in the art will appreciate that tests using requests initiated from other locations besides the Internet or an intranet may be used without departing from the scope of the invention. Further although tests N N and N N are shown in a particular sequential order they may occur in another order or may occur in parallel.

Test N logs into the archive system via the Internet at a pre defined frequency and determines whether the log ins were successful. Test N requests from the Internet the documents in the hitlist file N at a predetermined frequency. It determines whether the requests were properly fulfilled. Test N logs into the archive system via an intranet at a pre defined frequency and determines whether the log ins were successful. And test N requests from the Internet the documents in the hitlist file N at a predetermined frequency. Test N also determines whether the requests were properly fulfilled.

The results from each of the tests N N are stored in a Retrieval Health Check Result Database N. Information stored for each test may include the type of the test performed an identifier of the application that performed the test the date and time the test was initiated an identifier of the particular Retrieval and Output Distribution Manager application G that processed the request the test duration and the test status such as successful or an error code. If the test duration exceeds some predetermined threshold value or if the test status indicates a failure an alert may be communicated to an operator via user interface Z.

Turning now to the File Input Integrity Manager application FIIM P from will be described. The FIIM P controls the processes and data objects shown in whose reference symbols begin with the letter N. The FIIM P manages the end to end tracking monitoring and reconcilement of daily input files. It ensures that all input files are loaded to the targeted archives that operation staff are aware of loading exceptions and take the appropriate corrective actions and that customer agreed to performance rules are being met.

As discussed with reference to the File Transfer Manager C stores incoming document files C in pre defined staging sub directories and records details of the file reception events in transmission log C. The Routing and Distribution Manager RDM D takes the document input files C and distributes them to the appropriate Archive Loading Managers E. As the RDM D distributes the files it records the distribution events in distribution log D. Information stored in the distribution log D may include an identifier of the RDM D an identifier of the customer to which the file belongs the date and time the RDM D reviewed or registered the file from the staging sub directory the date and time that the RDM D distributed the file the staging sub directory path name the file name and size the target archive location and name the target landing zone name whether the file is for the primary or a back up archive and the status of the distribution such as successful or an error code. If a file is marked for loading into both a primary and one or more back up archives the distribution log D will contain multiple tracking records for the same file.

When an Archive Loading Manager E receives a file from an RDM D it stores it into the appropriate location in the archive storage system F and records the event in an archiving loading log E. The information loaded into the archive loading log E may include an identifier of the customer to which the file belongs the archive location name and directory the file name and size the date and time that loading began the duration of the loading and the status of the loading such as successful or an error code. If a file is loaded into both a primary and one or more back up archives the archiving loading log E contains multiple tracking records for the same file.

The Integrity Manager Database Update application P reconciles and combines the data in the transmission log C the distribution log D and the archive loading log E and loads the combined records into the end to end input file tracking database P to support reporting. The application P reconciles the logs C D E using the following rules. For each input file as recorded on log C there must be at least one record on log D indicating that every input file was distributed. For each record on log D there must be one matching tracking record on log E indicating that every distributed input file is loaded to an archive. And all tracking records for a file must have the same size. Any violations of these rules may be communicated as an alarm to an operator via user interface z.

Besides reconciling the log files C D E FIIM P ensures that customer agreed to performance targets are being met via a service level agreement SLA control database P. An example customer agreed to performance targets may specify that by 7 00 PM Easter Standard Time all invoices must be loaded into the primary archive. Such rules are stored in the SLA Control Database P. Table I below illustrates the format of the database P according to an embodiment of the invention.

The data in Table I illustrates performance targets indicating when particular files should be loaded into primary and secondary archives. The three columns to the left indicate warning levels that arise when loading extends beyond the target time period by a certain amount of time. For instance using row two of Table I if the invoices are not loaded until 18 45 EST an operator is alerted via user interface Z with an orange color coded signal indicating a severity level of two. The FIIM P accesses the data in the database P to determine the amount of time it is taking to load files and compares them to the target performance levels in the database P.

Transaction types and the documents associated with each transaction type may be input or modified via a user interface Q such as an on line form. The changes from user interface Q are processed by a Document Tracking Rulebook Maintenance application Q which incorporates the changes into a Document Tracking Rulebook database Q. The database Q stores all of the transaction types and the documents associated with each transaction type. The information stored in the database Q may include for each transaction type a location in the archive reserved for documents associated with the transaction type an identification of what customer or customers the transaction type is or are associated with and the documents including their types required for the transaction type.

Once the transaction types have been arranged a customer requests a new instance of a transaction type at Q. Each instance may be assigned an account number and multiple instances may be requested via an account list. The request for a new instance is processed at Q and with access to the data in the rulebook Q an expected document list Q is generated for each instance or account. The Document Tracking Database Update application Q stores the new instance s with expected document list s in the document tracking database Q. The database Q therefore stores all instances of transaction types and their expected document lists.

Document index files Q are monitored to determine whether expected documents have been received. Index files may be transmitted to the BCIM Q by having the data capture system at the customer site send the index files directly by having the Routing and Distribution Manager D send the index files or by having an extraction program extract the index records for newly loaded documents from the archive storage system F. The index files are parsed to identify the types of each input document and the instance or account to which each document is associated. This parsing process may be aided by accessing the rulebook Q. Once the document types and accounts have been identified the document tracking database Q is updated.

Reports based upon the database Q are generated by a reporting application Q. The reports may be generated based upon reporting rules Q. Examples of reporting rules may include listing all accounts with at least two missing documents and a last document captured date before date X. Another rule may be to list all accounts that are missing documents of a particular type. Such reports may be displayed with a user interface Z.

A new business event may be input as a message R into the BEIM R by an external application as one or more files or XML messages. Alternatively a new business event message R may be input via an online form to facilitate ad hoc event setup and maintenance. The business event message R may include an assigned event tracking identifier a message originator identifier and name a customer identifier and archive location and identifier an archive application or folder name an action code action triggers such as frequency timing or other trigger conditions and detailed instructions regarding execution of the event.

An input validate and update application R receives each new business event message R. The application R validates that the message R is coming from an authorized customer that the message R has proper structure and contents and that the event type or action code is an acceptable event type according to a business event rulebook database R. The database R stores information regarding all acceptable business event types such as automatic email generation or an archive query to pull select files from the archive. Once the application R validates the message R it stores the message R in the business event tracking database R which stores all business events to be executed.

One or more business event execution manager applications R monitor the business event tracking database R and execute business events when event action trigger conditions are met. The execution manager applications R may interface with other applications that ultimately perform execution of the event. In this situation the execution manager applications R instruct the other applications to execute the business events. For instance a report generation application may be instructed by an execution manager R to execute all report business events.

Upon execution of a business event the associated execution manager R creates a record in the business event execution log R. The record may include an identifier of the business event execution manager R associated with the event execution the date and time of execution of the event the event tracking identifier the associated message originator identifier and name the customer identifier the action code and event execution status such as successful or an error code.

A reconcile business events application R combines and reconciles the records between the business event tracking database R and business event execution log R to ensure that all planned events were successfully executed. The combined records are stored in a business event integrity database R. Any discrepancies between the database R and the log R may be communicated as an alert to an operator via user interface Z.

According to one embodiment of the invention the records in each of the databases discussed above are stored in the archive storage system F. For instance the file transfer integrity database C document migration integrity database J document destruction database K document retrieval database L communication integrity manager database M retrieval health check result database N end to end input file tracking database P document tracking database Q and business event integrity database R may all be archived to offer a long term audit trail of all integrity manager processes and events.

For instance if the File Transfer Integrity Manager H detects that a file scheduled to be transferred was not received section associated with the File Transfer Integrity Manager H may have a yellow color. If two scheduled files were not received section may be orange. If three or more scheduled files were not received section may be red. The same or a similar strategy may be used for the sections of the user interface. Advantageously an operator may customize the threshold levels associated with the different colors for each section .

According to an embodiment of the invention the operator may select a section e.g. with a mouse click known in the art and have displayed any error messages pertaining to the system associated with the selected section. For instance if the operator selects section when it is yellow the user interface displays information pertaining to the particular file that was not transferred or not transferred successfully.

Also upon selecting one of the sections the operator may be displayed a summary of the statistics of the associated system e.g. number of file transfers for the last X hours when section is selected detailed statistics such as the contents of the file transfer integrity database C when section is selected historical summary and detailed statistics for trend analysis.

It is to be understood that the above described embodiment is merely illustrative of the present invention and that many variations of the above described embodiment can be devised by one skilled in the art without departing from the scope of the invention. It is therefore intended that such variations be included within the scope of the following claims and their equivalents.

