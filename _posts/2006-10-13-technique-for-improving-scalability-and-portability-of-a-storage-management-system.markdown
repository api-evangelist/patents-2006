---

title: Technique for improving scalability and portability of a storage management system
abstract: A technique for improving scalability and portability of a storage management system is disclosed. In one particular exemplary embodiment, the technique may be realized as a storage management system operatively coupled to a storage system. The storage management system may comprise a plurality of processor modules, wherein each processor module is capable of intercepting write commands directed to the storage system, backing up data associated with the write commands, and generating metadata having timestamps for the backup data. The storage management system may also comprise one or more indexing modules that create one or more indexing tables for the backup data based on the metadata, wherein the one or more indexing modules are in communication with the processor modules and the storage system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07634497&OS=07634497&RS=07634497
owner: Symantec Corporation
number: 07634497
owner_city: Cupertino
owner_country: US
publication_date: 20061013
---
This patent application claims priority to U.S. Provisional Patent Application Nos. 60 726 186 60 726 187 60 726 192 and 60 726 193 all of which are filed on Oct. 14 2005. Each of these provisional applications is hereby incorporated by reference herein in its entirety.

This patent application is related to U.S. patent application Ser. No. 10 924 652 filed Aug. 24 2004 which is a continuation in part of U.S. patent application Ser. No. 10 668 833 filed Sep. 23 2003 each of which is hereby incorporated by reference herein in its entirety.

This patent application is also related to three co pending patent applications respectively entitled Techniques for Time Dependent Storage Management with a Portable Application Programming Interface Technique for Remapping Data in a Storage Management System and Technique for Timeline Compression in a Data Store filed concurrently herewith each of which is incorporated herein in its entirety.

The present disclosure relates generally to data storage and more particularly to a technique for improving scalability and portability of a storage management system.

In related U.S. patent application Ser. No. 10 924 652 and U.S. patent application Ser. No. 10 668 833 a time dependent data storage and recovery technique is disclosed. Embodiments of such a technique provide a solution for continuous data protection CDP wherein write commands directed to a storage system or data store are intercepted by a storage management system having a current store and a time store.

With a current copy of the digital content of the storage system in the current store and the historical records in the time store the storage management system adds a new dimension i.e. time to the storage system . Assuming the storage management system has been operatively coupled to the storage system since a past time the storage management system may quickly and accurately restore any addressable content in the storage system to any point in time between the past time and a present time.

There are a wide variety of implementation options for the above described CDP method. shows one exemplary implementation wherein a storage management system is operatively coupled to both a host and a storage system . The storage management system may or may not be positioned in a critical data path between the host and the storage system . If it is not in the critical data path the storage management system may be switched into a capture mode whenever it is desirable for it to intercept communications between the host and the storage system . The storage management system is typically implemented with one or more processor modules wherein each processor module performs a series of operations such as for example data interception data replication record creation and metadata indexing.

However the above described modularization of a storage management system is only a first step towards scalability. A number of limitations still restrict the environments in which the storage management system may be deployed. There are also platform specific restrictions that limit the portability of the processor modules. In addition the current architecture of the storage management system cannot take full advantage of emerging intelligent switch techniques.

In view of the foregoing it would be desirable to provide a storage management architecture which overcomes the above described inadequacies and shortcomings.

A technique for improving scalability and portability of a storage management system is disclosed. In one particular exemplary embodiment the technique may be realized as a storage management system operatively coupled to a storage system. The storage management system may comprise a plurality of processor modules wherein each processor module is capable of intercepting write commands directed to the storage system backing up data associated with the write commands and generating metadata having timestamps for the backup data. The storage management system may also comprise one or more indexing modules that create one or more indexing tables for the backup data based on the metadata wherein the one or more indexing modules are in communication with the processor modules and the storage system.

In accordance with other aspects of this particular exemplary embodiment the number of the plurality of processor modules may be scalable based on a desired capacity of the storage management system.

In accordance with further aspects of this particular exemplary embodiment the plurality of processor modules may be configured with fault tolerant redundancy.

In accordance with additional aspects of this particular exemplary embodiment the plurality of processor modules may be coupled to the storage system via fiber connections.

In accordance with another aspect of this particular exemplary embodiment each of the plurality of processor modules may comprise at least one target interface and at least one initiator interface.

In accordance with yet another aspect of this particular exemplary embodiment the plurality of processor modules may be in communication with one another.

In accordance with still another aspect of this particular exemplary embodiment the number of the one or more indexing modules in the blade farm may be scalable based on the number of processor modules supported by the blade farm.

In accordance with a further aspect of this particular exemplary embodiment the one or more indexing modules may have access to one or more metadata storage devices in the storage system via fiber connections.

In accordance with a yet further aspect of this particular exemplary embodiment the one or more indexing modules may communicate with the plurality of processor modules via one or more internal networks.

In accordance with a still further aspect of this particular exemplary embodiment the one or more indexing modules may communicate with the plurality of processor modules through a plurality of agents and proxies.

In accordance with another aspect of this particular exemplary embodiment the one or more indexing modules may further perform one or more functions selected from a group consisting of blade configuration remap engine global database production restore timeline compression indexing database interface metadata space management and vendor multipathing.

In another particular exemplary embodiment the techniques may be realized as a method for improving portability and scalability of a storage management system operatively coupled to a storage system. The method may comprise coupling a plurality of processor modules to the storage system wherein each processor module is capable of intercepting write commands directed to the storage system backing up data associated with the write commands and generating metadata having timestamps for the backup data. The method may also comprise coupling a blade farm having one or more indexing modules to the storage system. The method may further comprise causing the blade farm to communicate with the plurality of processor modules via one or more internal networks wherein the one or more indexing modules create one or more indexing tables for the backup data based on the metadata.

In yet another particular exemplary embodiment the techniques may be realized as at least one signal embodied in at least one carrier wave for transmitting a computer program of instructions configured to be readable by at least one processor for instructing the at least one processor to execute a computer process for performing the method as recited above.

In still another particular exemplary embodiment the techniques may be realized as at least one processor readable carrier for storing a computer program of instructions configured to be readable by at least one processor for instructing the at least one processor to execute a computer process for performing the method as recited above.

In a further particular exemplary embodiment the techniques may be realized as a method for improving portability and scalability of a storage management system operatively coupled to a storage system. The method may comprise intercepting at a plurality of processor modules write commands directed to the storage system. The method may also comprise backing up data associated with the write commands. The method may further comprise generating metadata having timestamps for the backup data. The method may additionally comprise creating at one or more indexing modules one or more indexing tables for the backup data based on the metadata wherein the one or more indexing modules are in communication with the processor modules and the storage system.

The present disclosure will now be described in more detail with reference to exemplary embodiments thereof as shown in the accompanying drawings. While the present disclosure is described below with reference to exemplary embodiments it should be understood that the present disclosure is not limited thereto. Those of ordinary skill in the art having access to the teachings herein will recognize additional implementations modifications and embodiments as well as other fields of use which are within the scope of the present disclosure as described herein and with respect to which the present disclosure may be of significant utility.

As used herein backup data refers generally to data that have been recorded and or organized with a purpose of restoring or recovering digital content of a storage system. Copy on write data or COW data refers to substantive data e.g. new data to be written or old data to be overwritten in response to a write command that have been recorded in a copy on write operation. New data to be written in response to a write command are sometimes referred to as after image data or after image while old data to be overwritten in response to a write command are sometimes referred to as before image data or before image. 

 Metadata refers to informational data e.g. timestamps regarding the corresponding COW data in a copy on write operation. Typically one copy on write operation causes one set of COW data and corresponding metadata to be created. Despite their correlation COW data and corresponding metadata may be stored in separate storage devices or segments. In a time store COW data may be organized in one or more timestamped data chunks. 

A typical storage system may comprise one or more storage devices which may be physical virtual or logical devices or a combination thereof. According to one embodiment a storage system may comprise a storage area network SAN having one or more datasets wherein each dataset may comprise one or more nodes and wherein one or more logical units LUs may be coupled to each node. Hereinafter for ease of illustration the term storage system may refer to an entire storage system or a portion e.g. dataset node or LU thereof.

Embodiments of the present disclosure provide an improved architecture of a storage management system that is more scalable and or more portable. In functionalities related to a time store input output I O processing may be physically separated from indexing functions. I O processing may be implemented with one or more I O processing modules known as Time Store Daemon TSD blades while indexing functions may be performed by one or more indexing modules known as indexing blades. The indexing blades may be grouped into an indexing blade farm that supports one or more sets of TSD blades.

Referring to there is shown an exemplary implementation of a storage management system in accordance with an embodiment of the present disclosure. The storage management system may comprise one or more storage management appliances e.g. and that are coupled to a storage area network SAN via fiber connections e.g. and . The storage management appliance may comprise one or more TSD blades and the storage management appliance may comprise one or more TSD blades . The fiber connection may have at least two channels one for an initiator mode and the other for a target mode. The same may be true with the fiber connection . Each TSD blade may perform time store functionalities some locally and others remotely to back up digital content in the SAN . A TSD blade may be configured as a modular component on a hardware platform similar to Revivio Inc. s CPS1200 Continuous Protection System or may be embedded in an intelligent switch or some other type of hardware. It is preferable that each storage management appliance e.g. or includes at least two TSD blades to achieve fault tolerance. Each storage management appliance may be coupled for example via Ethernet connections and or and to two internal subnets Internal Subnet and Internal Subnet . The storage management appliances may also be coupled to a local area network LAN .

The storage management system may also comprise an indexing blade farm that is coupled to the SAN via fiber connections and . The indexing blade farm may comprise a plurality of indexing blades which may be in communication with metadata storage devices in the SAN via the fiber connections and . The indexing blades may also be in communication with each of the storage management appliances and via redundant connections and through Internal Subnet and Internal Subnet . With the indexing functionality physically separated from the TSD blades the indexing blade farm may support multiple storage management appliances and accommodate the scaling of the storage management appliances and or the SAN . The capacity of the storage management appliances may be scaled up or down by adding or removing TSD blades and or by increasing or decreasing the number of the storage management appliances. The capacity of the indexing blade farm may also be scaled up or down by adding or removing the indexing blades .

According to embodiments of the present disclosure the indexing blade farm may be a scalable loosely coupled set of indexing blades running a base set of indexing software components which support basic indexing storage and retrieval along with value added features such as production restore timeline compression or timeline rollup and tiered storage services. The indexing blades typically do not participate in a workload work unit configuration. Instead logical unit number LUN assignments may be handled dynamically. Agents and proxies may be responsible for heart beating connections and if a blade either TSD or indexing goes away appropriate reconfiguration may be performed with help from blade configuration managers as will be described in detail below.

Taking advantage of separate TSD and indexing blades commits of before image table inserts may be batched to optimize performance. In configurations where the indexing operations may be running on a same blade as the I O processing replication of indexing batches between blades may take place to ensure that commit batching may still take place.

According to one embodiment each indexing blade in the indexing blade farm may require fiber connections to the same set of metadata LUs. Metadata LUs may be used as raw devices utilizing a MetaData I O Manager to ensure that no two indexing blades write to the same region. In another embodiment to utilize an existing I O interface indexing data may be stored in Berkeley databases. Initially a Structured Query Language SQL database may be used for global databases.

The versatility of managing metadata LUs as an inter blade shared set of raw devices means that file systems no longer have to be consciously managed and indexing of data for current store LUs need not be restricted to blades hosting the file system. This allows current store LUN assignments to be completely dynamic with no persistent configuration requirements although workloads may still be relevant on the TSD blade.

A remap engine technique was disclosed in U.S. Provisional Application No. 60 726 192 filed on Oct. 14 2005 which is hereby incorporated herein in its entirety. The remap engine technique may further enhance the blade farm versatility. One of the goals for the remap engine may be to provide a generic interface for performing remap reads and writes that don t require the remap engine to know or maintain state about user created objects such as time images.

Having separate TSD and indexing blades may have the additional advantage of allocating more hardware resources to indexing. As such there may always be available CPU cycles for performing feature related indexing blade tasks such as for example timeline compression as disclosed in U.S. Provisional Application No. 60 726 187 filed on Oct. 14 2005 which is hereby incorporated herein in its entirety. Furthermore there may no longer be any hard restriction on the platform that the indexing components live on leaving a system designer free to explore for example 64 bit architectures blade centers up to date versions of LINUX operating system etc.

The Portable TSD APIs may support all of the external interfaces as disclosed in U.S. Provisional Application No. 60 726 193 filed on Oct. 14 2005 which is hereby incorporated herein in its entirety. Otherwise most of the current TSD implementation may remain intact with the exception that all interactions with the indexing layer are preferably made through the TSD Indexing API . Other refinements may be made to take advantage of separate indexing blades wherever possible. For example with indexing data in two places indexing operations initiated by TSD as part of an I O event chain only have to wait for the successful copy to the indexing blade instead of a database commit disk I O .

The TSD Indexing API may be designed and implemented to provide a clean separation of components in a storage management system. Using the TSD Indexing API it may be possible for TSD to interface with indexing services either locally co resident on the platform or remotely via a transport.

The Agents and Proxies may include proxies that serve as the interfaces to agents running on indexing blades. Common responsibilities of these proxies may include for example establishing and maintaining connections to required indexing blades receiving input from the TSD Indexing API converting calls to messages and providing asynchronous callback messaging. According to one embodiment one or more of the following proxies may be implemented an Allocator Proxy an Indexer Proxy and a Remap Proxy. The Allocator Proxy may be responsible for communication with an Indexing Allocator Agent to allocate time store space as required. The Allocator Proxy may also include local caching of data chunks. The Indexer Proxy may be responsible for forwarding batches of indexing requests to indexer agents running on indexing blades. In a typical operation the indexing batch may be considered complete when it has been successfully replicated to the indexing blade farm. The Remap Proxy may be responsible for forwarding requests to remap engine agent s running on indexing blades.

The Agents and Proxies may include agents that serve requests from proxies running on indexing blades. One such agent may be an I O Agent. The I O Agent may listen for batched I O requests coming from indexing blades that are currently processing production restores or timeline compression and may forward the I O requests to the appropriate TSD blade interface. The I O Agent may be responsible for tracking the status of each request and responding appropriately to the indexing blade when requests complete.

The Blade Configuration Manager may be responsible for inter blade communications discovery services and configurations. A non persistent i.e. runtime configuration of TSD blades indexing blades and indexing LUN assignments may be maintained by the Blade Configuration Manager . Through inter blade communications and coordination a self configuring infrastructure may be constructed and dynamic load balancing among the blades may be achieved.

The Global Database may run on an indexing blade decided upon by blade configuration managers. There may not be many changes to the Global Database except for changes as required for Timeline Compression and New Production Restore .

New Production Restore may be based on redesigned production restore in order to eliminate its dependency on region maps as well as to increase its efficiency.

Berkeley databases may be used for all indexing tables. For Indexing Database Interface a Berkeley database interface library may be needed to wrap the various queries that may be required. Additionally a suite of debug routines may be implemented to query the indexing data.

Vendor Multipathing Software may be relied upon to provide a level of high availability HA needed for the metadata storage.

Agents and Proxies may include subcomponents that may be quite distinct from each other each presenting a distinct set of API methods and responsible for a specific set of tasks. Primary and common responsibilities of these subcomponents may include for example sending and receiving messages to from a peer blade handling faults related to loss of communication with a peer blade registering callbacks with an interface handler for unsolicited messages and statistics gathering and reporting.

A base class may be created with common methods and data. Agents and proxies both may be derived from this base class. A brief discussion of some of the main proxies and agents follows.

An Insert Proxy and Agent subcomponent may be provided in Agents and Proxies . An Insert Proxy may receive batches of indexing requests for various slices from TSD buffer them in buffers for the individual slices and send the batch to a peer insert agent i.e. Insert Agent on a peer indexing blade . Upon receipt of the response from the peer insert agent the batch may be considered secure and the TSD callbacks completing the events may be called. According to embodiments of the present disclosure each LU may be divided into a plurality of fixed size logical partitions e.g. 16 Gigabytes GB each for ease of management and for load balancing purposes wherein each fixed size logical partition may be referred to as one slice. 

An A and B buffer may exist for each slice. When the active buffer becomes full the alternate buffer may become active and the previously active buffer may be flushed to a scratch area on disk. When a maximum BII row count is reached the Insert Agent may be directed to seal the active BII table and upon receipt of the seal response the scratch area may be freed. The scratch area may be capable of holding the full contents of the active BII table and may be needed in case of an indexing blade failure. This alleviates the onus on the Indexing Database Interface to commit rows of data while an active table is being filled.

Memory utilization on the TSD blade may be a concern and may certainly limit factors such as buffer size and slice size.

An Insert Agent may receive batches of indexing requests from a peer insert proxy i.e. Insert Proxy on a peer indexing blade and may issue inserts into the Indexing Database Interface .

A Remap Proxy and Agent subcomponent may be provided in Agents and Proxies . A Remap Agent may receive remap requests from a peer remap proxy i.e. Remap Proxy on a peer indexing blade and forward the requests to the Remap Engine . It may also forward the Remap Engine results to the peer remap proxy.

An I O Proxy subcomponent may be provided in Agents and Proxies . An I O Proxy may forward batches of I O sequences to an I O Agent running on a TSD blade. Timeline rollups and production restores may both require I O operations.

A TimeStore TS Allocation Agent subcomponent may be provided in Agents and Proxies . The TS Allocation Agent may run on each indexing blade. It may receive allocation requests from TS Allocation proxies running on the TSD blades.

In addition a Timeline Rollup TLR Agent and a Product Restore PR Agent may also be provided in Agents and Proxies .

According to embodiments of the present disclosure a number of objects may be provided to facilitate communications and coordination among indexing blades and TSD blades. Exemplary objects may include for example interface handlers IfaceHdlr a blade message header BladeMsgHdr and connection handlers ConnHdlr .

The interface handlers may be an abstract base class that defines the methods required for inter blade communications. The interface handlers may work with one or two physical network connections. In the case of two physical network connections being present for each send the interface layer may randomly select one of the connections to transmit on in order to distribute network traffic on both physical networks. A loss of one physical path may be tolerated. A loss of connectivity on both networks may be considered a fault event and may be handled by calling registered fault handling callbacks.

The interface handlers may support variable sized messages preferably having a common header. Receiver threads may first drain the header portion of an incoming message before processing the remaining portion of a message. Batching of multiple messages may also be supported.

All message sends may be asynchronous and may employ callbacks for response processing. The interface handlers may support fire and forget message sends as well as messages that require a response. For the latter timeouts may be supported that may perform callbacks with an appropriate response status. Unsolicited messages received those that are not in response to a message sent may be handled by invoking registered callbacks.

The class may support connection oriented as well as connectionless interface types. Connection oriented interface handlers may be constructed as either servers or clients this differentiation may affect the behavior of the connect method and little else.

Listed below are a set of exemplary public methods that may be defined or employed by the interface handlers 

Initially a connectionless interface using User Datagram Protocol UDP datagrams and a connection oriented interface using Transmission Control Protocol TCP may be implemented.

The blade message header may be a common header included in all messages. Each agent or proxy may define messages specific to its set of APIs but all messages may share this common header. The common header may contain one or more of the following fields 

Conspicuously missing from this list is a version field. Whether to use a version field may depend on a choice between the approach of versioning messages and the approach of never modifying the contents of a MsgType but just creating new MsgTypes.

The connection handlers may be a base class acting as a container object for proxies agents and interface Handlers. There may be a TSD Connection Handler tsdConnHdlr and an Index Connection Handler idxConnHdlr derived from the base class.

Each connection handler may represent a nexus between a TSD blade and an indexing blade. All proxies agents and interface handlers needed for that nexus may be contained within that connection handler. Therefore all LU or slice based interactions between TSD and indexing blades may occur through the appropriate connection handler.

Some flavor of LunConfig may maintain the relationship between connection handlers and LUN slices. This may be the current implementation of LunConfig extended to include slices and the connection handler info.

Separation of indexing functionalities from I O processing may also require a management solution for both TSD and indexing blades. According to embodiments of the present disclosure configuration of blades may be managed by a Blade Configuration Manager.

In a static blade configuration a set of blade configuration data be set at software installation or via a supplied utility prior to a blade becoming fully operational. These configuration data may include for example Internet Protocol IP configuration for both subnets and blade node ID. The static blade configuration information may be persistent in a file on a local disk.

When blades are booted they may broadcast their blade information to all blades that are already running and may in turn be sent privately the blade information of each running blade. In this way the Blade Configuration Manager may have knowledge of every other blade s vital information. Exemplary fields in a bladeInfo struct may include 

Additionally anytime a blade s information changes the blade may broadcast the changed bladeInfo to other blades and or the indexing blade farm.

Blades may negotiate with one other to determine which blade may run specific services such as for example the global database server.

If a blade boots alone and there are no other blades running it may wait for some predetermined amount of time before deciding that it should proceed and start services.

Each indexing blade may have two fiber connection ports for metadata LUN access. All indexing blades in an indexing blade farm may be zoned to see the same set of metadata LUNs. Metadata LUN discovery may occur when an indexing blade is initially booting and a background process may periodically run discovery to find LUNs that have been added to an already running indexing blade. It may then be determined as to which LUNs out of the set of LUNs discovered are to be used for metadata. One approach may be to allow the indexing blades to use any and all LUNs discovered. This approach may obviate the need to have an external management interface for metadata LUN assignment. An alternative approach may be to have a management interface for the indexing blade farm that may allow a user to assign LUNs for metadata.

When an indexing blade farm is booted for the first time the indexing blade that wins the negotiation for running the global database service may be responsible for choosing a LUN on which to run the global database and to query all other indexing blades to ensure that this LUN is seen by all members of the indexing blade farm. It may then create a partition on the metadata LUN for the global database and start the service. The global database partition information may be stored in a local disk file and broadcast to the other indexing blades in the farm. Each indexing blade may persist the partition information the information being sufficient for any indexing blade to mount the partition and start the global database service.

The indexing blade starting the service on a fresh indexing blade farm may also populate a table in a global database with the metadata LUNs that it has discovered. As other indexing blades gain access to the global database service e.g. via the broadcast by the service owner they may also populate the table with the set of metadata LUNs discovered. The goal may be to come up with a union set of LUNs that are seen by all indexing blades since it may be a requirement that all indexing blades see the same set of LUNs. Any LUNs that are seen by some but not all of the indexing blades in the farm may be marked unavailable. The indexing blades may not enter a running state until a common set of LUNs has been determined.

When a late comer indexing blade boots into a farm that has one or more indexing blades in a running state and it cannot see the same set of metadata LUNs that the running blades see it may not continue booting up to a running state.

In the context of TSD LUN configuration indexing blades may not be responsible for LUNs but rather uniquely identified LBA ranges given to the indexing blade as a globally unique LUN identifier. The memory units so identified may be slices. The unique identifier may allow different storage management appliances to present LUNs to the same indexing blade farm. Use of this new LUN identifier may have to be propagated throughout TSD and the indexing blade applications. Since the indexing blades are handed these pseudo LUNs it may be agnostic to slice sizes. The Portable TSD APIs may still require slice manager functionality to split indexing operations that span a slice boundary.

In the context of TSD LUN configuration LUNs may not be assigned directly to indexing blades. Instead LUN owners may be dynamically chosen when LUNs are put in capture mode by TSD. An exemplary sequence for a TSD blade and an indexing blade to determine LUN ownership is illustrated in the following table 

The Blade Configuration Manager may start a connectionless interface handler datagram and apart from blade discovery and LUN ownership negotiation may be responsible for services negotiation connection handler creation and fault handling coordination.

The APIs between a TSD blade and an indexing blade may be used for all communications between the two blades. The APIs may be embedded within respective proxies. Configuration APIs may be handled by blade configuration managers. A list of exemplary API calls sorted by their related proxy are provided below.

The Configuration APIs may involve configuration specific information and may be handled via the blade configuration managers. The Configuration APIs may include the following 

At this point it should be noted that the technique for implementing a scalable and or portable storage management system in accordance with the present disclosure as described above typically involves the processing of input data and the generation of output data to some extent. This input data processing and output data generation may be implemented in hardware or software. For example specific electronic components may be employed in a storage area network SAN or similar or related circuitry for implementing the functions associated with storage management system scalability and or portability in accordance with the present disclosure as described above. Alternatively one or more processors operating in accordance with stored instructions may implement the functions associated with storage management system scalability and or portability in accordance with the present disclosure as described above. If such is the case it is within the scope of the present disclosure that such instructions may be stored on one or more processor readable carriers e.g. a magnetic disk or transmitted to one or more processors via one or more signals.

The present disclosure is not to be limited in scope by the specific embodiments described herein. Indeed other various embodiments of and modifications to the present disclosure in addition to those described herein will be apparent to those of ordinary skill in the art from the foregoing description and accompanying drawings. Thus such other embodiments and modifications are intended to fall within the scope of the present disclosure. Further although the present disclosure has been described herein in the context of a particular implementation in a particular environment for a particular purpose those of ordinary skill in the art will recognize that its usefulness is not limited thereto and that the present disclosure may be beneficially implemented in any number of environments for any number of purposes. Accordingly the claims set forth below should be construed in view of the full breadth and spirit of the present disclosure as described herein.

