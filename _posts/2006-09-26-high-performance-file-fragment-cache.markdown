---

title: High performance file fragment cache
abstract: A system, method, and computer program for caching a plurality of file fragments to improve file transfer performance, comprising the steps of exposing at least one file fragment of a computer file as a primary object to an application; caching said at least one file fragment at a plurality of points in a network system, wherein said at least one file fragment remains unchanged; and managing said at least one non-changing file fragment throughout said network system at a plurality of cache points and appropriate means and computer-readable instructions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08078686&OS=08078686&RS=08078686
owner: Siemens Product Lifecycle Management Software Inc.
number: 08078686
owner_city: Plano
owner_country: US
publication_date: 20060926
---
The present application claims priority of U.S. provisional application Ser. No. 60 720 758 filed Sep. 27 2005 which is incorporated herein by reference.

The presently preferred embodiment of the innovations described herein relate generally to file transfer performance. More specifically the presently preferred embodiment relates to a system and method for caching streaming and accelerating wide area file transfers.

In the current graphics intensive industries of computer aided drafting and simulation it is common to encounter resulting files that are so large they can take hundreds of hours to render. Likewise it can be desirable to transfer those very large files from location to location for numerous reasons e.g. programming presentation or development. In a multi site distributed network it is necessary to have those large files available to all who contribute to it. A common method for distribution uses peer to peer networks such as BitTorrent that downloads portions of the large file in anticipation of all the pieces being available for eventual combination into the large file. This technique is also referred to as caching as is seen with memory techniques to speed computer performance.

The drawback with the aforesaid peer to peer networks is the end result is always the whole file the partial file fragments are an intermediate artifact of the larger file transfer. In this type of caching technique partial file contents are not useful by themselves.

What is needed is a system that exposes fragments of files as primary objects to applications that can take advantage of those fragments or logical sections of their data files and manage and cache those fragments at all points of the system for enhanced performance and throughput.

To achieve the foregoing and in accordance with the purpose of the presently preferred embodiment as broadly described herein the present application provides a method of caching a plurality of file fragments to improve file transfer performance comprising the steps of exposing at least one file fragment of a computer file as a primary object to an application caching said at least one file fragment at a plurality of points in a network system wherein said at least one file fragment remains unchanged and managing said at least one non changing file fragment throughout said network system at a plurality of cache points. The method comprising the additional step of requesting data having said file fragment associated therewith. The method comprising the additional step of retrieving said file fragment from a shared cache if said file fragment is present in said shared cache. The method comprising the additional step of retrieving said file fragment from a private cache if said file fragment is absent from a shared cache. The method wherein said retrieval is authenticated by a security ticket. The method comprising the additional step of displaying said file fragment from a shared cache to said application.

Another advantage of the presently preferred embodiment is to provide a method of accessing a cached file fragment comprising the steps of requesting a file fragment by an application receiving said file fragment whereby said file fragment is available to a plurality of applications and utilizing said file fragment. The method wherein said file fragment is received from a shared mapped file memory on a first server.

A method of sending a cached file fragment comprising the steps of receiving a request to access a file fragment on a first server transmitting said file fragment if said file fragment is in a shared mapped file memory on said first server retrieving said file fragment from a private memory cache on a second server if said file fragment is absent from said shared mapped file memory on said first server storing said retrieved file fragment from said private memory cache on said first server and transmitting said file fragment. The method wherein said receiving step and said transmitting steps are in relation to an application.

And another advantage of the presently preferred embodiment is to provide a computer program product tangibly embodied in a machine readable medium to perform a method comprising instructions for exposing at least one file fragment of a computer file as a primary object to an application instructions for caching said at least one file fragment at a plurality of points in a network system wherein said at least one file fragment remains unchanged and instructions for managing said at least one non changing file fragment throughout said network system at a plurality of cache points. The computer program product comprising the additional step of requesting data having said file fragment associated therewith. The computer program product comprising the additional step of retrieving said file fragment from a shared cache if said file fragment is present in said shared cache. The computer program product comprising the additional step of retrieving said file fragment from a private cache if said file fragment is absent from a shared cache. The computer program product wherein said retrieval is authenticated by a security ticket. The computer program product comprising the additional step of displaying said file fragment from a shared cache to said application.

Yet another advantage of the presently preferred embodiment is to provide a computer program product tangibly embodied in a machine readable medium to perform a method of accessing a cached file fragment comprising instructions for requesting a file fragment by an application instructions for receiving said file fragment whereby said file fragment is available to a plurality of applications and instructions for utilizing said file fragment. The computer program product wherein said file fragment is received from a shared mapped file memory on a first server.

And yet another advantage of the presently preferred embodiment is to provide a computer program product tangibly embodied in a machine readable medium to perform a method of sending a cached file fragment comprising instructions for receiving a request to access a file fragment on a first server instructions for transmitting said file fragment if said file fragment is in a shared mapped file memory on said first server instructions for retrieving said file fragment from a private memory cache on a second server if said file fragment is absent from said shared mapped file memory on said first server instructions for storing said retrieved file fragment from said private memory cache on said first server and instructions for transmitting said file fragment.

Still another advantage of the presently preferred embodiment is to provide a data processing system having at least a processor and accessible memory to implement a method for caching a plurality of file fragments to improve file transfer performance comprising means for exposing at least one file fragment of a computer file as a primary object to an application means for caching said at least one file fragment at a plurality of points in a network system wherein said at least one file fragment remains unchanged and means for managing said at least one non changing file fragment throughout said network system at a plurality of cache points.

Other advantages of the presently preferred embodiment will be set forth in part in the description and in the drawings that follow and in part will be learned by practice of the presently preferred embodiment. The presently preferred embodiment will now be described with reference made to the following Figures that form a part hereof. It is understood that other embodiments may be utilized and changes may be made without departing from the scope of the presently preferred embodiment.

The numerous innovative teachings of the present application will be described with particular reference to the presently preferred embodiments. It should be understood however that this class of embodiments provides only a few examples of the many advantageous uses of the innovative teachings herein. The presently preferred embodiment provides among other things a system and method of for caching streaming and accelerating wide area file transfers. Now therefore in accordance with the presently preferred embodiment an operating system executes on a computer such as a general purpose personal computer. and the following discussion are intended to provide a brief general description of a suitable computing environment in which the presently preferred embodiment may be implemented. Although not required the presently preferred embodiment will be described in the general context of computer executable instructions such as program modules being executed by a personal computer. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implementation particular abstract data types. The presently preferred embodiment may be performed in any of a variety of known computing environments.

With reference to an exemplary system for implementing the presently preferred embodiment includes a general purpose computing device in the form of a computer such as a desktop or laptop computer including a plurality of related peripheral devices not depicted . The computer includes a microprocessor and a bus employed to connect and enable communication between the microprocessor and a plurality of components of the computer in accordance with known techniques. The bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The computer typically includes a user interface adapter which connects the microprocessor via the bus to one or more interface devices such as a keyboard mouse and or other interface devices which can be any user interface device such as a touch sensitive screen digitized pen entry pad etc. The bus also connects a display device such as an LCD screen or monitor to the microprocessor via a display adapter . The bus also connects the microprocessor to a memory which can include ROM RAM etc.

The computer further includes a drive interface that couples at least one storage device and or at least one optical drive to the bus. The storage device can include a hard disk drive not shown for reading and writing to a disk a magnetic disk drive not shown for reading from or writing to a removable magnetic disk drive. Likewise the optical drive can include an optical disk drive not shown for reading from or writing to a removable optical disk such as a CD ROM or other optical media. The aforementioned drives and associated computer readable media provide non volatile storage of computer readable instructions data structures program modules and other data for the computer .

The computer can communicate via a communications channel with other computers or networks of computers. The computer may be associated with such other computers in a local area network LAN or a wide area network WAN or it can be a client in a client server arrangement with another computer etc. Furthermore the presently preferred embodiment may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices. All of these configurations as well as the appropriate communications hardware and software are known in the art.

Software programming code that embodies the presently preferred embodiment is typically stored in the memory of the computer . In the client server arrangement such software programming code may be stored with memory associated with a server. The software programming code may also be embodied on any of a variety of non volatile data storage device such as a hard drive a diskette or a CD ROM. The code may be distributed on such media or may be distributed to users from the memory of one computer system over a network of some type to other computer systems for use by users of such other systems. The techniques and methods for embodying software program code on physical media and or distributing software code via networks are well known and will not be further discussed herein.

A file management services FMS system departs from traditional product lifecycle management PLM systems by providing a channel for data access that is separate from its primary PLM connection. This separation enables an administrator to put data close to a user while storing PLM metadata in a central database. The design to separate the data connection from the PLM connection requires a security ticket to be passed between the PLM and FMS systems. FMS provides file access when a valid security ticket is presented. At the same time FMS caches data as it passes through the system for both uploads and downloads enabling rapid file data delivery when a valid security ticket is presented to the FMS cache servers FCS . FMS manages cached data at both a private user and a shared server level.

Next the security ticket is received by the Rich Client Interface and queries if the FCC has the requested FMS File and displays it if so Step . Otherwise the FSC receives the security ticket validates the ticket and checks whether it has the requested FMS File where the FMS File is identified by a globally unique identifier GUID string and is preferably a file fragment but may also be an entire data file Step . If the FSC has the requested FMS File then the FSC sends the requested FMS File to the FCC for storage for that file Step . When the entire FMS file has streamed down the FMS returns the file path to the FMS Rich Client Interface for display Step . If the FSC does not have the FMS File the FSC queries the FMS Volume Server that receives the security ticket validates the ticket and serves the requested file to the FSC Step . The FSC receives the FMS file from the FMS Volume Server and streams it through to the FCC . The FSC stores the FMS File bits Step as they stream through the server process. The FCC receives the FMS file stream and stores it to the local client cache by the GUID string for that file Step . When the entire FMS file has streamed down FMS returns the file path to the FMS Rich Client Interface for display Step . The system optimizes a batch retrieval of tickets not currently cached. For example when a part node is expanded all of the tickets for that sub tree are retrieved. So at the first access use case there are preferably zero or one batch ticket calls.

The second and consecutive time the FMS file is accessed it is already stored on one of the caches either the FCC or the FSC requiring fewer processing steps and without requiring the passing of the FMS file request to the FMS Volume Servers . Writing to the FMS file also caches copies of itself along the path up to the FMS Volume Servers with processes analagous to the read of the FMS file previously discussed see Steps through .

New files that are uploaded to the system are streamed up the FMS Volume Servers and each cache along the route e.g. FSC FCC systems stores a copy of the FMS file as it streams through the FMS system. To write a modified file fragment for client cached data the user requests the file open or download on the FMS Rich Client Interface . The business logic file server validates that the user has permissions to upload and associate the file with an object and then generates a write ticket and a GUID is created for the file that is sent back to the FMS Rich Client Interface . The FMS Rich Client Interface passes the write ticket and file to the FMS system and requests a file upload. The FMS system copies the file into the local client cache at the FCC and uploads the file to the connected FMS cache server where the whole file and associated GUID is saved to cache. The FMS server cache receives the write ticket validates the ticket and then uploads the file to the connected FMS Server Cache saving a copy of the stream data as it passes. The FMS pulls the incoming stream into the volume file producing a new volume file at the FMS Volume Server . The file object is then created in the system at the business logic file server and a reference or relation is used to associate the file with the object such as a data set or document at the FMS Rich Client Interface .

When dealing with partial file transfers the user requests a particular piece of data such as part of an assembly file Step . A security ticket is generated Step . If the piece of data is available at the FCC then the FMS Rich Client application immediately reads the file fragment out of a shared virtual memory located in the local FCC cache Step . If the piece of data is not available in the virtually shared mapped file memory then the security ticket is sent to the FSC to get the file fragment Step . The file fragment is then returned to the user if it is cached at the FSC Step . If the file fragment is not in the FSC then retrieve it from the FSC Volume Server Step . When the retrieved file fragment is returned to the FCC it is written to the virtually mapped file memory where the FMS Rich client application access it from the shared virtually mapped memory file to display to the user Step . It is important to note that the FSC is a private cache i.e. there are not direct clients to the FSC as it resides on a separate computer and conversely FCC is a shared cache so that other client program scan access it in process. Therefore multiple rich client applications can run on the same fast cache concurrently so that the same data may be viewed by distinct applications.

Turning now from the system architecture to the internals of the partial file cache used by the server applications is a block diagram of a sample relationship between external applications and a partial file cache that is written in C. Referring to a C API application programming interface is provided to interface the partial file cache in order to allow requests for services to be made of it by other C applications for example a FCC Client Proxy . Also provided is a JNI layer that is a programming framework that allows server applications written in lava like FCC or FSC to call and be called by the partial file cache.

There is at least one file header pointer per cached file GUID string and contains information related specifically to that GUID string e.g. the GUID string itself and a file size length . Additionally the file header pointer contains next and previous indices for other file headers referencing the same file GUID string . Further the file header pointer contains 35 segment entries that references up to about 569 kilobytes of cached file data. And given that file header pointer is the basic space allocation unit all segments referenced by a file header are freed at the same time when memory is reallocated.

There are two types of allocated file header pointer primary and secondary for which there is a flag indicating either type. Referenced by the hash table the primary file header is characterized as the first file header for a file and contains the index of the next primary file header with the same hash. The primary file header can also be referenced from a secondary file header s previous index or from a least recent list. Secondary file headers are characterized by referencing via the next previous links in the same file GUID string and extend to the amount of data a file header can reference.

The presently preferred embodiment may be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations thereof. An apparatus of the presently preferred embodiment may be implemented in a computer program product tangibly embodied in a machine readable storage device for execution by a programmable processor and method steps of the presently preferred embodiment may be performed by a programmable processor executing a program of instructions to perform functions of the presently preferred embodiment by operating on input data and generating output.

The presently preferred embodiment may advantageously be implemented in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. The application program may be implemented in a high level procedural or object oriented programming language or in assembly or machine language if desired and in any case the language may be a compiled or interpreted language.

Generally a processor will receive instructions and data from a read only memory and or a random access memory. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of nonvolatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM disks. Any of the foregoing may be supplemented by or incorporated in specially designed ASICs application specific integrated circuits .

A number of embodiments have been described. It will be understood that various modifications may be made without departing from the spirit and scope of the presently preferred embodiment such as caching previously granted tickets at the FCC level and avoid the performance penalty of the ticket check i.e. only non possessory tickets are received for example. Further the file structure could have another method of sending receiving acknowledgement delay periods that allow a sender to transmit a number of data units before an acknowledgement is received or a before a specific event occurs. Likewise other caching methods to collecting data that duplicates the original stored elsewhere are within the teachings disclosed herein. Other caching methodologies can use heuristics to select the entry to based on factors such as latencies and throughput. Therefore other implementations are within the scope of the following claims.

