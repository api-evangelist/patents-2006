---

title: Timing aspects of media content rendering
abstract: Timing for execution of certain user inputs and application instructions occurring during play of an interactive multimedia presentation is discussed. A current state is defined by a state of the presentation system at the time a current media sample is being played to a user. A predicted state is defined by a state of the presentation system one or more future play times. Examples of current and predicted states include media retrieval states and media presentation states. An instruction or user input that is based on the current state is identified, and the predicted state is used to determine an effect of the instruction or input. The effect may then be executed at a predetermined time, such as after the next playable media sample is played to the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07861150&OS=07861150&RS=07861150
owner: Microsoft Corporation
number: 07861150
owner_city: Redmond
owner_country: US
publication_date: 20061107
---
Multimedia players are devices that render combinations of video audio or data content multimedia presentations for consumption by users. Multimedia players such as DVD players currently do not provide for much if any user interactivity during play of media content media content play is generally interrupted to receive user inputs other than play speed adjustments. For example a user of a DVD player must generally stop the movie he is playing to return to a menu to see the various options allowing him to select and receive features such as audio commentary or effects actor biographies or games.

Interactive multimedia players are devices such devices may include hardware software firmware or any combination thereof that render combinations of interactive content concurrently with traditional video audio or data content interactive multimedia presentations . Interactive content is generally any user selectable visible or audible object presentable alone or concurrently with other video audio or data content. Although any type of device may be an interactive multimedia player devices such as optical media players for example DVD players computers and other electronic devices are particularly well positioned to enable the creation of and consumer demand for commercially valuable interactive multimedia presentations because they provide access to large amounts of relatively inexpensive portable data storage.

To enhance investment in all types of media content players particularly interactive multimedia players and interactive multimedia presentations it is desirable to provide predictable and relatively glitch free play of video audio or data content and to ensure the accurate synchronization of interactive content with the video audio or data content.

An interactive multimedia presentation has a play duration and includes a media content component and an interactive content component. One example of media content is a movie but media content may be video audio data or any combination thereof. Media content is arranged into a number of samples. Sets of such samples are referred to as clips with one clip generally receivable from one media source. Interactive content is in the form of one or more applications which provide instructions for organizing formatting and synchronizing the presentation of interactive objects to a user often concurrently with media content. An application usually includes instructions both in declarative form for example extensible markup language form and in script form but may include only instructions in declarative form or only instructions in script form.

Sometimes execution of user input such as a play speed adjustment or selection of interactive content or application instructions affects what content is next played to a user. Often such user input or application instructions arise at times when media content and interactive content are being pre rendered when immediate execution of their effects could cause glitches in the play of the media content and or loss of synchronization between the media content and the interactive content.

Methods systems apparatuses and articles of manufacture for playing interactive multimedia presentations that are discussed herein involve identifying instructions or user inputs that are executable based on certain predefined states and timing the execution of such instructions or user inputs in a manner that minimizes glitches and or loss of synchronization. More specifically certain actions taken during play of an interactive multimedia presentation include using a media timeline to identify a current elapsed play time within a play duration of an interactive multimedia presentation. The current elapsed play time represents a time when a current media sample from a current media source is being played to a user. Current and predicted states are ascertained the current state is associated with an aspect of the presentation system at the current elapsed play time for example a state of the current media sample or the current media source the predicted state is associated with an aspect of the presentation system at one or more future times future play times may be any times in the future including but not limited to future play times at which one or more future media samples are playable or intervals thereof . An instruction or user input that is executable based on the current state is identified and instead of executing the instruction or user input based on the current state the instruction or user input is executed based on the predicted state.

One or more state values referred to as media state values for exemplary purposes which are associated with the current and predicted states are maintained in a data structure. A predicted state manager receives certain user inputs and application instructions and determines the effect of their execution based on the predicted state instead of the current state using the predicted state values for example . The effects of a particular instruction or user input may then be executed at a predetermined time such as after the next playable media sample is played to the user.

The predicted state manager may function at various places within the presentation system. In one scenario the predicted state manager functions as a virtual media processing pipeline that supplements or serves as a substitute for the performance of a physical media processing pipeline. Application programming interfaces APIs may also be provided so that application authors can access functions associated with the predicted state manager in a transparent manner.

This Summary is provided to introduce a selection of concepts in a simplified form. The concepts are further described in the Detailed Description section. Elements or steps other than those described in this Summary are possible and no element or step is necessarily required. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended for use as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

When a presentation system plays an interactive multimedia presentation that includes a media content component and an interactive content component it is desirable to time the effects of execution of certain user inputs or application instructions in a manner that ensures the predictable and relatively glitch free play of the media content component and perceived synchronization between the media content component and the interactive content component.

Certain user inputs such as play speed inputs and selection of interactive objects and application instructions such as script instructions affect what will be next played to a user. Often such user inputs and application instructions arise when portions of the media content component and or interactive content component are being pre rendered so it is important to determine whether their effects should be executed and shown to the user before after or instead of the effects of the pre rendered material.

Timing techniques described herein use the notions of current and predicted states. A current state is associated with an aspect of the presentation system at the time a current media sample is being played to a user for example with the state of the current media sample or with a state of a media source from which the current media sample is derived . A predicted state is associated with an aspect of the presentation system at a future time for example at the time one or more future media samples are playable to a user such as the time the next media sample which may or may not be the next consecutive media sample is playable to the user . An instruction or user input that is to be executed based on the current state is identified and instead of executing the instruction or user input based on the current state the effect of the instruction or user input is determined based on the predicted state. The effect may then be executed at a predetermined time such as before or after the next playable media sample is played to the user.

Various virtually unlimited states may be defined. For exemplary purposes media retrieval states and media presentation states and combinations thereof are discussed. Examples of media retrieval states include but are not limited to one or more of the following a normal play retrieval state a pause retrieval state a slow forward retrieval state a fast forward retrieval state a slow reverse retrieval state a fast reverse retrieval state a closed state a ready state and a pre rolling state. Examples of media presentation states include but are not limited to one or more of the following a media capture state a media layout state an audio play state and a user selection state. One or more state values referred to as media state values for exemplary purposes associated with both current and predicted states are maintained in a data structure.

The data structure is maintained and or accessed by functionality referred to herein as a predicted state manager within the presentation system that receives certain user inputs and application instructions and determines the effect of their execution based on predicted state values instead of current state values. In one implementation the predicted state manager is software that implements various aspects of one or more application programming interfaces APIs usable by application authors. The predicted state manager may function at various places within the presentation system. In one scenario the predicted state manager acts as a virtual media processing pipeline that may supplement or serve as a substitute for the performance of a physical media processing pipeline.

Turning to the drawings where like numerals designate like components is a simplified functional block diagram of an interactive multimedia presentation system Presentation System . Presentation System includes a media content manager an interactive content IC manager a presentation manager a timing signal management block and a mixer renderer . In general design choices dictate how specific functions of Presentation System are implemented. Such functions may be implemented using hardware software or firmware or combinations thereof.

In operation Presentation System handles interactive multimedia presentation content Presentation Content . Presentation Content includes a media content component media component and an interactive content component IC component . Media component and IC component are generally but need not be handled as separate data streams by media content manager and IC manager respectively.

Presentation System also facilitates presentation of Presentation Content to a user not shown as played presentation . Played presentation represents the visible and or audible information associated with Presentation Content that is produced by mixer renderer and receivable by the user via devices such as displays or speakers not shown . For discussion purposes it is assumed that Presentation Content and played presentation represent high definition DVD movie content in any format. It will be appreciated however that Presentation Content and Played Presentation may be configured for presenting any type of presentation of media content now known or later developed.

Media component represents the traditional video audio or data components of Presentation Content . For example a movie generally has one or more versions a version for mature audiences and a version for younger audiences for example one or more titles with one or more chapters not shown associated with each title titles are discussed further below in connection with presentation manager one or more audio tracks for example the movie may be played in one or more languages with or without subtitles and extra features such as director s commentary additional footage trailers and the like. It will be appreciated that distinctions between titles and chapters are purely logical distinctions. For example a single perceived media segment could be part of a single title chapter or could be made up of multiple titles chapters. It is up to the content authoring source to determine the applicable logical distinctions. It will also be appreciated that although media component is referred to as a movie media component may in fact be video audio data or any combination thereof.

Sets of media samples for example sets of video audio or data samples that form media component are referred to as clips clips are shown within media component media content manager and playlist . Referring to media content manager information associated with clips is handled by one or more media processing pipelines one media processing pipeline labeled N is shown to indicate that any number of media processing pipelines are possible . Within a particular media processing pipeline information associated with clips is received from a media source and demultiplexed decoded and or decrypted at a decoder block .

A particular media source is any device location or data from which video audio or data is derived or obtained. Examples of media sources include but are not limited to networks hard drives optical media alternate physical disks and data structures referencing storage locations of specific video audio or data. In general any computer readable medium may serve as a media source computer readable media are discussed further below in connection with .

Decoder blocks represent any devices techniques or steps used to retrieve renderable video audio or data content from information received from a media source . Decoder blocks may include codecs demultiplexers or decrypters for example. Decoder blocks and components thereof may be implemented using hardware software firmware or any combination thereof. Although a one to one relationship between decoders and media sources is shown it will be appreciated that one decoder may serve multiple media sources and vice versa. For example some commercially available DVD players include only one decoder.

In addition to physical media processing pipeline s media content manager includes one or more virtual media processing pipelines one shown . Virtual media processing pipeline communicates with media processing pipeline s . In one implementation virtual media processing pipeline includes a predicted state manager which may include implementations of application programming interfaces APIs accessed via instructions written by authors of applications discussed further below that are arranged for execution by IC manager . All as discussed further below in connection with predicted state manager receives certain user inputs and input and is used to determine timing for execution of the effects of such user inputs and input on played presentation .

Media data is data associated with media component that has been prepared for rendering by media content manager and transmitted to mixer renderer . Samples for example frames of media data generally include for each active clip a rendering of a portion of the clip. The exact portion or amount of the clip rendered in a particular set of media data may be based on several factors such as the characteristics of the video audio or data content of the clip or one or more parameters associated with the media source from which the media data is derived for example codec parameters or settings and encryption parameters or settings . Media content manager has a dynamic media processing load based on the identity and scheduling of the various clips comprising media component and or IC component discussed below .

Referring again to Presentation Content IC component includes interactive objects which are user selectable visible or audible objects optionally presentable concurrently with media component along with any instructions shown as applications and discussed further below for presenting the visible or audible objects. Interactive objects may be static or animated. Examples of interactive objects include among other things video samples or clips audio samples or clips images graphics text and combinations thereof.

Interactive objects originate from one or more sources not shown . A source is any device location or data from which interactive objects are derived or obtained. Examples of sources for interactive objects include but are not limited to networks hard drives optical media alternate physical disks and data structures referencing storage locations of specific interactive objects. Examples of formats of interactive objects include but are not limited to portable network graphics PNG joint photographic experts group JPEG moving picture experts group MPEG multiple image network graphics MNG audio video interleave AVI extensible markup language XML hypertext markup language HTML extensible HTML XHTML extensible stylesheet language XSL and WAV.

Applications provide the mechanism by which Presentation System presents interactive objects to a user. Applications represent any signal processing method or stored instruction s that electronically control predetermined operations on data. It is assumed for discussion purposes that IC component includes three applications which are discussed further below in connection with . Applications either alone or in response to user events may determine when media data associated with clips or interactive objects are presented to a user.

IC manager includes a script handling engine and a markup handling engine . Script handling engine receives interprets and arranges for execution of script commands associated with application script is shown and discussed in connection with . Markup handling engine receives interprets and arranges for execution of markup associated with application markup elements are shown and discussed in connection with . During execution of a particular application IC manager maintains the context for the state of the markup elements and or associated interactive objects affected thereby and a context for the script s variables functions and other states. As execution of application progresses and user input is received the properties of any affected elements media objects are recorded and may be used to trigger behavior within played presentation . Certain instructions of application labeled as input from ICM may facilitate communication or interoperability with other functionality or components within Presentation System . As shown input is received by virtual processing pipeline predicted state manager .

Interactive content data IC data is data associated with IC component that has been prepared for rendering by IC manager and transmitted to mixer renderer . Each application may have an associated queue not shown which when in use holds one or more work items not shown associated with rendering the application. It is possible however for an application to have no active work items.

Presentation manager which is configured for communication with media content manager IC manager mixer renderer and timing signal management block facilitates handling of Presentation Content and presentation of played presentation to the user. Presentation manager has access to a playlist . Playlist includes among other things a time ordered sequence of clips and applications including interactive objects that are presentable to a user. The clips and applications interactive objects may be arranged to form one or more titles . For exemplary purposes one title is discussed herein. Playlist may be implemented using an extensible markup language XML document or another data structure.

Presentation manager uses playlist to ascertain a presentation timeline for title . Conceptually presentation timeline indicates the times within title when specific clips and applications are presentable to a user. A sample presentation timeline which illustrates exemplary relationships between presentations of clips and applications is shown and discussed in connection with . In certain circumstances it is also useful to use playlist and or presentation timeline to ascertain a media content timeline media timeline an exemplary media timeline is discussed further below in connection with and an interactive content timeline IC timeline an exemplary IC timeline is discussed further below in connection with .

In operation presentation manager provides information including but not limited to information about presentation timeline media timeline and or IC timeline to media content manager and IC manager . Based on input from presentation manager media content manager prepares media data for rendering and IC manager prepares IC data for rendering. In one implementation presentation manager can control media processing pipelines and virtual media processing pipeline .

Timing signal management block produces various timing signals which are used to control the timing for preparation and production of media data and IC data by media content manager and IC manager respectively. In particular timing signals are used to achieve approximate synchronization of media data and IC data for example timing synchronization on a per frame basis or on another time basis . Details of timing signal management block and timing signals are discussed further below in connection with .

Mixer renderer renders media data in a video plane not shown and renders IC data in a graphics plane not shown . The graphics plane is generally but not necessarily overlayed onto the video plane to produce played presentation for the user.

With continuing reference to is a graphical illustration of a sample presentation timeline for title within playlist . Time is shown on horizontal axis . Information presentable within title specifically about media component clips are illustrated and IC component applications which present interactive objects are illustrated is shown on vertical axis .

Regarding clips associated with media component four clips are shown a first media clip media clip a second media clip media clip a third media clip media clip and a fourth media clip media clip . Script clip is a media clip such as an animated thumbnail which is not generally included in the playlist but which may be optionally invoked automatically or by a user via an application at variable times such as when no media content is scheduled for play or when media content play has been paused within played presentation .

Regarding IC component one application is responsible for presenting certain interactive objects that provide user selectable items for example buttons with associated text or graphics of menu . Another application is responsible for presenting one or more interactive objects that provide graphic overlay . As shown menu is displayed concurrently with media clips through and graphic overlay is displayable concurrently with media clip and a portion of media clip . A third application is responsible for presenting script clip when there is no media content scheduled for presentation as shown script clip is playable between 20 seconds and 30 seconds .

The particular amount of time along horizontal axis in which title is presentable to the user is referred to as play duration of title . Specific times within play duration are referred to as title times. Seven title times TTs are shown on presentation timeline TT TT TT TT TT TT and TT . Because a title may be played once or may be played more than once in a looping fashion for example play duration is determined based on one iteration of title . Play duration may be determined with respect to any desired reference including but not limited to a predetermined play speed for example normal or 1 play speed a predetermined frame rate or a predetermined timing signal status. Play speeds frame rates and timing signals are discussed further below in connection with .

It will be appreciated that implementation specific factors such as display techniques and specific rules regarding play sequences and timing relationships among clips and interactive objects for each title may impact upon exact values of a title s play duration and title times therein. The terms play duration and title times are intended to encompass all such implementation specific details.

Although title times at within which content associated with IC component is presentable are generally predetermined it will be appreciated that actions taken when the user interacts with such content may only be determined based on user input while Played Presentation is playing. For example the user may select activate or deactivate certain applications interactive objects and or additional content associated therewith during play of Played Presentation .

Media presentation intervals are defined by beginning and ending times of play duration between which particular content associated with particular clips is playable. That is presentation intervals are generally based on specific times within play duration . Application presentation intervals discussed further below in connection with may be similarly defined.

With continuing reference to is a functional block diagram of a single application . Application is generally representative of applications responsible for presenting interactive objects associated with menu graphic overlay and script clip shown in . Application includes instructions discussed further below . Application has associated therewith an application play duration and one or more application presentation intervals .

An application play duration is a particular amount of time with reference to an amount a part or all of play duration within which interactive objects associated with application are presentable to and or selectable by a recipient of played presentation . The intervals defined by beginning and ending title times obtained when an application play duration associated with a particular application is conceptualized on presentation timeline are referred to as application presentation intervals .

In some cases application may have more than one page pages are not shown . A page is a logical grouping of one or more interactive objects that are contemporaneously presentable within a particular application play duration and or application presentation interval . The number of applications and pages associated with a given title and the interactive objects associated with each application or page are generally logical distinctions that are matters of design choice.

Instructions when executed perform tasks among other tasks related to rendering of interactive objects associated with application based on user input. User inputs may affect presentation of IC component or media component . Examples of user inputs include but are not limited to user inputs that change the state of the media source for example play speed inputs and user interaction with interactive objects within played presentation such as selection of a button within menu selection of the circle associated with graphical overlay or invocation of script clip . Such interactions may occur using any type of user input device now known or later developed including a keyboard a remote control a mouse a stylus or a voice command. It will be appreciated that application may respond to events other than user events.

Generally instructions are computer executable instructions or commands encoded in computer readable media discussed further below in connection with . In the examples set forth herein instructions are implemented using either markup elements or script . Although either script or markup elements may be used alone in general the combination of script and markup elements enables the creation of a comprehensive set of interactive capabilities for a high definition DVD movie.

Script includes instructions written in a non declarative programming language such as an imperative programming language. An imperative programming language describes computation in terms of a sequence of commands to be performed by a processor. Examples of when script is used include responding to user inputs handling aspects of the presentation of interactive objects system events state management and resource management for example accessing cached or persistently stored resources . Script can affect what is next presented to a user via played presentation and it may be desirable to control timing for execution of certain script commands especially in an environment where multiple applications issue commands that affect or are conditioned upon what is being presented or scheduled for presentation to a user.

Markup elements represent instructions written in a declarative programming language such as Extensible Markup Language XML . An XML schema is a definition of the syntax es of a class of XML documents. Some XML schemas are defined by the World Wide Web Consortium W3C . Other XML schemas have been promulgated by the DVD Forum for use with XML documents in compliance with the DVD Specifications for High Definition Video and for other uses. It will be appreciated that other schemas for high definition DVD movies as well as schemas for other interactive multimedia presentations are possible.

With continuing reference to application may also use one or more application programming interfaces APIs such as virtual processing pipeline API to access or execute the functionality of predicted state manager discussed further in connection with . In general script authors use APIs to access resources within and external to a particular application. For example resources may be accessed using universal resource identifiers or other types of predetermined identifiers. Examples of resources within an application include but are not limited to interactive objects and markup associated with a particular application. Examples of resources external to a particular application include but are not limited to other applications network locations media content manager and components thereof such as virtual processing pipeline presentation manager and components thereof IC manager and components thereof mixer renderer and components thereof and timing signal management block and components thereof. In the context of specifications for high definition video published by the DVD Forum a class library of objects and methods accessible via APIs is set forth in Annex Z which is incorporated by reference herein for all purposes.

With continuing reference to is a simplified functional block diagram illustrating various components of timing signal management block and timing signals in more detail.

Timing signal management block is responsible for the handling of clocks and or timing signals that are used to determine specific times or time durations within Presentation System . As shown a continuous timing signal is produced at a predetermined rate by a clock source . Clock source may be a clock associated with a processing system such as a general purpose computer or a special purpose electronic device. Timing signal produced by clock source generally changes continually as a real world clock would within one second of real time clock source produces at a predetermined rate one second worth of timing signals .

Timing signal is input to IC frame rate calculator media frame rate calculator time reference calculator and time reference calculator . IC frame rate calculator produces a timing signal based on timing signal . Timing signal is referred to as an IC frame rate which represents the rate at which frames of IC data are produced by IC manager . One exemplary value of the IC frame rate is 30 frames per second. The frequency of IC frame rate referred to as the presentation clock frequency may dynamically change however. It will also be appreciated that the processing load within various components of Presentation System may change based on the presentation clock frequency. IC frame rate calculator may reduce or increase the rate of timing signal to produce timing signal .

Frames of IC data generally include for each valid application and or page thereof a rendering of each interactive object associated with the valid application and or page in accordance with relevant user events. For exemplary purposes a valid application is one that has an application presentation interval within which the current title time of play duration falls based on presentation timeline . It will be appreciated that an application may have more than one application presentation interval. It will also be appreciated that no specific distinctions are made herein about an application s state based on user input or resource availability.

Media frame rate calculator also produces a timing signal timing signal based on timing signal . Timing signal is referred to as a media frame rate which represents the rate at which media samples are produced by media content manager . The media frame rate may be the same as or different from IC frame rate . One exemplary value of the media frame rate is 24 frames per second. The frequency of media frame rate may dynamically change however. Media frame rate calculator may reduce or increase the rate of timing signal to produce timing signal .

A clock source produces timing signal which governs the rate at which information associated with clips is produced from media sources . Clock source may be the same clock as clock or based on the same clock as clock source . Alternatively clocks and may be altogether different and or have different sources. Likewise media frame rate may be the same as or based on the same value as timing signal or the timing signals may be different.

Clock source adjusts the rate of timing signal which is referred to as the media clock frequency based on a media state indicator signal which is produced by media state indicator block . The media clock frequency may also vary based on media source characteristics such as encoding or decoding rates. Thus the media clock frequency may change from clip to clip.

Media state indicator block may also represent or be used to determine one or more media states which are retrieval or presentation states of video audio or data information from a particular media source shown in . Examples of media retrieval states include but are not limited to the normal play retrieval state the paused retrieval state the slow forward retrieval state the fast forward retrieval state the slow reverse retrieval state the fast reverse retrieval state the closed state the ready state and the pre rolling state all discussed further below . Examples of media presentation states include but are not limited to media capture states media layout states audio play states or user selection states all discussed further below that indicate how or whether certain media data or IC data is presented within played presentation . Particular media retrieval states and media presentation states may have associated media state values discussed further below in connection with . Media state values are one or more properties attributes or parameters associated with a particular media state.

More detailed descriptions of various exemplary media states follow. Retrieval states of video audio or data information from a particular media source may be defined based on various play speeds of played presentation . Certain user input changes the play speed of played presentation and thus the speed of retrieval of video audio or data information from a particular media source . For example played presentation may proceed in a forward direction at a normal speed and may also proceed in both forward and reverse directions at speeds faster or slower than the normal speed. It will appreciated that normal speed is a relative term and that normal speed may vary from presentation to presentation and from clip to clip.

A normal play retrieval state is defined to occur when played presentation proceeds in a forward direction at normal speed. A slow forward retrieval state is defined to occur when played presentation proceeds in a forward direction but slower than in real time. A fast forward retrieval state is defined to occur when played presentation proceeds in a forward direction but faster than in real time. A slow reverse retrieval state is defined to occur when played presentation proceeds in a reverse direction but slower than in real time. A fast reverse retrieval state is defined to occur when played presentation proceeds in a reverse direction but faster than in real time. A paused retrieval state is defined to occur when played presentation is paused by a user.

During fast reverse and fast forward retrieval states the playing of certain media content is often skipped. Other user input may cause the playing of certain content to be skipped such as when the user jumps from one part of the movie to another by making selections from interactive menus such as menu for example .

Retrieval states associated with locating and or beginning to play video audio or data information associated with a particular clip from a particular media source may also be defined. For example a closed state is defined to occur before video audio or data information associated with a particular clip has been read from a particular media source . A ready state is defined to occur when a first group of samples of video audio or data information from a particular media source has been decoded and is ready to be rendered. A pre rolling state is defined to occur between the closed state and the ready state when steps are being taken to prepare the first group of samples of video audio or data information from a particular media source for rendering. Other media samples may be concurrently presented using another media processing pipeline or media source however such as when play of the previous clip is ending or when preparing for an unexpected transition without immediately stopping previous playback. Preparation steps include but are not limited to reading information from a particular media source and demultiplexing decoding and or decrypting the information. It will be understood that the first group of samples of information from a particular media source is not necessarily the first group of samples occurring within a particular clip and that how a first group of samples is defined may vary from presentation to presentation based on factors such as encoding or encryption formats or protocols.

Media presentation states that indicate how or whether media data or IC data is presented within played presentation may also be defined. For example a media capture state may be defined that can occur in the paused retrieval state a media layout state may be used to indicate whether the layout of media data within played presentation is changing and an audio play state may be used to indicate whether certain audio effects are playing and a resource indicator state may be used to identify an interactive object or another resource presentable within played presentation .

Referring again to the elements of elapsed clip play times represent the amounts of time that have elapsed within particular presentation intervals associated with active clips . For purposes of discussion herein an active clip is one that has a presentation interval shown in within which the current title time of play duration falls based on presentation timeline . Time reference calculator receives time references and produces a media time reference . Media time reference represents the total amount of play duration that has elapsed based on one or more time references . In general when two or more clips are playing concurrently only one time reference is used to produce media time reference . The particular clip used to determine media time reference and how media time reference is determined based on multiple clips is a matter of implementation preference.

Time reference calculator receives timing signal media time reference and media state indicator signal and produces a title time reference . Title time reference represents the total amount of time that has elapsed within play duration based on one or more of the inputs to time reference calculator .

Time reference calculator receives timing signal and title time reference and produces application time reference s and page time reference s . A single application time reference represents an amount of elapsed time of a particular application play duration shown and discussed in connection with with reference to continuous timing signal . Application time reference is determined when title time reference indicates that the current title time falls within application presentation interval of the particular application. Application time reference re sets for example becomes inactive or starts over at the completion of application presentation interval . Application time reference may also re set in other circumstances such as in response to user events or when trick play occurs.

Page time reference represents an amount of elapsed time within a particular application play duration for a particular page of an application with reference to continuous timing signal . Page time reference for a particular page of an application is determined when title time reference indicates that the current title time falls within an applicable page presentation interval not shown . Page presentation intervals are sub intervals of application presentation intervals shown in . Page time reference s may re set at the completion of the applicable page presentation interval s not shown . Page time reference may also re set in other circumstances such as in response to user events or when trick play occurs. It will be appreciated that interactive object presentation intervals which may be sub intervals of application presentation intervals and or page presentation intervals are also definable.

Table 1 illustrates exemplary occurrences during play of played presentation by Presentation System and the effects of such occurrences on application time reference page time reference title time reference and media time reference .

Having access to various timelines clock sources timing signals and timing signal references enhances the ability of Presentation System to achieve frame level synchronization of IC data and media data within played presentation and to prioritize the glitch free presentation of the clips that comprise media component .

With continuing reference to is a flowchart of one method for enhancing the ability of a presentation system such as Presentation System to present the media content and interactive content of a particular presentation such as clips and interactive objects associated with applications shown on presentation timeline of in a synchronous manner. More specifically the method of relates to timing for execution of certain user inputs and application instructions that affect the content of played presentation .

The process es illustrated in may be implemented in one or more general multi purpose or single purpose processors such as processor discussed below in connection with . Unless specifically stated the methods described herein are not constrained to a particular order or sequence. In addition some of the described method or elements thereof can occur or be performed concurrently.

The method begins at block and continues at block where at least a portion of a media timeline such as media timeline discussed in connection with is ascertained. At block the media timeline is used to identify a current elapsed play time and a current state such as a current media state associated with a state of the presentation system at the current elapsed play time. The current elapsed play time represents a time within a play duration of the presentation when a current media sample from a current media source is being played to a user. The media timeline is also used to identify a predicted state such as a media state associated with a state of the presentation system at a future time for exemplary purposes the future time is identified as a predicted elapsed play time but the future time may be any future time or interval thereof at block . The predicted elapsed play time represents a time within the play duration when the next playable media sample from a next media source is playable to the user but it will be understood that at the future time s one or more future media samples may be playable to the user. At block an instruction or a user input is identified that is executable based on the current media state and at block the instruction is executed based on the predicted media state. Although it may be stated that a predicted elapsed play time is the time at which the next playable media sample is presentable it will be appreciated that several frames or seconds may be buffered so that the predicted elapsed play time may in fact be several frames or seconds in the future and not necessarily the next consecutive media sample or next frame.

A current elapsed play time of play duration is shown on media timeline . Current elapsed play time may be the current value of title time for example. A next presentable media sample presentation time is also shown. Next presentable media sample presentation time represents the media sample presentation time associated with the next media sample s after the current media sample associated with current elapsed play time title time that is presentable to a user. It will be appreciated that the next presentable media sample may be the next consecutive media sample based on playlist or may be a media sample one or more media sample presentation times away from the media sample associated with current elapsed play time .

One way to ascertain next presentable media sample presentation time is to predict an amount of elapsed time of play duration in addition to current elapsed play time title time that has passed based on the play speed and media frame rate . In one implementation predicted elapsed play time is calculated by estimating how many media sample presentation times on media timeline have passed since current elapsed play time title time . For example the predicted elapsed play time may be calculated by adding a multiplier value to current elapsed play time . The multiplier value is obtained by multiplying a play speed factor which may be a positive or a negative number depending on the direction of the play speed change by a frame rate factor. The play speed factor is obtained by dividing a value representing the play speed by media frame rate . The frame rate factor is obtained by dividing media frame rate by IC frame rate . Then predicted elapsed play time is used to locate the particular media sample presentation time that will be the next presentable media sample presentation time .

Often at various play speeds patterns can be observed between the predicted amount of elapsed time and media sample presentation times corresponding thereto and corresponding next presentable media sample presentation times . Recognizing such patterns may reduce the need to perform calculations at each media sample presentation time . The patterns can be represented in predetermined tables or other data structures which can be used to look up next media sample presentation times based on particular media sample presentation times . Using predetermined data structures or tables in this manner rendering of certain frames and other adjustments may be skipped. In addition multiple media timelines may be processed concurrently in an instance where more than one clip is playing for example .

Media state values are defined to describe one or more aspects of states of the presentation system at various times within media timeline . For exemplary purposes initial media state values current media state values and predicted media state values are defined at an initial play time not shown current elapsed play time and predicted elapsed play time respectively. In one implementation media state values describe aspects of a media state such as a media retrieval state or a media presentation state. It will be appreciated however that states of the presentation system may be other than media related states and that any time base may be selected other than media sample presentation times .

Definitions for a wide variety of media states and media state values are possible. In one scenario at a particular time a media retrieval state may be defined to have different media state values corresponding to paused normal slow forward fast forward slow reverse and fast reverse. Alternatively at a particular time multiple media retrieval states may be defined each having media state values assuming Boolean values. In another scenario at a particular time multiple media presentation states may be defined such as a media capture state a media layout change state and an audio effect play state. The media presentation states may have Boolean values indicating whether or not video is being recorded a media layout is changing or an audio effect is playing respectively. In a further scenario a media presentation state such as a resource indicator state may have a value corresponding to the URI or other identifier associated with an interactive object or another resource.

Certain media states and media state values may be dependent on other media states or media state values . For example the media capture state may only be set to true when a particular media retrieval state has a paused value or alternatively when the paused retrieval state is true .

When media state values describe aspects of a predicted media state the predicted media state is generally a state that will exist at predicted elapsed play time . In some instances however an additional or different predicted media state may exist at one or more pre rendering times not shown that precede predicted elapsed play time by amounts based on variable time offset values. Pre rendering involves retrieving and preparing for rendering certain interactive objects or portions of clips from media sources prior to the time at which such objects or clip portions are scheduled for presentation. Examples of media retrieval states associated with pre rendering times include but are not limited to the closed state the ready state and the pre rolling state.

IC presentation times on IC timeline represent times within play duration at which application instructions are executable and or interactive objects are presentable or selectable. As shown IC presentation times occur at a rate based on IC frame rate which also defines the duration of periodic interactive content time intervals between IC presentation times . For discussion purposes IC frame rate is assumed to be 30 frames per second although the presentation clock frequency may change dynamically.

A current interactive content presentation time current IC presentation time is ascertained based on current elapsed play time . Generally IC presentation time that corresponds to current elapsed play time represents current IC presentation time . If there is no IC presentation time on IC timeline that corresponds exactly to current elapsed play time another IC presentation time generally the closest one may be deemed to be current IC presentation time .

A next IC presentation time is also ascertained with reference to IC timeline . In one implementation next IC presentation time is the IC presentation time that corresponds to next presentable media sample presentation time on media timeline . Next IC presentation time may not be the next consecutive IC presentation time with respect to current IC presentation time . One reason for these differences is because IC frame rate may be different than media frame rate . Another reason is because user input may have affected the play speed and or direction of the presentation.

In the case where next IC presentation time occurs before next presentable media sample presentation time or when application instructions or user input otherwise arise before next presentable media sample presentation time is reached it can be seen that the content of played presentation may be affected. In particular unduly immediate or delayed execution of such application instructions or user inputs may affect the current state of the presentation system causing glitches in the play of media data or loss of synchronization between media data and IC data . It is desirable to identify certain application instructions and user inputs and to determine whether their effects are best executed and shown to a user immediately or whether they are better executed before after or instead of the effects of pre rendered material.

Generally data structure includes one or more current state portions one shown referred to for exemplary purposes as a current media state portion and one or more predicted state portions one shown referred to for exemplary purposes as a predicted media state portion . Current media state portion is used to reference one or more states of Presentation System for example media retrieval states or media presentation states at current elapsed play time shown in . Predicted media state portion is used to store one or more aspects of one or more states of Presentation System for example media retrieval states or media presentation states at predicted elapsed play time also shown in and or pre rendering times associated therewith.

Current media state values are associated with current media state portion and predicted media state values are associated with predicted media state portion . As play of media component and IC component progresses predicted state manager updates current media state values and predicted media state values.

In one implementation predicted state manager serves as a virtual media processing pipeline shown in having output that affects or is substituted for the output of a physical media processing pipeline . For example predicted state manager may be an implementation of one or more APIs such as virtual processing pipeline API both APIs and API are shown in which are accessed via instructions written by authors of applications . Predicted state manager may appear to application authors as a physical media processing pipeline . In other implementations predicted state manager may be located in other physical or logical components of Presentation System such as IC manager mixer renderer presentation manager or aspects of timing signal management components .

In the case where predicted state manager appears to application authors as a physical media processing pipeline at each media sample presentation time for example each video frame presentation time predicted state manager initializes current media state values within current media state portion with one or more values states associated with the values states of the current physical media processing pipeline. Then certain APIs that manipulate the physical media processing pipeline are sent to the predicted state manager. Predicted state manager updates predicted media state values to reflect the APIs and queues up the effects of the APIs so that they may affect the content of played presentation at desired times as if executed by the physical media processing pipeline.

In one practical example the current media retrieval state is assumed to be the normal play retrieval state and it is also assumed with reference to media timeline that a media sample such as a frame number is currently being played to a user. The next playable media sample is frame number and as part of frame number one application associated with IC component is to execute authored script which will pause played presentation . Another application will query the media retrieval state to determine whether played presentation is playing or paused.

At a pre rendering time for frame number predicted state manager initializes one or more current media state values for example one or more values that indicate that the current media retrieval state is the normal play retrieval state within current media state portion of data structure . The script command used to pause played presentation is authored script using an API that calls one or more functions implemented by predicted state manager . Predicted state manager records for example queues that the physical media processing pipeline should execute a pause command but the pause command may or may not be immediately sent to the physical media processing pipeline. The predicted state manager also initializes one or more predicted media state values for example one or more values that indicate that the predicted media retrieval state is the paused retrieval state within predicted media state portion of data structure .

When the other application queries the media retrieval state by communicating with the predicted state manager via an API for example predicted state manager returns the predicted media retrieval state the paused retrieval state instead of the current media retrieval state the normal play retrieval state . This is consistent with what the application author would expect and it is the same as what would have occurred if the pause command had been immediately executed by the physical media processing pipeline.

Once frame number has been pre rendered for example the ready state is reached the predicted state manager and or the physical media processing pipeline are notified. When the next presentable media sample presentation time shown in associated with frame number arises the physical media processing pipeline or another component of Presentation System requests the recorded queued commands from predicted state manager in this case finding the pause command. The recorded queued commands in this case the pause command may be executed before after or in place of the material of frame number .

It will be appreciated that the effects of various user inputs and application instructions can be determined with respect to a virtually unlimited number of states associated with Presentation System and recorded queued by predicted state manager for timed execution or for immediate execution . Some additional examples include but are not limited to whether or not certain sound effects are playing and which interactive objects are presentable to a user with which media samples. Certain user inputs or application instructions may change state information within predicted state manager while other user inputs or application instructions may rely on state information within predicted state manager such as methods that execute conditional processing based on state information .

One or more processors are responsive to computer readable media and to computer programs . Processor s which may be physical or virtual processors control functions of an electronic device by executing computer executable instructions. Processor s may execute instructions at the assembly compiled or machine level to perform a particular process. Such instructions may be created using source code or any other known computer program design tool.

Computer readable media represent any number and combination of local or remote devices in any form now known or later developed capable of recording or storing computer readable data such as the instructions executable by processor . In particular computer readable media may be or may include a semiconductor memory such as a read only memory ROM any type of programmable ROM PROM a random access memory RAM or a flash memory for example a magnetic storage device such as a floppy disk drive a hard disk drive a magnetic drum a magnetic tape or a magneto optical disk an optical storage device such as any type of compact disk or digital versatile disk a bubble memory a cache memory a core memory a holographic memory a memory stick or any combination thereof.

Computer programs represent any signal processing methods or stored instructions that electronically control predetermined operations on data. In general computer programs are computer executable instructions implemented as software components according to well known practices for component based software development and encoded in computer readable media such as computer readable media . Computer programs may be combined or distributed in various ways.

Functions components described in the context of Presentation System are not limited to implementation by any specific embodiments of computer programs. Rather functions are processes that convey or transform data and may generally be implemented by or executed in hardware software firmware or any combination thereof located at or accessed by any combination of functional elements of Presentation System .

With continued reference to is a block diagram of an exemplary configuration of an operating environment in which all or part of Presentation System may be implemented or used. Operating environment is generally indicative of a wide variety of general purpose or special purpose computing environments. Operating environment is only one example of a suitable operating environment and is not intended to suggest any limitation as to the scope of use or functionality of the system s and methods described herein. For example operating environment may be a type of computer such as a personal computer a workstation a server a portable device a laptop a tablet or any other type of electronic device such as an optical media player or another type of media player now known or later developed or any aspect thereof. Operating environment may also be a distributed computing network or a Web service for example. A specific example of operating environment is an environment such as a DVD player or an operating system associated therewith which facilitates playing high definition DVD movies.

As shown operating environment includes or accesses components of computing unit including processor computer readable media and computer programs . Storage includes additional or different computer readable media associated specifically with operating environment such as an optical disc which is handled by optical disc drive . One or more internal buses which are well known and widely available elements may be used to carry data addresses control signals and other information within to or from computing environment or elements thereof.

Input interface s provide input to computing environment . Input may be collected using any type of now known or later developed interface such as a user interface. User interfaces may be touch input devices such as remote controls displays mice pens styluses trackballs keyboards microphones scanning devices and all types of devices that are used input data.

Output interface s provide output from operating environment . Examples of output interface s include displays printers speakers drives such as optical disc drive and other disc drives and the like.

External communication interface s are available to enhance the ability of operating environment to receive information from or to transmit information to another entity via a communication medium such as a channel signal a data signal or a computer readable medium. External communication interface s may be or may include elements such as cable modems data terminal equipment media players data storage devices personal digital assistants or any other device or component combination thereof along with associated network support devices and or software or interfaces.

On client side one or more clients which may be implemented in hardware software firmware or any combination thereof are responsive to client data stores . Client data stores may be computer readable media employed to store information local to clients . On server side one or more servers are responsive to server data stores . Like client data stores server data stores may include one or more computer readable media employed to store information local to servers .

Various aspects of a presentation system that is used to present interactive content to a user synchronously with media content have been described. It will be understood however that all of the described components of the presentation system need not be used nor must the components when used be present concurrently. Functions components described in the context of Presentation System as being computer programs are not limited to implementation by any specific embodiments of computer programs. Rather functions are processes that convey or transform data and may generally be implemented by or executed in hardware software firmware or any combination thereof.

Although the subject matter herein has been described in language specific to structural features and or methodological acts it is also to be understood that the subject matter defined in the claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

It will further be understood that when one element is indicated as being responsive to another element the elements may be directly or indirectly coupled. Connections depicted herein may be logical or physical in practice to achieve a coupling or communicative interface between elements. Connections may be implemented among other ways as inter process communications among software processes or inter machine communications among networked computers.

The word exemplary is used herein to mean serving as an example instance or illustration. Any implementation or aspect thereof described herein as exemplary is not necessarily to be constructed as preferred or advantageous over other implementations or aspects thereof.

As it is understood that embodiments other than the specific embodiments described above may be devised without departing from the spirit and scope of the appended claims it is intended that the scope of the subject matter herein will be governed by the following claims.

