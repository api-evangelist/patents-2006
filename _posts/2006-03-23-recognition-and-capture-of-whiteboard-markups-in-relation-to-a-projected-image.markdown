---

title: Recognition and capture of whiteboard markups in relation to a projected image
abstract: The computer implemented method, apparatus, and computer program product for capturing markup layers on a whiteboard in relation to a projected image. A presentation page is displayed on a whiteboard as the projected image. A set of markups on the whiteboard associated with the presentation page is identified. The set of markups on the whiteboard is isolated from the projected image of the presentation page to create a user input layer. The user input layer is saved as an overlay for the presentation page.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07880719&OS=07880719&RS=07880719
owner: International Business Machines Corporation
number: 07880719
owner_city: Armonk
owner_country: US
publication_date: 20060323
---
The present invention relates generally to an improved data processing system and in particular to an improved method apparatus and computer program product for capturing user input. In particular the present invention is directed to a computer implemented method apparatus and computer program product for recognizing and capturing whiteboard markup layers in relation to a projected image.

During conferences and meetings in which a presentation display is projected onto a whiteboard a presenter will frequently make annotations or markups of the presentation by drawing on the whiteboard with a marker directly over the projected presentation. Mark ups and annotations made onto the whiteboard by the presenter are visible to meeting attendees physically present in the conference room. However if the meeting is also a teleconference meeting attendees that are not physically present in the conference room are at a significant disadvantage because they may not be able to see the mark ups being made by the presenter.

Attempts to solve this problem have included using a stand alone camera to capture the presentation on video. However the presentation can loose resolution and image quality due to camera limitations and environmental factors such as room lighting conditions and objects and or people obstructing the camera s view.

A projector can be used to display a presentation image from a computer that permits the image to be modified using traditional computer input devices such as a mouse or keyboard. However traditional input devices are not as natural or convenient for humans to use as a pen on a whiteboard.

Rather than using a mouse or keyboard a digitizing tablet input device may be utilized. In a projected environment however digitizing tablets require a user to monitor the projected display while writing on the tablet. Moreover tablet devices provide only a small input space. In addition a digitizing tablet keyboard or mouse must be shared by all users.

Electronic whiteboards permit more natural input from users. However electronic whiteboards are also more costly which limits widespread installation of these devices. Moreover because electronic whiteboards are large they are not easily moved or shared between users. In addition the size of a projected image is limited to the size of the whiteboard itself.

The aspects of the present invention provide a computer implemented method apparatus and computer program product for capturing markup layers on a whiteboard in relation to a projected image. A presentation page is displayed on a whiteboard as the projected image. A set of markups on the whiteboard associated with the presentation page is identified. The set of markups on the whiteboard is isolated from the projected image of the presentation page to create a user input layer. The user input layer is saved as an overlay for the presentation page.

With reference now to the figures and in particular with reference to exemplary diagrams of data processing environments are provided in which embodiments of the present invention may be implemented. It should be appreciated that are only exemplary and are not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the present invention may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.

With reference now to the figures depicts a pictorial representation of a network of data processing systems in which aspects of the present invention may be implemented. Network data processing system is a network of computers in which embodiments of the present invention may be implemented. Network data processing system contains network which is the medium used to provide communications links between various devices and computers connected together within network data processing system . Network may include connections such as wire wireless communication links or fiber optic cables.

In the depicted example server and server connect to network along with storage unit . In addition clients and connect to network . These clients and may be for example personal computers or network computers. In the depicted example server provides data such as boot files operating system images and applications to clients and . Clients and are clients to server in this example. Network data processing system may include additional servers clients and other devices not shown.

In the depicted example network data processing system is the Internet with network representing a worldwide collection of networks and gateways that use the Transmission Control Protocol Internet Protocol TCP IP suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high speed data communication lines between major nodes or host computers consisting of thousands of commercial governmental educational and other computer systems that route data and messages. Of course network data processing system also may be implemented as a number of different types of networks such as for example an intranet a local area network LAN or a wide area network WAN . is intended as an example and not as an architectural limitation for different embodiments of the present invention.

With reference now to a block diagram of a data processing system is shown in which aspects of the present invention may be implemented. Data processing system is an example of a computer such as server or client in in which computer usable code or instructions implementing the processes for embodiments of the present invention may be located.

In the depicted example data processing system employs a hub architecture including north bridge and memory controller hub NB MCH and south bridge and input output I O controller hub SB ICH . Processing unit main memory and graphics processor are connected to NB MCH . Graphics processor may be connected to NB MCH through an accelerated graphics port AGP .

In the depicted example local area network LAN adapter connects to SB ICH . Audio adapter keyboard and mouse adapter modem read only memory ROM hard disk drive HDD CD ROM drive universal serial bus USB ports and other communication ports and PCI PCIe devices connect to SB ICH through bus and bus . PCI PCIe devices may include for example Ethernet adapters add in cards and PC cards for notebook computers. PCI uses a card bus controller while PCIe does not. ROM may be for example a flash binary input output system BIOS .

HDD and CD ROM drive connect to SB ICH through bus . HDD and CD ROM drive may use for example an integrated drive electronics IDE or serial advanced technology attachment SATA interface. Super I O SIO device may be connected to SB ICH .

An operating system runs on processing unit and coordinates and provides control of various components within data processing system in . As a client the operating system may be a commercially available operating system such as Microsoft Windows XP Microsoft and Windows are trademarks of Microsoft Corporation in the United States other countries or both . An object oriented programming system such as the Java programming system may run in conjunction with the operating system and provides calls to the operating system from Java programs or applications executing on data processing system Java is a trademark of Sun Microsystems Inc. in the United States other countries or both .

As a server data processing system may be for example an IBM eServer pSeries computer system running the Advanced Interactive Executive AIX operating system or the LINUX operating system eServer pSeries and AIX are trademarks of International Business Machines Corporation in the United States other countries or both while LINUX is a trademark of Linus Torvalds in the United States other countries or both . Data processing system may be a symmetric multiprocessor SMP system including a plurality of processors in processing unit . Alternatively a single processor system may be employed.

Instructions for the operating system the object oriented programming system and applications or programs are located on storage devices such as HDD and may be loaded into main memory for execution by processing unit . The processes for embodiments of the present invention are performed by processing unit using computer usable program code which may be located in a memory such as for example main memory ROM or in one or more peripheral devices and .

Those of ordinary skill in the art will appreciate that the hardware in may vary depending on the implementation. Other internal hardware or peripheral devices such as flash memory equivalent non volatile memory or optical disk drives and the like may be used in addition to or in place of the hardware depicted in . Also the processes of the present invention may be applied to a multiprocessor data processing system.

In some illustrative examples data processing system may be a personal digital assistant PDA which is configured with flash memory to provide non volatile memory for storing operating system files and or user generated data.

A bus system may be comprised of one or more buses such as bus or bus as shown in . Of course the bus system may be implemented using any type of communication fabric or architecture that provides for a transfer of data between different components or devices attached to the fabric or architecture. A communication unit may include one or more devices used to transmit and receive data such as modem or network adapter of . A memory may be for example main memory ROM or a cache such as found in NB MCH in . The depicted examples in and above described examples are not meant to imply architectural limitations. For example data processing system also may be a tablet computer laptop computer or telephone device in addition to taking the form of a PDA.

During conferences and meetings in which a presentation image is projected onto a whiteboard a presenter will frequently make annotations or markups of the presentation by drawing on the whiteboard with a marker directly over the projected presentation. However if the meeting is also a teleconference meeting attendees that are not physically present in the conference room are at a significant disadvantage.

Attempts to solve this problem have included using a stand alone camera to capture the presentation on video using a computer mouse keyboard or digitizing tablet to enter input or utilization of costly electronic whiteboards. However the aspects of the present invention recognize that capturing input in these ways can place physical constraints on the presenter limit the presentation image quality and resolution and or result in increased costs for users.

Generally the most natural position for a presenter of a presentation is standing in front of a conference or meeting room and pointing or drawing directly over the projected image projected on a whiteboard. Thus the aspects of the present invention recognizes a need exists for the capability to capture human input in the form of markups while permitting a more natural interaction with the projected image on a whiteboard but without the additional cost and limitations of using electronic whiteboards.

In addition unless captured human input is normalized in relation to the projected image the captured input cannot be saved as an overlay to the projected image. Further capturing the projected image and markup together does not permit a user to save and manage user input in a markup layer separately from the presentation page itself. Thus aspects of the present invention also recognize a need exists for the ability to save multiple overlays of user markups such that each markup overlay can be tied to a specific page of a presentation. In addition in a network environment that involves multiple users creating multiple overlays each specific overlay can be tied to or associated with a specific user that made the markups in the specific overlay.

As used herein a presentation page includes any type of pre prepared drawings figures text words graphs diagrams charts lines or dots on a page slide or other format prepared for display by a projection device at a meeting or conference. A projection device includes but is not limited to a projector or other device capable of projecting an image onto a screen or whiteboard. An example of a presentation page includes but is not limited to a power point presentation page.

Therefore the aspects of the present invention provide an improved computer implemented method apparatus and computer program product for recognizing and capturing whiteboard markup layers in relation to a projected image. Markup capture is a mechanism of the present invention that allows a user to draw directly on an ordinary non electronic whiteboard. A markup manager captures the markups using a camera and filter to isolate markups from the original presentation display.

Thus as a user draws and erases during a presentation the markup is captured by the markup manager in real time. As used herein the term markup includes marks made on a whiteboard by a marker or writing implement of any type or color. For example a marker could include but is not limited to a dry erase type marker of any color.

Computer is connected to any type of known or available projector capable of displaying a projected presentation display onto whiteboard such as projector . Projector projects an image onto a whiteboard such as whiteboard in a meeting room. In this illustrative example whiteboard is a standard non electronic whiteboard.

The initial active user is located at meeting location . In accordance with one embodiment of the present invention a single presenter begins a presentation and assumes control of the presentation as the initial active user. Control of the presentation can be switched to another active user at any time during a presentation. As used herein an active user is a presenter that is creating capturing controlling and or manipulating a whiteboard based markup layer corresponding to a projected page at a meeting location such as a conference room.

A camera such as camera is connected to computer via a universal serial bus USB a FireWire port on computer or any communications port on computer . A FireWire port is a port that follows the I.E.E.E. 1394 standard. In this illustrative example computer is also connected to remote meeting locations through network device that connects to a network connection such as network in .

Computer can be connected through the network to other remote meeting locations with one or more other active users remote meeting locations with one or more passive users and or to individual users not located at meeting location . In other words a remote meeting location is any location separate or apart from a conference room or meeting location where the current active user is physically located. As used herein a remote meeting location includes a different room in the same building as the active user s meeting location as well as a different building city state or country as the current active user s meeting location . Users at remote meeting location s have the same capabilities as users at meeting location . Remote meeting location s do not require presentation application because presentation application always runs on the computer of the initial active user.

Presentation application runs on the computer of the initial active user even if control of the presentation is passed to one or more other active users. Control can be passed to another active user at the same physical location as the first active user at meeting location or to another active user at one or more remote meeting location s .

In accordance with this illustrative embodiment of the present invention the initial active user s computer is the only one running presentation application . Passive users receive the video output from the active user s computer from the network through network device . Passive users do not require a copy of presentation application or the original presentation documents such as presentation page s . As used herein the term passive user refers to a user viewing a presentation display either at the same location as one or more active users and or at a remote location to one or more active users. A passive user passively views a presentation display presented by the active user. In addition the passive user can merge existing overlays with the presentation for viewing by the passive user or hide overlays from view at the passive user s own computer display. However the passive user does not create and capture new input layers or control the presentation viewed by any other active or passive user.

Markup manager utilizes calibrator to normalize a markup image received from camera and to calibrate filter . Calibrator performs calibration functions prior to beginning a presentation display. Calibrator performs an orthogonality calibration to enable markup manager to recognize which part of a markup image received from camera is the whiteboard image. This calibration also enables markup manager to make adjustments for oblique angles of the projection.

Calibrator performs a dark level calibration to calibrate filter . This calibration is performed to accurately distinguish between markups created by a user upon whiteboard and images projected onto whiteboard such as a user using a black marker and the darkest black projected by projector . The black marker markup will be darker than the black projected by projector . Based upon this determination calibrator sets a clip level that allows filter to differentiate user created black markups on whiteboard from a projected image projected by projector . So if for example the white value of a black markup pixel is five 5 out of 255 while the darkest black that can be produced by the projector has a white value of twenty one 21 the clip logic will be set to a clip level of between five 5 and twenty one 21 . Assuming the midpoint value 5 21 2 13 was used for the clip level then pixels in the camera image with a white value below thirteen 13 would be considered part of the markup layer.

Calibrator also calibrates defect filter to enable filter to ignore defects in a whiteboard surface on whiteboard that might otherwise appear to be user markups. Defects could include scratches seams and set in stains and marks that cannot be erased.

Calibrator calibrates defect filter by projecting a white image onto cleaned whiteboard . Calibrator applies a clip level determined during the dark level calibration to identify any defects in whiteboard that could be falsely interpreted as a markup. This information is saved in filter for use by defect filter . Defect filter filters marks from markup images received from camera that are likely due to defective areas on whiteboard . Marks identified as defects are not included in user input layer . Instead defect marks are simply ignored.

In the illustrative example shown in a presenter opens a presentation application on computer for display by projector onto whiteboard . The presentation is opened from within markup manager . Markup manager places the presentation in presentation mode by interfacing with a presentation controller . The presentation controller combines the video content from the presentation application with the user input layers . The initial active user creates the video content from presentation application . The video content from the presentation content is shared with all active and passive users at meeting location or any remote meeting locations . Presentation application can be any known or available presentation format for use on computer including but not limited to PowerPoint and Freelance Graphics.

The presenter initiates display of presentation page of the presentation session. Presentation controller displays the current presentation page and selected user input layers on computer full view screen or active window. The presentation is controlled within presentation controller so that when for example a user transitions from one presentation page to a different presentation page presentation controller can recognize that a different presentation page in the presentation is being viewed and can overlay with the associated input layers. A user can transition from one presentation page to a different presentation page for example by pressing a page up control to transition to the next page or pressing a page down control to transition to a previous page.

Presentation page and selected user input layers are merged by presentation controller and transmitted to projector for display on whiteboard . Camera records an image of the projected image displayed on the whiteboard to form camera image . Camera image is a picture of projected image together with markups made on whiteboard by one or more users. The series of black marks on whiteboard form black markup layer. Thus camera image comprises projected image and a black markup layer.

Filter filters camera image using defect filter to eliminate marks in the image caused by defects in whiteboard . Filter utilizes dark level filter to isolate black markup layer from presentation page based upon a difference in brightness level of the black markups and the projected black.

In other words dark level filter separates black markup layer from the original presentation page by determining a black level of the black markup layer relative to a black level of the projected image to form a user input layer. The black markup layer will be a darker black. Thus the black markup layer can be isolated and saved to form user input layer . User input layer includes only the markups and human input created by user at whiteboard . User input layer does not include any content from original presentation display projected by projector .

User input layer is saved in set of user input layers in database . Set of user input layers comprises one or more user input layers associated with a specified presentation page in a plurality of presentation pages for a presentation.

Set of user input layers is linked to presentation pages . In accordance with an embodiment of the present invention each presentation page is assigned a page identifier. When user input layer is stored within set of user input layers in database a page identifier for presentation page is stored in database with set of user input layers identifying presentation page as the page to which set of user input layers is linked.

In this manner set of user input layers is associated with a specified presentation page in a plurality of presentation pages within a given presentation. Moreover a different set of input layers can be stored in database in association with each different presentation page in the plurality of presentation pages in a given presentation.

Presentation page and a set of user input layers are transmitted to a set of remote meeting locations. A set of remote meeting locations comprises one or more remote meeting locations such as remote meeting locations via a network using any known or available conferencing applications such as Windows Net Meeting and WebEx Web Conferencing. Active user s can transmit one or more user input layers associated with presentation page to remote meeting location for display of user input layers as overlays to presentation page .

In accordance with this illustrative example set of user input layers and presentation page are transmitted dynamically over the network to remote meeting location . However presentation page is transmitted separately from set of user input layers to allow for other active users to switch the user input layers being displayed as overlays to presentation page .

Control of markup capture can be transferred to a second active user at remote meeting location . Moreover in accordance with another illustrative embodiment multiple active users can capture real time markups simultaneously. In such a case presentation controller dynamically incorporates each different active user s markups into presentation page for display in real time. Thus multiple secondary active users can create user input layers simultaneously.

Multiple active user input layers can be created captured and saved in association with presentation page either in real time or at staggered times in addition to set of user input layers generated by a primary active user utilizing computer . The additional user input layers associated with presentation page created by a second active user or multiple other secondary active users can be transmitted back to computer .

Additional other active users at the same location or at other remote locations can create capture save and transmit other user input layers associated with presentation page . In addition user input layers can be created and captured for other presentation pages in the plurality of presentation pages in the given presentation in the same manner as is described above with regard to presentation page .

Presentation controller processes one or more user input layers in set of user input layers for display as an overlay in conjunction with one or more presentation pages. As used herein an overlay is user input layer contents such as is shown in that can be overlaid on top of incorporated into or otherwise displayed in conjunction with the original presentation page or any other presentation page. In addition an overlay can be merged with a presentation page in conjunction with one or more other overlays just as transparencies can be stacked on top of one another in such a way that the graphics text on each transparency is visible simultaneously in an overlapping fashion.

For example if a presentation page is a bar graph showing revenues for to and an active user makes a markup to the graph adding revenues projected for the revenues markup can be captured as user input layer and stored in database . If an active user selects to display user input layer showing projected revenues for in conjunction with any presentation page presentation controller retrieves user input layer and transmits user input layer as an overlay to projector for display in conjunction with displayed presentation page . In accordance with this illustrative embodiment presentation application is a separate component from presentation controller . However in accordance with another embodiment of the present invention presentation application and presentation controller are embodied within a single component.

In accordance with an illustrative example each user input layer in set of user input layers stored in database can be assigned a unique color such that each user input layer is a different color from every other user input layer when displayed as an overlay by projector or on any computer and or digital display. Each user input layer can be assigned a unique color based upon the user that created the input layer and or the meeting location.

In another embodiment of the present invention each saved user input layer in set of user input layers can be assigned to a different function key. Thus a user can select to display a particular user input layer by pressing the function key associated with that user input layer. The function key can be pressed again to remove the overlay associated with the function from display in conjunction with presentation page . However the embodiments of the present invention are not limited to selecting user input layers by selecting function keys. For example a user input layer can be selected by a user in accordance with the embodiments of the present invention utilizing any known or available methods for selecting data in a database including but not limited to selecting or clicking on an icon on a graphical user interface or selecting a menu item on a menu driven interface.

In another exemplary embodiment of the present invention one or more user input layers can be displayed simultaneously as overlays to presentation page by pressing a function key assigned to each user input layer to be displayed. In an example in which multiple user input layers are displayed simultaneously the user input layers are displayed as overlays in a stacked fashion such that multiple overlays are visible simultaneously. In an illustrative example each user input layer can be displayed in a different color such that each overlay is distinguishable from every other overlay in the stack based upon the color of the user input layer.

In accordance with the aspects of the present invention a user input layer can be displayed as an overlay to presentation page in collaboration with multiple other overlays. In such a case a user selects a set of user input layers to display as overlays to presentation page . Each selected user input layer is overlaid on the projected image of presentation page in the active user s meeting location as well as on all other remote meeting locations such as remote meeting location .

Likewise one or more user input layers in set of user input layers can be hidden from display such that only certain user input layers are displayed as overlays and one or more hidden user input layers are not displayed in conjunction with presentation page . Thus a user input layer can be hidden from display with presentation page or deleted from set of user input layers in database .

In an illustrative embodiment database can store presentation page in conjunction with one or more overlays as a modified presentation page. Thus presentation page can be saved in database as multiple different modified versions of presentation page in which one or more different overlays are incorporated into each different version of the modified presentation page.

In an alternative illustrative embodiment camera and projector are embodied within a single unit such that camera is a component within projector .

In an illustrative example in which all users at a meeting location are passive users computer is connected to one or more master conference locations though a network such as network in . A master conference location is a meeting location such as meeting location at which one or more active users are located. In such a case computer is optionally connected to projector and camera .

In another exemplary embodiment of the present invention an active user creates and stores one or more user input layers associated with a presentation page in database without transmitting input layers to remote meeting locations . User input layers can be viewed and or manipulated by one or more users after the conference or meeting has concluded rather than in real time during the meeting. In such a case computer is optionally connected to remote meeting locations via a network.

In another embodiment of the present invention an active user must sign on or log on to markup manager on computer with a user name in order to initiate a markup capture of a markup layer associated with a presentation page. A user name could be a name associated with the active user or with the active user s conference location.

In another exemplary embodiment of the present invention a playback and print facility is provided by computer . The playback and print facility permits a passive user to view overlays associated with a particular presentation page at a later point in time such as after a conference has concluded. The playback and print feature permits the active user to update a presentation page to include one or more user input layers as a part of presentation page rather than only as an overlay to presentation page . Thus a user can update presentation page to contain content from one or more user input layers such that the presentation page reflects changes made during the course of a presentation as markups to presentation page .

A user creates markups on whiteboard using a marker marking pen or writing implement of any arbitrary color. Camera is a color camera. Camera captures an image of markups on whiteboard to form color camera image . Color camera image is an image of user markups made on whiteboard without presentation page projected onto whiteboard. Thus color camera image is an image of markups on whiteboard without projected image projected on whiteboard .

In order to capture color camera image camera takes a picture of markups on whiteboard during an interval in which projected displays a white background rather than presentation page . Presentation controller coordinates a periodic interval in which the projected image is blanked out and replaced by a projected background. The projected background can be any light color to illuminate markups on whiteboard . For example the projected background can be a pure white background an off white background a light gray background or any other light colored background to illuminate the markup layer. Camera opens a shutter associated with camera to capture an image of markups on whiteboard illuminated by the projected white gray background to create color markup layer during the interval in which presentation page is blanked and the white gray background is displayed by presentation controller .

Presentation controller coordinates a timing control sequence composed of sending a white gray background image to projector and a snapshot signal to camera to initiate opening of the camera shutter of camera to capture a color camera image . Shutter control controls the timing relationships between the blanking signal sent to the projector and the opening of the camera shutter and shutter speed required for proper exposure of the markups. After color markup layer has been captured the projector replaces the projected white gray background with the projected image of presentation page .

Markup manager utilizes calibrator to normalize an image of user markups such as color camera image received from camera as well as to calibrate filter . Defect filter removes marks in color camera image due to defects in the surface of whiteboard . In this manner user input layer is formed from user markups made in any arbitrary color on whiteboard .

User input layer is saved in set of user input layers in database . Set of user input layers comprises one or more user input layers associated with a specified presentation page in a plurality of presentation pages. Presentation controller retrieves user input layer to create an overlay for display in conjunction with presentation page .

In accordance with this illustrative embodiment set of user input layers and presentation page are transmitted dynamically over the network to one or more remote meeting location s .

In an alternative embodiment shutter control can be eliminated from camera and embodied within markup manager . In this embodiment camera continuously sends a camera image to markup manager . Markup manager selects camera image frames which correspond with the interval during the strobe of the white gray pulse from projector . Markup manager disregards camera image frames captured outside of the white gray pulse interval when presentation page is displayed on whiteboard by projector .

Calibrator performs dark level calibration so that the filter can distinguish between black markup content and the presentation page in a markup image received from the camera. The calibrator takes advantage of the fact that a distinct difference in brightness level exists between the darkest black of a projected black background and the darkest black of a black markup on a whiteboard. The black marker onto the whiteboard will be darker than a projected black color of the projected image.

Calibrator also performs an orthogonality region calibration to enable the markup manager such as markup manager in to recognize which portion of a markup image received from the camera in the active display image on the whiteboard image. Orthogonality calibration also enables the markup manager to make adjustments for oblique angles of projection. Orthogonality region calibration is accomplished by projecting a nearly full screen black background of calibration image with white targets in each corner. The calibrator is able to determine the whiteboard size and right angles of the whiteboard relative to a projected image so that all marks within a markup image received from the camera can be merged at the correct pixel location corresponding to the projected image of the presentation page.

Calibration image is displayed on a whiteboard. Calibration image includes a white target referred to as a dark level calibration target located on a projected black background of calibration image. A user colors in the target area of calibration target as shown in .

The calibrator analyzes the markup image received from the camera and compares the brightness level of the projected black background relative to the black marker on target location to establish a clip level. Once established the clip level allows the system to differentiate the black markup content made by the black marker or black marking pen from the image projected by the projector or any other displayed video content.

At time period the projection is transitioned from displaying normal presentation matter to displaying a pure white background. This transition can occur at a specific schedule. For example the normal presentation matter can be transitioned to the white gray light every five 5 seconds.

At time period a pure white or gray screen or background is projected by projector and the camera shutter is held open to capture markup data in the color markup layer. Because presentation page is not projected by projector the markup data captured by the camera does not include any of the normal presentation matter associated with the color markup layer.

Time period occurs after the camera shutter has closed but before the white background is replaced by the normal presentation data on the projected display. This interval of time occurs to ensure that the camera shutter is not still open when the presentation image is displayed onto the whiteboard again during time period .

In this illustrative example the process of blanking the projector image and opening a camera shutter to capture a color markup layer occurs at regular intervals in order to capture a constant stream of real time markup updates.

In another alternative a shutter control transition occurs only when a user selects to capture a color markup layer such as in a snapshot mode. In a snapshot mode the camera only captures an image of the whiteboard wherein a user selects a control to cause the blanking interval to occur. A user selects the blanking interval control each time the user wants to capture an image of markups on the whiteboard.

The snapshot mode can reduce flicker problems that may occur during a constant duty cycle of screen blanking in a real time markup capture of markups at regular intervals. In addition a user can utilize the snapshot mode where a final markup of a presentation page is only needed once all markups are complete. For example if the final markup version will be merged into an updated version of the presentation page at the end of the presentation a markup capture need only occur once after all markups are complete.

In another illustrative embodiment a shutter control controls the timing relationships between the blanking signal sent to the projector and the opening of the camera shutter and shutter speed required for proper exposure of the markups. The shutter control is calibrated to adjust the operating parameters of the projector and camera so that the data capture is optimized. The calibration also minimizes flickering that occurs during the blanking intervals.

System projects test pattern that covers the entire screen area using a fine grid of horizontal and vertical lines. The system then captures this as a reference image.

The system adjusts interval which is the time period between turning off the displayed image and starting the image capture until the smallest time is found where no residual test pattern luminance appears in the captured image.

The system projects pure white to illuminate the X and then the system adjusts the camera shutter time at interval until the minimum value is found to accurately capture the X .

The performs the actions of interval and interval and adjusts interval time between signaling a shutter close and representing the grid until the minimum value for interval is found

Now the minimum timing to allow markup capture. The system then finds the minimum time that the shutter must stay open in order to capture the X at interval .

Now the minimum timing for capturing the markup data is known. The final calibration step determines the maximum time of normal projection that is required to minimize flickering yet permit the desired markup capture rate. In one illustrative embodiment the final calibration is a manual setting where the operator is allowed though a setup interface to adjust timing to the point where flickering is longer noticeable. Thus the fastest markup capture rate is obtained while preventing or at least minimizing visual disturbances caused by the markup image capture.

The process receives a camera image from a camera step . The camera image is an image of a presentation page displayed on a whiteboard with markups. The process isolates a black markup content using a dark level filter to form a user input layer . If a user input is not greater than a clip level the input is ignored. The user input layer is stored in database step .

The process receives a user selection of a user input layer for display in conjunction with a presentation page step . The process retrieves the selected user input layer from a database and sends the user input layer to a projector for display as an overlay to the presentation page step with the process terminating thereafter.

In accordance with an exemplary embodiment of the present invention if one or more other overlays are already being displayed as overlays to presentation page the user input layer can be displayed as an additional collaboration layer in conjunction with the other overlays. In this illustrative example each overlay is displayed in a different color to distinguish between the various different overlays.

The process begins by determining whether a white gray strobe capture has been selected step . If the white gray strobe capture has not been selected the process terminates.

If the white gray strobe capture has been selected the process determines if a snapshot mode is selected step . If a snapshot mode is not selected the process displays a presentation page onto a whiteboard step . The process then determines if a given time interval has expired step . If the given interval of time has not expired the process returns to step . If the given interval has expired the process initiates a transition of the projected display of the presentation page to a projected display of a white background step .

Next the process opens a camera shutter to capture an image of the markup layer on the whiteboard while the white background is projected on the whiteboard step . The process closes the camera shutter step and reinitiates display of the presentation page step .

If the process determines that a user has not selected to end the process the process returns to step to await the expiration of the given time interval at which time the process will continue to capture a next markup layer.

Returning now to step if a user has selected a snapshot mode the process determines if a user has selected to capture a markup layer step . If the user has not selected to capture a markup layer the process returns to step until a user chooses to capture a markup layer.

If the user has selected to capture a markup layer the process initiates a transition of the projected display of presentation page to a projected display of a white background step . The process opens a camera shutter to capture an image of the markup layer step . Next the process closes the camera shutter step and initiates display of the presentation page step by the projector.

Finally the process determines if a user has selected to end the process step . If a user not selected to end the process the process returns to step until a user selects to capture a next markup layer. If a determination is made that a user has selected to end the process the process terminates thereafter.

Thus the aspects of the present invention provide a method for capturing handwriting and other free from natural human input made by marking on a standard non electronic whiteboard without the expense of purchasing costly pens digitizing tablets electronic whiteboards and or sensors. In addition this method apparatus and computer program product permit more natural human interaction with a projected image on a whiteboard. Moreover the presently claimed invention operates using existing commonly used display projection equipment cameras and computers.

In accordance with the illustrative embodiments of the present invention user markups made on a whiteboard can be merged with presentation content without distortion or losses to the content. In addition multiple users located in the same physical location or geographically separated are enabled to interactively collaborate by creating viewing and manipulating multiple user input layers associated with a specified presentation page.

The invention can take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment the invention is implemented in software which includes but is not limited to firmware resident software microcode etc.

Furthermore the invention can take the form of a computer program product accessible from a computer usable or non transitory computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any tangible apparatus that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium can be an electronic magnetic optical electromagnetic infrared or semiconductor system or apparatus or device or a propagation medium. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

A data processing system suitable for storing and or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input output or I O devices including but not limited to keyboards displays pointing devices etc. can be coupled to the system either directly or through intervening I O controllers.

Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modem and Ethernet cards are just a few of the currently available types of network adapters.

The description of the present invention has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

