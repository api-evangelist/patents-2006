---

title: System and method for synchronizing data
abstract: Systems and methods are disclosed for presenting a media stream to user next adjacent to text and other content via a graphical user interface. The graphical user interface allows allowing the user to select part of the content and associate it with a specified portion of the media stream. The a graphical user interface that displays and renders a media stream, such as a video stream, to a user in a first display area. Near the first display area is a second display area displaying content, such as text, to be associated with some portion of the media stream. The interface allows a user to select some of the content in the second display area with a pointing device. The selection also identifies a portion of the media stream based on what is being rendered as the selection is made and how the selection is made.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07900145&OS=07900145&RS=07900145
owner: Yahoo! Inc.
number: 07900145
owner_city: Sunnyvale
owner_country: US
publication_date: 20061108
---
A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by any one of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

Various computing methodologies exist or have been proposed for easily tagging or otherwise marking different portions of media streams with metadata. Such methodologies will allow a user to create and associate data referred to as metadata to the renderable data of a preexisting media stream. For example specific text or other data may be tagged to a specific portion of a video stream so that when the stream is played back i.e. rendered by a suitable media player the text is displayed by the media player during the specified portion of the video stream.

Different methodologies have been proposed that generally include creating metadata with the tagging information and then associating the data with the media stream data in some way. The term tagging will be used herein to broadly refer to associating a first set of data metadata with media stream data. In one proposed method a new file containing the media stream s data and the metadata is created so that the media stream data is not edited or changed. In another method a separate file of metadata is created that is then associated with the media file so that both are utilized upon playback. Other methodologies have also been proposed. Such methodologies are useful in creating close captioned video streams and generally in adding data to be displayed with pre existing media streams.

Currently however user interfaces for such tagging methodologies are still the complicated user interfaces that have been developed for audio and video remixing systems. Because remixing systems typically combine the text or other data to be displayed with the actual data of the media stream to create a combined media stream with little or no metadata.

Against this backdrop systems and methods have been developed for presenting a media stream to user next to text and other content in an interface allowing the user to select part of the content and easily associate it with a specified portion of the media stream. The system includes a graphical user interface that displays and renders a media stream such as a video stream to a user in a first display area. Near the first display area is a second display area displaying content such as text to be associated with some portion of the media stream. The interface allows a user to select some of the content in the second display area with a pointing device. The selection also identifies a portion of the media stream based on what is being rendered as the selection is made and how the selection is made.

In one aspect the invention may be considered as a method for associating text elements with different a portion of a video stream. The method includes rendering the video stream to a user in a video display area and simultaneously displaying one or more text elements to the user in a touch sensitive text display area. The method further includes detecting a first touch at a first location on the touch sensitive text display area as a portion of the video stream is being rendered. In addition the method includes selecting at least one text element in the text display area based on the first location of the touch and associating in response to the touch the selected at least one text element with the portion of the video stream.

In yet another aspect a method is disclosed for associating text elements to be selectively displayed with different portions of a media stream. The method includes rendering the media stream to a user and simultaneously displaying one or more text elements to the user in a text display area. The method further includes receiving a user input as a portion of the media stream is being rendered the user input selecting at least one text element in the text display area. The method further associates in response to the user input the selected at least one text element with the portion of the video stream.

In yet another aspect a graphical user interface GUI is disclosed which includes a first media display area in which a selected media stream is rendered over time. The GUI also includes a second media display area rendering one or more data elements to be associated with different portions of the media stream. In addition the GUI includes a user controlled selector allowing a user to select and associate at least one data element in the second display area with a currently displayed portion of the selected media stream in the first media display area.

In yet another aspect a computer readable medium encoding computer executable instructions for performing a method for associating displayable elements to be selectively and concurrently displayed with different portions of a video stream is disclosed. That method includes rendering the video stream to a user and simultaneously displaying one or more displayable elements to the user in a display area. In addition the method includes receiving a user input as a portion of the video stream is being rendered the user input selecting at least one displayable element in the display area. The method also includes associating in response to the user input the selected at least one displayable element with the portion of the video stream.

These and various other features as well as advantages will be apparent from a reading of the following detailed description and a review of the associated drawings. Additional features are set forth in the description which follows and in part will be apparent from the description or may be learned by practice of the described embodiments. The benefits and features will be realized and attained by the structure particularly pointed out in the written description and claims hereof as well as the appended drawings.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.

Embodiments of systems and methods for associating previously created content such as text images or audio to a previously created renderable media stream are disclosed below. The content is or is represented by displayable content that can be visually presented to a user in a display area on a display device such as a computer monitor touch screen or other type of display. Displayable content is usually textual but can an icon symbol or image. Content and its associated displayable content may be the same as in the case where the content is text or an image. If the content is not readily displayable an icon symbol or other representative displayable element may be displayed in the display area instead. The displayable content may be indicative or representative of any type of content text images audio for video etc that can be associated with a renderable media stream.

Renderable media streams as discussed above refer to data that when rendered create an user perceivable stream of information such as an audio only stream a video only stream a sequence of visual images a combined audio video stream an animation or a some combination of these. Media streams may be stored as media files or may be received as a transmission of streaming data. Media streams may also be generated in real time. The embodiments described below may be adapted for use with any type of media stream regardless of how the stream is generated or maintained.

For example in an embodiment the content and displayable content is a previously created transcript of a renderable audio video stream in which it is desired to display the transcript as the closed caption for the stream. As another example an embodiment may be used to create timed karaoke lyrics that have timing information for each word or even syllable for a specific song. In this example the lyrics are both the displayable content and the content to be associated with different portions of the audio stream of the song. In an embodiment images may also be associated with different portions of the song with the displayable content being represented by the image itself or by an icon.

In the embodiment shown the method starts with the rendering of a media stream which may be of any type as described above to a user in an initiate rendering operation . Concurrent with the rendering of the media stream a displaying content operation displays at least some of the text to be associated with different portions of the media stream to the user in a graphical user interface GUI for the system. As discussed above both the media stream and the text may have been previously selected by the user prior to initiating the method . The media stream and the text may be rendered in one or more different display areas on the GUI or by a different display device or means. For example the video of a media stream may be rendered in a first window i.e. video display area in a computer monitor while the audio of the media stream is rendered using speakers or headphones and some portion of the text containing a transcript of the media stream may be displayed in a separate displayable content area i.e. a text display area on the same computer monitor. The text display area and the video display area may be separate windows or areas of a single window adjacent to each other in a graphical user interface GUI for the system such as that GUI shown as shown in .

As the media stream is being rendered to the user the user can enter one or more user inputs through the GUI of the system. In the embodiment shown the method includes receiving a user input through the GUI in a receiving operation . The receiving operation may take the form of detecting a mouse click or depression of a button on some other pointing device. Alternatively a touch to a touch sensitive screen may be detected a voice command may be heard or some other system recognizable action performed by the user may be registered by the system.

The user input is analyzed and it is determined that the input selects at least some of the text displayed in the text display area in a selection operation . More detail is provided below with reference to concerning examples of how different user inputs may be resolved to determine the selection of different amounts of text. In any case the selection operation determines some portion of text displayed to the user in the text display area. The selection operation may include highlighting or otherwise altering the display of the text in the display area to indicate to the user what the system has selected in response to the user s input.

The method also includes an identification operation that identifies at least the point at which the user input was received and using this information determines approximately the point in the media stream that was being rendered when the user input was received. This point is used to identify a starting point for the portion of the media stream that will be associated with the text selected by the user input. In the high level embodiment shown the identification operation also includes identified an end point of the portion of the media stream that will be associated with the text selected by the user input. As discussed in greater detail below the end point may be determined by the same user input that selects the text to be associated with the portion or may be determined by the next received user input that selects other text to be associated with a next portion of the media stream.

The method further includes an association operation that associates the text selected by the user input with the portion of the media stream identified by the identification operation . As described above various computing methodologies exist or have been proposed for tagging media streams with metadata. The association operation may use one or more of any suitable methods to associated the selected text or other content associated with the displayable content selected with the identified portion of the media stream. For example the system may interact with a time tagging application programming interface to generate metadata for storage with a tagged copy of the media stream. The metadata may include an identification of the starting point of the portion the duration or end point of the portion and the text or other content to be associated with the portion of the media stream. A suitable media stream player may then be capable of rendering the tagged copy and interpreting the metadata so as to display the selected text when the associated portion of the media stream is being rendered played by the player. Other methods of tagging the media stream are also possible the details of which are unimportant to this specification. Regardless of the exact methodology used to associate the selected text with the identified portion the system through the GUI is adapted to generate the necessary information and perform the necessary functions under the methodology in response to the user s inputs.

The method further includes revising the text display area in response to the association of the selected text with a portion of the media file in a revise display operation . The revise display operation may include scrolling text though the text display area so that the user can see additional text that has not yet been associated with the media stream. In addition the operation may also visually indicate to the user what text has been associated based on the user s previous inputs by changing how the newly associated text is displayed. For example in response to a selection of less than a full row of text the system can optionally split and move the remaining text on that row to a new row to help selecting the remaining text. After the display area has been revised the method returns to the display operation and a waiting state in which it waits for the next user input.

The method although presented in the context of associated previously generated text with a media stream allows the easy selection and association of any displayable content with any media stream.

In addition the method could also be used to revise the metadata of a previously tagged media stream. In this application the method would display the renderable media stream and the text from the previously generated metadata and illustrate each set of selected text as each associated portion of the media stream is rendered. Through the interface any user inputs overwrite any existing associations and allow the user to easily revise change and hone the associations and the starting and ending points of the portions. When used for these revisions the method would operate essentially as described above except that the displayable content would be obtained from the metadata of the media stream and the display operation would display the displayable so as to identify the displayable content currently associated with the portion of the media stream currently being rendered.

In the embodiment shown the functions of any of the various elements of the architecture could be distributed so that each element may be associated with a separate computing device. Computing devices generally include a processor and memory for storing data and software as well as means for communicating with other computing devices e.g. a network interface module. Computing devices may be provided with operating systems and may be adapted to execute software applications in order to manipulate data and communicate with other systems. Alternatively some or all of the various elements could be combined on a single computing device and performed by one or more software applications that perform the functions described elsewhere herein. Examples of computing devices include personal computers smart phones personal data assistants servers and mainframes. One skilled in the art will recognize that although referred to in the singular a computing device may actually consist of a plurality of computing devices that operate together to provide data in response to requests from other computing devices.

In a computing device local files such as media files or raw data stored in a datastore may be stored on a mass storage device not shown that is connected to or part of any of the computing device. A mass storage device and its associated computer readable media provide non volatile storage for the computing device. Although the description of computer readable media contained herein refers to a mass storage device such as a hard disk or CD ROM drive it should be appreciated by those skilled in the art that computer readable media can be any available media that can be accessed by the computing device.

By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EPROM EEPROM flash memory or other solid state memory technology CD ROM DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer.

In an embodiment the computing device in the architecture is single computing device such as a personal computer smart phone laptop computer etc. connected to the display device which may be and integral part of the computing device or a separate device as shown. In an alternative embodiment one or more of the elements described in may be maintained on a remote server computer not shown . For example the display device may be attached to a client computer not shown provided with a browser that allows the client computer to access the computing device .

The architecture includes at least one renderable media stream illustrated in the embodiment shown as a media file . The media file is the source of the renderable media stream data and is of a form that can be accessed and rendered by the media player . In the embodiment shown the media player is illustrated as a separate program examples of which include Windows Media Player Yahoo Music Jukebox and Real Player to name but a few. Alternatively the media player could be included as an integral part of the tagging application .

In the embodiment shown the tagging application generates the GUI for the system. The GUI renders the media stream and displays the displayable content to the user and also receives the user inputs. Based on the inputs received and the portion of the media stream that is being rendered when the user inputs are received the tagging application generates the appropriate metadata or otherwise interacts with the media player and other components of the computing device as necessary to complete the association. Depending on the tagging methodology used the output of the tagging application may differ in order to effect the association. In the embodiment shown the tagging application is adapted to interface with the computing device and media player to generate a tagged media file that includes the metadata generated by the tagging application . Depending on the tagging methodology used a tagged media file may or may not ultimately be generated.

Adjacent to the media stream display area a second display area for displaying the text or other displayable content to be associated with the rendering media stream. The second display area is illustrated as containing multiple rows of text . As discussed above other elements could be displayed in the second display area in addition to text.

In the embodiment shown one method of selection of text is illustrated. In the the user has tapped i.e. issued a user input that is received by the system a location on the second in this case text display area . The tapping may take the form of a physical tap or the form of a mouse click while the selector is located within the text display area . The location tapped is determined by the system and resolved to identify what elements in the text display window should be selected in response to the tap.

In the embodiment shown the user has tapped a point to the left of a row of text. In response the system resolves this as a selection of the entire row and revises the display to highlight the selected row as shown.

In the system different locations within the text display area are resolved to different selections. In an embodiment user inputs that underline a word or portion of a word are resolved to select that word or portion of word. In addition as described below the tap may also specify the beginning and end times for a portion of the media stream for the selected text depending on the duration of the tap. For example the time the tap is first detected relative to the rendering media stream may be used to generate the start of the portion and the removal of the touch or release of the button on the pointing device may be used to determine the end of the portion and possibly the beginning of the next portion.

In an embodiment a tap in front of a text row or on an image if the metadata is an image and not text may be resolved to specify the beginning time only for the whole row of text see . In an embodiment a short tap on or under a word may be resolved to select the word and the beginning time for the word. In an embodiment a user input that draws a vertical line in the margin may select the beginning time for one or more rows. In an embodiment when selecting a row or multiple rows and a vertical line can be drawn between words or letters to specify the end time at that point in the text and time.

As discussed above in response to a selection the system can optionally split and move the remaining text on that line to a new line to help selecting the remaining text. The system also can optionally determine the end time for the previous tagged piece of information when the next portion is tagged that is tapping a row only sets the beginning time for that row but when the next row is tapped the end time is specified for the previous row in addition to the beginning time of the new row. Identification of the start time and end time of a portion of the media stream is discussed in greater detail with reference to .

The method starts with the detection of a touch to the touch sensitive display in a detect touch operation . In response the system identifies a starting point in the rendering media stream based on the time the touch was detected in a start point identification operation . The start point identified may be the exact frame or content being displayed when the touch is detected or may be some approximation such as the nearest or next I frame of an MPEG stream.

In addition based on the location of the touch detected in the detection operation a starting point in the text is identified. As discussed above the location may be resolved to a row of text an individual word in the text or even a portion of a word.

The text display is then revised to illustrate to the user what selection has been made based on the user input received in a revise display operation . As discussed above this may include highlighting the selection and or drawing a line or point on the GUI.

A determination operation may be performed to determine if the touch is a quick tap or a long touch. In an embodiment this is done by tracking how long the touch is detected for and comparing it to a predetermined threshold that may have been user dictated. If the touch is longer in duration than the threshold then the method continues on with a second determination operation discussed below.

If the touch is less than the threshold then the text selected in the selection operation is considered a starting point in the text for the content to be associated with the portion of the video stream. Neither the end point of the text nor the end point of the portion is known at this time. However upon detection of a next touch in a detect next touch operation this information can be determined by the method .

After the next touch is detected in the detect next touch operation an ending point selection operation is performed that selects the end point of the text displayed in the text display area. The operation identifies the location of the touch and resolves the location to a point in the text in the text display area. The location is used as the end point of the selection of text to be associated with the portion of the rendering media stream. In an embodiment the selected text is the text between the start point identified in the first selection operation and the end point identified in the second selection operation .

In addition the method includes identifying the end of the portion of the media stream in an end point identification operation . The operation uses the time the next touch is received and the media being concurrently rendered to identify the end of the portion of the media stream.

An association operation is then performed to associate the selected text i.e. the text between the first touch and the second touch with the portion of the media stream defined by what was being rendered when the first touch and second touch were detected. As discussed above the information generated and how that information is associated with the media stream will depend on the tagging methodology used. For example the system may generate metadata including the selected text and the identified portion of the media stream. This metadata may then be transmitted to the media player or some other program through a tagging application programming interface exposed by the media player. The program then may create a new version of the media stream with the metadata included so that when rendered by a compatible player the selected text is displayed when the identified portion is rendered. In addition to text and portion information other information may also be generated such as where and how the text is to be formatted and displayed later rendering of the tagged media stream.

In the embodiment shown the second touch detected in the next touch detection operation is treated as the start point for the next portion of the media stream. This is illustrated on the flow chart by an identify next portion operation .

Turning now to the operations illustrated in if the determination operation determines that the touch is detected for longer than the threshold then in the embodiment shown a second determination operation monitors the touch location to determine if the touch moves significantly within the duration of the touch. If the touch does not move then the time when the touch ceases is used to determine the end point of the portion of the rendered media stream. To effect this flow jumps to another identify end point operation discussed below. For example if a user touched a location on the touch sensitive display that indicates a row the user could maintain the touch until the user no longer wanted the row to be displayed on the tagged media stream. The second determination operation would detect no significant movement in location of the touch and flow would transfer to the identify end point operation . This ultimately causes the text selected in the starting point operation to be associated with the portion defined based on when the touch was first detected until it was no longer detected.

If the second determination operation determines that the touch moves within the text display area the display is again revised in another revise display operation to indicate the currently selected text i.e. the text between the initial location detected in the initial detection operation and whatever location the touch moves to in the display area. This operation may be an ongoing operation so the as the touch is moved the display is constantly revised.

When the user removes the touching device from the display a detect end of touch operation occurs. The extent of text is then selected for association with the portion of the media stream in a text selection operation based on the start location of the touch and the end location of the touch.

Detection of the end of the touch also causes the identify end point operation to be performed. The identify end point operation identifies the end of the portion of the media stream based on what was being rendered when the touch ceased.

An association operation is then performed to associate the selected text with the identified portion of the media stream and the appropriate data is generated and transmitted as described elsewhere. In the embodiment shown after the association operation the system returns to a waiting mode to wait for the next touch to be detected as illustrated by the flow returning to the detection operation on .

One skilled in the art will recognize that many variations in the order or redistribution of the functions of operations may be possible that still achieve the same results. For example in an alternative embodiment detection of the end of a long touch may also be used to determine a starting point for a next portion of the media stream as discussed in identify next portion start operation . As another example one or more of the selection and identification operations may generate and transfer some information regarding the portion and text in addition to or instead of the association operations. Such embodiments all achieve the same result and are considered within the scope of the present disclosure.

Those skilled in the art will recognize that the methods and systems of the present disclosure may be implemented in many manners and as such are not to be limited by the foregoing exemplary embodiments and examples. In other words functional elements being performed by a single or multiple components in various combinations of hardware and software or firmware and individual functions can be distributed among software applications at either the client or server level or both. In this regard any number of the features of the different embodiments described herein may be combined into single or multiple embodiments and alternate embodiments having fewer than or more than all of the features herein described are possible. Functionality may also be in whole or in part distributed among multiple components in manners now known or to become known. Thus myriad software hardware firmware combinations are possible in achieving the functions features interfaces and preferences described herein. Moreover the scope of the present disclosure covers conventionally known manners for carrying out the described features and functions and interfaces and those variations and modifications that may be made to the hardware or software or firmware components described herein as would be understood by those skilled in the art now and hereafter.

While various embodiments have been described for purposes of this disclosure various changes and modifications may be made which are well within the scope of the present invention. For example the systems and methods described above could be used to associate text as it is generated by a typist with a media stream. The interface would also allow the typist to easily revise the initial association by replaying the media stream with its associated text and adjusting the associations using the methods described above.

Numerous other changes may be made which will readily suggest themselves to those skilled in the art and which are encompassed in the spirit of the invention disclosed and as defined in the appended claims.

