---

title: Method to render a root-less scene graph with a user controlled order of rendering
abstract: A scene graph is provided which represents data and a set of processes thus providing an enhanced approach to the previously known scene graph concept. With this approach the scene graph becomes a rendering description of the data rather than a world description. Previously known scene graphs represent a structure of objects and their attributes. The scene graph has a notation of the traversing order, which together with the types of nodes, the nodes position, node functionality and node state determine the rendering order. Thus, any effects supported by the underlying rendering pipeline can be expressed directly in the scene graph by the user. An API is provided for the scene graph, controlling the actual rendering order and optimization to the user. The scene graph is extensible allowing the user to experiment and express new rendering algorithms in the scene graph semantic.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08400444&OS=08400444&RS=08400444
owner: Agency 9AB
number: 08400444
owner_city: Lulea, Danderyd
owner_country: SE
publication_date: 20061207
---
The present application claims priority to U.S. Provisional Patent Application Ser. No. 60 597 538 titled A Method To Render A Root Less Scene Graph With A User Controlled Order Of Rendering filed on Dec. 8 2005.

This invention relates generally to the field of computer graphics and more particularly to graphics systems and methods that manage and render three dimensional graphics data by means of scene graph.

The digital entertainment industry has taken a lead in creating realistic real time environments where the user can interact with the environment and others. Real time 3D graphics is also used in the industry where it is used in many different areas such as medical and health care for visualizing of the human body and in telematics where it is used in navigation and positioning. The ever growing ability to create a more realistic world on a screen has also created a new field of training systems serious gaming where for example a fighter pilot trains before combat or a surgeon prepares himself before a complicated operation. The real time 3D graphics industry has also gone mobile with next generation mobile phones which have the graphics and computing power to create stunning results.

The hardware is typically built around a Central Processing Unit CPU and Graphics Processor Unit GPU . The CPU is the unit controlling the interpretation of program instructions and their execution. It receives and sends data through input output channels retrieves data and programs from memory and conducts mathematical and logical functions of a program. There are many alternative terms to a CPU such as processor or embedded system. Other examples on equivalents are a Parallel Computing System or a Multi Processor System. The GPU is a specialized processor designed to draw 3D graphics. As such it s much faster for typical tasks involving 3D graphics than the processor is. Many other terms may be used for the GPU. The CPU GPU are typically connected over a bus such as AGP or PCIx on a PC system. Many GPU systems today have their own dedicated memory. This architecture can both be found in modern PC and workstations as well as future handhelds mobile phones game consoles and other similar units. The CPU and GPU on a PC are often connected through a high speed bus such as AGP or PCIx. This design has created a breakthrough in graphics computer power since the GPU can be optimized to handle graphically intensive tasks. Since the GPU is task oriented the speed of the GPUs has increased faster than Moore s law. The trend is also that the CPU is either multicore and or multiprocessor type with the ability to handle threads in parallel.

The industry growth has created a need for programmers and developers tools for doing rapid development of 3D applications. Today there are basically two different industry standards OpenGL and Direct3D which both offer a GPU and vendor independent way of communicating in a CPU GPU environment. Direct3D is generally available for platforms from Microsoft Corporation. OpenGL is available on PC and workstations as well as handhelds gaming consoles and embedded environments in the form of OpenGL ES. Both OpenGL and Direct3D have been designed as low level abstractions close to the machine hardware. Due to low level abstraction both OpenGL and Direct3D are complex and difficult to master. In a large and complex development environment with multiple developers this has become even more apparent. In such a development environment a single non intended state change in OpenGL is likely to have a negative impact and it may crash the rest of the application. Several attempts to create a higher abstracted development model have been made based on Open GL but with varying results. One of the most novel ideas has been the idea representing the graphic data in a graph known as a Scene Graph. The idea is that the developer attaches one or more transforms nodes to a root node and then a 3D object with a set of attributes defining the objects. This approach has been implemented both as script languages such as VRML and as a programming APIs for example in Java3D from SUN Microsystems. Both implementations have succeeded in reducing the complexity of the application development. A problem with the previous known scene graphs is a relatively high cost of speed during run time. Another problem with the known scene graphs is that the developer does not have control of all aspects of rendering nodes and objects. Additionally there are other related problems with the previous known scene graphs that need to be solved to meet the developer community demands. A particular problem for many developers is the insufficient ability of the suppliers of the previously known scene graphs and their related APIs to adapt to the rapid development of the GPU and the ever increasing number of rendering algorithms.

Java3D has been designed to be inherently multithreaded and rendering order independent. When traversing a scene graph the Java3D process starts from a virtual universal proceeds. The order of traversal is not defined and the actual location of the node has no meaning for the final result only the path from the root to a leaf. The approach in Java3D is that the user describes a set of objects and their attributes in the scene graph. Further the approach in Java3D comprises that the scene graph data is assembled and data is put into render bins. A similar approach can be found in graphs like VRML. Each render bin is then responsible for programming the rendering pipeline. The render bins are parallel structures and their internal order of execution is out of user s control and different threads often execute different bins.

This approach makes it very hard and often impossible for the developer to describe new novel rendering algorithms since the final result is order dependent. There is no natural way in the scene graph semantics to describe an algorithm. Thus making it difficult for Java3D developers to adapt to rapid development of the GPU and rendering theory. Developers dependent on new versions still strive to incorporate their needs and ideas. The difficulties also limit developers ability to innovate and create new effects never seen before.

The patent application publication US2001 0030647 describes a system and a method for processing of scene graph based data and or programs. Structures and threads may be configured to convey information about state changes through the use of messaging. The system may include support for messaging between threads messaging with time and or event stamps epochs to ensure consistency and ancillary structures such as render bins geometry structures and rendering environment structures. The patent application describes the Java3D API. The patent application describes a system that has the previously mentioned problems such as that the Java 3D programmer does not have control over the rendering order of objects. Another remaining problem is that the programmer does not have the possibility to use a new algorithm from a GPU vendor unless supported by the Java3D API.

U.S. Pat. No. 6 683 9062 from Microsoft Corporation describes that semantics usage allows shaders to be authorised independently of the actual vertex data and accordingly enables their reuse. This allows developers to program the shaders in the assembly and high level language with variables that refer to names rather than registers. By allowing this decoupling of registers from the language developers can work on the language separately from the vertex data and modify and enhance high level language shaders without having to manually manipulate the registers. This also allows the same shaders to work on different sets of mesh data allowing the shaders to be reused. In general semantics can be used as a data binding protocol between distinct areas of the rendering pipeline to allow more flexible workflow. However even though user semantics enable a higher abstraction level such as a description of uniforms it does not address the use of a scene graph and states still have to be manually assigned to the rendering pipeline. An alternative term to rendering pipeline is programmable pipeline.

It is desired to have a method and system that supplies an API for 3D graphics development on a high abstraction level that to a great extent is platform independent and allows programmers to work in scene graph environment with the programmer controlling the rendering order and the programmer has the ability to use the latest algorithms such as features from the GPU vendor without having to upgrade the system software such as Java3D.

An aim is that the above mentioned problems are solved by a method and a computer program for rendering a scene graph as described herein. An object of the invention is to provide a method and a computer program for rendering a scene graph comprising 3D graphical data in a computerized system the method and system enabling more efficient rendering in a CPU GPU environment to overcome limitations in previous known scene graphs. A CPU GPU environment is not restricted to a PC or server but is also valid for other types of devices with a separate unit handling graphics. An example of such a device is a mobile phone. Another example is system comprising glasses with visualizing capabilities.

The invention provides a scene graph which represents data and a set of processes thus providing an enhanced approach to the scene graph concept. With this approach the scene graph becomes a rendering description of the data rather than a world description. Previously known scene graphs represent a structure of objects and their attributes. This approach can be found for instance in environments based on Java3D or VRML. An advantage of the invention can be explained in the term of transparency. In the Java3D approach transparency is a surface attribute where as in the embodiment of the invention transparency is a rendering algorithm based on the rendering order which is user defined and optionally applied on a blending process. This fundamental difference removes the previous limitations and allows the user to express new algorithms directly in the scene graph in terms of processes and rendering order. The scene graph has a notation of the traversing order which together with the types of nodes the nodes position the nodes functionality and nodes state determine the rendering order. Thus the user can express any effects supported by the underlying rendering pipeline directly in the scene graph.

A further object is to provide an API for the scene graph that is easy to use still giving control of the actual rendering order and optimization to the user. The scene graph is extensible allowing the user to experiment and express new rendering algorithms in the scene graph semantics. The semantics of the scene graph allows the user to express optimizations. The scene graph is particularly suitable for a CPU GPU environment or similar. The API and the scene graph semantics enable the user to optimize rendering in computerized systems with both single and multiple CPU.

The invention enables the user to add an additional node to the scene graph where the order in which scene graph data is sent down the rendering pipeline depends on the position of the added node in the scene graph and its state. An added node may have a number of children. The added node and its children may comprise a rendering algorithm for 3D graphical presentation. In contrast to other scene graphs the rendering algorithm is previously unknown to the system software traversing the tree. In other previously known scene graphs such algorithms for 3D graphical presentations are not possible for a user to access unless the system software is updated with a version supporting the algorithm. Functions of the new algorithm may have its origins from the vendor of the graphical board comprising the GPU. It may for instance be a new algorithm for handling reflections in surfaces such as glossy furs.

Yet another feature of the scene graph is the ability for the user to extend a node so that certain state of the node is used to determine if children of the node are to be traversed. Such an extended node enables the user to optimize the algorithm.

The scene graph is constructed by assembling a set of nodes thus creating a directed acyclic graph. In contrast to previously known scene graphs any node may be set as a starting point node for scene graph traversal. The node may be a base class the scene graph is built from and defines the traversing order of its children. A node typically keeps a list of its children and any node can be added as a child to another node. The scene graph is traversed from top to bottom left to right or right to left . All scene graph nodes guarantee this traversal order. A user can extend any node and add restrictions related to in how the user defined order should be traversed. In one embodiment the restriction relates to if a condition regarding the state of a node is fulfilled at the time of a rendering pass. This gives the user total control over the traversal order and the rendering process. This also enables the user to build render order dependent optimizations directly into the graph this in contrast to earlier known scene graphs and their related APIs. A rendering API according to the invention is separated from the underlying hardware API such as Direct3D or OpenGL.

Traversal of the scene graph is repeated number of times per second. The node where to start traversal of the scene graph may be changed by the user from one traversing pass to the next. Traversal of the scene graph is defined in two passes the update and the render pass. This design is preferable in order to be able to optimize the use of hardware structure such as to maximize the Asymmetrical Multi Process ASMP behaviour of the CPU GPU architecture. The update pass may be time dependent and utilize only CPU resources. The intended use is to update states of nodes and perform CPU heavy calculations such as animation and geometry deformations in the update pass. The update pass can be run as single or multithreaded both on traversal and node levels without need of synchronization. The render pass communicates with the GPU and uses as little CPU resources as possible. The two passes allow the user to optimize the system for the best possible ASMP behaviours. The architecture allows multithreaded CPU behaviour on each node in the render pass but not on the actual traversal. With a single threaded traversal data can be sent down the rendering pipeline as fast as possible without any synchronization. Multithreaded traversal when rendering makes less sense since all rendering in the end is more or less order dependent. When the data has been sent down the pipeline the GPU can start processing data independently from CPU. As the GPU is processing geometry the CPU resources can be assigned to the update pass. The separation of update and render also allows partitioning resources between frames where only parts of a frame need to be updated in each frame.

The scene graph comprises two different basic types of nodes Transform and Components. A transform node affects the different transform stages defined in the render pipeline the transform matrix the projection matrix and the color matrix. When traversing the tree transform nodes are multiplied creating a hierarchical relationship in space. The component nodes define data a process or a combination from there on. When traversing the scene graph two component nodes of the same type replace each other.

In embodiments of the invention rendering is used to generate a 3D image. is a schematic overview of the rendering pipeline . Geometry and texture are held in storage. In the rendering pipeline patches often triangles are transformed and then projected on to a view plane by a set of matrices. The projected triangles are then culled and clipped and passed down to a rasterization process . In the rasterization process fragments are created and passed on to a fixed fragment shader or a programmable shader where they are textured and possibly lit i.e. shaded. The fragment then passes to fragment operations . The rendering pipeline further comprises a series of tests such as z buffer and stencil tests which may be performed in the core of the rasterization process. If it passes these tests the fragment eventually becomes a pixel in the color buffer of where it either is replaced or blended with an existing pixel occupying the location. One characteristic of rendering is that rendering is order dependent. Exactly the same patches rendered in a different order might yield a completely different result. A typical evidence of this is transparency. In one embodiment OpenGL will calculate the result of blending two pixels based on the equation 

The s and d subscripts specify the source and destination pixels. The S and D components are the blend factors. These values indicate how you would like to blend the pixels. The most common values for S and D are As As As As known as source alpha for S and 1 1 1 1 As As As As for D. This yields a blending equation that looks like 1 1 1 1 

The above equation yields transparent translucent style effects. If one looks at the red component of the blend equation we get and use the given pixels 0.1 0.3 0.5 0.2 1 1 1 1 0.1 0.2 1 1 0.2 0.82

On the GPU side the rendering is typically built in a pipeline architecture. A pipeline architecture has the advantage that it increases the polygon through put if it has a steady state and steady flow of data. With previously known scene graphs such rendering gives a penalty when interrupted since the pipeline needs to be flushed to adapt to changes.

The scene graph is constructed by assembling a set of nodes thus creating a directed acyclic graph which is the scene graph . The node is the base class the scene graph is built from and defines the traversing order of its children. A node keeps a list of its children and any node can be added as a child to another node. Example of a node is a node describing texture geometry or a transform. The scene graph is traversed in a top to bottom left to right manner. All scene graph nodes guarantee this traversal order. A method according to the invention renders a scene graph that comprises 3D graphical data. The method comprises the step of assembling nodes defined by the user to the scene graph . The scene graph resembles directed acyclic graph.

Further the method comprises the additional step of setting or rather the user choosing the node N from where to start traversing the scene graph . In one embodiment setting the node N involves evoking a rendering method of the node N itself. In another embodiment the node N may be used as a parameter in a rendering call however the setting step does not typically involve setting a parameter that is stored. A part of the complete scene graph that is traversed is shown in . In contrast to previously known scene graphs any node of the scene graph may be chosen as a position to start traversing. In previously known scene graphs the rendering starts at the top of the tree such as at Virtual Universe node.

During the traversal of the scene graph each node is evaluated to see if it is extended. If a node is extended at least one state of the node is used to determine if children are to be traversed. This enables the user to increase the performance of the traversing pass as well as the performance of the rendering pipeline since all nodes need not be traversed. The state may obviously change between different times traversing the scene graph . Hence a node and its children which are excluded from being sent down the rendering pipeline when traversing the scene graph at a first time may be sent down the rendering pipeline at a second time when traversing the scene graph . This depends on that the state of the node which may change between these two times is used to determine if children are to be traversed.

Scene graph data is sent down the rendering pipeline based on an order defined in the scene graph by the user. This order is based on depth first top down rigt left order. The data and processes such as defining an algorithm for graphical representation of the scene graph determine in which order data is sent down the rendering pipeline .

In the example there are numbers of restrictions assigned to states of nodes. In lines between nodes indicate restrictions . Node N and node N in are extended nodes and each has at the time of traversing the scene graph a state that may restrict traversing of their children. The restriction may also involve that components and transforms of the node such as N and N are excluded from being sent down the rendering pipeline . In the example in draw nodes are nodes leaves at the end of the branches in draw nodes would be N N N N N N N. In an embodiment it is a draw node that initiates the actual draw of graphics such as triangles on a screen while the components may communicate with the rendering pipeline as they have been traversed during the render pass. In one embodiment of the invention the rendering is made in such a way that data for instance components of nodes are sent only once down the rendering pipeline . The scene graph in itself handles optimization of components sent down the rendering pipeline . In such embodiment the rendering order of the scene graph of is 

Such embodiment may be preferred if states of nodes are allowed to be updated during the rendering pass.

An advantage of the approach with draw nodes is that they enable the user to control rendering. For instance a draw node initiates that a set of node data such as N N N are sent down the rendering pipeline. This means that components transforms and processes are handled in rendering pipeline before the end of the traversal of all nodes during the rendering pass. This contrasts the previously known scene graphs where rendering bins and many other data sorting techniques are used before data is sent further down the rendering pipeline .

In a preferred embodiment an appearance function handles node data before it is further sent down to the rendering pipeline . This approach may be seen as lazy evaluation. It is preferred that the appearance function is embedded in the appearance node N at the top of the scene graph . With the appearance node in the scene graph components relating to certain aspects such as texture are sent only once. In the scene graph of the nodes N and N comprise components that relate to the same aspects of an object such as texture. The order of components of nodes sent down the rendering pipeline from nodes of the left branch of is 

The method enables the user to change and control the rendering order of the scene graph . This may be achieved by a set of user s actions via graphical user interface or by means of user defined program. The method enables the user to add an additional node with a number of children.

The invention enables that the added node such as node N shown in comprises an algorithm for 3D graphical presentation. further shows that the node N may have a number of children making up a sub tree N. In contrast to other scene graphs the algorithm is previously unknown to the system software traversing the tree . The scene graph enables the user to access algorithms for 3D graphical presentation without the system software being updated with a version supporting the algorithm. The new algorithm may comprise processes and functions originating from the vendor of the GPU . It may for instance be a new algorithm for handling reflections in surfaces such as glossy furs. The scene graph data with the added node N is sent down the rendering pipeline in the new order defined by the user. And this is performed without updating the system software traversing the scene graph. The added node N or any of its children may earlier have been extended comprising a state that restricts children from being traversed providing that the condition is fulfilled. Lines between nodes indicate restrictions in .

In the example in of a scene graph where the node N is added the added node N has a number of children which resembles a sub tree . The children are N N and N. Each leaf of the scene graph is a drawn node. In the example there are numbers of restrictions assigned to states of nodes. Restrictions indicated as lines in fulfilled at the time of the rendering pass relate to the nodes R R and R. During the rendering pass the nodes are sent down the rendering pipeline in sets. The first set of node data to be sent down the rendering pipeline is 

In the example of an example of restriction of a state in each of the two siblings N N may refer to if a character in a game holds a sword or a map.

A user can extend any node and add restrictions to the node s children determining which of its children that should be traversed in a user defined order.

In one embodiment the user may extend a node such that the user defines an own node for instance MyNode based on an existing node such as A9Node. In the example below the extended node comprises the methods update and renders with a restriction based on state.

This enables the user to get total control over the traversal order and hence the order of component data and other data of nodes sent to the rendering pipeline . This further enables the user to express rendering algorithms as a scene graph . This also allows the user to build render order dependent optimizations directly into the graph which was not possible before.

In conjunction with the rendering pass of the scene graph data is sent down the rendering pipeline. Optimization is built in the scene graph such that no optimization is necessary in the CPU. This in contrast with previously known scene graphs such as Java 3D where an added node results in a CPU consuming optimization which often leads to a disturbance on the presentation on screen easily recognized by a human eye.

The invention enables that no optimization is made in the CPU of the computerized system to change the rendering order.

An example on the advantage of controlling rendering is in games as the user desires to perform HUD rendering. First the user may render a game tree followed by the user render a HUD branch.

Yet another example of the advantage when the user controls the rendering order is when the user works with lights. When working with rendering lights are not real lights but a form of shading. Shading is how the light interacts with the surface and it determines the color of pixel of the surface. Since lights are a form of shading and not a light simulation the behaviour of the lights differ from real lights. Surfaces do not occlude or reflect light to the scene which means that objects do not automatically cast shadows and shiny surfaces do not automatically reflect other objects. In the rendering process each patch is treated separately and without a relation to earlier patches. Thus light phenomena such as reflection and shadows are a combination of different rendering techniques.

Traversal of the scene graph is defined in two passes the update and the render pass. This design has been chosen to be able to optimize the structure to maximize the Asymmetrical Multi Process ASMP behaviour of the CPU GPU architecture. The update pass is time dependent and utilizes only CPU resources. The intended use is to update states of nodes and perform CPU heavy calculations such as animation and geometry deformations. The update pass can be run as single or multithreaded both on traversal and node level without need of synchronization. The render pass communicates with the GPU and uses as little CPU resources as possible. The two passes allow the user to optimize the system for best possible ASMP behaviours. The architecture allows multithreaded CPU behaviour on each node in the render pass but not on the actual traversal. With single threaded traversal data can be sent down the rendering pipeline as fast as possible without any synchronization. Multithreaded traversal when rendering makes less sense since all rendering in the end is more or less order dependent. When the data has been sent down the pipeline the GPU can start to process data independently from CPU. As the GPU is processing geometry the CPU resources can be assigned to the update pass. The separation of update and render also allows partitioning resource between frames where only parts of the frame need to be updated in each frame.

Advantageously an implementation of the method comprises an update package as part of the API. Update enables the user to determine that certain tasks relating to data in nodes are processed in the CPU while other data is processed by the GPU down the rendering pipeline . Such tasks may handle animation of geometry as defined in a geometry node. Animation is often CPU consuming. It is not the animation as such that is sent down the rendering pipeline but rather the result of the animation. It is suitable to first call render followed by a call to update. The call to update is suitable to be less frequent than the call to render. For instance render is called every frame while update is called every third frame.

The system and method according to the invention enables the user to utilize the graphical system in an efficient manner. There are obvious advantages with the multiprocessor system but there are also limitations and certain characteristics imposed by such underlying hardware. A multiprocessor system MP system can be either asymmetrical ASMP or symmetrical SMP . In an asymmetrical system each unit takes on different jobs and all memory is not available to all processors. Doing asymmetrical multi processing effective requires specialized knowledge about the tasks the computerized system should perform. Together the CPU and GPU form the basis of MP system that in many cases can be viewed as being asymmetrical. The CPU and GPU are dedicated to different tasks and many GPU often have their own dedicated memory or memory area. The picture becomes even more complex if we take into account that nowadays some systems have SMP capabilities such as multiple CPU or CPU with more than one core. This is the case for both modern PC as well as embedded and handheld devices. When working in a concurrent system optimal speed is achieved if each thread can work parallel. If threads are dependent upon each other they need to be synchronized. The actual synchronization has an overhead that might likely make threaded applications slower in non MP systems. Synchronization might also force threads to idle and wait which waste CPU cycles.

The system and method according to the invention enables the user to define scene graph with semantics that improves performance compared to previously known system and methods. For instance compared to Java3D the system and method do not need to utilize render bins. Render bins are parallel and they need to be synchronized to avoid fragmentation in the GPU but the invention reduces the risk of excessive state changes.

Load balance is enabled and the user controls it by means of the scene graph semantics. This is not possible in Java3D. One example of this is when rendering an environment where the viewer is standing in a room with one window showing the outdoor scenery. In such examples where all objects are simple opaque materials the rendering order does not affect the resulting image but could have a huge impact on the performance in a fill rate and memory bandwidth sensitive set up. The invention enables the user to define and control the rendering order to first render the room in such a way that the majority of the pixels would be filled. Then when rendering the outdoor scenery most fragments would be discarded early in z buffer test not consuming fill rate and memory bandwidth when being written to the back buffer and eventually swapped to the screen. When using previously known scene graphs where the rendering order is not user controlled the opposite rendering order would have consumed roughly twice the memory bandwidth since all fragments from scenery would have been written to the back buffer and discarded only when they where replaced by the fragments generated by the room.

It is an advantage if the scene graph comprises two different basic types of nodes Transform and Components. A transform node may affect different transform stages defined in the render pipeline such as the transform matrix the projection matrix and the color matrix. shows that while traversing the scene graph transform nodes T T T are typically multiplied creating a hierarchal relationship in space. The resulting transform T in transform node T is T. shows that the resulting transform T in node T is T T T.

The component nodes define data a process or a combination thereof. There may for instance exist components for creating processes. indicates that when traversing the scene graph two component nodes of the same type replace each other. When two non transform components of the same type such as appearances or geometry are relative they replace each other. When two geometry nodes in a relative order replace each other only geometry from the last geometry node is rendered when a draw node is encountered.

All node types have in common that they preserve node integrity. The nodes isolate their state. A node is only affected by the state of its parents and output is a result of the path from the top node to the end node. Siblings do not typically affect each other. The node integrity removes the complexity of state management.

In the peer level there is a bridge between the scene graph and the API of the rendering pipeline . indicates a flow of graphics data between the scene graph and the rendering pipeline . The bridge manages automatically access to scene graph states using uniforms. Thus the user does not need to manually assign uniforms such as matrices lights and textures that make the development process easier and less error prone. The bridge functionality also relives the dependency of states being available from the underlying hardware. This also makes a shader development transparent of the underlying API. An example of that is that the user can automatically access the texture by querying it.

In an embodiment lazy evaluation is implemented in the peer level. The lazy evaluator removes redundant state changes. In the determining step it is decided if the state of an object found in a node is to be sent down the rendering pipeline depending on if the state has previously been found in another object or in the object itself. An example is that the same texture may occur in several nodes or several times in the same node.

Below are a number of class definitions that are implemented in an embodiment of the invention. Several other embodiments are possible.

extends Object A9Node is in an embodiment the primary class for the scene graph . In such an embodiment all classes within the scene graph must extend A9Node.

It should be understood that this description is exemplifications of the invention and it should not limit the scope of the invention or its underlying idea.

