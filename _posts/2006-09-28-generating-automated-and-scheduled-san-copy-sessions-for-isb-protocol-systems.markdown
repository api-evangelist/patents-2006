---

title: Generating automated and scheduled SAN copy sessions for ISB protocol systems
abstract: Systems and methods for performing scheduled backups and recovery of data generated by a production application operating on a MAGIC platform located on a host computer. The data is stored in a primary storage in the form of a production volume and ISB protocol is used to create a clone volume. Exemplary methods for backing up a clone volume to a backup storage include receiving a backup command from a backup server, sending a split command to a host computer to initiate splitting of a production volume and a clone volume using ISB protocol, initiating creation of a snapshot from the clone volume, and initiating storing of the snapshot in the primary storage.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07587565&OS=07587565&RS=07587565
owner: EMC Corporation
number: 07587565
owner_city: Hopkinton
owner_country: US
publication_date: 20060928
---
This application is related to co pending U.S. patent application Ser. No. 11 536 121 filed Sep. 28 2006 co pending U.S. patent application Ser. No. 11 536 157 filed Sep. 28 2006 and co pending U.S. patent application Ser. No. 11 536 141 filed Sep. 28 2006. All of these applications are incorporated by reference herein in their entireties.

The present invention relates to systems and methods for backing up and restoring data. More particularly embodiments of the invention relate to systems and methods for performing replication operations using ISB protocol systems.

In this society where many personal and business interactions are data driven data can become easily lost or corrupted due to events such as system failures viruses power outages etc. Backing up data has become an important feature of computer networks because of this increasing dependence upon computers and networks to perform vital business and personal functions. The ability to easily accurately and reliably access data is expected by anyone accessing a computer and or network.

Backup and recovery of data is typically accomplished through the use of software that creates a backup copy of data and that recovers the data from the backup copy. As the amount of data continues to increase and as the applications for creating data become more complex backing up and recovering the data becomes more challenging. It would be advantageous to be able to restore the data at optimal points in time so that full recovery of all of the desired data is achieved without corrupting other data or processes on a computer.

In particular in the health care information system industry the MAGIC platform which operates using Integrated Serverless Backup ISB protocol both of which are provided by MEDITECH allows health care providers to perform basic backups of data. However it would be advantageous to provide administrators of these health care systems with the ability to perform scheduled backups recover data at particular points in time as well as perform other replication operations and recovery operations on saved data.

In the following detailed description of the various embodiments reference is made to the accompanying drawings which form a part hereof and in which are shown by way of illustration specific embodiments in which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

The principles of the present invention relate to a system configured for performing backup and restore operations using Integrated Serverless Backup ISB protocol to perform replication operations on data generated on a MAGIC platform. Data stored and recovered can be used for backup recovery operations e.g. disaster recovery mirroring functions data mining data consistency as well as other analysis.

Exemplary systems include a production application residing on a host computer and a production volume configured for continually storing changes that occur in the production application. Each time data is written by the production application that is being protected the production volume is triggered and a copy of the data involved in the read write operation is created and stored on the production volume. The production volume basically performs a continuous series of write operations. The production volume is able to retain information about every change to a selected application directory volume or the like over a long period of time and a user can later utilize the production volume to access stored data. Exemplary systems also include mirroring the data in the production volume using a clone volume. The present invention provides for remote backup of data in the clone volume.

In addition the present invention provides for snapshots to be created of the data stored in the production volume or clone volume at various points in time. The snapshots are read only point in time replicas or representations of the original data or contents of one or more volumes. A snapshot can be used to make an actual copy on another local or remote storage device. These snapshots can be recovered at a later time by reading the data for a snapshot created at a particular point in time. Furthermore numerous snapshots can be saved. Thus snapshots provide the user with greater control over how data is stored and or recovered.

As used herein the term replication operation covers various processes for creating a copy of a clone volume. One example of a replication operation includes creating a copy of a clone volume and storing the copy in backup storage. Storing a copy of clone volume is also referred to herein as a backup of a clone volume. Another example of a replication operation includes creating a copy of a clone volume in the form of a snapshot and storing the snapshot in a storage device. Thus a snapshot is considered to be a backup of a clone volume. Hence as used herein the term backup will be used to refer to both storing a copy of a clone volume in backup storage as well as creating a snapshot from a clone volume.

Backup clone volumes and or snapshots are beneficial for example to facilitate data recovery after the occurrence of a disaster. A disaster includes any event in which data is lost or corrupted in any way or when an operating system or other application is corrupted or damaged in any way that requires the operating system or application to be repaired or reinstalled. Data can be lost damaged or corrupted in any number of ways including a system crash burglary virus human error damage to the system and the like. A backup clone volume and or snapshot is stored on a backup storage medium such as an optical disk hard disk floppy disk tape or any other storage medium that is physically stored in a location separate from the production volume and accessed to recover the data after the production volume experiences a disaster.

As used herein the term data may include but is not limited to directories e.g. volumes file systems and the like user data system data applications services operating systems and the like that can be stored on one or more storage devices of a computer. Backing up or recovering the operating system may include backing up or recovering any of the data herein defined or understood by those of skill in the art. Data may be organized in logical directories that do not necessarily correspond to a particular storage device. The term directory can be used to refer to any means of logically organizing data on a computer.

Even though data may exist on many different storage devices data can be organized into logical directories and subdirectories so that a user can easily locate information. In one example in Windows operating system the main directories are referred to as volumes. Volumes include for example the C drive and D drive which are typical volumes of storage that are located on a computer even though the C or D drive itself may comprise a collection of hard disks or a portion thereof. It is not necessary for a user to know from which particular disk to obtain information. Thus directories exist to help a user navigate through the data on the computer. Other directories may exist to which the computer has access through a network.

For purposes of simplicity the term production application will often be used herein to describe the source of data that is being backed up. As will be described below complex software applications benefit from the backup and restore technology disclosed herein because the data related to applications are typically subject to constant alteration. The technology disclosed herein facilitates the backup and recovery of all types of data and or data structures and can be particularly beneficial to applications whose data is continually changing. Although certain embodiments described herein will often refer to the backup of production applications the technology described herein applies equally to the backup and recovery of all types of data including directories volumes file systems servers user data system data services operating systems and the like.

Certain embodiments described herein will involve electronic communication between a client computer system hereinafter referred to as a client requesting access to a network service at a server computer system hereinafter referred to as a server . Accordingly the client sends a request to the server for particular access to its system resources wherein if the client is authorized and validated the server responds with a response message providing the desired information. Of course other messaging patterns between client and server are available as is well known in the art.

As used herein the term user may refer to a person operating the server e.g. administrator . Alternatively the term user may refer to a person at a client or management console. Users are able to initiate a request for mirroring backup and or restore although it will be appreciated that the server may have additional functionalities not available to the client or management console.

In host computers A B C are communicatively coupled to a primary storage which includes one or more storage devices A B. Storage device A includes a production volume for storing data generated on a MAGIC platform on one or more of the host computers A B C. A clone volume stores a mirror copy of the data of the production volume .

Turning now to features of system A are shown in more detail with reference to system B wherein like elements will be referred to with like reference numerals. As shown in for purposes of describing the features of host computer a single host computer is depicted. However the description relating to host computer applies to any of the host computers A B C illustrated in .

In one embodiment host computer is an individual computer. In another embodiment host computer is a server that is in communication with a network of client computers not shown . In another embodiment host computer is a client computer that is communicatively coupled to a central server described below . Host computer is relatively simple e.g. a desktop computer or relatively complex e.g. a large database server a cluster of servers or a production server .

Host computer includes at least one production application which contains and generates data that can be stored mirrored backed up recovered data mined and the like. By way of example only production application may include applications such as but not limited to patient admissions medical records laboratory records pharmacy records personnel payroll records as well as other health care industry related applications. However the present invention is not specific to health care industry related applications and can extend to other enterprises.

Furthermore as mentioned above production application may be networked over multiple host computers volumes directories disks or the like. Conversely individual production applications may be located on distinct host computers so that a host computer is responsible for only certain production applications. As noted above the term production application is merely used by way of example to further illustrate the present invention because complex applications whose data is continually being altered benefit from the technology disclosed herein. However other data on host computer may also undergo storing mirroring backing up data mining and the like which data may also include directories volumes file systems servers and other types of data described previously.

The production application operates on a platform known as the MAGIC platform . The MAGIC platform initially evolved from the minicomputer based MAGIC platform to eventually run on a Windows platform. The MAGIC platform provides common services to the production application s including networking and data storage capabilities that are managed by network management service and database management service respectively.

The database management service organizes the storage of data for production application into primary storage . Thus the storage devices A B in primary storage contain data relating to the production application and or MAGIC platform . Database management service facilitates communication between the host computer and storage device A. Production volume records a copy of all changes made to the data of production application . As production application receives or transmits input output operations which is only one example of generating data the input output data is recorded by production volume . In one embodiment the input output data is sent from production application to production volume . In an alternative embodiment data is first sent to database management service which relays the input output data to production volume .

In one embodiment the production volume is organized into segments each segment comprising a range of blocks containing production application data. Each segment is configured to failover. Other configurations for production volume would be understood to those of skill in the art.

In addition the database management service performs basic data storage functions between host computer and primary storage . The database management service conventionally provided users with a mechanism to request replication of the production volume in primary storage in the form of one or more clone volumes . As shown in the production volume and clone volume are connected while data is being copied from a production volume to clone volume i.e. a normal state . The foregoing configuration provides the ability to mirror data from the production volume to the clone volume . This configuration provides multiple layers of redundancy where data is lost or corrupted. If the production volume fails the clone volume is able to restore the data to the same or another production volume . In contrast as depicted in the connection between a production volume and clone volume is temporarily severed i.e. a special state to perform other replication functions. This splitting of the production volume and clone volume between normal state and special state is accomplished using ISB protocol.

Primary storage includes an index for recording metadata containing information about the contents of the production volume and clone volume . Each storage array or device must be aware of any relationship that it is maintained between a production volume and a clone volume and the index provides a mechanism whereby a user can query that relationship. As shown in primary storage can be connected to a single or multiple host computers as well as other servers used for other purposes.

In primary storage is depicted as a storage area network SAN . For example primary storage is a CLARiiON storage cluster comprising one or more storage devices A B each of which may or may not be located at the same location and may or may not be located at different locations and networked together. The CLARiiON environment permits SAN Copy Sessions to be created the SAN Copy Sessions being one example of a snapshot . In another embodiment the primary storage includes one or more Symmetrix servers.

Broadly primary storage is one of many storage mediums that are commonly employed in the art to store data. Examples include but are not limited to disk storage e.g. optical disks hard disks RAIDs floppy disks zip disks and the like tape storage e.g. magnetic tape paper tape solid state memory devices e.g. flash memory EEPROM and the like as well as any other storage medium currently known in the art or developed in the future. In embodiments where the primary storage stores data on disk rather than on tape storage this allows files or entire volumes to be easily surfaced and copied to another location e.g. a different storage device within primary storage or a different storage network altogether for performing other functions on the data such as backup recovery data mining or data consistency analysis.

Turning back to the description of host computer illustrated in the MAGIC platform operates on an operating system . In one embodiment the operating system is modified so that some of the components are replaced by components of the MAGIC platform. For example as shown in the operating system could include a MAGIC IP Stack and a MAGIC File system . The operating system can be any operating system known in the art. In one embodiment the operating system is a Windows operating system.

The operating system boots off of the local hard drive and cannot access the MAGIC platform or production application . In contrast the MAGIC platform and production application boots off of production volume in the primary storage . Thus the production volume represents a large amount of data that is unavailable for desirable replication operations. Further the conventional database management service on MAGIC platform that controls the creation of the production volume and clone volume lacks various desirable replication operations including but not limited to snapshot management snapshot rotation policies advanced indexing high speed parallelism automated media management LAN free backup cluster awareness and dynamic tape drive sharing. These and other features would be desirable when performing backup recovery operations on data for production applications and or data relating to the MAGIC platform itself.

To overcome these deficiencies as shown in proxy host and backup server are provided to perform backup recovery functions. The proxy host uses the ability of the production volume and clone volume to be temporarily severed from a normal state to a special state in order to perform other replication functions. After severing has occurred proxy host directly communicates with primary storage as shown by the dashed line to initiate a remote backup recovery of the clone volume to or from backup storage or to create snapshots of the clone volume in the primary storage at time t. Thus in the event that the storage device A crashes the data is recovered from backup storage and or snapshots .

Snapshots reside on local or remote storage arrays B and can be used for quick recovery and disaster recovery. Using snapshots can result in less downtime compared to other remote backup options such as tape based restore which is one example of how backup storage can be used. In the embodiment of snapshots are shown stored on storage device B which is part of the primary storage but located at a different location than storage device A. Thus the snapshots located on a different storage device than production volume and clone volume provide an added level of protection for keeping data secure. In one embodiment the snapshot is a block level copy i.e. raw data of a production volume or clone volume . In one embodiment more than one snapshot is generated at different times from the production volume so that snapshots exist at various points in time.

Thus in one embodiment the request for creating a backup of clone volume and or generating snapshots is generated by backup server for example using a jobs daemon residing on backup server . The backup server may further be configured for controlling other backup operations. For example the backup server may control and direct all automated server initiated backup operations or processes while the proxy host may control ad hoc backup and recover operations. It will be appreciated that the backup server may have additional functionalities not available to the proxy host such as those listed above.

In the backup server communicates with backup storage where one or more copies of clone volume can be stored. The backup storage can be located at the backup server or may be distinct and separate from the backup server . The data at backup storage represents one or more copies of the clone volume that has been backed up by the backup server on the backup storage . The data may include data obtained from the primary storage or may also include other data such as the data stored on host computer as well as data from other sources.

The backup server may also store and manage a client file index and a media database on the backup server itself and or on the backup storage . The client file index is an index of the backed up data items. The media database is an index of the backup volumes. The client file index and the media volume will be collectively referred to herein as the online indices . However it will be appreciated that other operating systems may use similar data structures for maintaining the directories and backed up items in order to restore the directories and items during recovery. While snapshots are only stored in primary storage the online indices may also store media database entries and file indexes of snapshot copies which can be browsed to facilitate locating snapshot copies in primary storage for recovery or other replication operations.

Backup server and proxy host include a graphical user interface that is configured to display source of data i.e. host computers and or the contents of primary storage in an organized manner such as by displaying volumes in a hierarchical structure. With regard to displaying the source of data the graphical user interface can display an identification number for a host computer along with the associated production volumes relating to that host computer. The graphical user interface may also be used to display how one or more host computers are networked together e.g. network to understand how data relating to the one or more host computers is organized in primary storage . In another example data relating to a single host computer may actually be stored across multiple production volumes which can be graphically displayed to a user via graphical user interface . Graphical user interface may also allow the user to configure primary storage to ensure that the primary storage has sufficient storage allocated to protect a particular volume directory or application. The graphical user interface is configured to allow a user to initiate backup operations for clone volumes and or generate snapshots and determine where the data will be stored. The graphical user interface is further used during a recovery operation to select one or more backup clone volumes and or snapshots and to direct how the recovery operation should occur.

The backup operations performed by the backup server on the data of host computer are typically performed automatically in accordance with a schedule established by a user. However a user may initiate ad hoc backup operations directly from the proxy host and or backup server . Further recovery operations can be performed from proxy host and or backup server .

As further depicted in a proxy host initiates ISB protocol operations such as splitting the production volume and clone volume between normal state and special state which then enables the proxy host to communicate directly with primary storage see dashed line to perform a backup of a clone volume or generate one or more snapshots . While proxy host backup server and backup storage are shown as separate hardware devices in one embodiment aspects of the proxy host backup server and or backup storage can be combined into the same hardware device.

In one embodiment a replication API is installed on the MAGIC platform to allow the proxy host to communicate with the MAGIC platform and access ISB functionalities provided by the database management service in order to perform backup recovery operations on data related to the MAGIC platform including the production application . For example through backup server a user requests a backup of clone volume which is relayed to proxy host . Proxy host communicates with replication API to request quiescing or suspending of the subsystems including production application and splitting of production volume and clone volume from normal state to special state in order to accomplish this replication operation.

In one embodiment backup of a clone volume and or creation of a snapshot occurs while the appropriate protection sets are in an application consistent state. This may be accomplished by quiescing the production application related to the relevant protection sets prior to performing the replication operation. As such copies of clone volume and or snapshots that reflect an application consistent state allow critical components of the production application and or MAGIC platform to be backed up and recovered as a consistent unit. Further a backup of a clone volume and or snapshot can further be ensured of being in an application consistent state by severing the connection between a production volume and clone volume while performing the replication operation.

As previously mentioned the backup of clone volume and or snapshots is used to recover data that has been lost during a disaster as well as for other replication operations such as perform mirroring operations data mining data consistency checking and the like.

With reference to a system and or software architecture is illustrated in further detail wherein like elements with regard to will be referred to with the same reference numeral. System illustrates an exemplary software architecture that operates backup server proxy host and or host computer in further detail.

As shown in proxy host includes an ISB manager configuration . The ISB manager configuration is configured to map one or more production volumes into a logical protection set for a replication operation initiated by proxy host . In one embodiment the logical protection set may be a grouping . It will be appreciated that the one or more production volumes might all be attached to one host computer or portions of the production volumes might be distributed within different host computers A B C . Furthermore a set of snapshots created at different times can be created for each protection set of production volume s .

Proxy host also includes a job sequencer that coordinates the communications between the various modules in proxy host to perform a replication operation. Resource database manager communicates with the ISB manager configuration to identify production volumes and or clone volumes related to the replication operation. Host computer manager communicates with the host computer to initiate ISB functions of splitting a production volume and clone volume . Storage services manager communicates with the primary storage to prepare a clone volume for surfacing and mounting. Surfacing a clone volume involves exposing a clone volume on the primary storage so that the proxy host can recognize the clone volume in its directories to allow storage services manager to select the clone volume for replication operations. Mounting involves assigning a drive letter to the surfaced clone volume to allow a user to browse the clone volume for accessing files directories etc.

Snapshot manager communicates with primary storage to generate snapshots of a clone volume . Backup and recovery manager facilitates backup and recovery operations that involve backup storage or other storage devices that are remote from the production volume and clone volume e.g. storing a snapshot on a different storage device B than storage device A .

At proxy host performs a backup of the clone volume to backup storage . Alternatively at proxy host generates a snapshot of clone volume and stores the snapshot in a storage device B which can be the same or different storage array as the storage device A. Thus as used herein the term backup broadly refers to various methods for creating duplicate copies of data stored in production volume at a particular point in time which exemplarily include copying the clone volume to a remote storage or generating a snapshot .

At the proxy host using ISB protocol directs the host computer to return the production volume and clone volume back to their connected normal state. At the host computer resynchronizes the data on production volume and clone volume .

In further detail illustrates an exemplary method for performing a backup of clone volume to remote storage . At backup server initiates a backup. This includes backup server passing an initiate backup command to proxy host that includes client settings that identify the name of a group or network . The proxy host looks up the group name using the ISB manager configuration see to get the identity of host computers attached to the group . The data structure of the initiate backup command includes the type of backup operation to perform e.g. backup to remote storage or create snapshot .

At the proxy host initiates splitting of the production volume and the clone volume related to the group . The proxy host identifies which production volumes and or host computers are related to the protection set to be backed up. Identifying the production volume includes communicating with ISB manager configuration located on the proxy host . In one embodiment job sequencer on the proxy host sends a command to resource database manager to obtain the identification of the host computer associated with the backup command. This includes identifying one or more host computers i.e. a group of host computers that are associated with the backup operation. The resource database manager communicates with the ISB manager configuration to obtain the information about production volume related to the identified host computers which includes but is not limited to the one or more storage devices located in primary storage e.g. CLARiiON ID number the serial number and or LUN number of the production volume . The job sequencer receives the production volume information from resource database manager . The job sequencer passes the production volume information to the host computer manager to identify which production volume clone volume to split. A MAGIC IP coordinator in the host computer manager creates ISB worker threads which are sent to the host computers related to the production volume to identify the production volumes to split.

At the host computer responds with at least one production volume and initiates splitting of the production volume with a clone volume . Thus in the primary storage the connection between the production volume and clone volume are temporarily severed into a special state. While the connection is severed the host computer is still able to perform read write operations to the production volume .

At after the split is completed the storage devices containing the production volume and or clone volume return the identification of the clone volume to the host computer . This includes information that allows the host computer to uniquely identify the location of clone volume within primary storage as well as the MAGIC database segment name to be backed up. For example in a CLARiiON system the identification information for the clone volume can include the CLARiiON ID number of the storage device and the LUN number of the clone volume .

At host computer reports back to the proxy host that the split was successful and provides the identification information of the clone volume and the MAGIC database segment name to be backed up. This information is received by the MAGIC ISB coordinator on the host computer manager which allows the host computer manager to create a backup work list of clone volumes that is backed up per a successful split from their respective production volume . The host computer manager sends the backup work list to the job sequencer .

The job sequencer prepares to perform a backup of the clone volumes identified in the backup work list. This includes surfacing and mounting the clone volumes as described above. The job sequencer sends a surface and mount command to storage services manager including the backup work list. The storage services manager accesses the primary storage and maps the clone volumes . This includes accessing index located at primary storage . The storage services manager returns a mount map to the job sequencer . After receiving the mount map the job sequencer sends a persistent backup command to the backup and recovery manager . The backup and recovery manager has a coordinator that initiates a backup job for each item included on the backup work list.

At backup and recovery manager performs a backup of the clone volume to backup server which directs saved data to backup storage . Backup and recovery manager communicates with backup server to provide identification information of the clone volume to be copied and saved as well as facilitating the connection between the proxy host and primary storage .

At the proxy host prepares to finalize the ISB backup process. The backup and recovery manager at the proxy host receives the backup report and forwards the report to job sequencer . Job sequencer sends a command to host computer manager to reestablish the connection between the production volume and clone volume along with the backup report. The MAGIC ISB coordinator in the host computer manager sends a reconnect command to the host computer .

At the host computer sends a request to primary storage to resynchronize the production volume and clone volume . The database management service on the MAGIC platform of the host computer initiates reconnection between the production volume and clone volume back to a normal state and performs synchronization of any new data on the production volume that occurred during the backup operation to the clone volume .

At after synchronization is initiated the host computer returns the status to the proxy host . This includes sending a report to the host computer manager on the proxy host that the synchronization is underway.

At the proxy host initiates splitting of the production volume and the clone volume related to the group . The proxy host identifies which production volumes and or host computers are related to the protection set to be backed up. Identifying the production volume includes communicating with ISB manager configuration located on the proxy host . In one embodiment job sequencer on the proxy host sends a command to resource database manager to obtain the identification of the host computer associated with the backup command. This includes identifying one or more host computers i.e. a group of host computers that are associated with the backup operation. The resource database manager communicates with the ISB manager configuration to obtain the information about production volumes related to the identified host computers which includes but is not limited to the one or more storage devices located in primary storage e.g. CLARiiON ID number the serial number and or LUN number of the production volume . The job sequencer receives the production volume information from resource database manager . The job sequencer passes the production volume information to the host computer manager to identify which production volume clone volume to split. A MAGIC IP coordinator in the host computer manager creates ISB worker threads which are sent to the host computers related to the production volume to identify the production volumes to split.

At the host computer responds with at least one production volume and initiates splitting of the production volume with a clone volume . Thus in the primary storage the connection between the production volume and clone volume are temporarily severed into a special state. While the connection is severed the host computer is still able to perform read write operations to the production volume .

At after the split is completed the storage devices containing the production volume and or clone volume return the identification of the clone volume to the host computer . This includes information that allows the host computer to uniquely identify the location of clone volume within primary storage as well as the MAGIC database segment name to be backed up. For example in a CLARiiON system the identification information for the clone volume can include the CLARiiON ID number of the storage device and the LUN number of the clone volume .

At host computer reports back to the proxy host that the split was successful and provides the identification information of the clone volume and the MAGIC database segment name to be backed up. This information is received by the MAGIC ISB coordinator on the host computer manager which allows the host computer manager to create a snapshot work list of clone volumes from which one or more snapshots is created based on a successful split from their respective production volume . The host computer manager sends the snapshot work list to the job sequencer . The job sequencer gets Integrated Disaster Recovery IDR relationships for the snapshot work list from resource database manager . The IDR relationships map out available snapshot storage spaces and assigns the available snapshot storage spaces to store a copy of the identified clone volumes as a snapshot . The snapshots can be configured as full or incremental copies. Full copy snapshots will have the full copy of the clone volume while incremental copy snapshots will have a full copy of the clone volume and then copy only the changed blocks on subsequent execution. Identification of the snapshots corresponding to the clone volume or IDR relationships is required to create the snapshots for each clone volume and prepare the system for disaster recovery and quick recovery with minimal loss of data.

Job sequencer sends the IDR sessions identified in the snapshot work list to the snapshot manager . The snapshot manager communicates with the primary storage to identify which IDR sessions are available to ensure that the snapshot storage spaces that were identified at exist and are available and returns the identification of the available IDR sessions to the job sequencer . Proxy host uses the available IDR sessions to select from this list of snapshots one or more IDR sessions to perform. This includes sending the available IDR session list from the job sequencer to the resource database manager . The resource database manager communicates with the ISB Manager configuration to select one or more IDR sessions i.e. the name of a snapshot the snapshot storage space to which the snapshot will be saved and the clone volume s from which the snapshot will be copied to perform and sends these selections to the job sequencer via the resource database manager and this sequence is done iteratively for each clone volume in the work list.

At proxy host creates one or more snapshots from the selected IDR sessions. This includes job sequencer sending a command to snapshot manager to start the selected one or more snapshots and also sends the IDR relations. The snapshot manager communicates with the primary storage to generate the snapshots from the clone volume . In one embodiment this includes creating a San Copy Session of a clone volume effectively copying the data from clone volume into the snapshot storage space s that was selected.

The primary storage reports to the snapshot manager when the snapshots are generated. After the snapshot s are created job sequencer sends a commit IDR session command to the resource database manager which updates the ISB manager configuration . Job sequencer sends a save command to the backup and recovery manager which communicates with the primary storage to save the snapshots to the identified snapshot storage space s . This includes saving the snapshot on a storage device in the primary storage saving the snapshot in backup storage or saving the snapshot to another storage device in a storage cluster of storage devices separate from the primary storage. After the snapshots are saved to an identified snapshot storage space the proxy host reports to the backup server the location of the snapshots.

At the proxy host prepares to finalize the ISB backup process. The backup and recovery manager at the proxy host receives the backup report and forwards the report to job sequencer . Job sequencer sends a command to host computer manager to reestablish the connection between the production volume and clone volume back to a normal state along with the backup report. The MAGIC ISB coordinator in the host computer manager sends a reconnect command to the host computer .

At the host computer sends a request to primary storage to resynchronize the production volume and clone volume . The database management service on the MAGIC platform of the host computer initiates reconnection between the production volume and clone volume back to a normal state and performs synchronization of any new data on the production volume that occurred during the backup operation to the clone volume .

At after synchronization is initiated the host computer returns the status to the proxy host . This includes sending a report to the host computer manager on the proxy host that the synchronization is underway.

Disaster recovery site includes one or more storage devices including a disaster production volume and one or more recovery volumes A B C. The recovery volumes are copies of a clone volume . Alternatively the recovery volumes are copies of snapshots taken at different points in time. In one embodiment disaster recovery site is created by backup server accessing data in backup storage and recovering data into one or more recovery volumes . This is referred to as a pre restore period.

In one embodiment an existing proxy host can be used to facilitate recovery of a primary storage. Alternatively it may be desirable to provide a recovery proxy host in the event that the existing proxy host is unavailable for recovery. Where a recovery proxy host is used a graphical user interface can be restored or recovered to proxy host . Recovery of GUI involves recovery of the resource database manager and ISB Manager configuration . These will be used to browse the client file indexes for the backups of the clone volumes and or snapshots so that the user knows what information is available for recovery. The graphical user interface allows a user to select the volumes that need to be restored data to be used to recover the data that was lost and how the data should be restored.

Once the disaster recovery site is established backup server communicates with proxy host placing the proxy host in communication with the disaster recovery site . As shown in disaster recovery site also includes a host computer and a storage device that can be configured to function analogous to the host computer and storage device A. This allows the proxy host to perform various operations on the pre restored information in storage device to configure the storage device to hold a production volume and a clone volume that can be operational with a host computer which will be described further below. Backup server then may or may not disconnect from direct communication with the disaster recovery site . In the event that backup server does disconnect from direct communication with the disaster recover site backup server is able to communicate with the disaster recovery site via proxy host .

As illustrated in in one embodiment at a recovery volume from storage device on disaster recovery site is copied to recovery clone volume on recovery storage device of disaster recovery site . Alternatively at a recovery volume from storage device is copied to recovery production volume on recovery storage device of the disaster recovery site . In still another embodiment at the data from a recovery volume is copied to disaster production volume .

Thus if the user selects copying of recovery volume to disaster production volume the user can configure the storage device to act as a new primary storage with the recovery volume acting as a clone volume to the disaster production volume . Alternatively if the user selects copying of recovery volume to recovery production volume and recovery clone volume then the recovery storage device can act as the new primary storage.

At the recovery storage device or depending on the recovery scenario used is resynchronized with recovery host computer . This can include proxy host connecting the recovery host computer with whichever storage device acts as the new primary storage so that the recovery host computer can proceed to use the new production volume and clone volume to store data from a recovery production application located on the recovery host computer. This can further include connecting the disaster production volume with the recovery clone volume or alternatively connecting the recovery production volume and recovery clone volume using ISB protocol.

In summary the proxy host facilitates communication between the MAGIC platform on the host computer and the backup server making backup and recovery functions that were previously unavailable to the production volume and clone volume now possible. These functions include scheduling backups of clone volume to a backup storage scheduling creation of snapshots at various points in time. Performing remote recovery of data from the saved clone volumes and or snapshots is also facilitated by proxy host . In addition the backup server maintains records of backup snapshot operations and locations of backup snapshots in its online indices.

Embodiments included dedicated devices or systems that include both hardware and or software components. Embodiments within the scope of the present invention also include computer readable media having executable instructions or data fields stored thereon. Such computer readable media is any available media which is accessed by a general purpose or special purpose computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium which is used to store the desired executable instructions or data fields and which is accessed by a general purpose or special purpose computer. Combinations of the above should also be included within the scope of computer readable media. Executable instructions comprise for example instructions and data which cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions.

Those skilled in the art will appreciate that the invention are practiced with other computer system configurations including hand held devices multi processor systems microprocessor based or programmable customer electronics network PCs minicomputers mainframe computers and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules are located in both local and remote memory storage devices.

The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

