---

title: Simulation of connected devices
abstract: Simulating device interactions. A method may be practiced in a computing system for simulating interconnected devices. The method of simulating device interactions may be done in performing an overall transaction to obtain an output of system performance characteristics including measurement of latencies and/or device loads for actions performed by devices in performing the overall transaction. The method includes dividing a transaction into individual actions. The actions are applied to appropriate device models to produce latencies and/or device utilizations for the action as applied to the appropriate device model. This may be done by including an indication of an action type and optionally an action subservice. Memory resources may be conserved by ending the simulation when latencies and/or device utilizations have settled. Device utilization and latency may be aggregated and averaged over time. When changes in the latencies and/or device utilizations are within a predetermined range, the simulation can be ended.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07571088&OS=07571088&RS=07571088
owner: Microsoft Corporation
number: 07571088
owner_city: Redmond
owner_country: US
publication_date: 20060331
---
Computers and computing systems have affected nearly every aspect of modern living. Computers are generally involved in work recreation healthcare transportation entertainment household management etc. The functionality of computers has also been enhanced by their ability to be interconnected through various network connections.

Computer systems can be interconnected in large network configurations so as to provide additional functionality. For example one typical network configuration is a configuration of computer systems interconnected to perform e mail functionality. In one particular example an e mail server acts as a central location where users can send and retrieve emails. For example a user may send an e mail to the e mail server with instructions to the e mail server to deliver the message to another user connected to another e mail server. Users can also connect to the e mail server to retrieve messages that have been sent to them. Many e mail servers are integrated into larger frameworks to provide functionality for performing scheduling notes tasks and other activities.

Each of the computer systems within a network environment has certain hardware limitations. For example network cards that are used to communicate between computer systems have a limited amount of bandwidth meaning that communications can only take place at or below a predetermined threshold rate. Computer processors can only process a given amount of instructions in a given time period. Hard disk drives are limited in the amount of data that can be stored on the disk drive as well as limited in the speed at which the hard disk drives can store the data.

When creating a network that includes a number of different computer systems it may be desirable to evaluate the selected computer systems before they are actually deployed in the network environment. By evaluating the systems prior to actually implementing them in the network environment trouble spots can be identified and corrected. This can result in a substantial cost savings as systems that unduly impede performance can be upgraded or can be excluded from a network configuration.

Evaluation systems have previously been implemented to evaluate the performance of selected computer systems prior to the deployment of such systems. In previous evaluation systems the amount of memory required to perform the evaluation was often unknown. In particular in previous systems the systems would simulate for a selected period of time. The amount of memory used in the simulating system was dependent on the amount of time the simulation took and the various activities that took place within the simulation. Because previous systems maintained output data points for all simulation results data memory requirements for the simulating system were typically high and expanding as more data points were generated.

The subject matter claimed herein is not limited to embodiments that solve any disadvantages or that operate only in environments such as those described above. Rather this background is only provided to illustrate one exemplary technology area where some embodiments described herein may be practiced.

One embodiment included herein includes a method of simulating device interactions. The method may be practiced for example in a computing system for simulating interconnected devices. The method of simulating device interactions may be done in performing an overall transaction to obtain an output of system performance characteristics including measurement of latencies and or device loads for actions performed by devices in performing the overall transaction. The method includes dividing a transaction into individual actions. The actions are applied to appropriate device models to produce latencies and or device utilizations for the action as applied to the appropriate device model. This may be done by including an indication of an action type and optionally an action subservice.

Another method disclosed herein may be practiced in a computing system for simulating interconnected devices. The method is a method of simulating device interactions in performing an overall transaction to obtain an output of system performance characteristics including measurement of latencies and or device loads for actions performed by devices in performing the overall transaction. The method includes producing latencies and or device utilizations for one or more transaction by simulating actions of the transactions applied to the appropriate device models. One or more averaged transaction latencies and or device Et utilizations are stored over time for the one or more transactions. One or more current transaction latencies and or device utilizations are aggregated into the one or more stored averaged transaction latencies and or device utilizations. If the statistical characteristics of the averaged transaction latencies and or utilizations are within a predetermined range of statistics quality simulating device interactions is ended.

Another embodiment includes a computer readable medium for use in a computing system for simulating interconnected devices. The computer readable medium includes data structures for defining devices useful for simulating device interactions in performing an overall transaction to obtain an output of system performance characteristics including measurement of latencies and or device loads for actions performed by devices in performing the overall transaction. The computer readable medium includes a first field defining an action type for an action. The computer readable medium optionally includes a second field related to the first field defining a subservice defining a particular class of the action type. One or more device model fields are included on the computer readable medium defining device models that contain methods for calculating the latencies and or device utilization for actions simulated by the device models. The computer readable medium further includes a third field comprising a scheduling key correlating a device model to an action type and optionally a subservice.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Additional features and advantages will be set forth in the description which follows and in part will be obvious from the description or may be learned by the practice of the teachings herein. Features and advantages of the invention may be realized and obtained by means of the instruments and combinations particularly pointed out in the appended claims. Features of the present invention will become more fully apparent from the following description and appended claims or may be learned by the practice of the invention as set forth hereinafter.

Embodiments herein may comprise a special purpose or general purpose computer including various computer hardware as discussed in greater detail below.

One embodiment described herein includes functionality for modeling and simulating a complex computer system. In the embodiment described herein to model the complex computer system an overall model exists. Within the overall model are device models. The overall model describes how the device models are interconnected or which device models belong to other device models. For example one device model may represent a server and another device model may represent a client. The overall model includes information describing the connection between the server and the client. In another example one device model may be a hard disk drive. Another device model may be a server. The overall model may include information describing how the hard disk drive device model is incorporated into the server device model.

The overall model further includes a workload generator. The workload generator generates computing transactions that are to be performed between the device models within the overall model. For example the workload generator may generate a retrieve mail transaction. The retrieve mail transaction may be divided up into individual actions such as individual processor activities network activities and disk I O. These individual actions are simulated by the device models. As such information can be obtained about the usage of devices being modeled and or latencies for actions to be performed. As such an indication of the amount of time to complete a transaction can be calculated. The workload generated by the workload generator is dependent on device models within the overall model. For example a device model for a client computer system may specify that a transaction is performed at a given rate. The workload generator will then translate that transaction to specific workload tasks to be performed by device models within the overall model.

Some embodiments described herein further include functionality for performing the simulation by using a fixed amount of memory on the computer system performing the simulation. This can be accomplished by maintaining a limited number of data points. For example in previous systems the systems would simulate for a selected period of time. The amount of memory used in the simulating system was dependent on the amount of time the simulation took and the various activities that took place within the simulation. Because previous systems maintained output data points for all simulation results data memory requirements for the simulating system were typically high and expanding as more data points were generated. Some embodiments described herein minimize the memory resources usage by maintaining an average output. Specifically one embodiment described herein includes functionality whereby the output is aggregated into an averaged output such that there is no need to maintain all output data points. Additionally by using an averaged output one embodiment described herein is able to detect when the output is converging to a stable and consistent output. The output may include any indication of latencies and or device utilization outputs. When a sufficient number of latencies and or device utilization outputs have been collected to allow the simulation output to converge to a consistent steady state or to be within a reasonable deviation from the convergence a simulation can be terminated as further simulation will not necessarily provide additional information but may rather simply be an unnecessary use of computing resources.

Referring now to an overall model is shown. The overall model includes several components including a performance scenario application programming interface API a simulation controller a workload generator an event processor a statistics collector a device model library and device models and .

The performance scenario is a container that holds information regarding the system topology. For example the performance scenario defines the hardware instances modeled by device models hardware configuration of the device models and the workload definition. The performance scenario may define users and their characteristics to define the workload of the system being simulated by the overall model .

Referring now to some functionality of the performance scenario API is illustrated. The performance scenario API may define interconnections for a model of a computing system including device models . As illustrated device models may be connected in a fashion to represent the modeled system. The performance scenario API may specify device models that are interconnected with one another. For example the performance scenario API may specify servers interconnected with clients. For example the device model may represent a server model where the model represents a client model. An interconnection may be specified in the overall model connecting the server model to the client model . Additionally the performance scenario API may specify individual devices within a computer system. For example the structured model may specify for a computer system devices such as processors network connections storage memory and so forth. Illustratively illustrates that device model is specified as a component of device model .

The overall model may be used in one exemplary embodiment to evaluate complex computer systems to determine expected utilization of devices in the computer system and latencies for transactions performed within the computer system. This may be used to determine the stability of the complex computer system capacity of the complex computer system speed of the complex computer system and the like. The overall model therefore includes a workload generator . The workload generator produces activities to be simulated by the device models. For example if the device model is a model of a hard drive the workload generator may produce disk I O actions such as reads and writes that are to be performed by the device model. In one embodiment the workload generator produces transactions and activities according to transactions specified in a device model. For example a client device model may include a parameter that indicates that the device model generates get mail transactions per second. The workload generator creates the actions corresponding to these transactions for processing by device models within the overall model .

The workload generator creates transactions. The transactions may be modeled as a series of workload requests or actions. For example in one embodiment a transaction may be defined by an edge labeled directed graph that characterizes the causality dependencies between the workload requests. Referring to an example of an edge labeled directed graph is illustrated. The edge labeled directed graph illustrates an example of actions that may be included as part of a server request transactions. For example at processor activities as part of a server request are modeled. At network activities as part of a server request are modeled. The processor activities illustrated at may be defined in one embodiment as a number of cpu cycles. These cpu cycles can then be directed to an appropriate one of the device models for simulation. The network activities at may be defined in one embodiment as a transfer of an amount of data to be transferred over a network. In some embodiments the network activities may be further divided into smaller network transactions where the network transactions are divided into packets of an appropriate size. The network activities can be directed at the same device model for simulation.

The direction of the graph edges in the edge labeled directed graph represents the causality of actions. An action starts after all the previous actions are ended. A transaction is not always sequential. For example further illustrates an edge labeled directed graph with parallel segments that start with a fork node and end with a join node . The logic of the join node is that it is not complete until after all prior actions from the joining branches finish their processing.

Latencies can be calculated for an overall transaction by combining latencies of individual actions. When individual actions are performed in series such as is shown at graph the latencies can simply be added together to arrive at the overall transaction latency. When individual action are performed synchronously in parallel the longest latency in the parallel action may be used. So for example in the graph the overall latency is the longest of A B C D F and A E F.

As described previously an action of a transaction represents an integral application operation of one of an action type. In the examples shown an action is a modeling abstraction that covers a set of actual machine instructions or that consume a resource or a set of resources of similar types. For example the following actions may be included within a transaction compute operation disk I O and communication. A compute action may be defined as a number of cpu operations. A disk I O may be defined as including an operation and a size. For example a disk I O may specify one of a random read a random write a sequential read or a sequential write and a size of the operation. A communication operation may be defined in terms of a size of a block of data to be transmitted on a network.

Each action in the transaction is generated by a particular application service and is scheduled for execution in the same resource container i.e. the same computer that hosts the application service. In the case of the communication action the resource assigned to execute the action is the resource responsible for network coordination. The device model associated with the principal action resource is the master device that schedules the action on other device models and computes the overall action latency.

The workload transactions generated by the workload generator are dependant on the device models included within the overall model . For example certain client models may be designed to request mail at a given rate. The workload generator generates transactions for the client model at that rate. The workload generator will generate transactions for other affected device models as well. So for example the workload generator will generate transactions for responses from the server model to which the client model requests are directed.

The event processor creates from the transactions from the workload generator hardware events corresponding to the actions. For example a communication request from a web server to a database request will cause the event processor to create a send message event sent to a web server NIC and a receive message hardware event to the receiving database server NIC. The event processor calls the device models to determine how long the event will take i.e. the latency on the specific instance of hardware. For example a NIC device model will determine the time required to send 100 Kbytes through a fast Ethernet network. The event processor also takes into account queue effects such as when events compete for a single resource and resource sharing such as for example when multiple threads share a single CPU.

Due to the complex nature of devices being modeled by the device models and that a complex device can be modeled by several device models an application action can be scheduled on multiple device models. The set of device models that process the same application action usually represent a compound device or a subsystem that include connected devices. For example a RAID array may be modeled by several individual disk models interconnected together. As such the concepts of data mirroring and data striping common in RAID examples may cause the same actions be applied to several individual disk models when an action is applied to a RAID array model.

The following is an example of a networking example. At the transport layer of the OSI model an application sends a message over the network from computer X to computer Y. At the data link layer the message is split into packets and each packet travels through the network interface card in the computer X the network switch and finally through the network interface in the computer Y. Then the message is assembled from the packages in the computer Y and the application in X is notified that the communication has completed and it can proceed with subsequent actions.

This example demonstrates how a single application action has been processed by three difference devices. Each of these devices can introduce a latency component to the action and the total action latency is calculated out of the detailed device latencies by the device model that has been assigned to be the master device for this action.

Activities from a workload generator can be directed to a device model for simulation. The device models library is a container including the device models such as for example device models and . The device models define how device will act during simulation. The device models may define latency information for a given action simulated by the device model. For example a model of a disk drive may include eight parameters including a constant and slope for random reads a constant and slope for random writes a constant and slope for sequential reads and a constant and slope for sequential writes. Latencies for disk drives are generally linear depending on the size and type of the I O operation. By specifying a size and type of I O operation e.g. random read of 100 KB a latency can be calculated from the constant and slope. Similarly other device models may include defined latencies. For example CPU device models may specify latencies for a given number of processor operations or for a given number of processor cycles consumed. Network interface device models may specify latencies for sending or receiving a given amount of data.

The device model may include additional mapping for further distributing activities from the workload generator. An example is illustrated in . illustrates a device model representing a DeviceX. The device model may be for example a model of a client computer system. The device model is shown as being interconnected to a number of other device models and . In the example shown the device models and may be models of storage devices. For example the device models and may be models of SANs multi disk arrays individual hard drives and the like.

Notably while not shown explicitly when a model is for a higher level component the device model may include lower level device model components as part of the model. For example a multi disk array component model may include single disk drives as part of the component model. The following is an example of a single disk configuration 

In the example above several parameters are specified including the type of device the storage size the interface type the seek time the rotational speed the external transfer rate the internal transfer rate the controller cache size and the various constants and slopes described previously.

A composite storage device can be modeled by using a hierarchical data structure including a number of instances of definitions of parameters for a component of the composite storage device instantiated together. For example a disk group model may include disk models. Illustratively the following is an XML document that illustrates one example of the single disk configuration described above being implemented in a disk group configuration 

In this example of a disk group configuration the disk group model includes four instances of the single disk configuration described previously. Illustratively the references to include the single disk configuration by reference.

Returning once again to the example of a generic mechanism is used to represent associations between devices. The associations can represent physical connections between the devices such as network connections or a logical association through software configuration such as file mapping to disks. The associations can be queried by the device models to select the right subset of devices for the application actions depending on the action parameterization. The generic mechanism for device associations in the example shown in is implemented using scheduling keys and .

Each scheduling key represents that the device belongs to a scheduling subset of another device. For example the device model includes a scheduling subset . The scheduling subset includes actions and subservices. For example the scheduling subset illustrates Disk I Os as action types. Two subservices are called out namely Data and Log subservices for disk I O but other subservices are possible such as a subservice which models processor affinity by mapping compute actions to specific processors in a CPU configuration. Data Disk I Os may be disk reads and writes of data to a database or other data storage container. Log Disk I Os may be disk reads and writes of data to a log container. The scheduling subset maintains a correlation to device models for each unique value of a scheduling key so it can identify device models with an appropriate key when necessary and select a single device using any supported scheduling policy. A scheduling key in the embodiment shown is a tag attached to a device model that indicates that the device can perform a certain function. Other device models such as the device model can maintain lists of tags that they are interested in and the sets of device models that are marked with these tags.

As shown in device models and are tagged with scheduling keys . Device models and are tagged with keys and respectively with two key elements namely ActionType DiskI O and SubService Data. This means that both these device models can process disk I O actions that are targeted to the Data Subservice The device models and are tagged with the keys and respectively with two key elements namely ActionType DiskI O SubService Log. This means that both these device models can process disk I O actions that are targeted to the Log Subservice. Note that the device model is tagged with both keys simultaneously. This represents the fact that the disk drive that corresponds to the device model contains both file types and the application being modeled by the overall model is using this drive to store data and log information.

The device model in this example is a master device that maintains the scheduling subset including the list of scheduling keys and devices associated with them. If the device model is presented with an application action of the type DiskI O that has the subservice attribute of Log the device model may query the scheduling subset for the scheduling key ActionType DiskI O Subservice Log. The query would return a subset of devices including device models and . The device model can then use a scheduling policy to select a single device to continue processing the action. The scheduling policy may be for example random priority random least busy or random round robin and the like. Random scheduling is performed by randomly choosing a device model where each device model has identical probability of being selected. Priority random scheduling is performed by choosing a device model at random but where each device model has a priority that determines the probability for this device model being selected. In one embodiment the priority may depend on the device state. Least busy or random scheduling is performed by selecting the device with the least busy index. If more than one device has the same least busy index then a random policy is applied to those devices. Round robin scheduling is applied by organizing a list of device models in a closed loop and selecting a device model by selecting the next device model relative to a previously selected device.

While the preceding example has illustrated a disk I O example similar actions may be performed for processor activities or network activities. For example a similar scheme can be used for modeling combinations of network devices. A principle device model that represents the network coordination resource such as a LAN switch can send an action from the workload generator to sending and receiving computer models. The sending computer model finds a network interface card NIC model that is connected to the LAN switch that processes the action. Each NIC model has a scheduling key that indicates to what computer device model the NIC model correspond. The computer device model constructs the scheduling key for the NIC model and retrieves the NIC model for processing the action.

The structure of the scheduling keys can be different and depends on the nature of the association between devices. If a device is selected for the action based on its connectivity then the connectivity information may be part of the scheduling key. In one embodiment two types of scheduling keys are used namely subservice keys and communication keys. A subservice key contains two parameters as illustrated above action type and subservice. The action type identifiers an action type such as for example processor activities network communication activities or disk I O activities. The subservice argument identifies a particular type of action type. Any appropriate number of subservices may be define.

A communication key includes an action type a communication peer and a direction. For example a communication key may specify a network communication to from a specific device model where the communication is a send or receive. The communication keys may be used for example to identify WAN links for a WAN cloud device model. In this case the WAN cloud model schedules the action on a WAN link that is selected based on the direction that this WAN link is configured to model and the computer that the link connects to the cloud. Using these two parameters the WAN cloud model constructs an instance of the communication scheduling key and selects a WAN link for the action.

The scheduling key mechanism may be used for example for network modeling such as LAN connected computers via one or more NIC s and WAN links via NICs. The scheduling key mechanism may also be used for example to model RAID storage and or SAN storage.

Returning once again to the simulation controller may be embodied as set of APIs that control the start end and cancellation of the simulation process. The statistics collector uses the raw data produced by the event processor filters the data relevant to the users and keeps statistics such as the overall utilization of devices and the latency of end to end transactions.

In one embodiment device utilization and latencies statistics can be kept by keeping an averaged value of the device utilizations and latencies. For example illustrates a typical average device utilization over time graph. Notably at times near the beginning of simulation the average device utilization varies widely while as time progresses the device usage varies less.

Some embodiments are able to maintain a fixed memory footprint for the system used to simulate the overall model by maintaining a limited number of the data points generated by a device model and an averaged value for device utilization and or device latency. For example rather than maintaining output values for all values for the graph shown in a current averaged value along with one or more statistical measurements can be maintained. The averaged value will approach an asymptotic value which is the average device utilization and or latency when the simulation of the particular device or transaction is at a stabilized equilibrium.

The duration of the simulation is a function of the statistical variations of the results from the model. For example the statistic collector can maintain statistics including device utilizations and latencies in the system. The simulation controller can detect when certain statistical characteristics of the averaged device utilizations and or latencies are within given ranges and can thus end the simulation.

Device utilization and or latencies can be monitored for a number of devices and or transactions. When enough in some cases all of the device utilizations and or latencies have stabilized to within a specified deviation the simulation can be ended.

Notably various averaging techniques can be used. For example a true average may be calculated. Alternatively a current averaged value may be normalized with a previous averaged value. Additionally there are several techniques that may be used to calculate variances and standard deviation.

Referring now to a method of simulating device interactions in performing an overall transaction is illustrated. The method may be practiced for example in a computing system for simulating interconnected devices. The method of simulating device interactions in performing an overall transaction may be performed to obtain an output of system performance characteristics including measurement of latencies and or device loads for actions performed by devices in performing the overall transaction. The method includes dividing a transaction into individual actions act . The method further includes applying the actions to appropriate device models to produce latencies and or device utilizations for the action as applied to the appropriate device model. act . This may be done by including an indication of an action type and optionally an action subservice.

The method may further include obtaining a transaction latency and or device utilizations by combining the latencies and or device utilizations for the actions. Combining the latencies and or device utilizations for the actions may include adding latencies together for actions that are performed serially. Alternatively combining the latencies and or device utilizations for the actions may include including a longest latency of two or more latencies when the two or more latencies are performed in parallel. Notably parallel and serial combinations may be done together as well.

The method may further include storing one or more averaged transaction latencies and or device utilizations over time for one or more transactions. One or more current averaged transaction latencies and or device utilizations are aggregated into the one or more stored averaged transaction latencies and or device utilizations. If the one or more statistical characteristics of the averaged transaction latencies and or device utilizations are within a predetermined range that specifies the desired output accuracy the simulation may be ended.

Additionally a fixed memory footprint can be maintained when simulating device interactions by only maintaining a fixed number of stored averaged transaction latencies and or device utilizations and a fixed number of current averaged transaction latencies and or device utilizations.

The method further includes storing one or more averaged transaction latencies and or device utilizations over time for the one or more transactions act . For example the statistics collector of may be used to store latencies and or device utilizations obtained from the simulation of the device models in the device models library .

The method further includes aggregating one or more current averaged transaction latencies and or device utilizations into the one or more stored averaged transaction latencies and or device utilizations act .

The method also includes computing statistical characteristics of the averaged transaction latencies and or device utilizations act . For example computations may be made to calculate the how much averaged transaction latencies and or device utilizations have changed.

If the computed statistical characteristics of the average transaction latencies and or device utilizations are within a predetermined or otherwise computed range simulating device interactions is ended act . The simulation controller of can monitor the convergence of averaged transaction latencies and or device utilizations and can stop the simulation as appropriate.

Embodiments may also include computer readable media for carrying or having computer executable instructions or data structures stored thereon. Such computer readable media can be any available media that can be accessed by a general purpose or special purpose computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium which can be used to carry or store desired program code means in the form of computer executable instructions or data structures and which can be accessed by a general purpose or special purpose computer. When information is transferred or provided over a network or another communications connection either hardwired wireless or a combination of hardwired or wireless to a computer the computer properly views the connection as a computer readable medium. Thus any such connection is properly termed a computer readable medium. Combinations of the above should also be included within the scope of computer readable media.

Computer executable instructions comprise for example instructions and data which cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions. Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

