---

title: System and method for replacing contents addressable storage
abstract: Data is migrated from a first CAS (contents addressed storage) system to a second CAS system. When the migration process is started, the second CAS system retrieves a list of the objects stored on the first CAS system. The second CAS system, based on the list, retrieves each object from the first CAS system, calculates an object ID for each object, and stores each object and the calculated object ID into the storage devices in the second CAS system. Methods for reducing downtime during the migration process are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08131682&OS=08131682&RS=08131682
owner: Hitachi, Ltd.
number: 08131682
owner_city: Tokyo
owner_country: JP
publication_date: 20060511
---
The present invention relates generally to storage systems and in particular to storage systems composed of a plurality of contents addressable storage CAS systems

Of the number of different known methods for archiving data each method has certain disadvantages. Until recently archiving with tape has been the most commonly used method for archiving data but tape archives are often difficult to access and do not allow quick and easy retrieval of archived data. Because of this disk arrays have become more common as the archival medium of choice since they allow archived data to be more quickly and easily accessed. However prior art disk array archiving schemes suffer from several limitations such as users being unable to locate the correct file and the storage of a large amounts of duplicate data leading to increased costs for archiving.

Fixed Content Aware Storage FCAS is generally defined by SNIA Storage Networking Industry Association as storage of unchanging data fixed content and associated metadata based on a variety of naming schemas including Content Addressed Storage CAS and global content independent identifiers. In the storage industry CAS is also sometimes referred to as Content Addressable Storage Content Aware Storage or Content Archive Storage.

In CAS users and host computers store and retrieve data as an object composed of content and metadata rather than treating data as a standard file. The data content is appended with metadata attributes of the content and is assigned a unique object designator known as a content address or object ID . For archiving the object is stored to a permanent location on a hard disk. Since each object is unique multiple copies of the same file are not stored. This reduces the storage of duplicate data and reduces the total storage requirements thereby overcoming a major limitation of disk array archiving discussed above.

In a CAS object the content is a byte stream and the metadata is the additional information regarding attributes of the content such as creation time retention period size of the content comments regarding the content and the like. By attaching a detailed and well thought out metadata to the object data may be indexed classified or searched without knowing specific filenames dates or other traditional file designations. Thus enhanced metadata may include background information comments and other information on the data that can aid someone who accesses the data in the future in understanding or applying the data and that can also aid in searching for and locating desired data.

When an object is stored to CAS the CAS system generates identification information object ID or object identifier and then the object ID is returned to hosts users. Hosts users are able to access objects using the object ID. In some implementations of CAS the object ID is generated using a kind of hash algorithm such as SHA 1 Secure Hash Algorithm SHA 256 or MD 5 Message Digest 5 . But at the moment neither the method for generating the object ID nor the access protocol has yet been standardized. Therefore to enable object access in CAS host computers use what ever API Application Programming Interface is provided by the vendors of the particular CAS system that the user has purchased.

CAS also enables data reduction by locating commonality among data and by eliminating duplication of stored data. When data is stored to the CAS system a hash algorithm is applied to the data which produces a unique value according to the content. The CAS system compares that unique value against an index of unique values of other saved objects. If the unique hash value is not in the index then the data and its metadata are stored and the hash value is added to the index. However if the hash value is already in the index then that data has already been stored and only the metadata and a pointer to the already stored data are stored. This can result in substantial savings of archival storage space. Additionally in many applications less expensive SATA hard disks may be used in CAS systems rather than more expensive Fibre Channel disks which can result in additional cost savings. US Patent Application Publication No. US 20050125625 to Kilian et al. which is incorporated by reference herein in its entirety discusses one application of CAS for parsing a content address to facilitate selection of a physical storage location in a data storage system. This application discloses a method for data placement in a CAS storage system but fails to teach or suggest any method for the migration of data from one CAS storage system to another.

Because the lifetime of data is generally longer than that of the storage apparatus on which it is stored there sometimes arises the need to migrate data from a current storage system to a new replacement storage system. During data migration one important concern is to shorten any downtime required during the migration. U.S. Pat. No. 6 108 748 to Ofek et al. discloses one method for migrating data in storage systems while a host computer is online. Ofek et al. disclose a data migration method that is applicable to a mainframe storage system or a block access storage system in which the same access method is applicable to both the donor storage device storage system to be migrated and the donee storage device newly installed storage system . However as the method described in this disclosure is directed to data migration between CAS systems in which the data access methods are different from each other the technique disclosed by Ofek et al. cannot be used.

When migrating data between CAS systems it is likely that the object ID information will be changed and accordingly current data migration methods that are applicable to block based storage systems cannot be used. Since there is no industry standard for CAS systems when moving data between an old CAS system sold by one vendor and a new CAS system sold by a different vendor the object ID content address of each object will be different in the new system than it was in the old system. This is because the access method and the object ID generating method will be different. For example one vendor may use one or more first hash algorithms for creating the object IDs while another vendor might use different hash algorithms. Furthermore even if both CAS systems were manufactured by the same vendor the method of generating object IDs might be different when the new CAS system is upgraded. Therefore in CAS data migration another method is required for transferring data between a first CAS system having one data access method or object ID calculation scheme and a second CAS system having a different data access method and object ID calculation scheme.

Under the present invention a donor first CAS system a donee second CAS system and at least one host computer are provided. When the migration is started the second CAS system retrieves the list of the objects index from the first CAS system that are stored in the first CAS system. The second CAS system based on the list retrieves each object from the first CAS system calculates a new object ID of each object and stores each object and calculated object ID into the storage device in the second CAS system. After the process finishes the second CAS system sends the information to the host computer that records the mapping between the object ID of each object that was previously assigned by the first CAS system and the object ID of each object that is newly assigned by the second CAS system.

These and other features and advantages of the present invention will become apparent to those of ordinary skill in the art in view of the following detailed description of the preferred embodiments.

In the following detailed description of the invention reference is made to the accompanying drawings which form a part of the disclosure and in which are shown by way of illustration and not of limitation specific embodiments by which the invention may be practiced. In the drawings like numerals describe substantially similar components throughout the several views. Further the drawings the foregoing discussion and following description are exemplary and explanatory only and are not intended to limit the scope of the invention or this application in any fashion.

Donor storage system is a CAS system containing data to be migrated to donee storage system which is also a CAS system. In this embodiment donor storage system contains data in a first type of CAS object format calculation scheme and data access method. Under the invention this data is migrated to donee storage system which stores data in a second type of CAS object format calculation scheme and data access method. The most common reason for migrating the data from donor system to donee system is when the donor system is being replaced with the donee system although migration might also be carried out to create a copy of the data from the donor system or for other reasons. Donor system and donee system in this embodiment are assumed to contain similar hardware components and accordingly the following description of applies to both systems in this embodiment. Although it should be noted that in alternative embodiments the donee storage system may be composed of some hardware elements that differ from those of the donor storage system

Each storage system includes a disk controller and at least one storage device such as hard disk drives. Disk controller may include a CPU a memory a cache memory a NVRAM nonvolatile random access memory one or more network interfaces I Fs and a disk I F each of which is described in more detail below.

CPU executes software programs for processing host I O input output requests for storing and retrieving data in the storage devices and the like. The software programs executed by CPU under the invention are described in greater detail below.

Memory is used to store the software programs that are executed in the CPU and is used to store the information that is necessary to process and manage the data in the storage devices . Cache memory is used to temporally store data that is read to or written from host and for caching the data to shorten the response time of host . Cache memory may be of the type that includes a battery back up to preserve data even if the storage system power supply fails. Further during startup of the storage system the programs that are executed in the CPU are stored in the NVRAM . When the storage system starts booting the programs in the NVRAM are loaded into memory and are executed by CPU .

Network I Fs may be used to connect the storage systems to a network via a network switch and thereby enable communication of the storage systems with host . Network I Fs may also be used to enable donor storage system to communicate directly with donee storage system as will be discussed in greater detail below. In the present embodiment the network I F may be an Ethernet interface network interface controller NIC although other interface types may also be used with alternative network protocols.

Disk I F connects controller to the one or more storage devices . In the present embodiment the disk I F is a Fibre Channel FC interface and the storage devices are FC disk devices that are accessed by the disk controller in accordance with Fibre Channel protocol. In an alternative implementation the disk I F may be an ATA interface. In this case the storage devices that are connected to the disk I F may be S ATA Serial ATA type disk devices that are accessed by the disk controller in accordance with the serial ATA protocol. Yet still alternatively in another implementation the storage devices may be NAS Network Attached Storage devices that are accessed with NFS Network File System or CIFS Common Internet File System protocol. In this case the disk I F is an Ethernet interface.

Host computer hereinafter called host may be a typical PC AT compatible computer or workstation running a UNIX or Windows operating system. In another embodiment host may be a mainframe computer running an operating system such as OS 390 or z OS . Host includes at least a CPU a memory a disk I F and a network I F such as a network interface controller NIC to enable connection to network switch and thereby to enable communication with the donor storage system and the donee storage system via network . Host computer is able to store and access data in the donor storage system la and communicates with the donor storage system la via network and switch . When the data in the donor storage system is moved to the donee storage system host is connected for communication with the donee storage system . Further host may also be connected to its own external storage such as in the case in which external storage is used as active storage while storage systems are only used for archiving of data.

Network switch may be a LAN local area network switch and is a part of network that may be a LAN that enables communication between the donor storage system donee storage system and at least one host . In the present embodiment network is composed of at least one LAN switch which may be an Ethernet switch. Initially only donor storage system and host are interconnected via network through switch . When the donee storage system is installed the donee storage system is connected to the LAN switch . The physical interface of switch is Ethernet in this embodiment.

Additionally when donee storage system is installed a data link may be used to connect donor storage system and donee storage system each other. In this manner when data migration occurs the data migrated to the donee storage system can be transmitted via the data link rather than through network . The physical network I Fs used for data link are the same as those used to connect to LAN switch . In another embodiment it is possible that the data link may not exist and that the data to be migrated to the donee storage system is transmitted via LAN switch .

Donee storage system includes a command processing module that is similar to command processing module . Command processing module processes access requests made from a second application program interface API running on host and stores the data into storage devices in the donee storage system

Migration processing module is also included on donee storage system and is used to migrate data from the donor storage system to the donee storage system in accordance with the present invention as will be discussed in greater detail below. Migration processing module is preferably embodied as software stored in memory or other computer readable medium located at storage system or remotely and executed by CPU on donor storage system

Application program AP on host is a program that accesses donor storage system or donee storage system . When AP accesses the donor storage system or the donee storage system this takes place via API or API .

First application programming interface API is used by AP to access data in the donor storage system . API includes a programming library and is generally provided along with the donor storage system by the vendor of donor storage system . Similarly second application programming interface API is used by the AP to access data in the donee storage system . API includes a programming library and is generally provided with the donee storage system by the vendor of donee storage system

An operating system is also located on host and provides the basic infrastructure to enable AP API or API to be executed. In an alternative implementation API and or API may be implemented as part of the operating system . Before the donee storage system is installed API does not reside on host but AP API and operating system are installed in the host . When the donee storage system is installed in the system API is also installed on the host . The functions and interactions of these programs as discussed in more detail below.

Object ID This field contains a unique identification number of each content. Before the CAS system donor storage system or donee storage system stores an object it calculates and assigns the object ID to the object that is unique within the CAS system. The object ID is generated or calculated from the content and so long as the content is unique in the system then the object ID will also be unique. To generate the object ID a hash algorithm such as SHA 1 or MD5 is used in the preferred embodiment although other methods may also be used.

Creation date time This field is used to store the date time at which the object is first stored in the CAS system.

Accessed date time This field is used to store the date and time when the object was last accessed read or written in the CAS system.

Retention period In the present embodiment a user can set the object to a write protected state for a certain period of time. When the user sets the object to the write protected state the user may also specify how long the object should remain write protected. The time is called the retention period and is stored in this field. When the user does not set the object into the write protected state then a NULL value is set as the retention period .

Comment A comment or multiple comments may be added by the user in each object via API or API . The comment is stored in the comment field and may be used to aid in indexing or searching for the object to provide contextual information or for other purposes depending on the type of data and the particular implementation.

When the CAS system donor storage system or donee storage system is accessed from host each of the command processing modules and receives a command from the application programming interface and respectively. The commands which are exchanged between the command processing module and the first application programming interface API or between the command processing module and the second application programming interface API are generally proprietary commands defined by the vendors of the donor storage system or the donee storage system . In another embodiment the commands may be defined based on standard or de facto standard I O protocols such as NFS or http.

In the present embodiment each of API and API is provided in the form of the C Programming library which includes a set of C Programming functions. AP is linked with one of API and API when AP is executed. That is AP is programmed so that AP calls the functions defined in API or API . When AP reads or writes data in the CAS system the functions defined in the API or API are called. The following is a brief description of the common functions typically defined in API or API

Create object This function is used to create and store an object in the CAS system. When using the create object function AP designates the content information and when necessary it passes additional comment information via API or API . The CAS system in response creates the object and returns to AP the object ID information.

Read object This function is used to retrieve an object from CAS system. When using this function AP designates the object ID and in response the CAS system returns the object content and metadata to the host.

Write object This function is used to update an object that already currently resides in the CAS system.

Set Retention This function is used to set the retention period of the designated object though the retention period can only be modified when no date information is set in the retention period or when the retention period is expired. When using this function AP designates the object ID.

Modify attribute This function is used to modify the information in the metadata . Not all information can be modified by the function. In the present embodiment the only information that can be modified by this function is the comment and retention period though the retention period can only be modified when no date information is set in the retention period or when the retention period is expired. In the present embodiment users can use either of the Set Retention function and the Modify attribute function when the retention period is set changed. In another embodiment the Set Retention function may not be supported in API or API that is only the Modify attribute function may exist to set change the retention period .

List object This command is used to retrieve all object IDs for objects that are currently stored in the CAS system.

Query This command is used to retrieve the list of object IDs that match a specified condition. When using this function AP can specify one or more conditions. For example when the user wants to retrieve a list of object IDs that were created for a certain period of time AP issues the query function by designating the creation data time information . The CAS system then returns the object IDs of the objects that were created during the designated time period.

List mapping In accordance with the present invention this command is used to retrieve object mapping information discussed in detail below with reference to when the migration of data from the donor storage system to the donee storage system has taken place. This function does not have to be supported by the donor storage system and API but the donee storage system and API should support the function.

Object ID This field contains the object ID information of all objects that the donor storage system currently maintains.

Disk location In this field the location information of the content is stored that the object ID specifies. In the present embodiment the location information is stored as a LBA logical block address within the storage devices . In another embodiment when the storage devices are NAS devices the location information can be file name information.

Disk location This field contains the location information of the metadata that is specified with the object ID and is also stored as a LBA. In the present embodiment content and metadata are not necessarily stored in locations adjacent to each other in the donor storage system . Therefore the donor storage system la maintains the disk locations of both the content and the metadata separately.

Object ID Similar to object ID discussed above this field contains the unique object IDs of all objects that the donee storage system currently maintains.

Disk location Similar to disk location discussed above this field contains the location information where the content of each object in the donee storage system is stored.

Disk location Similar to disk location discussed above this fields contains the location information where each metadata of each object in the donee storage system is stored.

Former object ID This field is used for the objects migrated from the donor storage system . When the donee storage system copies an object from the donor storage system the object ID information that the donor storage system has assigned to the object is stored in the former object ID field. Details of how the information in the former object ID field is used will be described later.

Further illustrates the mapping information that provides the mapping between the new object ID in the donee system and the former object ID in the donor system . Thus mapping information includes an object ID field that corresponds to object ID field discussed above and a former object ID field that corresponds to the former object ID field discussed above. The mapping information is delivered to the user or host as is discussed in more detail below with reference to step of .

In the present embodiment AP is a relational database RDB and stores the data in the external storage system in addition to the donor storage system or donee storage system . illustrates an example of a database table that AP stores into the external storage system . Columns through are the attributes of the table such as an ID for an entry a user a title a description and in column are stored the object IDs maintained by AP . Under one embodiment table is stored in external storage system while the objects listed in table are stored in the donor storage system la prior to migration . AP retrieves or stores the information stored in the database table in accordance with the users requests. When the objects in the CAS system need to be retrieved AP retrieves the specified object using the object ID . When objects need to be stored AP stores the objects using API before migration or API after migration . Further since the object ID is returned from the CAS system when the object is created AP stores the received object ID information into the database table .

Step Initially a user or host stops the execution of the application program to prevent write attempts during migration which could result in lost data.

Step The user disconnects the donor storage system la from network and connects the donor storage system to the donee storage system . The disconnection process can be done by physically removing the cable that resides between the donor storage system and network so that donor storage system is no longer in communication with host . In another embodiment the disconnection can be done logically by changing the network configuration such as by the user changing the IP address assigned to the donor storage system

Step The user puts the donee storage system into communication with host . The connection process may be done by physically attaching a cable between the donee storage system and network and when needed the user may have to set the IP address of the donee storage system as the same IP address that was assigned to the donor storage system . In another embodiment the connection can be done by logically changing the network configuration such as IP addresses. Additionally if data link is to be used that connection is made at this time. After connecting the donee storage system the user is ready to start the migration process.

Step Migration is carried out in the donee storage system as will be described in more detail below with reference to .

Step The user or host receives notification from the donee storage system that the migration process is complete.

Step The user installs new API in the host . In some cases AP may be uninstalled and the user may have to also install a new application program not shown in or a modified version of AP which is particularly configured for accessing the donee storage system using API

Step The user or host receives the object mapping information from the donee storage system . Based on the mapping information the contents management information is updated so that each object in the donee storage system may be accessed using the new object ID that is assigned by the donee storage system . The object mapping information that the user receives from the donee storage system specifies what object ID is assigned for each object migrated from the donor storage system to the donee storage system . As discussed above shows an example of the object mapping information including a list of object IDs which are assigned to each object by the donee storage system and a list of former object IDs that were previously assigned to the objects when the objects resided in the donor storage system . Alternatively the donee storage system can maintain object management table and use this information for responding to future read requests from host rather than requiring host to update contents management information table .

Step After step is completed the user restarts AP and the process ends. After the process is completed the user may remove the donor storage system la from the system.

Step The migration processing module in the donee storage system prepares to access the donor storage system . In the present embodiment it is assumed that the donor storage system has an authentication function when host or the donee storage system attempts to access objects. Therefore the donee storage system logs on to the donor storage system and executes the authentication process. The authentication information such as a password is setup in the donee storage system by the user.

Step After step the migration processing module retrieves the list of object IDs from the donor storage system of all objects that are currently stored on the donor storage system . To retrieve the list of object IDs the migration processing module issues a List object or a Query function to the donor storage system . Thus the migration module may include the same or a similar functions equal to the List object or Query functions discussed above for API

Step Based on the list of the object IDs the migration processing module retrieves an object from the donor storage system . Thus in the present embodiment where the content and metadata are stored in separate locations the content is retrieved and also the metadata for that content.

Step The migration processing module calculates a new object ID according to the content of the object that was retrieved at step such as by hashing algorithms and configures new metadata for the object according to parameters existing in the retrieved metadata and any new parameters such as additional comments that may have been established for the donee storage system . The migration processing module stores the object content and metadata including the new object ID for each object into the storage devices .

Step The migration processing module updates the mapping information with the new object ID and also updates the object management table for managing the locations where the content and metadata of each newly created object are stored. As discussed previously for each object the content and the metadata may be stored in separate locations or adjacently.

Step The migration processing module checks whether all objects that are listed in the list of the object IDs obtained at step have been migrated. If all objects have been migrated the process proceeds to step . If not the process goes back to step .

Step Once all objects have been migrated from donor storage system to donee storage system the migration processing module notifies the host that the migration is complete. In another embodiment there exists a management console not show in the drawings and the migration completion message is displayed for the user on the GUI screen of the management console.

Step Migration processing module passes the object mapping information to host . In another embodiment the mapping information is sent to the management console. Based on the object mapping information the user or AP updates the contents management information .

In the first embodiment the host application AP must be stopped steps of until all objects have been migrated to the donee storage system . When the amount of data to be migrated is large a long downtime can occur which may be undesirable in many industries. The method set forth in the second embodiment makes the downtime shorter than that of the first embodiment. The second embodiment is useful in systems in which the host does not update or overwrite objects once they have been written to the donor storage system such as in the case of a WORM write once read many system. In this situation the host may continue to write new objects to the donor storage while the existing objects are migrated to the donee storage. Once the existing objects are migrated the donee storage is connected to the host and the remaining objects that were created while the initial migration was taking place are then migrated to the donee storage . illustrates an overview of the migration operation according to the second embodiment and includes the following steps 

Step The user connects the donor storage system with the donee storage system . The connection process can be done by physically connecting the cable for data link between the donor and donee storage systems and or via network . At this point the donee storage system is not connected to host .

Step The user stops AP and starts migration of data from the donor storage system to the donee storage system by initializing migration processing module .

Step An initial migration process is carried out by the donee storage system as will be described in more detail below with reference to steps of .

Step The user checks if the migration between the donor storage system and the donee storage system has completed or waits until notification of completion of initial migration is received. When the initial migration has completed the process proceeds to step .

Step Once the initial migration has completed the user stops AP again and installs new API in the host . In some cases AP may also have to be uninstalled from host and the user may have to install a new application program or a modified version of AP which is specifically configured for accessing the donee storage system using API

Step The user disconnects the donor storage system from communication with host and connects the donee storage system into communication with host . The connection process is done by physically attaching the cable between the donee storage system and network and when needed the user may have to set the IP address of the donee storage system into the same IP address that was previously assigned to the donor storage system . In another embodiment the connection can be done by changing the network configuration such as by logically changing the IP address. The connection between donor storage system and donee storage system also remains intact.

Step The donee storage system starts copying the remaining objects by carrying out steps in . The remaining objects are the objects which were newly created by host AP in the donor storage system during the steps between and . To copy the remaining objects under one method the user instructs the donee storage system to retrieve any objects that were created after the time at which step is started.

Step Once the secondary migration has completed the user receives notification that migration is complete such as by receiving at the host or at a management terminal or the like.

Step The user or host receives the object mapping information from the donee storage system . Based on the mapping information the contents management information is updated so that each object in the donee storage system may be accessed using the new object ID that is assigned by the donee storage system

Step After step is completed the user restarts AP and the process ends. After the process is completed the user may remove the donor storage system from the system.

Step Similar to step the migration processing module retrieves a list of object IDs from the donor storage system . But the received list of object IDs at this step contains the object IDs that were in existence in the donor storage system at the time just before the step in is executed by user i.e. just before the AP was stopped. The object IDs that will be generated after the step are not received by the migration processing module at this step. Accordingly under the invention of this embodiment the AP is stopped the migration processing module obtains a list of object IDs and the AP may then be restarted. The time at which the AP is restarted is noted so that any objects created after that time will be able to be retrieved during step .

Step Similar to step the migration processing module retrieves each object from the donor storage system based on the list of the object IDs.

Step Similar to step the migration processing module sends a notification to the user or host that the initial migration is complete and the user then carries out steps in .

Step The migration processing module waits until the user has carried out steps in and the process is then ready to proceed to step .

Step The process is invoked by the host or user. At step in when the user instructs the donee storage system to start migrating remaining objects the process starts. The process is also similar process to step in the first embodiment. The migration processing module retrieves the list of object IDs from the donor storage system . The object IDs that are received at this step are the object IDs of objects that were created by the host on the donor storage system between the steps and of .

Step At this step steps through described above are executed repeatedly until all the additional objects have been migrated.

Under the second embodiment of the invention the downtime of AP on host is shorter than under the first embodiment of the invention but downtime still exists between steps and . In the third embodiment the migration is performed almost on line with minimal downtime. Similar to the second embodiment the third embodiment is useful in systems in which the host does not update or overwrite objects once they have been written to the donor storage system such as in the case of a WORM write once read many system. In the third embodiment the host writes any new objects to the donee storage while the existing objects are migrated from the donor storage to the donee storage. Further should the host request access to an object that has not yet been migrated the donee storage retrieves the object from the donor storage and returns the object to the host. shows the overview of the migration operation in the third embodiment and includes the following steps 

Step Similar to step the user stops AP and installs new API . The user may also install a new or modified version of AP that is configured to work with API

Step Similar to step the user disconnects the donor storage system from LAN and connects the donor storage to the donee storage system

Step Similar to step the user connects host with one storage system . After the connecting operation the user instructs the donee storage system to start migration.

Step The user restarts AP . AP accesses the donee storage system via API . How the donee storage system handles access requests is set forth in detail in .

Step The migration of objects is carried out from donor storage system to donee storage system using essentially the same process set forth in detail in until all objects have been migrated. Accordingly since has been described above with respect to the first embodiment it will not be described again here. Once all objects are migrated notification is sent from the donee storage system to the user.

STEP The user receives notification that the migration of objects from donor storage system to donee storage system is complete.

Thus when the migration starts at step the donee storage system starts copying data from the donor storage system . The process of migrating objects to the donee storage system is almost the same as that of the first embodiment except that step passing of object ID mapping is not necessarily executed unless host or the user explicitly makes a request to retrieve the object mapping information . Thus the donee storage system may maintain the mapping information and use this to fulfill access requests. Alternatively once migration is complete the donee storage system may pass the mapping information to host or the user so that table can be updated. Also in the third embodiment the donee storage system is able to process read write requests while the migration process is being carried out while in the first embodiment the AP was stopped during the migration process. This substantially eliminates downtime of the AP and host with the exception of the time required to install API and connect donee storage to host .

Step The donee storage system receives a read request for an object from host . The read request designates the object according to the object ID of the object.

Step When the command processing module of donee storage system receives the read request it checks whether the donee storage system maintains the object having the object ID designated by the host in the read request. The determination is made by checking whether the object ID designated by the host is included in the object ID column in the object management table . If command processing module determines that the donee storage system maintains the designated object the process proceeds to step . However if the object ID is not located in the object ID column in the object management table the process goes to step .

Step Since the designated object is already in the donee storage system the command processing module retrieves the object corresponding to the designated object ID from storage devices in the donee storage system using the information in the object management table .

Step If the object is not located in the donee storage system the command processing module then checks whether the object ID designated in the request from host is included in the list of object IDs that were received from the donor storage system at step in when the migration process is started. If the designated object ID is located in the list the process proceeds to step . If not the command processing module terminates and returns an error to API since it was unable to locate the object in either the donee storage system or the donor storage system

Step The command processing module instructs the migration processing module to migrate the designated object from the donor storage system a. The migration processing module retrieves the object corresponding to the designated object ID from the donor storage system la.

Step The migration processing module calculates a new object ID and stores the object both the content and the metadata including the new object ID for each object into storage devices in donee storage system . The calculation of a new object ID is performed so that the calculated object ID cannot coincide with the object IDs that have already been created by the donee storage system or the donor storage system . Details of the process carried out in this step are set forth with reference to below.

Step The command processing module deletes the object ID information stored in the former object ID column in the object management table . In another embodiment step may not exist the object ID information may not be removed from the object management table and the donee storage system maintains the object mapping information so that the object IDs to be calculated in the donee storage system in future cannot coincide with the object IDs that have already been created by the donor storage system

In accordance with the process above when AP issues a request to read an object that has already been migrated from the donor storage system to the donee storage system AP receives the updated object ID in response to the read request. When AP receives the updated object ID AP updates the row of the database table where the corresponding object ID information is stored. After the object ID information is updated the next time AP reads the object it can issue the read request using the new object ID. Therefore in the migration method of the third embodiment a modified version of AP should be installed at step so that when AP receives the updated object ID from API AP updates the contents of the database table .

Step Similar to step described above the migration processing module calculates a new object ID and stores the object both the content and the metadata including the new object ID for each object into storage devices in donee storage system . Details of the process carried out in this step are set forth with reference to below.

Step The command processing module b returns the object ID that is associated with the newly created object.

Step If the calculated object ID coincides with one of the object IDs that is already recorded in the former object ID column in the object management table the object IDs that were already stored in the donor storage system the process goes to to recalculate the new object ID so as not to coincide with any of the former object IDs. This way a former object and a new object will not have the same ID which otherwise might cause confusion from a host s perspective when trying to access an object. When the calculated object ID does not equal any of the former object IDs the process goes to step .

Step The process recalculates the object ID and goes back to step to check if the re calculated object ID is equal to the other object IDs already stored.

Step If the calculated object ID coincides with one of the object IDs that is already recorded in the object ID column in the object management table the object IDs that are stored in the donee storage system the process proceeds to step . When the calculated object ID does not equal any of the object IDs already stored the process goes to step to store the object into the storage device .

Step The process reads the content of the object from the storage device whose object ID is determined to be equal at step to the object ID calculated at step or at step or and compares the content with the content of the object that is to be written in the process.

Step If both of the contents that were compared at step are completely equal the process terminates without storing the object since the same content is already stored in the storage device . If not the process goes to step to recalculate the new object ID so as not to coincide with other object IDs.

Step This is a similar process to step . The process recalculates the object ID and goes back to step to check if the re calculated object ID is equal to the other object IDs already stored.

Step When it has been determined that there is no coincidence of object IDs the command processing module stores the object to storage devices by storing both the content and metadata including the new object ID.

Thus it may be seen from the foregoing that the present invention sets forth a novel method to enable data migration between CAS systems. Additionally the invention sets forth methods for minimizing downtime during the migration process. Further while specific embodiments have been illustrated and described in this specification those of ordinary skill in the art appreciate that any arrangement that is calculated to achieve the same purpose may be substituted for the specific embodiments disclosed. This disclosure is intended to cover any and all adaptations or variations of the present invention and it is to be understood that the above description has been made in an illustrative fashion and not a restrictive one. Accordingly the scope of the invention should properly be determined with reference to the appended claims along with the full range of equivalents to which such claims are entitled.

