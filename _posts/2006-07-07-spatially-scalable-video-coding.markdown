---

title: Spatially scalable video coding
abstract: Video data for a high resolution image unit is coded with regard to both a low resolution reference image unit and a high resolution reference image unit. In an example encoding implementation, both low pass information and high pass information of residue data for a current image are generated. In an example decoding implementation, a current image is reconstructed by synthesizing both low pass information and high pass information for the reconstructed image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09332274&OS=09332274&RS=09332274
owner: Microsoft Technology Licensing, LLC
number: 09332274
owner_city: Redmond
owner_country: US
publication_date: 20060707
---
Video may be displayed on many different types of electronic devices. Example electronic device types include televisions computer monitors personal entertainment appliances e.g. portable game machines portable video players etc. mobile phones and so forth. These different types of electronic devices have an equally diverse variety of screen resolutions that they are capable of displaying.

Video data may be distributed using some type of transmission media. Example transmission media types include cable digital subscriber line DSL the internet cellular wireless links local or wide area networks Ethernet networks and so forth. These different types of transmission media have an equally diverse number of bandwidths that they are capable of providing.

Video data is often compressed in accordance with some coding algorithm to enable its transmission over communication links having a limited bandwidth. Example coding algorithms include Moving Pictures Expert Group MPEG 2 and MPEG 4. Some of these coding algorithms are capable of coding the same video data in different manners so that it may be transmitted at different bandwidths.

Video data for a high resolution image unit is coded with regard to both a low resolution reference image unit and a high resolution reference image unit. In an example encoding implementation both low pass information and high pass information of residue data for a current image are generated. In an example decoding implementation a current image is reconstructed by synthesizing both low pass information and high pass information for the reconstructed image.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Moreover other method system scheme apparatus device media procedure API arrangement etc. implementations are described herein.

In conventional approaches to video coding with spatial scalability the coding of a higher resolution layer either uses inter frame prediction or inter layer prediction but they are all relatively inefficient because they do not employ these two predictions simultaneously.

In contrast an example motion compensation framework as described herein for multiple resolution layers can more efficiently code the higher resolution layer s . In a described implementation each frame at the higher resolution is decomposed into low pass signals that represent the low resolution video and high pass signals. Each resolution layer uses motion compensation to exploit the redundancy within the layer itself. For the low pass signals traditional image domain motion compensation may be used. But for the high pass signals high pass decomposition is used for the motion prediction with the current frame to determine high pass prediction and high pass original signals before compensation. Image decomposition and motion compensation at each resolution layer can enable the simultaneous efficient exploitation of both the inter layer redundancy and the inter frame redundancy.

In an example described implementation a video coder codes a current image unit at a given resolution level using prediction data determined at the given resolution level and prediction data determined at a lower resolution level. More specifically the prediction data determined at the lower resolution level may be determined from low pass information for a reference image having a time that corresponds to a time of the current image unit and or the prediction data determined at the given resolution level may be determined from a reference image having a time that differs from a time of the current image unit.

Matrix includes four image units I I I and I. The Iis a low resolution reference image unit . The Iis a low resolution current image unit . The Iis a high resolution reference image unit . The I is a high resolution current image unit . The coding is to be performed or is in progress for high resolution current image unit . The image units may represent any definable area or amount of an image. Example image units include but are not limited to frames macroblocks and so forth.

In layered coding schemes that support spatial resolution scalability input video frames are down sampled and coded at each resolution. The following example pertains to a high resolution coding scenario. It is given that at a certain coding instance there are two previously reconstructed reference images I at a low resolution and I at a high resolution. There is also a reconstruction image unit of the current frame at low resolution I. A goal of an example spatial scalable coding scheme implementation as described herein is to code the high resolution current image frame I efficiently based on the information already coded in I I and I.

With existing spatial scalable coding schemes the high resolution frame to be coded is either i predicted from the reconstructed low resolution image of the same frame or ii predicted from the previously coded reference frames at the same resolution e.g. at the high resolution . In other words existing techniques are relatively inefficient because they fail to combine the two prediction sources.

In contrast implementations for spatially scalable video coding as described herein enable high resolution image frame prediction from both i the reconstructed low resolution image of the same frame and ii at least one of the previously coded reference frames at the same resolution e.g. at the high resolution . For example the prediction for a high resolution frame may be accomplished by using a prediction for low pass content from the lower resolution of the current frame and a prediction for high pass content from the reference s at the high resolution of different frame s . Low resolution prediction and high resolution prediction may therefore be combined in an efficient manner to achieve a better overall prediction. Consequently each bit that is coded at the lower resolution can efficiently contribute to the higher resolution coding.

In a described implementation a coding device is any electronic device that is capable of encoding and or decoding video data. At least some coding devices are capable of directly or indirectly displaying video data on a display screen that is either integrated with or separate from the coding device. Examples of coding devices include but are not limited to computers e.g. a client a server a personal computer a workstation a desktop a laptop etc. televisions game machines e.g. a console a portable game device etc. set top boxes consumer electronics e.g. DVD player recorders camcorders digital video recorders DVRs etc. personal digital assistants PDAs mobile phones portable media players some combination thereof and so forth. An example electronic device is described herein below with particular reference to .

Network may be formed from any one or more networks that are linked together and or overlaid on top of each other. Examples of networks include but are not limited to an internet a telephone network an Ethernet a local area network LAN a wide area network WAN a cable network a fibre network a digital subscriber line DSL network a cellular network a Wi Fi network a WiMAX network a virtual private network VPN some combination thereof and so forth.

Channel is established between transmitter of encoding device and receiver of decoding device . Channel may be any physical or other network layer that enables communication over network . During operation transmitter sends encoded video to receiver . Authentications handshaking verifications acknowledgments etc. between the two communication endpoints result in some two way data exchange across channel . Examples of what encoded video may comprise are provided herein below.

Although illustrated differently each of encoding device and decoding device may have both a transmitter and a receiver including a joint transceiver not explicitly shown . Similarly each of encoding device and decoding device may have both a video encoder and a video decoder . A video coder not explicitly shown may include an encoder and or a decoder . Example encoding processes are described herein below with particular reference to . Example decoding processes are described herein below with particular reference to .

High pass information determining processor H also includes a mixing operation and two filters down sampling filter D and up sampling filter U . Both down sampling filter DO and up sampling filter U may be realized using traditional down and up sampling filters respectively which involve relatively mature technology.

In a described implementation the high pass information determining process operates as follows. The image at high resolution is applied to down sampling filter D . The down sampling of high resolution image creates low pass information . This low pass information also comprises the image at a lower resolution and may be coded and displayed as such.

Low pass information is applied to up sampling filter U to create up sampled low pass information not explicitly shown in . Mixing operation of high pass information determining processor H ascertains high pass information . More specifically the output of up sampling filter U which is the up sampled low pass information is subtracted from high resolution image to ascertain high pass information which is the difference between the two.

In a described implementation the high resolution image synthesizing process operates as follows. Low pass information is applied to up sampling filter U to create up sampled low pass information not explicitly shown in . Combination operation of synthesizing processor S produces image at high resolution . More specifically the output of up sampling filter U which is the up sampled low pass information is added to high pass information to produce high resolution image . As is more apparent from the description of below the low pass information and the high pass information that are input to the synthesizing process S are reconstructed versions thereof.

The interrelationships between an image at high resolution the image at low resolution low pass information high pass information a down sampling filter D an up sampling filter U a high pass information determining processor H and a high resolution image synthesizing processor S are described quantitatively below. Although the principles may be applied equally effectively to any image unit the quantitative description herein refers to image frames for the sake of clarity.

In this mathematical analysis the current frame to be coded is denoted as I. Given a low pass filter the low resolution image of I can be created via a down sampling process D 1 where Iis the low resolution image. This low resolution image contains low pass information of the original image I. D is a down sampling process. Correspondingly the low pass information Ican be up sampled back to the original resolution. Let U denote an up sampling process.

The high pass information Iof the original image I can then be ascertained by process H 2 Hence by determining two filter processes D and U the image can be partitioned or decomposed into a low pass part Iand a high pass part I. Given these two information parts the original image I can be recovered losslessly by synthesizing process S 3 

Encoding process includes the following operation blocks motion compensation MC operations and down sampling filter D operation high pass information determination processor H operation and and mixing operations and . Encoding process includes the following image units current image I reference image I low pass information for reference image I prediction data I low pass information of prediction data I high pass information of prediction data I low pass information for current image I high pass information for current image I low pass information of residue data I and high pass information of residue data I.

The reference image unit s may be from any reference image. By way of example only for an MPEG implementation reference image unit s may be from an infra I image unit a predicted P image unit a bi directional B image unit and so forth. The motion compensation of MC operations may be performed in accordance with traditional motion compensation techniques which is a relatively mature technology.

In a described implementation current image I is applied to down sampling filter D to create low pass information for current image I. Low pass information for current image Iis part of mixing operation . Low pass information for reference image Iis applied to motion compensation MC operation to determine low pass information of prediction data I.

Low pass information of residue data Iis generated from mixing operation . More specifically in mixing or difference operation low pass information of prediction data Iis subtracted from low pass information for current image Ito generate low pass information of residue data I which is the difference between the two. In this context subtracted from implies that mixing operations effectively remove from the main low or high pass image unit information the image information that is contained in the low or high pass information of the predicted data respectively.

Current image I is also applied to high pass determining processor H to ascertain high pass information for current image I. High pass information for current image Iis part of mixing operation .

Reference image Iis applied to motion compensation MC operation to determine prediction data I. Prediction data Iis applied to high pass information determining processor H to ascertain high pass information of prediction data I.

High pass information of residue data Iis generated from mixing operation . More specifically in mixing or difference operation high pass information of prediction data Iis subtracted from high pass information for current image Ito generate high pass information of residue data I which is the difference between the two.

With reference to encoding device may transmit low pass information of residue data Iand high pass information of residue data Iover channel to decoding device . Decoding device may then perform a decoding process as described below with particular reference to .

Decoding process includes the following operation blocks motion compensation MC operations and high pass information determination processor H operation high resolution image synthesizing processor S operation and combination operations and . Decoding process includes the following image units reference image I low pass information for reference image I prediction data I low pass information of prediction data I high pass information of prediction data I low pass information of residue data I high pass information of residue data I low pass information for reconstructed image I high pass information for reconstructed image I and reconstructed current image I.

In a described implementation low pass information for reference image Iis applied to motion compensation MC operation to determine low pass information of prediction data I. Low pass information of prediction data Iand low pass information of residue data Iare combined e.g. added with combination operation to generate low pass information for reconstructed image I. Low pass information for reconstructed image Iis applied to high resolution image synthesizing processor S operation .

Reference image Iis applied to motion compensation MC operation to determine prediction data I. Prediction data Iis applied to high pass information determining processor H to ascertain high pass information of prediction data I. High pass information of prediction data Iand high pass information of residue data Iare combined e.g. added with combination operation to generate high pass information for reconstructed image I. High pass information for reconstructed image Iis also applied to high resolution image synthesizing processor S operation .

Thus low pass information for reconstructed image Iand high pass information for reconstructed image Iare both applied to high resolution image synthesizing processor S operation . From these two inputs high resolution image synthesizing processor S operation produces reconstructed current image I. Hence the high resolution reconstructed current image Iis produced using predictions from both the current low pass information for reference image Iand a reference image Iat the high resolution.

In a more specific example implementation high resolution image synthesizing processor S operation of corresponds to high resolution image synthesizing processor S of as well as equation 3 above. Consequently low pass information for reconstructed image Iis up sampled by up sampling filter U of to create up sampled information for the reconstructed image. This up sampled information for the reconstructed image is combined with high pass information for reconstructed image Iin a combination operation to produce reconstructed current image I.

The relatively quantitative example mathematical analysis that was introduced above is continued here with reference to the operation blocks and image units of . It is given that there are two resolutions of reference images Iand I which correspond to Iand I respectively. Certain described implementations of spatially scalable video coding generate difference signals to be coded based on these two references.

For the low resolution image I the prediction image Imay be generated in accordance with traditional motion compensation 4 where MC is a motion compensation process and MVsdenotes the motion field for the low resolution. The difference signal or residue to be coded for the low resolution is . 5 

For the high resolution image I because the low pass part which corresponds to the low resolution image I has already been motion compensated the prediction can be focused on the high pass part. Prediction data need not be generated for the whole high resolution image. This reduces if not eliminates the redundancy in traditional approaches that exists between the motion compensation of the low resolution and that of high resolution because the low pass part of the image is also motion compensated in the motion compensation processes of all resolutions. 

For the high resolution image I the prediction data is first determined by 6 where MVs denotes the motion field for the high resolution image which is not necessarily the same as MVs. The residue image Ito be coded for the high resolution is 7 or . 8 Equation 8 by relying on equation 2 above indicates that the residue image Ito be coded is generated by subtracting the up sampled low resolution image Iand the high pass information of prediction data for the current image H I from the high resolution image I.

Furthermore when the low resolution s reconstruction image Iis available it can be substituted for the low resolution image Iin equation 8 so that any mismatch between the encoder and the decoder can be decreased. This is because both the encoder and the decoder have the reconstructed version of the low pass information for image I but the decoder does not have access to the original low pass information for the current image I. Hence the residue may be generated by the following equation 9 when the low resolution s reconstruction information Iis available . 9 

As noted above there are at least two approaches to applying the spatially scalable video coding. These two approaches are on a frame level and on a macroblock level. With either approach low resolution video may be coded using traditional video coding. In a frame based scheme equation 8 or 9 is employed for the whole frame. In a macroblock based scheme equation 8 or 9 is employed for the current macroblock.

According to equation 2 H can be ascertained by using both up sampling and down sampling filters which also ultimately makes H a filter too. However it may in practice result in the filter of H having too long of taps which increases the computational complexity. In general equation 9 can be further generalized into 10 where f is a filter and denotes convolution. The taps of filter f can be acquired by minimizing the energy of the residue signals given a constraint of the number of taps of filter f.

At block low pass information of residue data for the current image is generated based on low pass information for the current image. This generation may be accomplished for example using mixing operation and low pass information of prediction data.

At block high pass information for the current image is ascertained responsive to the current image. For example the high pass information for the current image may be ascertained with a down sampling filter D an up sampling filter U and a mixing operation as part of a high pass information determining processor H .

At block high pass information of prediction data for the current image is ascertained responsive to prediction data for the current image. This ascertainment may be accomplished using for example a high pass information determining processor H .

At block high pass information of residue data for the current image is generated based on the high pass information for the current image and the high pass information of prediction data for the current image. For example the high pass information of residue data for the current image may be generated using mixing operation by taking away the high pass information of prediction data for the current image from the high pass information for the current image.

At block low pass information for a reconstructed image is generated based on low pass information of residue data for the current image. For example the low pass information for a reconstructed image may be generated in a combination operation with low pass information of residue data for the current image and low pass information of prediction data.

At block high pass information for the reconstructed image is generated based on high pass information of residue data for the current image. For example the high pass information for a reconstructed image may be generated in a combination operation with high pass information of residue data for the current image and high pass information of prediction data.

At block a reconstructed current image is produced by synthesizing the low pass information for the reconstructed image and the high pass information for the reconstructed image. A reconstructed current image may be produced for example in a high resolution image synthesizing processor S .

Application of de sampling filter D A creates first level low pass image information . De sampling and up sampling may be performed at any ratio. However in the example of block diagram the ratio is . Hence first level low pass image information is at the resolution level of the full resolution image original image .

Application of up sampling filter U A creates an up sampled first level low pass image information not explicitly identified in that is subtracted from full resolution original image in mixing operation A to ascertain a first level high pass image information for the full resolution .

Continuing with the second resolution decomposition level first level low pass image information is down sampled with D filter B to create second level low pass image information . Because the example down and up sampling ratio in this example is second level low pass image information has 1 16 the resolution of full resolution original image .

Application of up sampling filter U B creates an up sampled second level low pass image information not explicitly identified in that is subtracted from first level low pass image information in mixing operation B to ascertain second level high pass image information for the full resolution.

In operation a destination or decoding device can indicate the resolution that it desires e.g. based on hardware capability currently available software resources an assigned window etc. . Accordingly transmitting or encoding device may tailor its transmission of coded video data to correspond to the indicated resolution level. In other words an originating device may transmit the low pass information of residue data for a current image and the high pass information of residue data for the current image that corresponds to an identified resolution level of a destination device.

For example if a destination device has 1 16 of the full resolution the originating device may transmit second level low pass image information which is also the 1 16 resolution image. If a destination device has a full resolution capability the originating device may send second level high pass image information and second level low pass image information . In this manner different resolution levels may be handled efficiently without sending the amount of duplicative information that is sent with existing approaches.

Generally a device may represent any computer or processing capable device such as a server device a workstation or other general computer device a personal digital assistant PDA a mobile phone a gaming platform an entertainment device one of the devices listed above with reference to some combination thereof and so forth. As illustrated device includes one or more input output I O interfaces at least one processor and one or more media . Media include processor executable instructions .

In a described implementation of device I O interfaces may include i a network interface for communicating across network ii a display device interface for displaying information on a display screen iii one or more man machine interfaces and so forth. Examples of i network interfaces include a network card a modem one or more ports and so forth such as a transmitter or a receiver . Examples of ii display device interfaces include a graphics driver a graphics card a hardware or software driver for a screen or monitor and so forth. Examples of iii man machine interfaces include those that communicate by wire or wirelessly to man machine interface devices e.g. a keyboard a remote a mouse or other graphical pointing device etc. .

Generally processor is capable of executing performing and or otherwise effectuating processor executable instructions such as processor executable instructions . Media is comprised of one or more processor accessible media. In other words media may include processor executable instructions that are executable by processor to effectuate the performance of functions by device .

Thus realizations for spatially scalable video coding may be described in the general context of processor executable instructions. Generally processor executable instructions include routines programs applications coding modules protocols objects components metadata and definitions thereof data structures application programming interfaces APIs etc. that perform and or enable particular tasks and or implement particular abstract data types. Processor executable instructions may be located in separate storage media executed by different processors and or propagated over or extant on various transmission media.

Processor s may be implemented using any applicable processing capable technology. Media may be any available media that is included as part of and or accessible by device . It includes volatile and non volatile media removable and non removable media and storage and transmission media e.g. wireless or wired communication channels . For example media may include an array of disks for longer term mass storage of processor executable instructions random access memory RAM for shorter term storing of instructions that are currently being executed link s on network for transmitting communications e.g. video data and so forth.

As specifically illustrated media comprises at least processor executable instructions . Generally processor executable instructions when executed by processor enable device to perform the various functions described herein including those actions that are illustrated in flow diagrams and of respectively and those processes illustrated in and so forth. By way of example only processor executable instructions may include a video encoding coder e.g. including the components of a video decoding coder e.g. including the components of encoded video e.g. including image unit information such as high pass information for current image I low pass information of residue data I high pass information of residue data I etc. some combination thereof and so forth.

The devices actions aspects features functions procedures modules data structures protocols image information components etc. of are illustrated in diagrams that are divided into multiple blocks. However the order interconnections interrelationships layout etc. in which are described and or shown are not intended to be construed as a limitation and any number of the blocks can be modified combined rearranged augmented omitted etc. in any manner to implement one or more systems methods devices procedures media apparatuses APIs arrangements etc. for spatially scalable video coding.

Although systems media devices methods procedures apparatuses mechanisms schemes approaches processes arrangements and other implementations have been described in language specific to structural logical algorithmic and functional features and or diagrams it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

