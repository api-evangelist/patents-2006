---

title: System and method for prefetching uncacheable embedded objects
abstract: A system and method for prefetching one or more embedded objects marked uncacheable using a buffer on a prefetch cache to temporarily store the uncacheable object. The buffer is allocated to a socket that is established between the prefetch cache and a server subsequent to the establishment of an initial connection. A prefetch caching process retrieves one or more embedded objects from the server using the socket based on the preconfigured set of rules. The prefetch caching process determines whether the embedded object is uncacheable, and if so loads the object into the buffer. The prefetch caching process waits a predetermined time period for client request for the object. If the request is received prior to expiration of the time period, the prefetch caching process sends the object to the client. Otherwise, the process “flushes” the buffer, thereby discarding the object, and then closes the socket.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07685255&OS=07685255&RS=07685255
owner: Blue Coat Systems, Inc.
number: 07685255
owner_city: Sunnyvale
owner_country: US
publication_date: 20060807
---
The present invention relates to prefetching in a computer network and more particularly to a technique for prefetching uncacheable embedded objects in a computer network.

In general a server may be configured to provide information to one or more clients according to a client server model of information delivery. According to this model the server may comprise a storage system that typically contains one or more mass storage devices such as magnetic hard disks in which information may be stored and retrieved as desired. The server is usually deployed over a computer network comprising a geographically distributed collection of interconnected communication links such as Ethernet optical or wireless links that allow the clients to remotely access the server s stored information. The clients may include network devices or computers that are directly or indirectly attached to the server via e.g. point to point links shared local area networks LAN wide area networks WAN or virtual private networks VPN implemented over a public network such as the Internet. Other clients may include software applications executing on computers configured to communicate with the server.

In some client server arrangements the server may be configured with a prefetch cache that stores previously accessed or frequently accessed client information. As such the prefetch cache reduces the load on one or more servers origin servers by performing a prefetch operation to anticipate and retrieve data objects from the origin server before client requests are received based on a preconfigured set of rules or polices e.g. selected by a system administrator. That is the prefetch cache performs the prefetch operation to obviate the need for the origin server to process future requests to retrieve these same data objects. Processing of such requests consumes resources of the server and increases the latency associated with servicing the requests particularly if the data objects must be retrieved from disks of the server. As used herein a data object is broadly defined as any collection of data that is identifiable by a common name such as a uniform resource locator URL and therefore may include conventional files HyperText Markup Language HTML files webpages streaming media software applications JAVA applets etc. Furthermore a collection of data objects is a data set e.g. a webpage of a website wherein the term website includes both the origin server and the prefetch cache. However one skilled in the art could contemplate a website including only the origin server with the prefetch cache residing at a different location in the network. Additionally an embedded object is any data object except html which is stored within a data set or more precisely an html file.

Clients typically communicate with the prefetch cache by exchanging discrete packets of data formatted according to predefined file access protocols such as the HyperText Transfer Protocol HTTP Network File System NFS protocol Common Internet File System CIFS protocol File Transfer Protocol FTP etc. A client may issue a file access request that specifies among other things a specific file to access and a particular file operation to perform. The prefetch cache receives the client request processes the request and when appropriate returns a response. For example the client may issue a file read request to the cache and in response the cache may return a file access response containing the client s requested file.

In practice the prefetch cache can be configured to operate as a reverse proxy or forward proxy cache. A reverse proxy cache is a server that stores a selected set of information from one or more origin servers. For example a multimedia company may copy selected streaming audio or video content from its origin servers to a reverse proxy cache which is then used as an accelerator for providing access to the selected content. In contrast a forward proxy cache is a server that stores network data for a particular set of clients. Accordingly unlike the reverse proxy cache the forward proxy cache does not necessarily store selected data from specific origin servers and instead may store data from a variety of different origin servers i.e. based on the network traffic patterns of the cache s associated set of clients.

Communication between the origin server and the prefetch cache involves the exchange of information using communication resources of the server and cache. The communication resources include the allocation of memory or buffers and network protocol stacks. A network protocol stack typically comprises layers of software such as a transport layer an internetwork layer and a media driver layer. The Internet protocol IP is an internetwork layer protocol that provides network addressing between the prefetch cache and the origin server whereas the transport layer provides a port service that identifies each process executing on the cache and server and creates a connection between those processes that indicate a willingness to communicate.

As used herein a process is a software program that is defined by a memory address space. An application programming interface API is a set of software calls and routines that are made available exported by a process and that can be referenced by other processes. Services provided by the process are typically embodied as APIs. For example services of a database process such as lookup operations queries and insertions are provided via APIs that enable other processes to perform those operations.

Transport layer services may be further embodied as a socket interface comprising a client socket library contained within each process and a socket server of the network protocol stack. A process accesses the network protocol stack via the socket interface by creating a process message data structure that is passed to the socket server. The process message is typically embodied as information data payload appended to a transport header the type of which depends on the transport layer protocol used by the process. Examples of conventional transport layer protocols include the Transmission Control Protocol TCP User Datagram Protocol UDP and Raw IP. The TCP transport service provides reliable delivery of the message or packet using a TCP transport header prepended to the packet while the UDP service provides best efforts delivery using a UDP header. Raw IP denotes a process that does not use the transport provided by the socket interface but directly interfaces to the IP layer of the network protocol stack.

The prefetch cache and origin server generally utilize their communication resources such as buffers and network protocol stacks to enable communication among their processes over the network. For example to establish communication with a receiving process on the destination prefetch cache a sending process executing on the source origin server constructs a process message using its socket library and passes it to the socket server or transport layer of the network protocol stack. The process message includes inter alia a destination network address of the prefetch cache a destination port number of the receiving process and if appropriate payload data . The sending process passes that information as a connection request to its socket library to initialize a socket i.e. open a virtual connection . The communication resources of the origin server and prefetch cache then establish communication between the processes.

To that end the socket server also includes a library that is used to create a network layer e.g. IP header having inter alia source and destination network IP addresses. The socket server prepends the IP header to the transport header and passes that packet structure to the IP layer which constructs a media access MAC header. The information contained within the packet structure including any data is stored in a buffer allocated to the socket. The IP layer performs a lookup operation into a forwarding information base FIB to determine an outgoing physical interface for the connection. The FIB includes a forwarding table that contains forwarding information such as mappings of layer 3 L3 network addresses to layer 2 L2 MAC addresses and outgoing interfaces. Upon obtaining the proper outgoing interface the IP layer prepends the MAC header to the packet structure and passes it to the media layer which sends the resulting information in the buffer as a packet over the network to the prefetch cache.

As noted the prefetch cache operating in either reverse proxy or forward proxy mode may be used to anticipate client requests using e.g. a conventional method of object prefetching over a virtual connection or socket between the cache and origin server. In response to a client sending a request to access a data set e.g. a webpage the prefetch cache determines whether the data is stored locally on its disks and if so sends the data set to the client. Otherwise the prefetch cache retrieves the data from the origin server over the socket. When retrieving the data the prefetch cache anticipates future client requests for data objects based on the preconfigured set of rules and to that end attempts to retrieve cache the objects from the server for storage on its disks. In the case of the webpage the prefetch cache retrieves an html file from the server and examines headers of data objects embedded in the file embedded objects to determine whether the objects are cacheable. If so the prefetch cache instructs the server to send the objects over the socket to the cache. If the embedded objects are uncacheable the prefetch cache and origin server cooperate to close the socket and the objects are not retrieved.

Certain data objects may be rendered uncacheable for a variety of reasons. For example a website administrator may render i.e. mark an object as uncacheable in order to obtain an accurate count of the number of times the website is accessed i.e. the number of hits on the website. Here a count can be taken from the number of times the object is downloaded to a user. Another reason that an administrator may want to mark an object as uncacheable is the object frequently changes such as in the example of an image file of a local radar display. Note that in both cases the object may be an embedded object e.g. an applet within a file e.g. an html file . By marking the object as uncacheable the administrator ensures the user accesses the most up to date version of the object.

Website administrators commonly mark embedded objects on a website uncacheable by for example setting a cache control response header of the object to values of no cache private or max age 0. Uncacheable or no cache denotes that the object is marked to prevent caching by forcing a request to an origin server before releasing the object each time that the object is requested. Private denotes the object is marked to limit access only to a certain predetermined end user or group of end users. For example after a login page all the objects on an html mail site may be marked private. Max age 0 does not automatically render the object uncacheable but results in the object being uncacheable because the object needs to be revalidated upon every request. The header alerts the cache to only retain the object for 0 seconds and revalidate after the expiration of that time period.

As noted when an embedded object is uncacheable the conventional method of object prefetching abandons any prefetch operation and closes the socket between the prefetch cache and origin server. Thus the conventional method cannot prefetch the embedded object i.e. the object cannot be retrieved from the origin server and stored on the prefetch cache to obviate future retrieval requests for the object to the server. The present invention is directed to reduce the response time to the client when the embedded objects are uncacheable.

The present invention overcomes the disadvantages of the prior art by providing a system and method for prefetching one or more embedded objects marked uncacheable using a staging area on a prefetch cache to temporarily store load the uncacheable object. According to the invention the staging area is a buffer allocated to a socket that is established between a prefetch cache and the server subsequent to the establishment of an initial connection. A prefetch caching process of the prefetch cache opens the socket and retrieves the embedded object. The prefetch caching process then determines whether the embedded object is uncacheable. If the embedded object is uncacheable then the embedded object is stored in the buffer on the prefetch cache. Notably however the prefetch caching process does not automatically send the object to the client. Instead the prefetch caching process waits a predetermined time period for the cache to receive a client request for the object. If the request is received prior to expiration of the time period the prefetch caching process sends the object over the socket to the client. Otherwise the process flushes the buffer thereby discarding the object and then closes the socket.

In the illustrative embodiment a client issues a request to a website to access a data set e.g. a webpage. The prefetch cache intercepts the request and determines whether the requested webpage is stored locally on the cache or remotely on an origin server of the website. If the webpage is locally stored then the cache sends the data set directly to the client. If the webpage is not locally stored or is only partially locally stored then the prefetch cache connects to the origin server. The prefetch cache then issues a request to retrieve the webpage and all data objects necessary to service the request and the server responds by sending the information to the prefetch cache.

Furthermore the prefetch cache applies a preconfigured set of rules to anticipate possible future requests for one or more additional data objects that might be issued by the client. The prefetch caching process then opens one or more connections to retrieve the one or more additional objects. If the additional data object e.g. an embedded object is cacheable the prefetch cache sends the data object for local storage on one or more disks of the cache. If the object is marked uncacheable then the prefetch cache loads the uncacheable embedded object into the buffer allocated to the socket.

In response to the determination that the embedded object is uncacheable the prefetch caching process on the prefetch cache creates an entry for the uncacheable embedded object in a cache table. The cache table entry illustratively includes a timestamp field containing a timestamp representing the time at which the object was loaded into the buffer of the socket. The prefetch caching process uses the timestamp associated with the embedded object to determine whether a threshold time limit e.g. 5 seconds is exceeded before a client request directed to the object is received at the prefetch cache. If the threshold time limit is not exceeded the prefetch caching process sends the object from the buffer over the socket. Otherwise the prefetch caching process flushes the buffer and closes the socket.

The cache table entry also includes a network address field containing a network address of the requesting client i.e. a requesting network address . If the uncacheable embedded object is also marked private the requesting network address e.g. an IP address is stored in the network address field. When the client request directed to the object is received the prefetch caching process determines whether the requesting network address matches a predefined network address that is allowed to access the embedded object. If the addresses match then the prefetch caching process transmits the embedded object over the socket to the client socket. If the network addresses do not match then the object is not accessible to the client and the prefetch caching process flushes the buffer and closes the socket.

The prefetch cache may be configured to operate in a forward or reverse proxy mode. That is the prefetch cache may be used to accelerate access to a selected subset of files stored in the origin servers reverse proxy mode or may be configured to store copies of those files that were recently accessed from the origin servers by a selected set of clients forward proxy mode . In either mode of operation the prefetch cache may intercept an object access request issued by a client and directed to an appropriate origin server . The client s request typically identifies a particular file a data set or a webpage that the client desires to access. The prefetch cache analyzes the received request to determine whether it contains a local copy of the client requested object. If so the prefetch cache returns its local copy of the requested object to the client in an object access response . However if the client requested object is not already resident in the prefetch cache the prefetch cache may be configured to retrieve the requested object from the appropriate origin server .

Although the object access request and response are depicted as individual data packets exchanged between the client and the prefetch cache those skilled in the art will appreciate that the request and response may be transmitted as a plurality of data packets. Typically the request and response are formatted according to a predetermined object access protocol such as HTTP and are transported using a reliable transport protocol such as the conventional Transmission Control Protocol TCP . More generally the client server communications may be implemented using any acceptable network protocol s and or physical media.

In the illustrative embodiment the prefetch cache and one or more servers are operated as a website configured to store one or more embedded objects EO comprising streaming audio or video files image files etc in the form of e.g. a webpage. The prefetch cache is further configured to prefetch the embedded objects based on a preconfigured set of rules. To that end the prefetch cache retrieves the embedded objects from the server using one or more connections e.g. a socket connection . The prefetching caching process opens a socket to retrieve one or more embedded objects using e.g. an Open command. The Open command may be a Listen command where the Listen command directs a connection to a socket and waits for a Receive command. Another command type used to open the socket is an Accept command which accepts a connection to a foreign socket such as a client socket . The Open command Close command Send command and Receive command are all described in 121 Apr. 21 1971 which is hereby incorporated by reference. The prefetch caching process then determines whether the embedded objects are cacheable or not cacheable. If cacheable then each embedded object is loaded onto the prefetch cache using a conventional method of object prefetching to enable faster access to the object upon a client request. The cacheable objects are loaded and stored in disks connected to the prefetch cache .

If the object is not cacheable then according to the present invention a prefetch caching process uses a Load command to load the embedded object into a buffer allocated to the socket . Conventionally the buffer can store 16 KB of data and the embedded object is loaded into the buffer up to the maximum capacity of the buffer. If the object is greater than 16 KB or the maximum capacity of the buffer then only part of the embedded object is stored in the buffer and the remaining part may be streamed through the socket once data is read from the buffer. Though the novel system and method as described herein uses a 16 KB buffer differing sized buffers may be used with the present invention. When a client request is intercepted by the prefetch cache the prefetch cache sends the embedded object from the buffer of the socket to a client socket using Send and Receive commands respectively.

Each network interface includes the mechanical electrical and signaling circuitry for sending and receiving data packets to from other computers connected to the cache e.g. over Ethernet links optical links wireless links etc. Each network interface A B may contain specialized processing elements such as logic or processors that format incoming and outgoing data packets consistent with a predetermined network communication protocol. For example a first network interface A may be configured to exchange HTTP messages with a remote client e.g. coupled to the first interface over the network A while a second network interface B may be configured to exchange FTP messages with the server e.g. coupled to the second interface via the network B.

The storage adapter interfaces with one or more storage devices to store and retrieve a set of objects that are accessible to the clients . The storage adapter includes input output I O interface logic and circuitry that couples to the devices over an I O interconnect arrangement such as a conventional Fibre channel serial link topology. Client requested objects may be retrieved by the storage adapter and if necessary processed by the processor or the adapter itself prior to being forwarded over the system bus to an appropriate network adapter A B. The requested object is then formatted into an object access response and returned to the requesting client .

Each storage device may be embodied as a type of writable storage device such as a magnetic or optical disk drive a non volatile random access memory e.g. FLASH memory a magnetic or optical tape drive an erasable programmable read only memory EPROM or any other form of storage device. Preferably the storage devices are embodied as disks which may be arranged into one or more Redundant Array of Independent Disks RAID groups wherein each RAID group includes one or more disks configured to store striped data and at least one disk configured to store parity data e.g. in accordance with a conventional RAID 4 configuration. However other configurations e.g. RAID 5 having distributed parity across stripes are also contemplated.

The memory comprises storage locations that are addressable by the processor and adapters for storing software programs i.e. specific sets of ordered operations and data structures. Portions of these locations are arranged and organized as buffers for use with a protocol stack. The memory preferably comprises a form of random access memory RAM that is generally cleared by a power cycle or other reboot operation e.g. it is a volatile memory . The processor and adapters comprise processing elements logic and or circuitry configured to execute the programs and manipulate the data structures such as cache table stored in the memory . It will be apparent to those skilled in the art that various types of memory means including computer readable media and electromagnetic signals may be used for storing and transporting program instructions pertaining to the inventive technique described herein.

An operating system portions of which are typically resident in the memory and executed by the processor functionally organize the cache by inter alia invoking operations in support of processes executing on the processor. As used herein a process refers to an instance of a program being executed by e.g. the processor and a thread is an instance of a sequence of the program s code. An example of a process is prefetch caching process which is configured to store and retrieve client requested objects from the disks . Illustratively the prefetch caching process includes inter alia a plurality of executable threads that are configured to perform the inventive technique described herein. That is the caching process may include one or more threads for generating and or maintaining cache table and for using the table to determine whether client requested objects are cacheable or uncacheable. The prefetch caching process cooperates with the server process on an origin server to acquire the set of objects for storage on disks . The prefetch caching process may be used to configure the prefetch cache as either a forward or reverse proxy server. Furthermore the prefetch caching process may be embodied within a version of the NetCache software developed by Network Appliance Inc. of Sunnyvale Calif. or any other similar software that is used to manage proxy caching operations. The prefetch caching process includes instructions for performing a novel prefetch operation by retrieving an embedded object from the server through e.g. a socket to acquire an uncacheable embedded object .

In operation a client may send an object access request to an origin server which request is intercepted by a network interface of the prefetch cache . The network interface cooperates with the prefetch caching process to process the request and generate an appropriate object access response . If client requested object is stored locally e.g. on disks of the cache the prefetch caching process instructs the storage adapter to retrieve the client requested object from the disks before formatting the retrieved object to generate the client s object access response. However if the object is not locally stored or is only partially stored the caching process connects to origin server to retrieve the object.

In prior art implementations a prefetch cache would automatically discard an embedded object when it is marked uncacheable. In accordance with the illustrative embodiment the prefetch caching process loads the embedded object in a buffer associated with socket on the prefetch cache .

The storage adapter interfaces with one or more storage devices to store and retrieve a set of objects that are accessible to the clients and the prefetch cache . The storage adapter includes input output I O interface logic and circuitry that couples to the devices over an I O interconnect arrangement such as a conventional Fibre channel serial link topology. Client requested objects and prefetch cache requested objects may be retrieved by the storage adapter and if necessary processed by the processor or the adapter itself prior to being forwarded over the system bus to an appropriate network adapter A B. Each requested object is then forwarded to cache where it is formatted into an object access response and returned to the requesting client .

Each storage device may be embodied as a type of writable storage device such as a magnetic or optical disk drive a non volatile random access memory e.g. FLASH memory a magnetic or optical tape drive an erasable programmable read only memory EPROM or any other form of mass storage device. Preferably the storage devices are embodied as storage disks which may be arranged into one or more Redundant Array of Independent Disks RAID groups wherein each RAID group includes one or more disks configured to store striped data and at least one disk configured to store parity data e.g. in accordance with a conventional RAID 4 configuration. However other configurations e.g. RAID 5 having distributed parity across stripes are also contemplated.

The memory comprises storage locations that are addressable by the processor and adapters for storing software program code and data structures. The memory preferably comprises a form of random access memory RAM that is generally cleared by a power cycle or other reboot operation e.g. it is a volatile memory . The processor and adapters comprise processing elements logic and or circuitry configured to execute the software code and manipulate the data structures stored in the memory . It will be apparent to those skilled in the art that various types of memory means including computer readable media and electromagnetic signals may be used for storing and transporting program instructions pertaining to the inventive technique described herein.

An operating system portions of which are typically resident in the memory and executed by the processor functionally organizing the origin server by inter alia invoking operations in support of server process executing on the processor. An example of such a process is server process which is configured to store and retrieve prefetch cache requested objects from the disks . Illustratively the server process includes inter alia a plurality of executable threads that are configured to perform the inventive technique described herein. That is the server process may include one or more threads to send an embedded object to the prefetch cache through the server socket . The server process cooperates with the prefetch caching process as further described herein to receive a command calling for the server to send a set of objects stored on disks . The server process includes instructions for performing the operations of establishing a connection between the server and the prefetch cache creating a server socket and sending an uncacheable embedded object over the socket to the prefetch cache .

In operation the prefetch cache sends a prefetch cache object request to a network interface of the server . The network interface that receives the prefetch cache object request cooperates with the server process to process the request and generate an appropriate response. Specifically the server process may instruct the storage adapter to retrieve the prefetch cache requested object from the disks before formatting the retrieved object to generate the client s object response.

In prior art implementations a server would automatically shut down a connection to a prefetch cache when an embedded object is uncacheable. In accordance with the illustrative embodiment the prefetch cache remains connected to the server through a network protocol stack when the object is uncacheable.

The Internet protocol IP is an internetwork layer protocol that provides network addressing between the prefetch cache and the origin server . IP is primarily a connectionless protocol that provides for internetwork routing fragmentation and assembly of exchanged packets and that relies on transport protocols for end to end reliability and other service characteristics. An example of a transport protocol is the TCP protocol which is implemented by the transport layer and provides connection oriented end to end reliability services to the upper layer protocols of the protocol stack. Examples of other transport protocols include the User Datagram Protocol UDP which provides best efforts delivery and Raw IP. Raw IP denotes a process that does not use a transport but directly interfaces to the internetwork layer of the network protocol stack .

Broadly stated the transport layer provides a port service that identifies each process executing on the server and prefetch cache and creates a connection between those processes when they indicate a willingness to communicate. This transport layer service may be embodied as a socket interface comprising a client socket library created within the process address space of processes and a socket server of the network protocol stack . Each process accesses the network protocol stack via the socket interface by creating a process message data structure message that is exchanged with the socket server . The message is typically embodied as information data payload appended to a transport header the type of which depends on the transport layer protocol used by the process.

The client socket library thus cooperates with the socket server to provide the service needed for the process to communicate over the network protocol stack . In order to use access the service of the socket server application programming interfaces APIs are required. That is a process may access the socket server via APIs complied by its client socket library . Examples of APIs or function calls include create socket and open socket. The process issues these function calls to the client socket library which implements those calls to effectuate communication.

The present invention is directed to a system and method for prefetching one or more embedded objects marked uncacheable using a staging area on a prefetch cache to temporarily store load the uncacheable object. According to the invention the staging area is a buffer allocated to a socket that is established between a prefetch cache and the server subsequent to the establishment of an initial connection. A prefetch caching process of the prefetch cache opens the socket and retrieves the embedded object. The prefetch caching process then determines whether the embedded object is uncacheable. If the embedded object is uncacheable then the embedded object is stored in the buffer on the prefetch cache. Notably however the prefetch caching process does not automatically send the object to the client. Instead the prefetch caching process waits a predetermined time period for the cache to receive a client request for the object. If the request is received prior to expiration of the time period the prefetch caching process sends the object over the socket to the client. Otherwise the process flushes the buffer thereby discarding the object and then closes the socket.

In the illustrative embodiment a client issues a request to a website to access a data set e.g. a webpage. The prefetch cache intercepts the request and determines whether the requested webpage is stored locally on the cache or remotely on an origin server of the website. If the webpage is locally stored then the cache sends the data set directly to the client. If the webpage is not locally stored or is only partially locally stored then the prefetch cache connects to the origin server. The prefetch cache then issues a request to retrieve the webpage and all data objects necessary to service the request and the server responds by sending the information to the prefetch cache.

Furthermore the prefetch cache applies a preconfigured set of rules to anticipate possible future requests for one or more additional data objects that might be issued by the client. The prefetch caching process then opens one or more connections to retrieve the one or more additional objects. If the additional data object e.g. an embedded object is cacheable the prefetch cache sends the data object for local storage on one or more disks of the cache. If the object is marked uncacheable then the prefetch cache loads the uncacheable embedded object into the buffer allocated to the socket.

In response to the determination that the embedded object is uncacheable the prefetch caching process on the prefetch cache creates an entry for the uncacheable embedded object in a cache table. illustrates a cache table which may be used in accordance with the illustrative embodiments of the present invention. The table includes a plurality of entries each of which comprises an Object ID field a File ID field a Flag field a Timestamp field a Network Address field and in alternate embodiments additional fields . For example Object ID field contains an identification of the embedded object. The File ID field contains applications of the file type. The Flag field contains the file type of the embedded object. The Timestamp contains the time the embedded object was loaded into the buffer . The Network Address field contains an address to retrieve the embedded object. For example the object identified in field of entry e.g. OBJ is being marked as FILE in field as such the file can be sent immediately to prefetch cache and locally stored on disks . Note that entry e.g. OBJ is similar to entry . In contrast the object identified in field of entry e.g. OBJ could be an image or a sound bite as denoted by the Flag being marked SOCKET. Notably marking of the object as SOCKET indicates that the object is stored in a buffer associated with socket . The content of Network Address field for entry is an address e.g. IP address indicating the location of socket on prefetch cache that terminates the socket virtual connection .

Using its object file matching thread the prefetch caching process compares a client requested object with the contents of cache table in order to determine whether the embedded object is stored in a buffer associated with socket . The flag in each entry of cache table indicates whether the object is a file stored in disks of the prefetch cache or sent to the buffer on the prefetch cache . Accordingly by examining the file type stored in the cache table as well as other information about the client requested object the prefetch caching process can determine the location of the socket that receives the object from the server and then forwards the object to the client socket upon a client request .

As noted each cache table entry illustratively includes a timestamp field containing a timestamp representing the time at which the object was loaded into the buffer of the socket. The prefetch caching process uses the timestamp associated with the embedded object to determine whether a threshold time limit e.g. 5 seconds is exceeded before a client request directed to the object is received at the prefetch cache. That is the timestamp is used to determine if the object has aged too long before a client request is received. Periodically the timestamp is compared with the threshold limit and if the difference between the actual time and the timestamp is greater then the threshold the buffer is flushed of the embedded object . If the difference between the actual time and the timestamp is less than or equal to the threshold the object remains in buffer associated with socket and waits for the client request . An object is flushed from the buffer after a threshold time is reached because of limited memory allocated for the network protocol stack and for converting packets for storage.

However if the object is uncacheable the prefetch caching process at step creates an entry for the uncacheable object in the cache table . The entry s fields are populated with an Object ID a File ID a Flag a Timestamp and a Network Address . As noted the network address can be an IP address of the network interface terminating the socket. At step the prefetch caching process loads the embedded object into buffer associated with socket as described herein.

The prefetch cache then waits for a subsequent client request for the embedded object. The prefetch caching process determines if a subsequent client request is received at step . If a subsequent client request is not received the prefetch caching process determines at step if the difference between the actual time and the timestamp is less than a threshold e.g. 5 seconds. If the difference between the actual and the time stamp is more than the threshold then at step the prefetch caching process flushes the embedded object from the buffer associated with the socket . At step the connection between the prefetch cache and the server is closed and the procedure completes at step . However if the difference between the actual time and the time stamp is less than or equal to the threshold then the prefetch caching process determines if a subsequent client request is received yet at step .

After the prefetch cache receives a subsequent client request for the uncacheable embedded object the prefetch cache locates the socket using the cache table at step . At step the embedded object is served to the client socket through the prefetch cache using the socket . The procedure then completes at step .

In summary the prefetch cache intercepts a request issued by a client to an origin server for e.g. a webpage. The prefetch cache sends the client the requested webpage that is either stored locally on the prefetch cache or on the origin server . The prefetch cache then attempts to prefetch embedded objects in anticipation of a subsequent client request based on a preconfigured set of rules. The prefetch caching process retrieves one or more embedded objects using one or more socket connections between the server and the prefetch cache . Furthermore the prefetch caching process determines if the selected embedded object is cacheable or uncacheable. If uncacheable the prefetch caching process loads the embedded object into buffer up to the maximum capacity of the buffer or the maximum size of the object. The prefetch cache then waits for a client request for the object. Upon receiving the client request the prefetch caching process locates the network address for the socket in a cache table and then sends the embedded object to a client socket .

Furthermore when an uncacheable embedded object is marked max age 0 the procedure is used even though the embedded object may be immediately writable to disk. Here the prefetch cache requests the anticipated embedded object marked max age 0 and the object is sent from the prefetch cache socket to the client socket through the prefetch cache . The buffer associated with the socket is more efficiently accessible than the server disks thereby reducing the searching and downloading time needed to determine whether the embedded object is an up to date version.

If the object is marked as private then at step the prefetch caching process stores the network address of the client in field of the cache table along with the Object ID the File ID the Flag the Timestamp and the Network Address of the socket . At step the prefetch caching process determines if the client network address matches a predefined network address allowed to retrieve the object. Note that the network address can be any type network address such as an IP address. If the two network addresses do not match then at step the embedded object cannot be transferred to the client. The prefetch cache closes the connection to the server at step and the procedure completes at step . If the two network addresses match then at step the prefetch caching process loads the embedded object into a buffer associated with socket . At step the prefetch cache waits for a client request at step . As noted the client request must be made within a certain time period from loading of the buffer i.e. the threshold time period. If the client request is not made or comes after the threshold the embedded object is flushed from the buffer and the socket is closed.

At step a client request is received by the prefetch cache and at step the prefetch caching process serves the embedded object from the socket to the client socket . The procedure then completes at step .

The foregoing description has been directed to specific embodiments of this invention. It will be apparent however that other variations and modifications may be made to the described embodiments with the attainment of some or all of their advantages. For instance it is expressly contemplated that the teachings of this invention can be implemented as software including a computer readable medium having program instructions executing on a computer hardware firmware or a combination thereof. Accordingly this description is to be taken only by way of example and not to otherwise limit the scope of the invention. Therefore it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.

