---

title: System, method and computer program product for dynamically identifying, selecting and extracting graphical and media objects in frames or scenes rendered by a software application
abstract: A technique is described herein for dynamically enhancing and measuring a software application without having to change and recompile the original application code. A system includes a staging environment that monitors the application and indexes items of graphical and/or audio information into a first database. A second database is then populated with business rules that are associated with the objects indexed. The system further includes a run-time environment that identifies items of graphics and/or audio information generated during run-time, and upon determining that an identified item is associated with a business rule, applies the business rule, measures the object and its related attributes and optionally report the data back to a third database. Also described herein are techniques for dynamically measuring attributes of objects rendered and/or referenced by software applications, for dynamically serving advertisements to a computer game, and for pre-processing software applications to identify spots desirable for advertisement placement.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08629885&OS=08629885&RS=08629885
owner: Exent Technologies, Ltd.
number: 08629885
owner_city: Petach-Tikva
owner_country: IL
publication_date: 20061027
---
The present application is a continuation in part of pending U.S. Non Provisional patent application Ser. No. 11 492 069 titled System Method And Computer Program Product For Dynamically Serving Advertisements In An Executing Computer Game Based On The Entity Having Jurisdiction Over The Advertising Space In The Game filed on Jul. 25 2006 which is a continuation in part of pending U.S. Non Provisional patent application Ser. No. 11 472 454 titled System Method And Computer Program Product For Dynamically Measuring Properties Of Objects Rendered And Or Referenced By An Application Executing On A Computing Device filed on Jun. 22 2006 which is a continuation in part of pending U.S. Non Provisional patent application Ser. No. 11 290 830 filed on Dec. 1 2005 and claims the benefit of U.S. Provisional Patent Application No. 60 797 669 filed on May 5 2006 U.S. Provisional Patent Application No. 60 798 710 filed on May 9 2006 and U.S. Provisional Patent Application No. 60 810 177 filed on Jun. 2 2006 all of which are herein incorporated by reference in their entireties.

The present invention generally relates to software applications. In particular the present invention relates to techniques for dynamically enhancing software applications during execution on a computing device and for dynamically measuring attributes of objects rendered and or referenced by such software applications.

Software applications and video games in particular render graphics information to a display device using a variety of techniques. One well known technique is to place function calls to a low level application programming interface API such as DirectX or OpenGL . In response to receiving such function calls these APIs issue commands to the graphics hardware of a computer system or in the alternative attempt to emulate relevant hardware functionality in software. Similarly software applications may play audio information by placing function calls to DirectSound which is an API within the DirectX suite of APIs.

It is of interest to various parties that make such applications available to end users for example publishers retailers and service providers to augment some of the graphics and audio information rendered by these applications based on a dynamic set of business rules . For example such business rules could be used to display advertising content on a graphics element rendered by a video game or to insert advertising content within an audio stream played by the video game. Ideally the dynamic nature of the business rules would allow them to be periodically changed. For example it would be advantageous if the inserted advertising content could be changed on a periodic basis.

One possible method of achieving this is to embed the business rules directly in the original application logic or source code and then to recompile the application with those business rules. However this technique of coding and recompiling an application to accommodate the business rules might not be achievable for all software applications. By way of example the party wishing to insert the business rule might not have access to the source code. As another example the application that is sought to be enhanced may already have been deployed in the field or purchased by consumers or others.

Another method of achieving the dynamic insertion of graphics content into an application is to integrate special client software into the original application logic during the software development phase of the application. When the application is executed the special client software serves the application to communicate with a server which based upon some predefined business rules may dynamically insert graphics content into the application in a pre allocated space that has been identified and registered in advance by the application. However this method is limiting because it will only work if the application as originally programmed includes the necessary special client software interfaced during development time and has identified in advance the areas and or objects on which the dynamically inserted graphics information may appear.

It is also of interest to various parties to track and determine the impact of graphics and audio objects rendered by applications. For example for a given object of interest it would be of interest to know how often that object appeared in frames the length of each such exposure the size of that object when it appeared the extent to which the object was obscured the angle in which it was viewed etc. In the case where the object was part of an advertisement such information would be useful for calculating advertising royalty fees e.g. for CPM based royalties . However for the reasons discussed above it is difficult to provide such functionality with software products that have already been deployed in the field or purchased by consumers or others or where the source code is not available.

It is further of interest to various parties to serve advertisements to executing computer games. However for the reasons discussed above it is difficult to provide such functionality with software products that have already been deployed in the field or purchased by consumers or others or where the source code is not available.

What is desired then is a system method and computer program product for dynamically enhancing an application such as a video game executing on a computing device without having to change and recompile the original application code. Dynamically enhancing the application should include the ability to dynamically modify graphics and or audio information generated by the application during execution to dynamically render additional graphics and or audio information during execution of the application or to perform other functions relating to the executing application that are not provided for or invoked by the source code of the application. What is also desired is a system method and computer program product for dynamically tracking and determining the impact of objects rendered and or referenced by an application without having to change and recompile the original application code. It is desired to track and measure the impact of applications enhanced as described herein and also track and measure applications without such enhancements i.e. in their original form . This latter case may be used in order to collect valuable information to understand the rating according to popularity exposure parameters etc. of each such original object to later on be able to prioritize where one may want to advertise or what objects one may want to measure track. What is further desired is a system method and computer program product for dynamically serving advertisements to advertising space in executing computer games based on the entity or entities having jurisdiction over such advertising space without having to change and recompile the original application code. It is also desired to have a system method and computer program product for dynamically identifying programs executing on a computer in order to decide whether or not to activate the business rules.

What is additionally desired is a system method and computer program product to identify and designate spots in a computer game to place advertising or other information without having to change and recompile the original code of the computer game in a manner that is external to the game itself. The identification of such spots would be useful for many applications such as but not limited to the advertisement serving application mentioned above.

The present invention provides a system method and computer program product for dynamically enhancing an application such as a video game executing on a computing device without having to change and recompile the original application code. In one implementation dynamically enhancing the application includes the ability to dynamically modify graphics and or audio information generate by the application during execution. In another implementation dynamically enhancing the application includes the rendering of additional graphics and or audio content during execution of the application. In still other implementations dynamically enhancing the application includes the performance of other functions relating to the executing application that are not provided for or invoked by the source code of the application such as measuring and tracking the exposure of objects of interest.

In one implementation a system in accordance with an embodiment of the present invention includes a staging environment that monitors the execution of the application and indexes a subset of items of graphics and or audio information generated by the application into a first database. The subset may be small or encompass all the objects and information generated by the application. Note that the staging environment is not required in all embodiments. For example in the case where one wants to calculate the rating of various objects inside the game one may want to track all objects in the production run time environment in order to know what objects are more valuable than others. A system administrator or other entity then populates a second database by manual or automated means with one or more business rules wherein each business rule is associated with zero or more of the items indexed in the first database. Business rules may also instruct the run time systems as follows on what objects to measure track. The system further includes a run time environment that identifies items of graphics and or audio information as they are generated by the application during run time uses the second database to determine if an identified item is associated with a business rule and responsive to a determination that an identified item is associated with a business rule applies the business rule. Application of the business rule may result in the modification of graphics and or audio information generated by the application during execution the rendering of additional graphics and or audio information or the performance of other functions relating to the executing application that are not provided or invoked by the source code of the application including the measurement of specific objects.

The invention includes an additional embodiment for dynamically measuring attributes of objects rendered and or referenced by software applications without the need to revise the source code of such applications. This embodiment includes an optional object tagging component that executes in the staging environment and an object measurement component that executes in the run time environment. The object tagging component is responsible for generating information about what objects are to be tracked measured. When wishing to be able to track a subset of objects one embodiment of the invention is to intercept a function call issued by a first instantiation of the application executing in the staging environment determine if an object referenced by the function call satisfies tagging criteria and tag the object as an object of interest if the object is determined to satisfy the tagging criteria. The object measurement component intercepts a function call issued by the application executing in the run time environment determines if an object referenced by the function call is an object of interest and determines an impact of the object if the object is determined to be an object of interest.

The invention also includes an embodiment for dynamically serving advertisements to a computer game executing in a computer. In an embodiment advertisements are served to advertising space in the computer game depending on the entity or entities having jurisdiction over such advertising space. Embodiments of the invention generally operate as follows. First a game of interest executing in the computer is identified. This can be done for example by detecting the launching of new processes and determining whether the new processes are games of interest. Second information on the game of interest is collected. Such information may include but is not limited to the IP address of the computer the geographical location of the computer the operating system s regional settings whether or not the game is a retail copy whether or not the game is a digitally distributed copy whether or not the game is a demonstration copy whether or not the game is a trial version and or whether or not the game is a pirated copy. Third advertisements are served to the game of interest based on the collected information. For example more advertisements may be served to pirated copies as compared to retail copies demonstration copies and trial copies.

The invention also includes embodiments for pre processing computer games and other software applications to identify spots in the game where such spots are desirable for future advertisement placement or for other purposes . These embodiments generally operate by allowing the user to traverse the various possible elements or spots during the operation of an application identifying the ones that are interesting for further processing e.g. by allowing the user to visually highlight objects on the screen by for example creating a frame around the object enabling a user to browse through at least a subset of the game s objects determining whether the user selected one or more of the objects while browsing and if the user selected one or more of the identified objects then storing information pertaining to the selected object for future reference purposes. The invention also includes embodiments for performing this function in an automated manner. Such embodiments generally operate by intercepting a function call to a low level graphics audio function gathering information pertaining to an object referenced by the intercepted function call and storing the information.

Further features and advantages of the present invention as well as the structure and operation of various embodiments thereof are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

The features and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings in which like reference characters identify corresponding elements throughout. In the drawings like reference numbers generally indicate identical functionally similar and or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit s in the corresponding reference number.

In an alternative embodiment staging environment information database does not include object index information. Instead or in addition to such object index information the staging environment information database includes rules and or criteria that objects must satisfy so as to be tracked and measured or to be otherwise processed according to the embodiments described herein.

As will be described in more detail herein after staging environment information database has been populated by staging environment a system administrator or other entity then populates a business rules database by manual or automated means with a set of business rules wherein each business rule in database is associated with one or more of unique IDs of objects indexed in staging environment information database .

Run time environment represents the environment in which an end user actually runs the application software. The application is the same as the application executed in staging environment in that it is another copy or instance of essentially the same computer program although it need not be completely identical. As will be described in more detail herein run time environment monitors the execution of the application on a computing device and also identifies application generated graphics and audio objects. If run time environment determines that an object generated by the application matches a business rule associated with the above mentioned object in business rules database then it applies the business rule. The business rule may be used for example to determine whether or not to modify the object in run time i.e. during execution of the software application although other business rules will also be described herein.

In terms of hardware components each of staging environment and run time environment consists of a computing device that is configured to execute software applications that generate graphics and audio information. Each computing device further includes application program interfaces for rendering and displaying the application generated graphics information and for playing back the application generated audio information. For the sake of convenience from this point forward each of staging environment and run time environment will be described as comprising a personal computer PC based computer system although the invention is not so limited. For example staging environment and run time environment may each comprise a server a console a personal digital assistant PDA or any other computing device that is capable of executing software applications and displaying associated application generated graphics and audio information to an end user.

Application is programmed such that during execution it makes function calls to low level graphics audio functions . The interaction of application with low level graphics audio functions is well known in the art. However in accordance with an embodiment of the present invention such function calls are intercepted by interception component and provided to an indexing component prior to being passed to low level graphics audio functions . Interception component and indexing component are software components that are installed on the computer system of staging environment prior to execution of application . As will be described in more detail herein indexing component identifies graphics and audio objects associated with the intercepted function calls and indexes each of the objects in staging environment information database along with a unique ID.

In an implementation of the present invention interception component comprises one or more emulated versions of corresponding low level graphics audio functions . For example in an implementation in which low level graphics audio functions are contained in graphics and audio libraries such as in dynamic link libraries or DLLs interception component comprises emulated versions of one or more of those libraries. These emulated libraries have the same names as the original libraries that they are intended to replace so that they are linked to application at run time. A particular example of interception by emulation will now be explained with reference to .

In contrast to the conventional software architecture illustrated in illustrates a software architecture including emulated graphics and audio libraries in accordance with an embodiment of the present invention. As shown in interception component has been inserted between application and Direct3D API . This may be achieved by emulating one or more graphics or audio libraries within Direct3D API . As a result certain function calls generated by application are received by interception component rather than Direct3D API . Interception component provides the intercepted function calls or graphics and audio objects associated with the intercepted function calls to an indexing component . Interception component also passes the function calls to Direct3D API by placing calls to that API where they are handled in a conventional manner. It is noted however that the function calls need not necessarily be passed to Direct3D API in order to practice the invention.

Depending on the operating system emulating a genuine graphics API can be achieved in various ways. One method for emulating a genuine graphics API is file replacement. For example since both DirectX and OpenGL are dynamically loaded from a file emulation can be achieved by simply replacing the pertinent file OpenGL.dll for OpenGL and d3dX.dll for DirectX where X is the DirectX version . Alternatively the DLL can be replaced with a stub DLL having a similar interface which implements a pass through call to the original DLL for all functions but the hook functions.

As further shown in run time environment includes an application an interception component business logic and low level graphics audio functions . Application is the same as application of staging environment in that it is another copy or instance of essentially the same computer program although it need not be completely identical. Low level graphics audio functions are software functions resident in memory of the computer system that are accessible to application and that assist application in the rendering of application generated graphics information and the playing of application generated audio information. Low level graphics audio functions and are similar in the sense that they provide the same functionality and services to application and application respectively through similar APIs.

During execution on the computer system of run time environment application makes function calls to low level graphics audio functions in the same well known manner that application made function calls to low level graphics audio functions in staging environment . However in accordance with an embodiment of the present invention such function calls are intercepted by interception component which either passes the function call on to low level graphics audio functions on to business logic or both. Interception component and business logic are software components that are installed on the computer system of run time environment prior to execution of application .

When interception component intercepts a function call it passes control along with the relevant object to business logic which determines if the object is associated with one or more business rules in database . If the object is associated with a business rule in database then business logic applies the business rule.

In one implementation application of the business rule results in modification of the object which may include lighting sources point of view textures or shading during run time. If no modification is to occur the intercepted function call is simply passed on to low level graphics audio functions . If a modification is to occur then the function call may be handled by business logic alone or by business logic in conjunction with low level graphics audio functions . As will be described in more detail herein modifying the object may include altering a portion of the object replacing the object with a different object or simply not rendering or playing back the object. The application of other business rules will also be described herein.

In one implementation staging environment information database is created or populated in local memory of the computer system of staging environment . A system administrator or other entity then populates business rules database by manual or automated means with one or more business rules wherein each business rule is associated with one or more of the objects indexed in the first database. The association between the business rule and an object is created by forming a relationship between the business rule and the unique ID of the object in database . In one implementation a wild card scheme is used to permit a single business rule to be associated with a group of logically related objects.

Generally speaking a business rule is any logic that when applied within the context of application causes application to perform a function that is not provided for in the original application source code. As noted above a business rule may call for modification of a graphics object associated with an intercepted function call such that the graphics object when rendered appears differently than it would have if it were not so modified. For example a business rule may cause advertising content to be dynamically inserted into a graphics object. A business rule may also add additional objects graphics sound etc. to the application. This can be done by calling additional graphics library and logic functions as part of the intercepted calls. Further examples of business rules and their application are set forth below in Section IV. However these examples are provided for illustrative purposes only and are not intended to limit the present invention.

Because the business rules can be changed at any time by a system administrator or other entity they provide a dynamic mechanism by which to enhance application . For example the business rules provided a dynamic mechanism by which to augment graphics and audio content generated by that application.

In one implementation once business rules database has been created or updated by a system administrator or other entity a copy of database is transferred to local memory of the computer system of run time environment . The transfer may occur by transferring a copy of database to a recordable computer useable medium such as a magnetic or optical disc and then transferring the computer useable medium to run time environment . Alternatively a copy of database may be transferred via a data communication network such as a local area and or wide area data communication network. In yet another implementation database is not transferred to local memory of the computer system of run time environment at all but is instead stored at a central location in a computing network where it can be accessed by multiple run time environments using well known network access protocols. However these examples are not intended to be limiting and persons skilled in the relevant art s will appreciate that a wide variety of methods may be used to make database available to run time environment .

The following description of the method of flowchart assumes that each of the software components of staging environment have already been installed on a computer system. The method also assumes that software application is executing on the computer system. Executing software application encompasses both launching the application and interacting with the application through one or more user interfaces in a manner that causes the application to generate graphic and or audio information. For example if application is a video game executing the application encompasses both launching the video game and playing through at least a portion of the video game using appropriate user input output I O devices.

The method begins at step in which software application generates a function call directed to low level graphics audio functions . At step it is determined whether or not the function call is intercepted by interception component . If no interception occurs then processing proceeds to step where the function call is handled by low level graphics audio functions in a conventional manner. Processing of the function call then ends as indicated at step . However if the function call has been intercepted processing instead proceeds to step .

At step interception component identifies a graphics or audio object associated with the intercepted function call. A graphics object may comprise a model texture image parameter or any other discrete set of information or data associated with the intercepted function call and used in rendering a graphics information on behalf of application . An audio object may comprise an audio file a digital sound wave or any other discrete set of information or data associated with the intercepted function call and used in playing back audio information on behalf of application . The graphics or audio object may be part of the function call itself or may be addressed by or pointed to by the function call. For example if the intercepted function call is a SetTexture function call to the Direct3D API the associated graphics object may consist of a texture pointed to by the SetTexture function call.

At step indexing component indexes the graphics or audio object identified in step in staging environment information database . In one implementation indexing the object includes storing the object or a portion thereof in staging environment information database along with a unique identifier ID for the object. The unique ID may be arbitrarily assigned or may be calculated based on information contained in the object itself. For example in an implementation the unique ID comprises an error correction code such as a cyclic redundancy code CRC that is calculated based on all or a portion of the content of the graphics or audio object. In an alternate implementation an encryption and or hashing algorithm is applied to all or a portion of the content of the graphics or audio object to generate the unique ID. For example the unique ID may be an MD5 hash signature that is calculated based on all or a portion of the content of the graphics or audio object. A benefit of generating a unique ID based on the content of the object itself is realized in run time environment where the unique ID instead of the object itself which may be quite large can be used to search for matches in business rules database . In one implementation of the present invention the unique ID alone is stored in business rules database to represent an underlying graphics or audio object. As a result the storage requirements for business rules database can be substantially reduced.

In one implementation the unique ID is not calculated as part of the method of flowchart but instead is calculated by a separate process that occurs after completion of the method when staging environment information database has been populated with graphics and audio objects.

In an alternative embodiment not all objects identified in step are indexed in step . Instead in order for an identified object to be indexed the object must satisfy some criteria or rule. This operation is similar to that described below with reference to step in and or step in .

At step after indexing is complete the function call is then passed to low level graphics audio functions where it is handled in a conventional manner. After this processing of the function call ends as indicated at step .

As noted above the method of flowchart would likely be executed numerous times during execution of a software application within staging environment . Furthermore the method may be applied to the execution of multiple software applications in order to index graphics and audio objects therefrom. The indexed graphics and audio objects for the multiple applications may be stored in a single staging environment information database or in multiple databases . Each of these databases may then be used to populate one or more business rules databases which are provided for use in one or more run time environments .

The following description of the method of flowchart assumes that each of the software components of run time environment have already been installed on a computer system. The method also assumes that software application is executing on the computer system. Executing software application encompasses both launching the application and interacting with the application through one or more user interfaces in a manner that causes the application to generate graphic and or audio information.

The method begins at step in which software application generates a function call directed to low level graphics audio functions . At step it is determined whether or not the function call is intercepted by interception component. If no interception occurs then processing proceeds to step where the function call is handled by low level graphics audio functions in a conventional manner. Processing of the function call then ends as indicated at step . However if the function call has been intercepted processing instead proceeds to step .

At step interception component identifies a graphics or audio object associated with the intercepted function call. As noted above a graphics object may comprise a model texture image parameter or any other discrete set of graphics information associated with the intercepted function call and an audio object may comprise an audio file a digital sound wave or any other discrete set of audio information associated with the intercepted function call. The graphics or audio object may be part of the function call itself or may be addressed by or pointed to by the function call. For example if the intercepted function call is a SetTexture function call to the Direct3D API the associated graphics object may consist of a texture pointed to by the SetTexture function call.

At step business logic determines if the identified object is associated with at least one business rule in business rule database . This step may include comparing the identified object or a portion thereof to a graphics or audio object or portion thereof stored in database . Alternatively this step may include calculating a unique ID for the identified object and then comparing the unique ID for the identified object to a set of unique IDs stored in database . For example as described above in reference to the unique ID may comprise an error correction code such as a CRC calculated based on all or a portion of the content of the identified object or a signature such as an MD5 hash signature derived by applying an encryption and or hashing algorithm to all or a portion of the content of the identified object. It should be noted that wild cards or other logical groupings of objects may be used in accordance with the present invention to associate a business rule with multiple objects. For example business rules database may include business rules that will be applied to all objects identified by a catch all matching expression.

If the identified object is not associated with at least one business rule in database then processing proceeds step where the function call is processed by low level graphics audio functions in a conventional manner.

However if the identified object is associated with at least one business rule in database then business logic applies the at least one business rule as shown at step . In one implementation the application of the business rule results in the modification of the identified object. Such modification may include replacing the identified object with a different object altering the content of the identified object or simply not rendering or playing the identified object at all. However the present invention is not limited to simply modifying the object. For example a business rule may include preceding the rendering or playing of the object with the rendering or playing of another object or succeeding the rendering or playing of the object with the rendering or playing of another object. Note that because application of the business rule may include rendering or playing an object such application may include placing one or more function calls to low level graphics audio functions .

In fact the business rule need not include the rendering of any graphics information or playing of any audio information. Instead the business rule may simply consist of performing some activity within the context of software application in response to the identification of a certain graphics or audio object by interception component . By way of example the business rule may include moving pointers associated with user input devices to predefined regions of the display screen useful for auto aiming in shooting games or for automatic orientation within on screen game menus generating a key sequence such as inputting cheat codes logging and or reporting a user s progress within the software application or other activities. Each of these events can be performed before instead of or after the graphics or audio object associated with an intercepted function call has been rendered or played by the original non emulated low level graphics or audio libraries.

After one or more business rules have been applied at step processing of the function call then ends as shown at step .

As described above an embodiment of the present invention facilitates the application of business rules to a software application executing on a computing device thereby permitting the application to be enhanced in a dynamic manner that does not require modifying and recompiling the original application code. Additionally because an embodiment of the invention can be implemented in run time environment using emulated libraries the operation can be essentially transparent to the end user. Indeed aside from the installation of the necessary software components i.e. interception component business logic and optionally business rules database in run time environment the end user need not take any proactive steps to link or interface the software application with an external software component.

The distribution of the necessary software components to the computing device of an end user may be achieved in a variety of ways. For example the software components may be distributed from a centralized entity to a number of run time environments over a data communication network such as the Internet. Such a system is illustrated in in which a centralized network entity is shown communicating with a plurality of user run time environments and over a data communication network . By combining such network based distribution with auto installation software the installation of such components on an end user s computing device may be achieved in a manner that advantageously requires minimal end user intervention. Furthermore since only a single copy of the run time components is needed on the end user machine one can also bundle those components with one or more applications 

In an implementation of the present invention the business rules themselves are dynamic in the sense that an entity for example a publisher retailer or service provider can change them periodically to enhance a given application in different ways. Business rules can be changed or added by making modifications to business rules database . Copies of business rules database or updates thereto may be distributed from a centralized network entity to multiple run time environments over a data communication network using a network system such as that shown in .

In an alternate implementation copies of business rules database are not distributed to run time environments at all but instead business rules database resides remotely with respect to run time environments and is accessed only when required via a data communication network such as the Internet. For example business logic rules database may reside on a centralized network entity such as a server where it is accessed by computing devices associated with multiple run time environments . Again such a network configuration is illustrated in . This implementation is advantageous in that changes to the business rules need only be implemented once at the central server and need not be actively distributed to the multiple run time environments .

In an implementation where interception component comprises one or more emulated libraries a determination may be made during installation of interception component or at application run time as to which libraries should be emulated. Consequently different sets of libraries may be emulated for each software application that is to be dynamically enhanced. The determination may be based on the characteristics of the software application that is to be dynamically enhanced upon some externally provided metadata or provisioned from the staging environment by one means or another.

Some exemplary applications of the present application will now be described. These examples are provided for illustrative purposes only and are not intended to limit the present invention in any way.

An implementation of the present invention facilitates the embedding of in game advertising in games that were not designed to support such a feature. In accordance with this implementation staging environment operates to index the texture of a game related surface such as the hood of a car in a racing game in staging environment information database . A system administrator then defines a business rule to overlay the hood of the car with a logo associated with an advertised product. That business rule is captured in business rules database where it is associated with the texture for the hood of the car. In run time environment interception component identifies the texture as it is accessed for rendering on an end user s computer and business logic matches it to the business rule stored in database . As a result the business rule is applied to augment the image of the texture for the car hood with the product logo and to render the manipulated image to the screen. The end result is that the product logo will be displayed upon the car hood inside the graphic display associated with the game.

Based on the teachings provided herein persons skilled in the relevant art s will appreciate that the present invention is equally applicable to the insertion of audio advertising content within an audio object played within the context of a game. Furthermore the present invention is also applicable to render graphic and audio advertising content that bears no relation to any specific intercepted object and that is rendered or played independently of that object.

In a further embodiment of the present invention run time environment further includes logic for capturing input output I O from an end user device such as a keyboard or mouse. The software components for such an embodiment are shown in . In particular as shown in the software components of run time environment include an application low level graphics audio functions and an interception component inserted between them that is in communication with business logic similar to the software architecture shown in . However in the implementation shown in an additional I O capture component has been provided that allows business logic to monitor events associated with the use of a user input device such as a keyboard or mouse. In one implementation this monitoring is achieved by emulating functions associated with processing mouse or keyboard input.

A system in accordance with can be used to extend the functionality of an implementation of the present invention that facilitates the embedding of in game advertising. For example while an embedded product logo is being rendered within a graphic display associated with the game I O component monitors user input to identify when a user has interacted with the logo for example by pointing to the logo with a mouse and clicking. In response to a determination that user interaction has occurred business logic performs a function. By way of example the function may include displaying a form for the user to enter data to be sent to a server display some other graphic or audio content to the user or provide the user with a prize or a notification that they will receive a prize.

In accordance with an implementation of the present invention level advancement and achievements with a game can be identified and certain actions can be taken based on the advancement or achievement. For example a business rule can be associated with a graphics or audio object identified in staging environment that is unique to or representative of a certain level or stage within a game that is divided into levels or stages. When the same object is identified in run time environment the end user has reached the level or stage within the game and the business rule is applied. The business rule may include logging information about the achievement or advancement and then transmitting it to a centralized repository over a data communication network such as the Internet to enable tournaments and merit allocation schemes. Alternatively in games that display game scores on the screen the rendered information can be captured and the actual score the user has achieved can be logged and used as the data for enabling tournaments and merit allocation schemes.

In accordance with an embodiment of the present invention the ability to measure rendering and or exposure of objects in the game or other computer application can be logged and transmitted to a centralized server for various purposes including but not limited to 

This section describes additional embodiments of the present invention. These embodiments relate to techniques for dynamically tracking and determining the impact of objects rendered and or referenced by an application executing in a computer without having to change and or recompile the original application code.

For illustrative purposes the invention is sometimes described in this Section V with reference to graphical objects. However the invention is not limited to graphics and covers any type of media used in an application such as sound video etc.

As described above while an application is running on a computer device it is possible to identify when a specific object is rendered or otherwise referenced and execute a business rule associated with the object. For example in the case where the object is a graphic texture the associated business rule might replace the original texture with a new texture or play an audio file. Where the invention is used in the in game advertising field the new texture or audio file might be associated with an advertisement. In this example which is provided for purposes of illustration and not limitation the invention enables the dynamic insertion of advertising content into a computer game without requiring changes in the computer game itself.

This section V describes embodiments of the invention for dynamically tracking and determining the impact of objects rendered and or referenced by an application as the application executes in a computer without requiring changes in the original application source code. For example for a given object of interest embodiments of the invention track the object as the application executes and measure properties such as those listed below. The below is not an exhaustive list. Other object properties will be apparent to persons skilled in the relevant art s . 

Measuring such object properties is useful for many applications. Consider computer games wherein the display is dynamic and changes according to the behavior of the game and the decisions made by the user. Accordingly with in game advertising the location and size of advertisements vary over time. As such there is a need to measure for example the actual display of each advertisement according to the total time it was seen the number of times it was seen more than N seconds its display size the angle in which it was viewed whether or not it was hidden behind another non transparent object etc. Also in embodiments there is a need to calculate the rating of individual objects inside the game. Such ratings are useful in many respects including but not limited to using rating information when developing planning advertising campaigns. Tracking and measuring such object properties is useful for calculating advertising royalty fees for the in game advertising field as well as other fields.

Another example includes computer game tournaments. Because the invention tracks and measures object properties including how objects interact the invention makes it possible to run a computer game tournament where such tournament is not an original element of the computer game. Consider an example where the tournament is a race and a particular tree is designated as the finish line. By tracking the object s corresponding to the tree the invention makes it possible to determine which user reaches the tree first. As a result the invention makes it possible to add tournament play to existing computer games without having to modify the source code of the games.

Another example includes centralized information sources and applications on top of them. Because the invention tracks and measures object properties the invention makes it possible to know which users have achieved certain things in the game. For example what users in a MMORPG massively multiplayer online role playing game posses a certain weapon. By tracking the object s corresponding to the weapon and reporting it back to a centralized server or other designated location s and or component s the information can be made available to other users applications as well allowing the creation of real time virtual asset trading.

Embodiments of the invention include an optional object tagging component shown in and an object measurement component shown in . In an embodiment the object tagging component is part of the staging environment and may be a stand alone component or may be part of another component such as indexing component . Also object tagging component is optional as one may not want necessarily to pre designate objects to be measured but may want to instead provide rules or criteria that objects must satisfy e.g. all objects larger than 5 of the screen to be measured. Object measurement component is part of run time environment and may be a stand alone component or may be part of another component such as interception component or business logic .

As described in detail below object tagging component operates to tag certain objects such as but not limited to certain objects that are indexed in staging environment information database . Object measurement component tracks and measures attributes of those tagged objects. Such operation shall now be described in greater detail with reference to a flowchart shown in . According to an embodiment in flowchart steps and are performed in staging environment and steps and are performed in run time environment .

In step object tagging component identifies objects of interest. In an embodiment such objects of interest are a subset of the objects indexed in staging environment information database . In other embodiments there may be objects of interest that are not indexed in staging environment information database . In still other embodiments the staging environment information database includes rules providing criteria that objects must satisfy in order to be considered objects of interest without identifying individual objects An object of interest is for example a graphical audio or video object corresponding to an advertisement or a graphical audio or video object corresponding to a tournament or any other object that one wishes to track and monitor for whatever reason.

In step object tagging component tags the objects of interest. Such tagging of an object may be achieved in a number of ways such as 1 setting a flag in the object s entry in the staging environment information database and or 2 creating a new table such as a new hash table and storing in the table information identifying the object such as a CRC of the object .

In an embodiment object tagging component performs steps and augmenting as part of interception component and indexing component as they are populating staging environment information database . Specifically at the time that indexing component identifies objects associated with function calls to low level graphics audio functions that were intercepted by interception component and indexes such objects in staging environment information database object tagging component also performs step where it identifies objects of interest and step where it tags objects of interest .

Alternatively object tagging component performs steps and after interception component and indexing component have populated staging environment information database specifically after flowchart in has been performed . This can be used to allow batch logging of such objects during the execution of the applications in run time environment while steps are performed by an administrator without interacting with the application itself but rather by altering information in database .

Steps and that is the operation of the object tagging component are further described below in Section V.B.

In step the object measurement component operating in the run time environment tracks objects of interest to thereby monitor objects of interest as the scenes rendered by the application evolve and change. In particular the object measurement component reviews the objects referenced in function calls directed to low level graphics audio functions such function calls having been intercepted by interception component as described above and determines whether any of those objects are objects of interest i.e. by checking the staging environment information database or by checking for information in the objects themselves etc. . In an embodiment once an object is initially identified as being an object of interest subsequent tracking of that object in run time environment can be achieved by 1 inserting information into the object itself indicating that the object is an object of interest one example of this operation in DirectX may be by using the function SetPrivateData or 2 creating a proxy of the object whereby future references to the object are directed to the proxy instead of the object itself the proxy would include a pointer or other reference to the underlying object as well as information indicating that the object is an object of interest One example of this approach in C may be by implementing a proxy class that inherits from the original class and adding to the new class members that store the required information. An instance of the gateway class is returned to the calling function instead of the original class by casting the returned instance or by other methods that will be apparent to persons skilled in the relevant art s .

In step object measurement component determines the impact of the objects of interest. In embodiments object measurement component performs step by determining measuring and or collecting information about the objects such as the object size orientation collisions with other objects whether the object is in view distance of the object from other objects and from the camera etc.

In step which is optional object measurement component transfers this object impact information to a server or other designated location s for further processing. In an embodiment step is performed directly after step such that the object impact information is transferred in real time. Alternatively step is performed in batch mode wherein object impact information is collected for some time period and then transferred to the server.

Steps and that is the operation of the object measurement component are further described below in Section V.C.

In an alternative embodiment instead of or in addition to tracking pre identified objects object measurement component tracks and measures objects that satisfy pre determined rules and or criteria where such rules and or criteria may be stored in staging environment information database . In this embodiment and as mentioned above an administrator inserts into staging environment information database such rules and or criteria. Thereafter in run time environment object measurement component determines whether objects referenced in intercepted function calls satisfy the rules and or criteria. If the rules and or criteria are satisfied then object measurement component tracks and measures such objects as the application executes in run time environment . This alternative embodiment is also further described below in Section V.C.

Flowchart in represents the operation of object tagging component as it identifies objects of interest and as it tags such objects of interest. In other words flowchart shows in greater detail the operation of object tagging component as it performs steps and of .

Flowchart essentially describes the processing steps carried out by object tagging component with respect to the handling of a single graphics or audio function call generated by a single software application. Persons skilled in the relevant art s will readily appreciate that a software application will likely generate numerous such function calls and thus that the method of flowchart would likely be carried out numerous times during execution of the software application. The method will now be described in part with continued reference to certain software components illustrated in and described above in reference to that figure. However persons skilled in the relevant art s will appreciate that the method of flowchart is not limited to that implementation.

In step object tagging component reviews each object referenced in a function call directed to low level graphics audio functions . This function call was generated by application in staging environment and was intercepted by interception component in the manner described above. Object tagging component determines whether the object satisfies tagging criteria.

The tagging criteria define some of the objects that will be tracked and measured. In an embodiment the tagging criteria are pre defined by users and accordingly the tagging criteria are implementation and application dependent. The tagging criteria may pertain to any object properties and may pertain to a single property or a combination of properties. For example the tagging criteria may specify the minimum size object that will be tracked and or may specify that only objects of certain shapes and or colors will be tracked. Other tagging criteria will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

If the object satisfies the tagging criteria then in step the object tagging component tags the object. By tagging the object it is meant that the object is somehow marked or otherwise distinguished so that in the future the object can be identified as being an object of interest i.e. as being an object that one wishes to track and measure . There are many ways of tagging the object. For example object tagging component may set a flag or insert other tagging indicia into the object s entry in the staging environment information database see step or may create a new table such as a new hash table and insert information identifying the object such as a CRC of the object into the hash table only tagged objects would be represented in this new table . Additionally in embodiments an opportunity may be provided to augment information on the object such as providing a name or description of the object see step . This can be done manually by an administrator for example and can be part of the process of or can be performed off line.

Returning to step if object tagging component determines that the object does not satisfy the tagging criteria then step is optionally performed. Step is performed only in embodiments that allow manually tagging of objects by users. Accordingly in step object tagging component enables the user to indicate whether or not the object should be tagged. Step can be performed as part of the process of or can be performed off line. If the user indicates that the object should be tagged then step is performed as described above.

The manual tagging of objects in step may be performed for example by allowing the user to interact with the application in a certain way e.g. by a certain key combination . Interception component may intercept such user inputs. In an embodiment the interception component may intercept key strokes that allow the user to 

In certain embodiments step is not performed in which case flowchart is performed entirely automatically by object tagging component . In other embodiments tagging of objects is performed entirely manually. In still other embodiments flowchart is performed automatically with some user interaction in the manner described above. In still other embodiments flowchart is not performed at all and rules are defined to provide criteria for objects to be measured without identifying individual objects.

Referring again to flowchart in it was described above that steps and are performed by object measurement component in run time environment . In an embodiment such operation of object measurement component occurs during step of flowchart in . The steps of flowchart were described above and that description is not repeated here. 

As described above during step business logic applies business rule s that are applicable to the object being processed referred to above as the identified object . In an embodiment such business rules include measurement business rules that when applied cause the object measurement component to determine measure and or collect attribute information on the identified object. As noted above object measurement component may be a separate component in run time environment or may be part of business logic . The operation of this embodiment is represented by flowchart in . Flowchart includes steps and which collectively correspond to steps and . Note that as it relates to measurement in an embodiment step may take the form of a generic question and not just an object identification criteria for example does the object occupy X of the screen Such generic criteria may be retrieved from business rules database or other information sources such as but not limited to staging environment information database .

In step interception component intercepts a call to low level graphics audio functions and in step an object referenced by such intercepted function call is identified in the manner described above.

In step the object measurement component determines whether the identified object is tagged. As explained above if the object is tagged then the object is one that we wish to monitor its progress and measure its attributes. The operation of object measurement component in step depends on how the object tagging component tagged the identified object in step described above . For example object measurement component may 1 check for a flag in the identified object s entry in database or and or 2 determine whether the identified object is represented in a hash table dedicated to tagged objects. The object measurement component may perform one or more of these checks.

In embodiments once an object is identified as an object of interest as described above we can mark it in the run time environment to facilitate keeping track of it as it is being processed by multiple functions and libraries during a certain 3D scene buildup. This can be accomplished for example by inserting tagging indicia into the object itself. Alternatively this can be accomplished by creating a proxy of the object whereby future references to the object are directed to the proxy and inserting tagging indicia into the proxy the proxy would also include a pointer or other reference to the underlying object . Other techniques for tagging objects will be apparent to persons skilled in the relevant art s .

If the identified object is tagged then step is performed. In step the object measurement component performs one or more measurement business rules. Some of these measurement business rules may apply to all objects or all tagged objects while others may be associated with only certain tagged objects. Techniques for associating particular business rules with a given object are described above. As a result of applying such measurement business rules the object measurement component operates to determine the impact of the tagged object by for example determining measuring and or collecting attribute information on the identified object. Application of such measurement business rules may also cause the transfer of such object attribute information to the server or other designated location s in either real time or batch mode or a combination of real time batch mode. Further discussion of step is provided in Section V.D. below.

In an alternative embodiment steps and are not performed during the performance of step . Instead steps and are performed during a separate measurement algorithm process .

This is shown in flowchart in . Flowchart is similar to flowchart in except in flowchart the measurement algorithm process has been added. Most of the steps of flowchart were described above during the description of and that description is not repeated here. It is noted that regarding the measurement embodiment being discussed in some cases no business rules are applied in step . This may occur for example when information is being obtained on objects for the purpose of rating such objects. Measurement algorithm process includes steps and which collectively correspond to steps and . Steps and shall now be described.

In step the object measurement component determines whether the identified object is one that should be measured. As explained above if the object is an object of interest then the object is one that the user wishes to monitor its progress and measure its attributes. The operation of object measurement component in step depends on how the object tagging component tagged the identified object in step described above .

If the identified object is tagged then step is performed. In step the object measurement component determines the impact of the tagged object by for example determining measuring and or collecting attribute information on the tagged object. Also optionally during step object measurement component transfers such object attribute information to the server or other designated location s in either real time or batch mode or a combination of real time batch mode. Further discussion of step is provided in Section V.D. below.

Specifically in step interception component intercepts a call to low level graphics audio functions and in step an object referenced by such intercepted function call is identified in the manner described above.

In step object measurement component determines whether the object satisfies certain pre determined rules or criteria. Such rules and or criteria are described elsewhere herein.

In step if the object satisfies the rules criteria then the object measurement component logs metrics about the object i.e. determines the impact of the object . Such information is stored and may be optionally transferred to a server or other designated component s in real time or in batch mode.

In steps and object measurement component determines the impact of an object being tracked. In an embodiment the operation of object measurement component in performing step or is represented by flowchart in .

Flowchart essentially describes the processing steps carried out by object measurement component with respect to processing an object of interest that was referenced in a graphics or audio function call generated by software application . Persons skilled in the relevant art s will readily appreciate that software application will likely generate numerous such function calls. Also each such function call may reference numerous objects. Thus the method of flowchart would likely be carried out numerous times during execution of the software application . The method will now be described in part with continued reference to certain software components illustrated in and described above in reference to that figure. However persons skilled in the relevant art s will appreciate that the method of flowchart is not limited to that implementation.

In step object measurement component determines whether the object satisfies measurement criteria. As reflected by step in certain embodiments the attributes of an object are measured only in frames wherein the tagged object satisfies measurement criteria. For example it may not be interesting to measure a tagged object in those frames or scenes where its relative size is less than a minimum. The criteria comprise one or more object properties that must be satisfied by the object in a given frame in order for the object to be measured in that frame.

In an embodiment the measurement criteria are pre defined and accordingly the measurement criteria are implementation and application dependent. The measurement criteria may pertain to any object properties and may pertain to a single property or a combination of properties. For example the measurement criteria may be based on object size for example an object less than a certain size will not be measured angle for example only objects within a minimal and maximal angle will be measured collision obfuscation with another object for example an object will not be measured if the collusion area is greater than a maximum hiding or partial hiding by another object for example an object will not be measured if it is hidden by more than a maximum percentage distance from camera for example an object will not be measured if the distance between the object and the viewport is greater than a maximum distance between objects for example an object will not be measured if it is too close to another object and or object display time for example an object will not be measured until it appears in a certain number of consecutive frames . The above is not an exhaustive list. Other measurement criteria will be apparent to persons skilled in the relevant art s based on the teachings contained herein. In one example when a certain object of interest is identified the impact is measured when the object is at a certain size and above. When the impact measurement code identifies that the object is at that size the time will be stored in memory. Once the object disappears or measured as smaller than the minimum size the time passed will be calculated and the time passed will be logged. The criteria to verify may include additional or different attributes than size.

It is noted that step is optional. Some embodiments do not include step in which case attributes of objects of interest are always measured. Alternatively all objects the application is trying to render may also be measured.

The process in includes a particular combination by way of example of measurement criterions that must be satisfied in order for the tagged object to be measured. Such measurement criterions are represented by steps and the substance of which will be apparent to persons skilled in the relevant art s . If all of these criterions are satisfied then in step the object measurement component determines that the measurement criteria is satisfied. Otherwise in step the object measurement component determines that the measurement criteria are not satisfied.

In other embodiments the measurement criteria are based on a different set of object attributes. Also in other embodiments satisfying a subset of the measurement criterions may be sufficient to enable the object measurement component to determine that the criteria is satisfied step . It should also be noted that multiple measurement criteria groups may be defined for each object.

Returning to if the object measurement component determines in step that the tagged object satisfies the measurement criteria then step is performed. In step object measurement component determines measures and or collects attribute information pertaining to the tagged object. Step is further described in Section V.E. below.

In step in an embodiment object measurement component processes the object attribute information from step . For example consider the case where the size of the tagged object is measured and it is of interest to know the number of times the size of the tagged object falls within a first size range a second size range a third size range etc. Such information may be useful in the in game advertising field where advertising royalties are based on exposure of advertisements in scenes rendered by the computer game. In this example object measurement component in step determines which size range the tagged object falls into for the current frame and then increments the counter associated with that size range.

In embodiments the object measurement component may perform similar range calculations with regard to the object s angle the object s distance from camera the distance between objects the object s display time as well as other object properties as will be appreciated by persons skilled in the relevant art s based on the teachings contained herein.

In embodiments step is not performed by object measurement component in run time environment . Instead step is performed at the server and or other designated components remote to run time environment. In other embodiments processing of step is shared between object measurement component and the server and or other designated components remote to run time environment.

In step object measurement component transfers the object attribute information to the server and or other designated components remote to run time environment. As discussed step may be performed in real time or in batch. Object measure component may transfer the raw data from step or the processed data from step or a combination of the raw and processed data.

As described above object measurement component in step determines measures and or collects attribute information pertaining to the tagged object. Embodiments for determining measuring and or collecting such attribute information are described in this section. These embodiments are provided for purposes of illustration and not limitation. Other techniques for determining measuring and or collecting object attribute information will be apparent to persons skilled in the relevant art s .

For illustrative purposes the following description is made with reference to graphical objects. However the invention is not limited to graphics and covers any type of media used in an application such as sound video etc. Determining measuring and or collecting attribute information for other types of objects will be apparent to persons skilled in the relevant art s .

Measurements may be performed between objects for example the distance between objects or the collision between objects or the collusion of one object by the other or on the absolute value of an object for example the size or angle of an object or the distance of the object from the viewport . As will be appreciated such measurements may be made by making calls to low level graphics audio functions . Accordingly the following describes by way of example how the tasks can be accomplished using DirectX. However the invention is not limited to this example embodiment. Determining measuring and or collecting attribute information for objects using other than DirectX function calls will be apparent to persons skilled in the relevant art s .

Other object attribute information may be obtained from the calls intercepted by interception component or via the operating system. Determining object attribute information from these sources as well as other sources will be apparent to persons skilled in the relevant art s .

Note that for all examples illustrated below for measurement such measurement can occur on an every frame basis or based on a periodical e.g. every 10frame to alleviate performance issues. Obviously such periodical measurement has an impact on the granularity of exposure times reported.

Interaction and collision between objects can be measured in many ways. There are more accurate and less accurate methods with associated computation performance issues.

One method is to cross correlate over all polygons that are building the objects and determine if and what properties x y z are related to collisions between the object geometries. This approach requires substantial computational resources.

An alternative method involves bounding the objects within a simpler geometric body such as a box and performing a collision check on only the bounding boxes. In DirectX bounding box calculation is a relatively straightforward process using the D3DXComputeBoundingBox API. The returned position vectors are used as data for the collision detection process. The bounding box collision detection process is simpler than when performed at the polygon or vertex level.

Another alternative approach is to project the 3D representation into 2D space using the DirectX D3DXVec3Project API and then perform the collision detection process in the 2D world.

 In view check determines if an object is located within the viewport. In view check is interesting because some applications render objects that are not visible from the viewport.

Similar to the collision check the in view check can be done in the 3D world or in the 2D world. The in view check can be performed with regard to the frustum and or the viewport. The in view check returns outside inside or intersection. Like the collision check the 3D in view check can be done using the bounding box approach or by projecting the 3D representation into 2D space.

An example approach uses the DirectX ProcessVertices API and or D3DXVec3Project API to project the vertices from 3D to 2D. Then the projected vertices are examined to determine whether the object is inside or outside the viewport.

Distance can be calculated from cameras or between objects. Distance units are relative to the game but can be normalized to enable comparisons between games.

Distance is calculated by measuring the length between the center of the object geometry and the camera position. Alternatively distance is calculated between the centers of object geometries. In DirectX this measurement can be performed using the sqrt function on the sum of dx dy dZ.

A special case is where the tagged object is being reflected by a mirror or lake or another reflecting body and the real distance to the object is not the distance to the mirror. In such cases there is a need to take into account the existence of a render target. If there is a render target for the tagged object then the distance is calculated with regard to that render target.

All elements that are displayed in the viewport have size. In an embodiment an object s size is measured by projecting the 3D representation of the object into 2D space. Then the 2D projected size within the viewport is calculated.

Alternatively the bounding box approach can be used. Specifically the object s size is measured by projecting the 3D bounding box instead of the object itself. The 2D size calculations are then performed on the projected 2D bounding box. This approach is less accurate but is also less computationally demanding.

Projection from 3D to 2D in DirectX can be done by using the ProcessVertices and D3DXVec3Project APIs.

After projecting the bounding box points from 3D to 2D the bounding box of the projected 2D points is again calculated. Then the area of this bounding box is calculated as the percentage from the total viewport size.

In the 3D world objects have a z axis value that can be covered or partially hidden by other objects.

In order to determine the displayed area of an object there is a need to deduct those areas of the object that are being hidden by other non transparent objects. In the case of objects that are partially transparent the decision whether to deduct the covered area or not is based on the threshold levels of the transparency properties. Such properties include but are not limited to alpha channel value blending function and drawing order.

In order to measure an object s covered area all objects that might have a cover potential are identified. Next the cover contribution of each of these objects is calculated.

An object has cover potential if 1 the object collides to some extent with the tagged object 2 the object is closer to the viewpoint camera than the tagged object and 3 the object is not transparent.

The covered area is measured by projecting both the object with cover potential and the tagged object from 3D to 2D. Then the area that is common to both objects is calculated.

An alternative approach is to operate as just described but with bounding boxes instead of the actual object geometries. This approach is less accurate but also less computationally demanding.

Another alternative approach is to use the z buffer mechanism built into DirectX and the graphics card. When detecting an object of interest one may check the z buffer before and after applying the object. The differences in the z buffer depth map provide us with the contour of the 2D application of the 3D object. That 2D application can be compared to the rendering of the object on a clean z buffer to determine if it is hidden by objects that were previously rendered and to what extent. At the end of the scene creation the z buffer may be checked again in reference to the area previously identified as corresponding to the 2D application of the object of interest. If any of those pixels in the end of scene depth map have changed from the object was rendered it means that the object may have been further hidden by other objects.

In an embodiment the angle between objects or the angle between an object and the camera is treated as the angle between the objects normal vectors.

An example method of determining the angle in which the object is being displayed involves calculating the face normal of the bounding box using a cross product function D3DXVec3Cross . Then a dot product function D3DXVec3Dot where the input is the three plane vertices is executed between the camera look at vector and the bounding box normal.

The result of this operation is the angle between the camera look at vector and the bounding box normal. In an embodiment the face normal is transformed with the world matrix using the DirectX D3DXVec3TransformNormal API before this angle is calculated.

This section describes an example embodiment for measuring exposure of an object using DirectX also see for example the process in . This example is provided for purposes of illustration and not limitation. The DirectX functions mentioned herein are well known and are described in numerous places such as but not limited to http msdn.microsoft.com.

When the game calls those functions the hooked functions are called instead. The hooked functions may eventually forward the calls to the original function depending on the business rules .

 1 First check if this texture is a texture of interest by checking the database of tagged objects from the staging environment or objects that satisfy certain criteria as described above . An object that was marked of interest previously may contain that knowledge already in its private data to be retrieved by using GetPrivateData.

 3 Verify that the texture has geometry data. Geometry data helps calculate measurements and should be created at least one time for the texture lifetime. Once calculated it can be save. In one example it can be saved in the texture private data.

 4 If the texture private data does not hold the geometry data calculate the following and store it in the private data 

The information collected above can be calculated per texture per frame and is used by the measurements logic in order to calculate the total exposure of textures inside an application.

VI. Dynamically Serving Advertisements in an Executing Computer Game Based on The Entity Having Jurisdiction Over the Advertising Space in the Game

Embodiments of the invention provide the functionality of applying business rules and more specifically dynamically serving advertisements to games as they execute in computers. In embodiments such application of business rules such as serving of advertisements to executing games is based on the entity or entities having advertising jurisdiction over such games. This is required to support cases for example where one would want to serve advertisements from different entities based on the geographical location of the user or other such information.

This functionality is enabled in games that do not natively have this functionality i.e. the source code and binaries of the games do not provide this functionality . The invention provides this functionality without requiring changes to the original source code or binaries of the games.

Generally speaking this functionality is achieved by identifying and tracking particular games herein called games of interest for reference purposes that are executing in computer s using methods and techniques similar to those described above and further described in this section . Information is collected about such executing games of interest. Such information may include but is not limited to the IP address of the computer the geographical location of the computer the operating system s regional settings whether or not the game is a retail copy whether or not the game is a digitally distributed copy whether or not the game is a demonstration copy whether or not the game is a trial version and or whether or not the game is a pirated copy. Such information is used to serve advertisements to the game.

Accordingly the invention enables dynamic in game advertising for games that are already in the field. Also for yet to be released games the invention enables in game advertising without the need in these games of code dedicated to this feature.

While the invention is described in terms of games it should be understood that the invention is not limited to this example embodiment. The invention is applicable to any computer application where it would be of value or otherwise desired to dynamically serve advertisements or to apply business rules to manipulate the output of the application to the screen.

Also while the invention is described herein in terms of advertisements it should be understood that the invention is not limited to this example embodiment. The scope of the invention includes the serving of any information or messages to executing computer applications.

According to embodiments of the invention advertisements are dynamically served to advertising space in executing computer games. Such advertising space may correspond to any aspect feature or element of an executing computer game. For example in embodiments advertising space may correspond to or be associated with objects in scenes rendered by computer games. For example suppose a computer game renders a scene that includes a billboard a car and a television. The invention may display a first advertisement on the billboard and a second advertisement on the hood of the car where the first and second advertisements are images. The invention may also display a third advertisement in the television where the third advertisement is a video clip. The invention may also serve a fourth advertisement as the car drives by where the fourth advertisement is an audio clip.

As should be apparent by this example the advertisements served by the invention may be in any form such as but not limited to graphics sound and video.

The invention shall now be described in greater detail with reference to wherein flowchart represents an exemplary embodiment of dynamically serving advertisements to an executing computer game. Flowchart will now be described in part with continued reference to certain software components illustrated in and described above in reference to that figure. However persons skilled in the relevant art s will appreciate that the method of flowchart is not limited to that example implementation.

In step the interception component identifies a game of interest executing in run time environment . A game of interest is any game or other application to which advertisements or other information or messages is desired to be served. illustrates an example embodiment for performing step . First interception component monitors all new processes launched in run time environment step in . For example interception component may monitor CreateProcess function calls. Second interception component determines whether the new process is a game of interest step . This can be done for example by performing a hash of the executable binary of the new process and comparing that hash to those in a games of interest database .

The games of interest database includes the hash or other information identifying games of interest. The games of interest database is similar to and may be part of staging environment information database . In an embodiment games of interest database is populated by any known means prior to performance of flowchart .

In an alternative embodiment interception component performs step by identifying all processes currently executing in run time environment . This can be achieved for example by appropriate inquiries to the operating system as will be apparent to persons skilled in the relevant art s . Then interception component determines whether each process is a game of interest. This can be done for example by performing a hash of the executable binary of each process and comparing that hash to those in the games of interest database . The processing of this alternative embodiment may be performed periodically by interception component and or may be performed in combination with the processing of the embodiment in .

Referring again to in step the interception component collects information about the game of interest from one or more sources. Such information may include but is not limited to the IP address of the computer the geographical location of the computer the operating system s regional settings whether or not the game is a retail copy whether or not the game is a digitally distributed copy whether or not the game is a demonstration copy whether or not the game is a trial version and or whether or not the game is a pirated copy. Collection and determination of such information shall now be described in greater detail.

The IP address can be obtained by querying the operating system of the computer i.e. run time environment in which the game is executing according to well known methods. Once the IP address is known there are a number of well known methods to determine the geographical location of the computer. It is useful to know the geographical location of the computer when serving advertisements. For example some advertisements are applicable and or appropriate for some locations but not for others.

Also it may be useful to know the geographical location of the computer to determine the identity of the advertisement serving organization having jurisdiction over the advertising space of the game as further described below.

The regional settings can be determined by querying the operating system of the computer in which the game is executing according to well known methods. It is useful to know the regional settings of the computer when serving advertisements. For example the regional settings may indicate the end user s language and accordingly advertisements in the end user s language can be served. Also it may be useful to know the regional settings of the computer to determine the identity of the advertisement serving organization having jurisdiction over the advertising space of the game.

There are many well known methods and techniques for determining whether the game is a retail copy a digitally distributed copy a demonstration copy a trial version and or a pirated copy. One approach involves querying the game itself. Such querying may produce the version of the game for example. Another approach includes keeping a database or other repository of all executables of interest of the game this information may be maintained in the games of interest database for example . In this manner for example a hash of the executable of the game executing in the computer can be compared to the hashes of the corresponding retail version digitally distributed version demonstration version trial version etc. of the game.

Alternatively information in the registry of the computer may indicate the nature of the game being executed. For example if the game is a trial version then the registry may include information indicating the date the trial expires.

Pirated copies can be detected by determining whether there are any variations or deviations in the executable of the executing game from its known state. Such variations or deviations may indicate cracks in the game that were introduced when the game was hacked which would thereby indicate that the game is a pirated copy. For example such cracks will result in a different hash of the game executable or other file of the game.

Other parameters that can be used in order to identify the application and its type can be any combination of the following Application executable data e.g. version number and or other application file CRC file size linker date retrieved from the executable PE header module name any attribute of the file version information registry entries installed by the application and more as will be appreciated by persons skilled in the relevant art s . In general any attribute related to the application can be used in order to identify it or its variations and any environment parameter OS regional settings OS language IP geographic location etc. can be used in order to identify the environment where the application is running. Any set of combinations using AND OR or other rules can be used in order to identify the application. As well some parameters may be mandatory and some may be optional. Any combination of these and other parameters can be used in order to better target the ads inside the game and in order to collect information about the running application.

Another way to identify a target application is by using an interface where the application can store information identifying the application in a shared storage registry or file for example and the software will identify the application based on this information. Alternatively there may be an API between the application and the software so the information can be provided at run time.

In step advertisements are dynamically served to advertising space in the game based on the information collected in step . Step may be performed by interception component or some other entity in run time environment such as advertisement serving module . In embodiments performance of step includes interaction with remote server s and or other remote entity entities as will be described in greater detail below.

In embodiments step involves serving advertisements based on the entity or entities having jurisdiction over the advertising space in the game. For purposes of reference and not limitation the entity or entities having jurisdiction over the game s advertising space is herein called the ad serving organization. Such jurisdiction over the advertising space in the game may be established for example by who owns the game who distributes the game who sells the game to end users and or via agreements or contracts for such advertising space or by other means and business arrangements captured in the ad serving organization database .

The ad serving organization database may be located locally in run time environment or remotely at a remote server or other remote entity in which case the advertisement serving module would access or query the ad serving organization database at such remote server entity . In an embodiment the ad serving organization database is populated by any known means prior to performance of step .

In step advertisements are served to the advertising space in the game wherein the content frequency and or other characteristics of such advertisement serving is determined by or otherwise associated with the ad serving organization. In essence since the ad serving organization has jurisdiction over the advertising space in the game the ad serving organization can dictate which advertisements to serve to the game the frequency of serving advertisements to the game where to serve advertisements when to serve advertisements how to measure ad impression etc.

In embodiments the frequency of serving advertisements varies depending on whether the game is the retail version or is a demo or trial version or is a pirated version. In an embodiment the frequency of serving advertisements to retail versions is less than that to demo and trial versions which is less than that to pirated versions.

Also the selection and content of the advertisements may vary depending on whether the game is the retail version or is a demo or trial version or is a pirated version. Also the selection and content of the advertisements may differ depending on the geographical location of the executing computer since advertisements that are applicable and appropriate for some geographical regions may not apply or may be inappropriate for other geographical regions.

The operation of step is shown in greater detail in . includes operational branch which represents real time interaction with the ad serving organization and operational branch which represents cached or non real time interaction with the ad serving organization.

Operational branch shall first be described. In step advertisement serving module provides the information collected in step to the ad serving organization. The ad serving organization determines the content frequency and or other characteristics of advertisements to serve to the advertising space in the game based on this collected information and or based on other criteria which may be specific to the particular ad serving organization.

In step advertisement serving module receives from the ad serving organization the advertisements to serve to the advertising space of the game. In an embodiment this is done by means of creating business rules as described above. The ad serving organization in determination of the above mentioned advertising information may consult business rules database which may hold relevant information. Such information may then be delivered to the end user machine to be subsequently used in step as part of business logic . Additionally advertisement serving module may receive instructions or other information related to advertisement serving. For example advertisement serving module may receive one or more pointers to rules in business rules database wherein such rules when processed result in particular advertisements being served to the game. Alternatively advertisement serving module may receive one or more pointers to advertisements in a local advertisement database . The local advertisement database is located in run time environment and will be further described below.

In step advertisement serving module may optionally receive other instructions from the ad serving organization such as instructions on how frequently it should serve advertisements to the game instructions that identify the advertising spaces to serve the advertisements instructions on when advertisements should be served instructions on attributes of the advertisements for example the playback speed of a video clip the sound level of an audio clip the transparency of a graphic etc. and or other instructions the nature of which will be apparent to persons skilled in the relevant art s .

In step advertisement serving module serves advertisements to the advertising space in the game based on the advertisements instructions and or information it received in steps and .

Operational branch shall now be described. Prior to performance of step it is assumed that the ad serving organization has directly or indirectly stored advertisements and or instructions related to advertisement serving in local advertisement database . As noted above local advertisement database is located in run time environment . In step advertisement serving module accesses local advertisement database for advertisements to serve to the game based on the information collected in step . For example advertisement serving module may retrieve certain advertisements if the game is the retail version and other advertisements if the game is a pirated version. In embodiments such logic may have been provided by the ad serving organization prior to performance of step . For example such logic may be embedded in one or more business rules associated with the game and or the ad serving organization and advertisement serving module may perform step by executing such business rules.

In step advertisement serving module serves advertisements to the game based on the results of step .

In embodiments branch is performed for some ad serving organizations and branch is performed for other ad serving organizations. Also branches and may be performed for the same ad serving organization depending on the circumstances. For example branch may be performed when run time environment is in communication with the applicable ad serving organization and branch is performed when run time environment is not in communication with the applicable ad serving organization.

VII. Identifying Selecting and Extracting Graphical and Media Objects in Frames or Scenes Rendered by a Software Application

When providing in game advertising based on the teachings contained herein it is desired to perform a pre production process on the game in order to identify spots in the game where it would be desirable to place advertising or to condition the appearance of advertising based on some characteristic of the designated location object or spot. Accordingly the invention includes embodiments for identifying spots in a computer game to place advertising without having to change and recompile or even have access to the original code of the computer game. Such pre production embodiments are described in this section.

It should be understood that while such embodiments are described herein with respect to computer games and advertising the invention is not limited to these particular examples. The invention is applicable to any computer application and any type of message and or information as further discussed herein. For example the spots identified by the pre production process can be associated with any business rule s not just those related to advertising.

According to embodiments the invention analyzes the structure of a game in run time and provides tools for human operators including non technical operators to identify spots within the game. More particularly using the techniques described herein such as hooking the invention identifies when an object graphic sound video etc. is used inside an executing computer game. The invention identifies such objects and then allows operators to select any of those objects for future use and or reference. Alternatively the invention may log all objects into a database including sufficient information about each such logged object and allow a human operator to later select the objects that are of interest. These selected objects may be associated with business rules to perform any number of functions as described elsewhere herein.

The invention shall now be described in greater detail with reference to an example flowchart in . In an embodiment the steps of flowchart are performed by an encoding or pre production module shown in . In an embodiment encoding module operates in staging environment and depending on the function it is performing at any given time may correspond to interception component or indexing component or both.

Flowchart begins with step wherein encoding module identifies objects in the frame or scene being built and or rendered by application . For reference purposes such frame or scene is called the current frame. However reference to a single frame is provided solely for illustrative purposes and is not limiting. According to embodiments of the invention and from a technical point of view a frame does not necessarily correlate to a single rendered frame on the screen as such frames may be rendered up to 60 times per second. Current Frame in its meaning here relate to a conceptual scene displayed on the screen which typically correlates to one or more technical frames scenes. As described above the application builds renders the current frame by making function calls to low level graphics audio functions . As shown in encoding module performs step by intercepting function calls to low level graphics audio functions step and identifying objects referenced by such intercepted function calls step in the manner described herein. Note that not necessarily all objects are being identified during this state and there may be some logic to allow identifying only a subset of the objects in the current frame. Encoding module identifies the identified objects using any of the techniques described herein as well as others well known to persons skilled in the relevant art s step .

In step a human operator or user is allowed to browse through objects in the current frame. In an embodiment the user navigates through the objects in the current frame by using the Tab Page Up Page Down arrow keys mouse and or any other well known navigation input method. In an embodiment this navigation is performed while the actual application is running allowing the user to traverse the different identified objects currently on display in the current frame. Encoding module hooks input devices such as the keyboard the mouse the touch screen etc. using well known methods to identify such user action. Such hooking is required to override the application game interpretation of the relevant key strokes and mouse movement and add the augmented traversal tagging human interaction flow described herein. In an embodiment the user is allowed to browse through all of the objects identified in step . In other embodiments the user is allowed to browse through only those objects identified in step that satisfy some criteria such as the size of the selected object the angle of the selected object the distance of the selected object from the viewport the amount to which the selected object is covered by another object or any other criteria described herein.

As the user navigates through the objects in the current frame the current object is highlighted on the display in some manner. For example a box may be drawn around the current object the current object may be shaded a certain color the current object may be caused to blink etc. Encoding module keeps track of the current object and when intercepting calls to render it to the screen performs the additional highlighting just mentioned.

In step encoding module determines if the user has selected an object in the current frame. The user can select an object by performing a specified action while the object is highlighted where such specified action may be pressing the Enter key double clicking the mouse touching the touch screen or any other well known selection technique. If the user does not select any objects in the current frame then control returns to step to enable the application to render the next frame.

If instead the user selects an object in the current frame then step is performed. In step encoding module automatically gathers information on the selected object. As will be appreciated by persons skilled in the relevant art s such information is readily available and or obtainable from a number of sources including but not limited to 1 the operating system 2 by making function calls to low level graphics audio functions 3 by retrieving information from the intercepted function calls etc. Such information may include any combination of the following 

Step is an optional step and may be performed in real time or off line. In step the user is allowed to provide additional information on the selected object and or to edit the information obtained in step . Such additional information may include for example a name and description of the selected object. As represented by step in the user may review and edit the information on a plurality of objects akin to a batch mode of operation.

In step encoding module stores the information on the selected object in a database such as the staging environment information database .

Following operation of step control returns to step to enable the user to browse through other objects in the current frame.

Note that objects may persist between multiple frames and the system allows the selection and navigation to persist between frames.

An alternative embodiment of the invention is shown in the example flowchart of . In this alternative embodiment information on objects is gathered and temporarily stored after such objects are identified in the current frame instead of after the objects are selected by users as was the case with the embodiment of . Such temporary storage is represented by a current frame database shown in . In an embodiment the current frame database is located in staging environment and is reconstructed on a frame by frame basis When a user selects an object the information on the selected object is transferred from the current frame database to the staging environment information database . Flowchart shall now be described in detail.

In step encoding module identifies objects in the current frame being built and or rendered by application . The operation of step is similar to step described above.

In step encoding module automatically gathers information on the objects identified in step . Such operation of step is similar to step .

In step the user is allowed to browse through objects in the current frame. Step is similar to step .

In step encoding module determines if the user has selected an object in the current frame. Step is similar to step .

If the user selected an object in step then step is performed. Step is an optional step and may be performed in real time or off line. In step the user is allowed to provide additional information on the selected object and or to edit the information on the selected object that is stored in the current frame database . As represented by step in the user may review and edit the information on a plurality of objects akin to a batch mode of operation.

In step encoding module stores the information on the selected object in the staging environment information database . The information stored includes the information on the selected object contained in the current frame database as well as any information entered in step .

Following operation of step control returns to step to enable the user to browse through other objects in the current frame.

Flowchart begins with step wherein encoding module intercepts a function call to low level graphics audio functions that is made by application in the manner described above.

In step encoding module gathers information on an object referenced by the intercepted function call. The operation of step is similar to step described above.

In step encoding module stores the information gathered in step in staging environment information database .

Steps and are performed for all of the objects referenced in the intercepted function call. Such iterative operation is represented by step .

It is noted that flowchart essentially illustrates the processing steps carried out by encoding module with respect to the handling of a single graphics or audio function call to low level graphics audio functions generated by the application . Persons skilled in the relevant art s will readily appreciate that application will generate numerous such function calls and thus that the method of flowchart will be carried out numerous times during execution of application .

In an embodiment the steps of flowchart are performed only upon satisfaction of certain conditions such operation is represented by step in . Such conditions may be the start of the game the start of a particular point of the game X minutes after start of the game where X is pre defined or user provided upon certain user input or instruction etc. In a similar way in certain embodiments operation of flowchart ends after satisfaction of certain conditions which may include end of the game end of a particular point of the game Y minutes after start of the game where Y is pre defined or user provided upon certain user input or instruction etc. Accordingly in such embodiments objects are logged only during certain portions of the game.

In an embodiment users are allowed to edit the object information stored in staging environment information database . Such operation is represented by step in .

An alternative embodiment of the invention is shown in example flowchart in . Flowchart represents an embodiment where information is stored only for objects that satisfy certain conditions.

Flowchart begins with step wherein encoding module intercepts a function call to low level graphics audio functions that is made by application in the manner described above.

In step encoding module determines whether an object referenced by the intercepted function call satisfies certain criteria. Generally such criteria defines the types of objects that are desirable for the later placement of advertisements. The nature of such criteria is implementation dependent. Examples include but are not limited to the size of the selected object the angle of the selected object the distance of the selected object from the viewport the amount to which the selected object is covered by another object or any other criteria described herein.

If the object does not satisfy the criteria then encoding module begins processing another object referenced by the intercepted function call as represented by step . If the object satisfies the criteria then step is performed.

In step encoding module gathers information on the object. The operation of step is similar to step described above.

In step encoding module stores the information gathered in step in staging environment information database . After step is performed encoding module begins processing another object referenced by the intercepted function call as represented by step .

It is noted that flowchart essentially illustrates the processing steps carried out by encoding module with respect to the handling of a single graphics or audio function call to low level graphics audio functions generated by the application . Persons skilled in the relevant art s will readily appreciate that application will generate numerous such function calls and thus that the method of flowchart will be carried out numerous times during execution of application .

In an embodiment the steps of flowchart are performed only upon satisfaction of certain conditions such operation is represented by step in . Such conditions may be the start of the game the start of a particular point of the game X minutes after start of the game where X is pre defined or user provided upon certain user input or instruction etc. In a similar way in certain embodiments performance of the steps of flowchart end after satisfaction of certain conditions which may include end of the game end of a particular point of the game Y minutes after start of the game where Y is pre defined or user provided upon certain user input or instruction etc. Accordingly in such embodiments objects are logged for only certain portions of the game.

In an embodiment users are allowed to edit the object information stored in staging environment information database . Such operation is represented by step in .

As shown in example computer system includes a processor for executing software routines. Although a single processor is shown for the sake of clarity computer system may also comprise a multi processor system. Processor is connected to a communication infrastructure for communication with other components of computer system . Communication infrastructure may comprise for example a communications bus cross bar or network.

Computer system further includes a main memory such as a random access memory RAM and a secondary memory . Secondary memory may include for example a hard disk drive and or a removable storage drive which may comprise a floppy disk drive a magnetic tape drive an optical disk drive or the like. Removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit may comprise a floppy disk magnetic tape optical disk or the like which is read by and written to by removable storage drive . As will be appreciated by persons skilled in the relevant art s removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

In an alternative implementation secondary memory may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means can include for example a removable storage unit and an interface . Examples of a removable storage unit and interface include a program cartridge and cartridge interface such as that found in video game console devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system .

Computer system also includes at least one communication interface . Communication interface allows software and data to be transferred between computer system and external devices via a communication path . In particular communication interface permits data to be transferred between computer system and a data communication network such as a public data or private data communication network. Examples of communication interface can include a modem a network interface such as Ethernet card a communication port and the like. Software and data transferred via communication interface are in the form of signals which can be electronic electromagnetic optical or other signals capable of being received by communication interface . These signals are provided to the communication interface via communication path .

As shown in computer system further includes a display interface which performs operations for rendering images to an associated display and an audio interface for performing operations for playing audio content via associated speaker s .

As used herein the term computer program product may refer in part to removable storage unit removable storage unit a hard disk installed in hard disk drive or a carrier wave carrying software over communication path wireless link or cable to communication interface . A computer useable medium can include magnetic media optical media or other recordable media or media that transmits a carrier wave or other signal. These computer program products are means for providing software to computer system .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs can also be received via communication interface . Such computer programs when executed enable the computer system to perform one or more features of the present invention as discussed herein. In particular the computer programs when executed enable the processor to perform features of the present invention. Accordingly such computer programs represent controllers of the computer system .

Software for implementing the present invention may be stored in a computer program product and loaded into computer system using removable storage drive hard disk drive or interface . Alternatively the computer program product may be downloaded to computer system over communications path . The software when executed by the processor causes the processor to perform functions of the invention as described herein.

While various embodiments of the present invention have been described above it should be understood that they have been presented by way of example only and not limitation. It will be understood by those skilled in the relevant art s that various changes in form and details may be made therein without departing from the spirit and scope of the invention as defined in the appended claims. Accordingly the breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

