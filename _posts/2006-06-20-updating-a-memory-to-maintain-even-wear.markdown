---

title: Updating a memory to maintain even wear
abstract: A memory leveling system updates physical memory blocks, or blocks, to maintain generally even wear. The system maintains an update count for each block, incrementing a wear level count when the update count reaches a wear level threshold. The system compares a wear level of blocks to determine whether to update a block in place or move data on the block to a less-worn physical block. The system groups the blocks into wear level groups identified by a common wear level to identify blocks that are being worn at a faster or slower than average rate. If an empty block count of a least worn group drops below a threshold, the system moves data from one of the blocks in the least worn group to an empty block in a most worn group.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08060718&OS=08060718&RS=08060718
owner: International Business Machines
number: 08060718
owner_city: Armonk
owner_country: US
publication_date: 20060620
---
 This invention was made with Government support under Agreement No. NBCH30390004 awarded by DARPA. The Government has certain rights in the invention. 

The present invention generally relates to addressable memories and in particular to storage class memories with a finite allowable number of writes to the memory before the memory wears out. The present invention further relates to a method of updating a memory to level wear on the memory maximizing the life of the memory.

Storage Class Memories SCM are nonvolatile storage technologies using low cost materials such as chalcogenides perovskites phase change materials or magnetic bubble technologies. Storage class memories exhibit DRAM like performance at lower cost than DRAM. The extrapolated cost over time can be equivalent to or less than that of enterprise class disk drives. The cost performance of the storage class memories provides a level in the storage hierarchy between the DRAM main system memory and disk storage. This level of storage may be viewed as a very large disk cache in which data can be stored permanently due to the nonvolatile characteristics of storage class memories.

Many storage class memory technologies are physical block addressed i.e. unlike DRAM a block of data is read or written. The physical block sizes typically range from 512 bytes to 4K bytes. Hence storage class memory is suitable as a replacement for block access disk drives.

However unlike DRAM and disk drives storage class memory technologies provide a finite number of write cycles. Flash memories also exhibit this characteristic. While flash memories provide 10to 10write cycles storage class memory technologies support 10to 10write cycles. To optimize the life of a storage device data are written so that the storage medium is used in a uniform manner even if the write accesses are skewed to use a small set of addresses. The physical device space is divided into physical blocks that are written and read. The number of write cycles is tracked for each physical block so that when a physical block is updated the data in the physical block further referenced as a block of data or data may be written to another physical block with lower wear. Distributing the written block of data to level the write operations prevents the loss of the device due to wear in a subset of physical block address that has frequent updates.

Flash memories use algorithms and file management structures to level the wear in the device. These differ from the storage class memory technologies in that flash memories require data be written into a physical block that has been erased. The erase process takes significant time compared to the read and write cycle time. Flash memories are organized with erase zones containing multiple physical blocks to enable the erasing of a number of physical blocks in parallel so that physical blocks are available for updating physical blocks of data. Thus in a flash memory the data moves with each update. Journal file structures have been used for wear leveling tracking the wear level for each physical block is not required since all physical blocks are uniformly written. While providing even wear many journal file mechanisms move a significant portion of the data and are actually a major cause of wear. Further a time delay of milliseconds may be required to erase the physical blocks prior to updating. While useful for current applications this time delay is unacceptable for most system memory applications.

In contrast to memory management of flash memories storage class memory technologies provide an update in place capability so data need not be moved for update. A conventional wear leveling mechanism used by storage class memory technologies prolongs the life of the storage class memory device and requires additional data structures and overhead in accessing the physical blocks compared to direct physical block addressing.

A conventional wear leveling mechanism comprises an address translation system and a method for tracking physical block wear and for identifying physical blocks with low usage. Although this technology has proven to be useful it would be desirable to present additional improvements.

The address translation system uses an address to access a block of data stored in a physical block of memory the address translation system expects that the address used to access the data is constant independent of the physical block in which the data is stored. The storage class memory device provides a mapping of the system address for a block of data to the physical location of the physical block. When a block of data is accessed the address translation identifies the physical block. For rapid address translation an index structure or hash tables may be constructed. When a block of data is written to another physical block location the map is changed to reflect the address of the newly written physical block. For a hashed or indexed translation table the hash tables or indices are also changed. However changing location of the data to another physical block requires address translation updating overhead.

A file system may provide the address translation in this case the file system directories are updated when a block of data is written in a physical block of lower wear rather than the original physical block for the data.

Conventional storage class memory systems comprise a method for tracking wear of a physical block such that the number of write cycles for each physical block is tracked. For each write operation that requires the data to be moved for even wear a physical block with a low wear level is identified and used.

One conventional mechanism for identification of empty physical blocks with low wear is an ordered list of physical blocks. The physical block at the end of the list has the lowest wear level. When the physical block with lowest wear is used the wear level is incremented and the physical block is removed from the list. When the physical block is updated the data in the physical block is moved to the physical block with least wear and the previously used physical block is inserted into the empty physical block list to maintain the ordered list. This conventional approach is useful for small devices. However large devices pose a significant problem in maintaining the ordered list. For a device of 10 million physical blocks the list requires a double linked list in which each link can address 10 million elements. An index structure can be defined for ease of insertion the index can point to the boundaries between physical blocks with the same count. However the number of wear level values can be very large since these technologies provide 10to 10write cycles.

Conventional storage class memory systems further comprise a method for identifying physical blocks with low usage. Some of the physical blocks are written infrequently or contain read only data. These physical blocks have very low wear levels compared to physical blocks that have an average number of updates. If the percentage of physical blocks with infrequent write activity is low having physical blocks with low usage does not affect the maximum lifetime of the storage class memory. However if the percentage of physical blocks with infrequent write activity is significant the remaining physical blocks experience significant wear compared to the physical blocks with infrequent write activity. For example if 33 of the physical blocks in a storage class memory device are physical blocks with infrequent write activity then the other 66 of the storage class memory device experiences 150 of the wear. Consequently the life of the storage class memory device is 66 of a similar storage class memory device with even wear on most of the physical blocks.

What is therefore needed is a system a computer program product and an associated method for updating a memory to maintain even wear. A system is further needed to minimize overhead by minimizing a frequency of physical block moves and address table updates required to level wear on the memory. The need for such a solution has heretofore remained unsatisfied.

The present invention satisfies this need and presents a system a service a computer program product and an associated method collectively referred to herein as the system or the present system of updating a memory that includes physical memory blocks to maintain generally even wear across the physical blocks.

The present system maintains an update count for each physical memory block. When the update count reaches a predetermined wear level threshold the present system increments a wear level for the physical memory block. The present system further compares a current wear level of the physical memory block to current wear levels of other physical memory blocks to determine whether to update the physical memory block in place or move data on the physical memory block to a less worn physical memory block to provide even wear on the physical memory blocks. Updating the memory comprises editing deleting or otherwise changing portions of the data on the selected physical memory block. The update count represents a count of data writing events addressed each of to the physical memory blocks. Updating in place comprises updating to the physical memory block in which the data to be updated resides.

The present system groups the physical memory blocks into a plurality of wear level groups each of the wear level groups identified by a common wear level to identify physical memory blocks that are being worn at a faster than average rate or slower than average rate. The wear level groups comprise a least worn group with a lowest wear level a least worn group plus one with a wear level equivalent to the least worn group plus one and a least worn group plus two with a wear level equivalent to the least worn group plus two.

Moving the data comprises moving the data to a selected physical memory block that is empty in the least worn group and incrementing the wear level of the selected physical memory block.

The present system maintains an empty block count of empty physical blocks in the least worn group and if the empty block count drops below a predetermined empty block count threshold moving data from at least one of the physical memory blocks in the least worn group to a selected physical memory block that is empty in the least worn group plus two and incrementing the wear level of selected physical block.

The present system utilizes an address table that provides translation from an address memory location to a location of any of the physical memory blocks the address table comprises a listing of at least some of the physical memory blocks. The address table comprises a double linked list to identify one or more of a plurality of empty physical memory blocks and one or more of a plurality of not empty physical blocks. The address table further comprises a value of the wear level for at least some of the physical memory blocks represented in the address table.

In one embodiment the present system identifies an empty physical memory block in which data can be written by scanning the address table to locate a selected physical memory block in the least worn group to receive data from a physical memory block in the least worn group plus two. The present system further identifying an empty physical memory block for receiving data by scanning the address table to locate a selected physical memory block in the least worn group plus two to receive data from a physical memory block in the least worn group.

System can take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In one embodiment system is implemented in software which includes but is not limited to firmware resident software microcode etc.

Furthermore system can take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any apparatus that can contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

The medium can be an electronic magnetic optical electromagnetic infrared or semiconductor system or apparatus or device or a propagation medium. Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD.

The storage class memory comprises a set of physical blocks interchangeably referenced herein as physical memory blocks or blocks in which data is stored the physical blocks are represented in as block block through block N collectively represented as physical blocks interchangeably referenced as blocks . System comprises a wear leveling controller and a wear counter for at least some of the physical blocks . For an associated physical block the wear counter maintains a value of a wear level and a count of the number of updates interchangeably referenced as data writing events of an associated physical block. The host system accesses the storage class memory through a controller .

Controller receives the storage block address from the host system and maps the storage address to the physical block address in the SCM with a storage address to physical block address table. Controller communicates with the wear leveling controller on write operations to update the counters and when required write data to a block with less wear and change the storage address to physical block address table.

One or more of the physical blocks may contain data that is read only or updated infrequently. The background process module provides wear for these low wear physical blocks by moving data in these low wear physical blocks to physical blocks with higher wear. The background process module minimizes a frequency of moving data with low update frequency while still using the physical blocks for data with higher wear characteristics. System minimizes the frequency of moving data with low update frequency by updating data in place until a predetermined threshold is exceeded. In contrast conventional storage class memory technology moves data from one physical block to another physical block at each update.

The block manager utilizes a window of at least three wear level groups to implement wear leveling a current group a current 1 group and a current 2 group collectively referenced as wear level groups . The current group is the least worn group as determined by a wear level of the physical blocks . The current 1 group represents the a least worn group plus one wear level as determined by a wear level of the physical blocks . The current 2 group represents the least worn group plus two wear levels as determined by a wear level of the physical blocks .

The current group comprises a set of zero or more current empty physical block s and a set of zero or more current not empty physical block s . The current 1 group comprises a set of zero or more current 1 empty physical blocks and a set of zero or more current 1 not empty physical blocks . The current 2 group comprises a set of zero or more current 2 empty physical block s and a set of current 2 not empty physical block s .

System does not require that the absolute least worn physical block in the current group be used any of the least worn physical blocks can be selected. Since storage class memory technologies support a large but not infinite number of write cycles the range between wear level groups in number of updates or write cycles can be large. For example for a technology that supports 10write cycles the wear level groups can be spaced approximately 10or 10write cycles apart. The wear characteristics are not precise. For example the difference between 1 134 567 write cycles and 1 687 654 write cycles is difficult to discern when compared to a life of 10write cycles.

Any of the physical blocks may be updated in place for a number of cycles i.e. a predetermined update threshold before moving a data block stored on one of the physical blocks to a less worn physical block. For example system may update in place a data block in block until the low order bits of the wear counter associated with block are all zero. System then increments the higher order bits of the associated wear counter . For instance a wear counter with low order 10 bits at zero indicates that the associated physical block e.g. block was updated 1024 times etc. System may use a higher update threshold for example 15 bits 32K or 2 or 20 bits 1 M or 2 . Increasing the update threshold reduces the address directory updates and the level of garbage collection. Essentially the frequency of overhead operations associated with moving a data block from one of the physical blocks to another of the physical blocks is reduced by the reciprocal of the update threshold.

A current group manager manages the current group . A current 1 group manager manages the current 1 group . A current 2 group manager manages the current 2 group . The current group manager the current 1 group manager and the current 2 group manager are collectively referenced as the group managers .

The current group manager comprises a current empty block counter a current empty block list a current not empty block counter and a current not empty block list . The current 1 group manager comprises a current 1 empty block counter a current 1 empty block list a current 1 not empty block counter and a current 1 not empty block list . The current 2 group manager comprises a current 2 empty block counter a current 2 empty block list a current 2 not empty block counter and a current 2 not empty block list . An address table comprises the current empty block counter current empty block list the current not empty block counter the current not empty block list the current 1 empty block counter the current 1 empty block list the current 1 not empty block counter the current 1 not empty block list the current 2 empty block counter the current 2 empty block list the current 2 not empty block counter and the current 2 not empty block list .

System maintains a tight distribution of high order block counter values by grouping the physical blocks into wear level groups . The current group manager tracks the physical blocks that are least worn and thus are candidate physical blocks to be filled. The current 1 group manager tracks the physical blocks with wear levels in the least worn group plus one. The current 2 group manager tracks the blocks with wear levels in the least worn group plus two. For example the update threshold is 1 M. When physical blocks in the least worn group the current group have a wear level of 125 each of the physical blocks in the current group has been updated 125 1 M times. Consequently the current 1 group has a wear level of 126 126 M updates and the current 2 group has a wear level of 127 127 M updates .

When system selects one of the physical blocks for updating the block update module examines the wear value for the selected physical block as maintained by the wear counter for the selected physical block. If the wear counter comprises all zeros in the lower 20 bits for 1 M update writes per block before moving then the higher order bits are compared with the value of the wear level for the current 1 group i.e. 126 for the previously discussed example. If the wear level of the selected physical block is the same as the wear level of the current 1 group then the selected physical block is updated in place. Updating in place avoids changing the address table and indices. If the value of the high order bits is that of the current 2 group with a wear level of 127 in the previously discussed example then the data in the physical block is moved to any of the current empty blocks in the current group with a wear level of 125 in the previously discussed example .

When the value of the current empty block counter drops below a predetermined empty block threshold near zero data in physical blocks associated with the current group are moved to physical blocks associated with the current 2 group with a wear level of 127 in the previously discussed example . The block manager increments by one the wear counter of the physical blocks to which the data is moved indicating an update in the physical block. This moves the low update activity and read only data as far forward in wear as possible to minimize the number of times this low update activity and read only data is moved. If the data block is not read only or low update frequency the data block is moved to a block in the current group when the data block is updated. A penalty for incorrectly estimating the wear of a physical block is one extra data move and one extra write cycle. If the number of updates in place is 1 M or even as low as 1024 one extra write cycle for an incorrect estimate of wear is insignificant.

When some or all of the physical blocks in the current group are used and assigned to the current 1 group with a wear level of 125 in the previous example the current group is empty. The current 1 group becomes the current group with a wear level of 126 the current 2 group becomes the current 1 group with a wear level of 127 . The wear counter for the physical blocks in the previous current group with a wear level of 125 are zero and used for the current 2 group with a wear level of 128 . At the start of this cycle the current 2 group has no members so the current 2 not empty block counter and the current 2 empty block counter are zero.

Physical blocks assigned to any of the wear level groups are classified as empty physical blocks further referenced as empty blocks or not empty physical blocks further referenced as not empty blocks . Empty blocks may be used for data from more worn physical blocks . As previously described the block manager maintains an empty block counter and a not empty block counter for each of the wear level groups . When the block manager increments the wear counter associated with one of the physical blocks the wear counter is checked to determine whether the associated physical block has to move to the next of the wear level groups . Associated group counters i.e. the current empty block counter the current not empty block counter etc. are updated when any of the physical blocks moves from one of the wear level groups to the next of the wear level groups . The physical block that previously held the moved data is marked as empty or available for update in the current 1 group .

In one embodiment the block manager associates linked lists with each of the wear level groups . One linked list references the empty physical blocks for a specific group in the associated one of the wear level groups that is the data in the empty physical block has been moved to a physical block with less wear. Another linked list references physical blocks in a specific group of the wear level groups with active data. In the linked lists for the current group comprise the current empty block linked list and the current not empty block linked list . The linked lists for the current 1 group comprise the current 1 empty block linked list and the current 1 not empty block linked list . The linked lists for the current 2 group comprise the current 2 empty block linked list and the current 2 not empty block linked list .

Order in the linked lists is not critical since all blocks in a linked list are treated similarly. Any of the empty blocks in the current group the group with lowest wear is used for the next data move. To smooth the workload the block data migration of read only low update usage data can be triggered when the number of available blocks falls below a threshold the data movement can be a background task. If the wear is set so that a block is changed after a large number of write cycles 1024 1 M etc. then the address directory change frequency can be reduced by dividing the update write frequency by this large factor.

Another embodiment does not require linked lists and uses the physical blocks in sequence by scanning through the physical blocks . When an empty physical block has a wear level in the current group the empty physical block may be used for data from a block with higher wear. When the number of available blocks in the current group is below a low level number then not empty physical blocks with a wear level corresponding to the value of the current group are moved to the current 2 group .

The background process module scans physical blocks and moves data in a background task that maintains a list of least worn candidate blocks for the updated physical blocks and most worn candidate blocks for the low update frequency data blocks. The scan need only find a number of candidates and not be exhaustive. As previously described if the wear is set so that a physical block is changed after a large number of write cycles 1024 1 M etc. the address directory change frequency can be reduced by dividing the update write frequency by the large factor. When the count of available physical blocks drops below a target number an address table may be scanned to construct a linked list of available empty physical blocks and a linked list of physical blocks that were in a group when the group was made the least worn group. These lists can be significantly shorter than linked lists of all of the blocks. Physical blocks cannot reduce their wear level so the address table need only be scanned once per group cycle.

In yet another embodiment system can be used in a storage device without extra physical blocks for empty blocks. Data that causes high wear is exchanged with data that causes lower wear to effect wear leveling.

As illustrated in data block A is written to block data block B is written to block data block C is written to block and data block D is written to block . Block block block and block have each experienced one write or update as indicated by the wear level 1 for each of these blocks. The current group the least worn group comprises empty blocks block and block each of which has a wear level 0. The current 1 group the least worn group plus one comprises block block block and block .

As illustrated in and data block C is updated. Since data block C is already associated with the current 1 group and wear level 1 system moves the data block C to any of the physical blocks with a wear level lower than that of block . In this case system moves the data block C to block in the current group . The block manager increments the wear level of block by one wear level 1 . Block is removed from the current group and added to the current 1 group .

As illustrated in and data block C is updated again. Since data block C is associated with the current 1 group and wear level 1 system moves the data block C to any of the blocks with a wear level 0 e.g. block in the current group . The block manager increments the wear level of block by one wear level 1 . Block is removed from the current group and added to the current 1 group .

As illustrated in and data block A is updated. All physical blocks are in the current 1 group . Consequently data block A is updated in place. The block manager increments the wear level of block by one wear level 2 . Block is removed from the current 1 group and added to the current 2 group .

As illustrated in and data block D is updated. No physical blocks are available with a lower wear level than block the physical block in which data block D resides. Consequently data block D is updated in place. The block manager increments the wear level of block by one wear level 2 . Block is removed from the current 1 group and added to the current 2 group .

As illustrated in and data block A is updated. Block is currently in the current 1 group with a wear level 2. The block manager moves the data block A to any of the blocks with a wear level 1 e.g. block . The block manager increments the wear level of block by one wear level 2 . Block is removed from the current 1 group and added to the current 2 group .

As illustrated in and data block C is updated. No physical blocks are available with a lower wear level than block in which data block C resides. Consequently data block C is updated in place. The block manager increments the wear level of block by one wear level 2 . Block is removed from the current 1 group and added to the current 2 group .

As illustrated in and data block C is updated again. The block manager moves the data block C to any of the blocks with a wear level 1 e.g. block . The block manager increments the wear level of block by one wear level 2 . Block is removed from the current 1 group and added to the current 2 group .

As illustrated in and no empty blocks remain in the current 1 group with a wear level 1. In a background task illustrated by the background process module moves the data block B to any of the empty blocks with a wear level 2 in the current 2 group e.g. block . The block manager increments the wear level of block by one wear level 3 . The data blocks with a wear level 1 are placed in the current group . The data blocks with a wear level 2 are placed in the current 1 group . Block is added to the current 2 group .

As illustrated in data block D is updated. The data block D resides in block in current 1 group . The block manager moves the data block D to one of the data blocks in the current group i.e. block . The block manager increments the wear level of block by one wear level 2 . Block is removed from the current group and added to the current 1 group .

The wear counter for each of the physical blocks increments the wear level each time the associated physical block is updated. The wear counter is logically divided into segments a wear level group segment interchangeably referenced herein as a wear level a higher count segment and a lower count segment interchangeably referenced as an update count . The lower count segment counts the number of updates before the block manager makes a block data move decision. The block manager increments the wear level group segment when the lower count segment high order bit carries into the higher count segment when the wear counter is incremented. When the high order bits of the wear level group segment are incremented the block manager makes a block data move decision.

If the incremented wear level of a physical block in the current group is greater than the wear level for the current 1 group the block manager moves the data in the physical block to an empty block with the wear value of the current group. The block manager marks as used the physical block to which the data is moved and the address table is updated to point to the physical block as the address of the data. The previous physical block is marked as empty and added to the current 2 group .

If the incremented block wear level is less than or equal to the wear level of the current 1 group then the data in the block is not moved. Instead the data in the block is updated in place.

When the number of empty blocks with the value of the wear level group segment of the current group drops below a target value the background process module moves the data in blocks that have the wear level of the current group to blocks with the most wear i.e. physical blocks in the current 2 group . The data in these least read blocks are read only or have very low update frequency and are moved to maintain consistent wear level over some or all of the physical blocks . Data in these least read blocks are moved to physical blocks with high wear to minimize the frequency of moving data blocks exhibiting low update frequency. When the data are moved the background process module adds the physical blocks to which the data are moved to the current 2 group and marks as empty the physical blocks from which the data is moved. These newly emptied physical blocks have wear levels of the current group and are now available for use.

When the low update activity blocks have been moved and the current empty block counter is zero the block manager converts the current 1 group to the current group and the current 2 group to the current 1 group . The current empty block counter of the previous current group is used for the current 2 group .

When data in one of the physical blocks with low update frequency is moved the wear value may be very low and the block of data moved into the physical block may not have the activity to move the block of data into the current group . The current not empty physical block counter includes counts of physical blocks that have the wear value of the current group or lower. When the current empty physical block linked list is below the target for moving data data in a physical block with the lower wear value are moved and another block of data moved into the physical block with low wear value. The replacement block of data may have higher update activity and wear the physical block.

The address table associates an address table entry with each of the physical blocks in the storage class memory . The address table entry comprises an indication if the associated block is empty or contains data is not empty . The address table entry further comprises the address of the data. Each address table entry comprises an update count that is the count of write cycles executed on the block.

In this embodiment the scans of the minimized address table need only be performed when a physical block reaches the number of updates in the lower count and the physical block count in the least worn empty physical block is below the minimum. A block of data is considered for a move when the lower count is completed. This may divide the update count by a million for a single physical block. The frequency of full address table scanning is very low.

The block manager determines whether the update count for the selected physical block is less than a predetermined maximum threshold a maximum decision step . If no the block manager resets the update count for the selected physical block step . The block update module determines whether the wear level for the selected physical block is less than or equal to the value of the current group the current value decision step . The wear level indicates to which of the wear level groups the selected physical block is currently assigned. If yes the block update module increments the wear level for the selected physical block moving the selected physical block from one of the wear level groups to another of the wear level groups step .

The block update module writes the update data in the selected physical block step and exits block update step . If at decision step the update count of the wear counter of the selected physical block is less than a maximum or predetermined threshold the block update module writes the update data in the selected physical block step and exits block update step .

If at decision step the wear level is greater than the current value the block update module selects an empty physical block further referenced as the selected empty block with a group count less than or equal to the current value step . The block update module writes the update data in the selected empty physical block step . The block update module increments the wear level of the selected empty physical block step moving the selected physical block from one of the wear level groups to another of the wear level groups . The block update module adds the selected physical block as an empty physical block with group count current value 1 step and exits block update step .

The background process module initiates a background process step . If the number of empty physical blocks in the current group 0 decision step the background process module determines whether the number of used physical blocks in the current group 0 decision step . If yes the background process module sets the wear level of the current group to the current value plus one step . The background process module sets the wear level of the current 1 group to the current value plus 2 step . The background process module sets wear level of the current 2 group to the current value plus three step . The background process module exits the background process step . If at decision step the number of empty physical blocks in the current group is greater than zero the background process module exits the background process step .

If at decision step the number of used physical blocks in the current group is greater than zero the background process module selects a not empty physical block in the current group step . The background process module selects an empty physical block with a wear level greater than the current group step . The background process module moves data from the selected not empty physical block to the selected empty physical block step . The background process module increments the wear level of the selected empty physical block in which data was written step . The background process module designates the selected not empty physical block as an empty physical block and sets the associated wear level to the current value step . The background process module exits the background process step .

In one embodiment system maintains more than three active wear level groups so that the range between the least worn group and most worn group is greater than two. In this embodiment the read only or low update activity data moves at a lower rate. For example if four wear level groups were used the wear level groups comprise a least worn group a least worn 1 group a least worn 2 group and a least worn 3 group. System moves the read only and low update data when some or all of the least worn group and the empty least worn 1 group are used. System moves the read only and low update data to the least worn 3 group. With four wear level groups these blocks of data bypass the least worn 1 group and least worn 2 group and do not move until the third cycle. With three wear level groups these blocks of data bypass the lease worn 1 group and do not move until the second cycle.

System uses an update in place property of the storage class memory to reduce the frequency of block address changes and address table updates to block update frequency divided by the number of update in place cycles. The number of update in place cycles before changing address may be in the range of 10to 10and is a significant reduction of the time and processing overhead for address changes in a conventional storage class memory.

System maintains wear leveling within a narrow band of update writes for some or all physical blocks . The band is approximately 3 times the number of update in place cycles. For example if 10updates are performed before a block address change is performed most the physical blocks are within 3 10update cycles of each other.

System manages physical blocks that are read only or very low update usage. Low update usage physical blocks are exposed to updates so that the maximum number of updates can be supported in a storage class memory. When physical blocks with lowest usage are used the data in physical blocks that have low usage are moved to one of the physical blocks that have had highest usage. By moving to physical blocks of highest usage the data need not be moved until the second cycle after the current cycle 

It is to be understood that the specific embodiments of the invention that have been described are merely illustrative of certain applications of the principle of the present invention. Numerous modifications may be made to the system and method of updating memory to maintain even wear described herein without departing from the spirit and scope of the present invention.

