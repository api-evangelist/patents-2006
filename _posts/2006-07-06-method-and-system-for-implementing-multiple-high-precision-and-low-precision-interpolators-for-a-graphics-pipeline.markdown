---

title: Method and system for implementing multiple high precision and low precision interpolators for a graphics pipeline
abstract: A rasterizer stage configured to implement multiple interpolators for graphics pipeline. The rasterizer stage includes a plurality of simultaneously operable low precision interpolators for computing a first set of pixel parameters for pixels of a geometric primitive and a plurality of simultaneously operable high precision interpolators for computing a second set of pixel parameters for pixels of the geometric primitive. The rasterizer stage also includes an output mechanism coupled to the interpolators for routing computed pixel parameters into a memory array. Parameters may be programmably assigned to the interpolators and the results thereof may be programmably assigned to portions of a pixel packet.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08749576&OS=08749576&RS=08749576
owner: Nvidia Corporation
number: 08749576
owner_city: Santa Clara
owner_country: US
publication_date: 20060706
---
This Application is a continuation of commonly assigned U.S. patent application A METHOD AND SYSTEM FOR IMPLEMENTING MULTIPLE HIGH PRECISION AND LOW PRECISION INTERPOLATORS FOR A GRAPHICS PIPELINE by Hutchins et al. Ser. No. 10 845 640 filed on May 14 2004 now U.S. Pat. No. 7 079 156 which is incorporated herein in its entirety.

This application is related to and incorporates by reference the following commonly assigned U.S. patent applications 

The present invention is generally related to computer implemented graphics. More particularly embodiments of the present invention are directed towards low power programmable processors for graphics applications.

The rendering of three dimensional 3D graphical images is of interest in a variety of electronic games and other applications. Rendering is the general term that describes the overall multi step process of transitioning from a database representation of a 3D object to a two dimensional projection of the object onto a viewing surface.

The rendering process involves a number of steps such as for example setting up a polygon model that contains the information which is subsequently required by shading texturing processes applying linear transformations to the polygon mesh model culling back facing polygons clipping the polygons against a view volume scan converting rasterizing the polygons to a pixel coordinate set and shading lighting the individual pixels using interpolated or incremental shading techniques.

Graphics Processing Units GPUs are specialized integrated circuit devices that are commonly used in graphics systems to accelerate the performance of a 3D rendering application. GPUs are commonly used in conjunction with a central processing unit CPU to generate 3D images for one or more applications executing on a computer system. Modern GPUs typically utilize a graphics pipeline for processing data.

Prior art shows a diagram depicting the various stages of a traditional prior art pipeline . The pipeline is a conventional deep pipeline having stages dedicated to performing specific functions. A transform stage performs geometrical calculations of primitives and may also perform a clipping operation. A setup raster stage rasterizes the primitives. A texture address and texture fetch stage are utilized for texture mapping. A fog stage implements a fog algorithm. An alpha test stage performs an alpha test. A depth test performs a depth test for culling occluded pixels. An alpha blend stage performs an alpha blend color combination algorithm. A memory write stage writes the output of the pipeline.

The stages of the traditional GPU pipeline architecture illustrated in are typically optimized for high speed rendering operations e.g. texturing lighting shading etc. using a widely implemented graphics programming API application programming interface such as for example the OpenGL graphics language Direct3D and the like. The architecture of the pipeline is configured as a multi stage deep pipeline architecture in order to maximize the overall rendering throughput of the pipeline. Generally deep pipeline architectures have sufficient data throughput e.g. pixel fill rate etc. to implement fast high quality rendering of even complex scenes.

There is an increasing interest in utilizing 3D graphics in portable handheld devices where cost and power consumption are important design requirements. Such devices include for example wireless phones personal digital assistants PDAs and the like. However the traditional deep pipeline architecture requires a significant chip area resulting in greater cost than desired. Additionally a deep pipeline consumes significant power even if the stages are performing comparatively little processing. This is because many of the stages consume about the same amount of power regardless of whether they are processing pixels.

As a result of cost and power considerations the conventional deep pipeline architecture illustrated in is unsuitable for many graphics applications such as implementing 3D games on wireless phones and PDAs. For example such conventional deep pipelines are configured to compute the various parameters required to render the pixels of an object using multiple standardized high precision functions. Typical per pixel parameters include for example texture coordinates colors depth values level of detail parameters and the like. The functions are implemented such that they generate high precision results even in those circumstances where such precision is redundant or unnecessary.

The costs of such precision can be an expansion in the amount of data that must be pushed down the pipeline architecture an increased number of transistors necessary to compute all parameter cases with the specified precision an increased amount of circuit switching activity and the like. Each of these costs run counter to the objective of implementing efficient high performance 3D rendering on a portable handheld device. Therefore what is desired is a processor architecture suitable for graphics processing applications but with reduced power and size requirements.

Embodiments of the present invention provide a method and system for implementing multiple high precision and low precision interpolators in a raster stage of a graphics pipeline. Embodiments of the present invention direct parameter computations requiring high precision to execute on high precision interpolators. Those pixel parameter computations that do not significantly benefit from high precision are directed to execute on low precision interpolators. Both the high precision and low precision interpolator computations execute in parallel. In this manner embodiments of the present invention provide a graphics processor architecture with reduced power and size requirements.

In one embodiment the present invention is implemented as a raster stage having a plurality of simultaneously operable low precision interpolators for computing a first set of pixel parameters e.g. low precision parameters for pixels of a geometric primitive and a plurality of simultaneously operable high precision interpolators for computing a second set of pixel parameters e.g. high precision parameters for pixels of the geometric primitive. The rasterizer stage also includes an output mechanism coupled to the interpolators for routing computed pixel parameters into a memory array e.g. one or more pixel packet rows . The low precision interpolators require significantly less silicon area and consume significantly less power than the high precision interpolators.

In one embodiment the plurality of interpolators of the raster stage are configured to use Barycentric coordinates to interpolate parameters for each pixel of a polygon. By using Barycentric coordinates the interpolators can be implemented as fixed point interpolators e.g. as opposed to floating point thereby reducing their gate count and power consumption. Additionally the interpolators can programmably store their results into multiple positions of a pixel packet row.

Reference will now be made in detail to the preferred embodiments of the present invention examples of which are illustrated in the accompanying drawings. While the invention will be described in conjunction with the preferred embodiments it will be understood that they are not intended to limit the invention to these embodiments. On the contrary the invention is intended to cover alternatives modifications and equivalents which may be included within the spirit and scope of the invention as defined by the appended claims. Furthermore in the following detailed description of embodiments of the present invention numerous specific details are set forth in order to provide a thorough understanding of the present invention. However it will be recognized by one of ordinary skill in the art that the present invention may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail as not to unnecessarily obscure aspects of the embodiments of the present invention.

Some portions of the detailed descriptions which follow are presented in terms of procedures steps logic blocks processing and other symbolic representations of operations on data bits within a computer memory. These descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. A procedure computer executed step logic block process etc. is here and generally conceived to be a self consistent sequence of steps or instructions leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated in a computer system. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the present invention discussions utilizing terms such as processing or accessing or executing or storing or rendering or the like refer to the action and processes of a computer system e.g. computer system of or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

With reference now to a computer system in accordance with one embodiment of the present invention is shown. Computer system in accordance with one embodiment of the present invention provides the execution platform for implementing certain software based functionality of the present invention. As depicted in the computer system includes a CPU coupled to a graphics processor via a host interface . The host interface translates data and commands passing between the CPU and the graphics processor into their respective formats. Both the CPU and the graphics processor are coupled to a memory via a memory controller . In the system embodiment the memory is a shared memory which refers to the property whereby the memory stores instructions and data for both the CPU and the graphics processor . Access to the shared memory is through the memory controller . The shared memory also stores data comprising a video frame buffer which drives a coupled display .

As described above certain processes and steps of the present invention are realized in one embodiment as a series of instructions e.g. software program that reside within computer readable memory e.g. memory of a computer system e.g. system and are executed by the CPU and graphics processor of system . When executed the instructions cause the computer system to implement the functionality of the present invention as described below.

As shown in system shows the basic components of a computer system platform that implements the functionality of the present invention. Accordingly system can be implemented as for example a number of different types of portable handheld electronic devices. Such devices can include for example portable phones PDAs handheld gaming devices and the like. In such embodiments components would be included that are designed to add peripheral buses specialized communications components support for specialized IO devices and the like.

Additionally it should be appreciated that although the components are depicted in as a discrete components several of the components can be implemented as a single monolithic integrated circuit device e.g. a single integrated circuit die configured to take advantage of the high levels of integration provided by modern semiconductor fabrication processes. For example in one embodiment the CPU host interface graphics processor and memory controller are fabricated as a single integrated circuit die.

A setup stage receives instructions and graphics primitives from a host such as a software application running on the CPU . In one embodiment setup stage performs the functions of geometrical transformation of coordinates X form clipping and setup. The setup unit takes vertex information e.g. x y z color and or texture attributes etc. from primitives and applies a user defined view transform to calculate screen space coordinates for each geometric primitive often referred to as triangles because primitives are typically implemented as triangles which is then sent to the raster stage to draw the given triangle. A vertex buffer may be included to provide a buffer for vertex data used by setup stage . In one embodiment setup stage sets up barycentric coordinate transforms. In one implementation setup stage is a floating point Very Large Instruction Word VLIW machine that supports 32 bit IEEE fl S15.16 fixed point and packed 0.8 formats.

Raster stage receives data from setup stage regarding triangles that are to be rendered e.g. converted into pixels . Raster stage processes parameters for each pixel of a given triangle by interpolation and determines shader attributes that need to be interpolated for a pixel as part of rendering such as calculating color texture and fog blend factors. In one embodiment raster stage calculates barycentric coordinates for pixel packets. In a barycentric coordinate system distances in a triangle are measured with respect to its vertices. The use of barycentric coordinates reduces the required dynamic range which permits using fixed point calculations that require less power than floating point calculations.

Raster stage generates at least one pixel packet for each pixel of a triangle that is to be processed. Each pixel packet includes fields for a payload of pixel attributes required for processing e.g. color texture depth fog x y location along with sideband information and an instruction sequence of operations to be performed on the pixel packet. An instruction area in raster stage not shown assigns instruction sequence numbers to pixel packets. The sideband information may also include a valid field and a kill field. The pixel packet may include one or more rows of pixel information.

Gatekeeper stage performs a data flow control function to the downstream units. In one embodiment gatekeeper stage has an associated scoreboard for scheduling load balancing resource allocation and hazard avoidance of pixel packets. Scoreboard tracks the entry and retirement of pixels. Pixel packets entering gatekeeper stage set the scoreboard and the scoreboard is reset as the pixel packets drain e.g. retire out of graphics processor after completion of processing or marked as killed.

Data fetch stage fetches data for pixel packets passed on by gatekeeper . This may include for example fetching color depth and texture data by performing appropriate color depth or texture data reads for each row of pixel packets. The data fetch stage may for example fetch pixel data from a frame buffer not shown fetch texel data from a texture map and may also manage a local texture fog cache and a color depth cache . Data that is fetched is placed onto a pixel packet field prior to sending the pixel packet on to the next stage.

The row of pixel packets enter an arithmetic logic unit ALU pipeline for processing. ALU pipeline has a sequence of ALUs. While four ALUs are illustrated more or less ALUs may be used in ALU pipeline depending upon the application.

The output of ALU pipeline goes to data write stage . The data write stage converts pixel packets into pixel data and stores the result e.g. color z depths etc. in a write buffer or directly to a frame buffer in memory. Examples of functions that data write stage may perform include color and depth write back and format conversion.

As described above the raster stage receives data from setup stage regarding triangles that are to be rendered e.g. converted into pixels . For each received triangle the raster stage rasterizes the triangle into each of its constituent pixels with a number parameters interpolated for each pixel. The rasterizer computes rendering parameters for each of the pixels of the triangle by systematically evaluating each of the pixels in a deterministic sequential manner e.g. walking the triangle . The parameters are computed through an interpolation process from the data associated with the triangle s vertices.

The raster stage advantageously utilizes an array of programmable interpolators to compute the parameters in parallel. As the raster stage walks each pixel the parameters for that pixel are iterated and the resulting data is passed down to subsequent stages of the pipeline e.g. as a pixel packet . The interpolated results can be placed in programmably selectable positions in the pixel packet. As is generally known complex 3D scenes can typically have a large number of polygons and additionally a large number of rendering parameters for each polygon. Such parameters include for example color texture coordinates transparency depth level of detail LOD and the like. A real time 3D rendering pipeline needs to perform many millions of calculations per second to maintain the pixel throughput e.g. fill rate required to draw a realistic 60 70 frames per second. The raster stage utilizes the parallel array of interpolators to maintain the required pixel fill rate while conserving power consumption and silicon area.

The outputs of the interpolators are used to construct a plurality of pixel packet rows e.g. a data structure in a memory array . In the present embodiment a programmable packing logic module e.g. including a crossbar switch functions by arranging the outputs of the interpolators into a pixel packet row and formatting the fields of the row for the pixel parameters required for subsequent processing e.g. color texture depth fog etc. . The placement of the outputs e.g. of the interpolators into the rows is programmable. In addition to these parameters the packing logic module arranges processing instructions e.g. for the subsequent operations to be performed on the pixel packet into the pixel packet row. For example as a pixel is iterated the computed parameters produced by the interpolators enable subsequent stages of the graphics pipeline to fetch the required surface attributes e.g. color texture etc. needed to complete the pixel s rendering. For a simple 3D scene a given pixel can be described using a single row e.g. a one row pixel packet . In comparison for a more complex 3D scene a given pixel description may require a plurality of rows e.g. a four row pixel packet .

In the present embodiment the interpolators are programmable and can be flexibly assigned interpolation computations. In other words the parameter assignment to the interpolators is programmable. The assigned interpolation computations can be software scheduled such that each of the eight interpolators is kept busy as much as possible e.g. on a per clock basis . In one embodiment a software scheduler ensures the interpolators are kept busy and that latency idle time is avoided. In this manner a given pixel parameter computation can be flexibly assigned to any one of the interpolators . Once made for a triangle the parameter assignment to the interpolators is fixed for each of the pixels of that triangle. The parameter assignment can be reprogrammed or otherwise reconfigured for the next triangle. In this manner the parameter assignment to the interpolators is programmable on a per triangle basis.

In the present embodiment the array of interpolators are divided into high precision interpolators e.g. interpolators and low precision interpolators e.g. interpolators . The division is configured to maintain the flexible assignability of interpolation computations while simultaneously conserving silicon area dedicated to the interpolator array. The division is configured to take advantage of the fact that some parameters need to be computed in high precision e.g. texture coordinates while other parameters do not. For such low precision parameters the extra precision afforded by a high precision computation provides no significant contribution to the resulting image. Accordingly low precision parameters can be assigned to the low precision interpolators . The low precision interpolators require significantly less silicon area for their implementation. Additionally the low precision interpolators consume less power per clock cycle. These are important design considerations for a handheld device.

In one embodiment the interpolators use barycentric coordinates for their parameter computations. As described above the use of barycentric coordinates permits the use of fixed point calculations that require less power than floating point calculations. In one embodiment the high precision interpolators produce a plurality of 14 bit interpolant coefficients and the low precision interpolators produce a plurality of 8 bit interpolant coefficients although any resolution range can be implemented. Generally the precision selected for the interpolant coefficients is dictated by the maximum allowed error tolerable for the resulting high and low precision interpolated values.

Additionally in one embodiment the interpolators use perspective corrected barycentric coordinates for their parameter computations. This allows interpolation perspective corrected parameters by the interpolators . In one embodiment the perspective correction process uses a perspective correction pixel parameter w that is computed in floating point precision once for each pixel of a triangle.

As described above the raster stage receives data from setup stage regarding triangles e.g. polygons that are to be rendered e.g. converted into pixels . This is illustrated in as the triangle propagating down to the raster stage from the set up stage . The triangle comprises a geometric primitive having associated therewith instructions e.g. instructions indicating the manner in which the triangle is to be rasterized and rendered and primitive data e.g. parameter data such as color texture coordinates transparency xy depth etc. .

The raster stage includes an instruction unit that receives and processes the instructions associated with the triangle and controls the manner in which the primitive data is loaded and processed by the interpolator array e.g. interpolators . The instructions include raster interpolation instructions that control the manner in which the primitive data of the triangle is to be interpolated across each of the triangle s pixels. As described above the parameters for each of the triangle s pixels are interpolated from the primitive data associated with the triangle s vertices. The raster instructions control which parameter e.g. of the primitive data is processed by which of the high precision interpolators e.g. interpolators or low precision interpolators e.g. interpolators . In other words the instruction unit implements a programmable software based scheduler that schedules and allocates the parameter data interpolation computations to the interpolators in accordance with the raster instructions .

The raster instructions also control the locations where the interpolation results from the interpolators will be loaded into each row of a generated pixel packet. The instruction unit interacts with the packing logic to implement the desired row load out.

In this manner the raster instructions control the building of the pixel packets of the triangle . For example for each pixel of the triangle the raster instructions determine the parameter inputs for each of the interpolators and also determine the row locations of the interpolated parameter outputs fields for the pixel parameters required for subsequent processing e.g. color texture depth fog etc. and processing instruction sequence numbers for the subsequent operations for the pixel packet. In typical operation one row of a pixel packet is formed each clock cycle. Thus two row pixel packets are built in two clock cycles three row pixel packets are built in three clock cycles and accordingly n row pixel packets are built in n clock cycles. As the pixel packets are formed e.g. pixel packets they are propagated to subsequent stages of the pipeline.

As described above it should be noted that in one embodiment the programming of the allocation of the primitive data to the interpolator array e.g. which parameters are assigned to which of the interpolators is programmable on a per polygon basis. For example once the instruction unit configures the interpolator array to build the pixel packets of the triangle that configuration remains constant for each of the constituent pixels of the triangle .

In the present embodiment sideband information includes a type field of one or more bits. There may be different types of data packets flowing through the pipeline of . The type field is used to identify pixel packet as a row of a pixel packet containing pixel data.

In the present embodiment sideband information of may include an even odd e o field . In one embodiment the e o field is a single bit in length. Additionally sideband information of also includes a kill field . In one embodiment the kill field is a single bit in length. As mentioned above if the kill bit is set somewhere in the pipeline of then the pixel packet will proceed through the remainder of the pipeline without active processing.

In the present embodiment the sideband information of includes a sequence field . In one embodiment the sequence field is three bits in length. The sequence bits link pixel packet to an instruction that is to be applied to the pixel packet in the subsequent stages e.g. DF ALU stages and DW .

Continuing with reference to in the present embodiment the data in payload portion of pixel packet is separated into one or more rows . . . N in raster stage of . That is the payload portion may consist of a single row of data or it may consist of a group of rows.

The sideband information for pixel packet is associated with each row or rows formed from the payload portion . In one embodiment each row includes the sideband information and 80 bits of pixel data as illustrated in .

Each row of pixel packet is processed in succession in pipeline of with each new clock cycle. For example row starts down pipeline on a first clock followed by row on the next clock and so on. Once all of the rows associated with pixel packet are loaded into pipeline rows associated with the next pixel packet are loaded into pipeline . In one embodiment rows of pixel data for one pixel packet are interleaved with rows of pixel data from the next pixel packet. By interleaving rows of pixel packets in this fashion stalls due to functional unit latencies in the pipeline can be avoided.

With reference now to a block diagram of pixel data loaded into a register is shown in accordance with one embodiment of the present invention. The pixel data in each row is 80 bits in length. In one such embodiment the pixel data in each row is represented using four 4 sets of 20 bit values e.g. . Each of the sets of 20 bit values may represent one or more instances of pixel data. Examples of pixel attributes that may be included in a 20 bit set of pixel data include but are not limited to 16 bit Z depth values 16 bit s t texture coordinates and a 4 bit level of detail value a pair of color values each with ten 10 bits of precision e.g. 10 bits high precision and 10 bits low precision or packed 5555 RGBA red green blue alpha values each five 5 bits in length. The particular data layout or packing format depends on how the interpolators are programmed by the raster instructions for the primitive.

As described herein the instructions commanding the iterating e.g. the 4 high precision 4 low precision instructions are assigning one of the 4 high precision interpolators to take one parameter that the pixel setup stage is sending and perform the interpolation on it. Moreover the destination in the instruction indicates how to pack the interpolated data in the row . For example the raster stage walks pixel by pixel across the geometric primitive e.g. triangle or the like interpolating all parameters and packing them into an 80 bit value for flowing down the pipeline .

In one embodiment the raster stage can perform the 4 high precision and 4 low precision iterated values per clock. The software operating on the raster stage will program the interpolators with the clock length of the pixel. For example if the pixel packet will take only one row of 80 bits or if it has enough texture to require a plurality of rows to contain all the data for the pixel. Moreover the assignment of the pixel data to the 20 bit set e.g. of the row may also be changed per geometric primitive. That is the assignment and instructions per geometric primitives are fixed in the raster stage but they are variable between geometric primitives.

Process begins in step where the raster stage receives or otherwise accesses a polygon from the set up stage of the graphics pipeline. In step the polygon is rasterized into a plurality of constituent pixels. In step parameter computations for the pixels are allocated to a set of low precision interpolators e.g. interpolators and a set of high precision interpolators e.g. interpolators in accordance with raster instructions for the polygon. As described above the polygon comprises constituent geometric primitive data and associated raster instructions e.g. that control the build out of the pixel packets for the polygon . An instruction unit within the raster stage configures the interpolators to process the pixels of the polygon and build the pixel packets.

In step the allocated interpolator calculations are executed in parallel. In step the resulting interpolator outputs are loaded into a row of a pixel packet in accordance with the raster instructions for the polygon. As described above the instruction unit configures the packing logic to build the pixel packet row in the specified manner. In step if the pixel processing is complete in step process outputs the completed pixel packet to the subsequent stages of the graphics pipeline. Otherwise process proceeds to step and executes the allocated interpolation calculations in parallel for the next row of the pixel packet. In this manner successive rows of the pixel packet are built until the pixel s description is complete. As described above a simple 3D scene can often have one row per pixel packet while a comparatively complex scene can have two three or more rows per pixel packet.

With reference now to a data flow diagram of a method for reducing color value size is shown in accordance with one embodiment of the present invention. Specifically shows a geometric primitive of any size e.g. a triangle entering the raster module of the present invention. As the geometric primitive enters the rasterizing module of the graphics pipeline the rasterizing module interpolates the geometric primitive via interpolator to produce a first color value . In general the interpolator interpolates the geometric primitive in a pixel by pixel manner to transform the data from geometric primitive data to pixel data. In one embodiment the first color value is a high bit color value e.g. 8 bit or greater .

The first color value is then truncated at the truncation portion of the raster module . In general truncation removes the least significant bits from a set of bits. For example the truncation portion may truncate the first color value e.g. an 8 bit color value to produce a truncated color value e.g. a 5 bit color value . The rasterizing module then utilizes a dither table to dither the truncated color value to produce a truncated and dithered color value . In general dithering is used to reduce the banding effect normally associated with truncated color values . The truncated and dithered color value is then propagated from the rasterizing module and enters the remainder of the downstream pipeline . In so doing the power use is minimized regarding propagation of and processing of the color values. It should be noted that the selection of said truncation and or dithering may be a programmable attribute such that software applications can choose whether to use the full color precision or the truncated dithered version of the color value assuming the remainder of the pipeline is likewise programmable. This is desirable since simple pixels i.e. pixels which are only using interpolated color values may need higher precision to be visually pleasing while complicated pixels i.e. pixels which involve many processing steps such as texturing fog etc. have a lower total contribution from iterated color and thus have less need of full color precision in order to maintain high overall visual quality. It is further desirable to allow the choice of dithering to be independent of the choice to truncate the color value since some graphics APIs i.e. OpenGL require this flexibility.

With reference now to a block diagram of a color value reduction via truncation is shown in accordance with one embodiment of the present invention. In general diagram illustrates a first color value having N bits with a length of . In the reduced file a portion of the transformed color value has been truncated or removed. The resulting is therefore smaller and easier to process than the original N bit file.

For example the original file size may be 8 bits e.g. N would be eight color value may be three bits wide and would result in a truncated color value size of 5 bits. The 5 bits would then be processed through the pipeline. It is noted that the 5 bits is simply one of the plurality of possible truncated size options. Moreover it is well known that the color value or bit size is per color. That is or may be a red color value or blue color value or green color value or any other parameter desired by the designer. However it is only a single color value and other color values are treated in the same way. Therefore if the graphics pipeline used a three color application in one embodiment there would be three 1120 bit sections to be processed through the pipeline. Not a single 1120 bit section covering all the colors.

With reference now to a flowchart of a process for reducing power consumption for graphic architecture on a handheld computing device is shown in accordance with one embodiment of the present invention that uses reduced bit width color values.

Referring now to step of a triangle primitive is received by the raster stage from the setup stage of the graphics pipeline e.g. graphics pipeline . As described above the triangle has a number of parameters that control the manner in which its constituent pixels are rendered by the graphics pipeline of the hand held computing device. As stated herein the handheld computing device may be a mobile phone pager personal digital assistant or the like. Moreover the graphics pipeline may be a plug and play component coupled with the processor or logic of the handheld computing device. In another embodiment the graphics pipeline may be fixedly coupled with the handheld computing device at the time of manufacture.

With reference now to step of and to in one embodiment a color value is generated via interpolation at interpolator of rasterizing module of the graphics pipeline. As stated herein the color value may be of any size e.g. 8 bit 16 bit 32 bit or the like. In one embodiment the computing of pixel parameters includes interpolating the geometric primitive including a plurality of vertices wherein each vertex has a respective color value and the interpolating is performed by an interpolator portion of a rasterizing module . For example the rasterizer initially interpolates a respective color value for each pixel of the geometric primitive wherein the respective color value is of a first bit width e.g. 8 bits 16 bits 32 bits etc. .

Referring now to step of and to in one embodiment the interpolated color value is truncated at the truncation portion . In one embodiment the truncation may result in a truncated color value reduced to a second bit width to produce a respective truncated color value. In one embodiment the second bit width may be any number of bits between 2 and 7. As is well known in the art truncation is simply the reduction of the possible number of variations for a color. For example a color block or file may be introduced to the truncating portion as a variation of red. The initial color reference may be pink e.g. 8 bit color during the truncation process at the truncation portion the new color reference e.g. truncated color value may be light red e.g. a 5 bit color . In this case the least significant 3 bits are discarded. Therefore as is well known in the art the color value size and actual reference color has been changed.

With reference now to step of and to in one embodiment the resulting truncated e.g. transforming or the like color value is altered e.g. dithered or the like by the dither table . For example the transformed color value may be dithered using a screen location based dither table to produce a truncated dithered color value . Additionally the respective truncated dithered color value may be propagated to downstream modules of the graphics pipeline. In one embodiment the screen location based dither table returns a dither value based on a screen position of each pixel and wherein the dither value is used to alter the respective color value of each pixel to prevent visual artifacts that may result from the color formations.

As is well known in the art dithering is the process that is used to improve the image when the full range of colors in a particular image are not available e.g. due to truncation or reduced palette size . For example if a gradient is to be displayed and the system does not have the resources to display all of the shades that make up the gradient then the image or colors are dithered. That is the remaining colors are mixed in such a way as to recreate the missing colors by trading spatial resolution for color resolution. For example if the called for color is pink the raster module may intersperse a few white pixels within a plurality of red pixels. In so doing the eye blends the interspersed white with the red and sees pink. Thus in the gradient example the color smoothly transitions from red to white via the introduction of more white and less red interspersed throughout the gradient. This can be based on the screen location of the pixel being dithered.

By producing a truncated dithered color value at the rasterizing module the number of gates and the power necessary to complete the pipeline of the graphics pipeline on the handheld computing device is reduced.

In addition to the truncation and dithering of color values in one embodiment the rasterizing module can truncate and dither iterated color values. Moreover the rasterizing module may apply mathematical operations to the iterated color values after truncating and dithering the files.

With reference now to a block diagram of a geometric primitive is shown in accordance with an embodiment of the present invention. In general the geometric primitive is in one embodiment a triangle with three vertices . As is well known in the art the three vertices are the coordinates necessary to establish the a triangle. The banding issues are shown in the color variation of geometric primitive . The bands are caused by the reduction in bit color and the resulting reduced color palate. The dithering portion illustrates an exemplary embodiment of dithering resulting in a smoother apparent color transition on a limited color palate. Although one version of dithering is shown there are numerous dithering methods which are well known in the art and which may be used by the present invention.

In one embodiment the raster stage accesses the primitives comprising the polygon e.g. triangle and rasterizes the triangle into its constituent pixels. The bounding box is used by the rasterizer module e.g. rasterizer of the raster stage in the rasterization process of the triangle . Associated parameters for each pixel are then interpolated from the vertices . These parameters include a depth parameter z. During rasterization of the triangle respective z values are interpolated by the raster stage for each pixel of the triangle . Each z value is represented within a predefined numerical range e.g. an integer portion of zero and a fractional portion ranging from zero to one which substantially corresponds to a depth range between a near clipping plane and a far clipping plane as related to a view volume. Z values outside the clipping planes are not screen displayable positions.

As is generally known the z values between the near clipping plane and the far clipping plane comprise the inner and outer boundaries of the view volume. Thus triangle may have a significant portion that is further from the viewpoint than the far clipping plane e.g. those z values greater than one and or a significant portion which is closer than the near clipping plane e.g. those z values that are less than zero . In this manner the normal Z range is for those pixels which contribute to the scene is 0.0 to 1.0 e.g. between the near and far clipping planes . Accordingly the bounding box extends significantly beyond this range.

In one embodiment the raster stage takes advantage of the fact that the valid range for the z value is modular ranging from 0.0 to 1.0 and repeats consistently and deterministically as is the integer value of the z parameter increases or decreases. For example in the prior art a graphics pipeline would need to accommodate a very large range for z values that extend beyond the valid range. In contrast in the raster stage during the iteration of the z values for each pixel the fractional portion of the z values are allowed to roll over within this modular framework and repeat with each new integer increment or decrement and the integer value is allowed to increment and decrement outside the valid range e.g. increment above one and decrement less than zero . A flag can be recorded when the Z value is determined to be outside the near far clipping planes.

Thus for example even though a z stepper of the raster stage may begin at 2.0 z value by the time the raster stage steps into the view volume e.g. z values between 0.0 and 1.0 the fractional portion will behave correctly and consistently. Similarly in a case where the z stepping process begins at positive 6.0 z value the fractional portion of z will consistently and deterministically roll over as the integer value steps from 6.0 to 0.0. It is possible to take advantage of this behavior because other separately iterated parameters the barycentric coefficients determine which pixels are within the two dimensional x y projection of the primitive. Rasterizing correct z values is only important within this two dimensional projection of the primitive in the x y plane outside of this region the z stepper need only act as an error term such that the correct z values are generated once the rasterizer steps into the triangle.

The modularity characteristic of the z stepping function allows the integer portion to increment and decrement as necessary while the raster stage need only keep accurate track of the modular fractional portion of z e.g. from 0.0 to 1.0 . For example if z is increasing outside the view volume positive integers can be discarded. Similarly if z is decreasing outside the view volume negative integers can be discarded. This allows the raster stage to use fewer bits for the integer portion of z e.g. outside the 0.0 to 1.0 range . In both cases some number of integer z bits e.g. three bits can be retained as a multi bit indicator to indicate when the z stepping process is in the positive or negative range outside the view volume. This is necessary since in general the z stepper will not be exactly precise in relation to the other coefficients which precisely determine pixel membership in the two dimensional x y projection of the triangle i.e. the barycentric coefficients . In this manner the z parameter values produced by the z stepping process are clamped to remain substantially within the valid range of the view volume for transitional pixels at the edges of the primitive.

In one embodiment for a 1K pixel screen 16 z bit precision e.g. a 16 bit wide depth buffer is used to track the fractional z value and 10 error bits are used e.g. in order to have less than one part in a thousand z error for a maximally sized primitive . Additionally two or three error bits can be used for the integer portion. These bits will indicate the sign of the z value e.g. when the z value is outside either the near or far plane and become guard bits to indicate when the z stepping process penetrates the near or far clipping planes. The number of indicator bits selected determines the allowable multiple of the 0 to 1 z range at which true clipping must be performed on a primitive if any of the z values at the vertices exceed said range e.g. for three indicator bits primitives with z values between 3.0 and 3.0 can be rasterized correctly . Note that due to the modular nature of the z fractional bits this is only a requirement for pixels which are inside the two dimensional x y projection of the triangle it is still possible to iterate outside pixels correctly even when they exceed the multiple of the z range since the z value will roll over into the legal range prior to stepping into an inside pixel .

In one embodiment the z stepping process implemented by the raster stage can be used to implement a per pixel clipping process. As is well known traditional clipping is a computationally expensive process. The integer guard bits enable a per pixel clipping process whereby the geometric computations involved in a traditional clipping process are avoided. For example those pixels having a z value greater than 1.0 are further than the far clipping plane and are outside the view volume and can be discarded or bypassed. Similarly those pixels having a z value less than 0.0 are inside the near clipping plane and can similarly be discarded or bypassed. In this manner if the iterated z value of a pixel is outside the clamped range that pixel can essentially be clipped thereby performing clipping at the pixel level as opposed to the polygon level. Per pixel clipping is less computationally expensive than traditional per polygon clipping. It should be noted that in addition to clipping the clamped z value stepping process can be beneficial to other types of rendering operations such as for example stencil shadows.

Thus the z stepping logic of the raster stage can be designed to compute the z values with less precision in comparison to typical prior art implementations while the devoting a larger domain to the z value range within the near far clipping planes. For example while traditional z stepping logic needed to be implemented with 56 bits e.g. for a 1K pixel screen z stepping logic in accordance with one embodiment of the present invention can be implemented with 29 bits e.g. 3 guard bits 16 z bits and 10 error bits . This makes hardware significantly less expensive in terms of silicon area consumed and in terms of power requirements while devoting excellent resolution to the range between the near far clipping planes.

Process begins in step where the raster stage accesses a geographic primitive comprising a plurality of vertices of a polygon. In step the primitive is rasterized into a plurality of corresponding pixels. In step the raster stage computes z parameter values for each pixel of the polygon wherein each z parameter value comprises an integer portion and a fractional portion.

In step the integer portion of the z parameter is clamped to a valid range bit width plus a guard indicator e.g. a small number of integer bits to indicate the sign of the z parameter. Additionally in step the computed z values are allowed to roll over within the valid range upon an overflow condition. This sets the guard bit to indicate overflows. In step per pixel clipping is implemented using the guard indicator of the z parameter. As described above the guard bits can indicate those pixels which are further than the far clipping plane e.g. far clipping plane or closer than the near clipping plane e.g. near clipping plane . These pixels can then be discarded or ignored in the rendering process. Optionally e.g. under software control such pixels can be clamped to the near or far z values instead of being clipped which may be useful for some software algorithms.

In one embodiment texture parameters are computed by the raster stage and these texture parameters are clamped to a valid range. In other words as texture coordinates are computed by the raster stage e.g. s and t coordinates the computed textures are clamped to a valid range early in the pipeline e.g. in the raster stage as opposed to later in the pipeline.

In one embodiment the fractional portion is represented as a 16 bit value. In a typical implementation the 16 bit each s and t coordinates of the texture map are used to fetch the addressed texel and one or more adjacent texels for a blending operation. The fractional portion allows the data fetch stage to fetch the correct adjacent texels for the blending interpolation.

In one embodiment the raster stage computes texture coordinates in accordance with a wrap texture mapping mode. In the wrap mode the texture repeats itself as the integer portion of the computed texture increments or decrements. In the wrap mode at the edges of the texture e.g. s or t at 1 or 0 the data fetch stage fetches adjacent texels from the adjacent edge of the next repeating version of the texture map to do the interpolation. In this way the textures wrap around without visible seams or artifacts.

In another embodiment the raster stage computes texture coordinates in accordance with a clamp texture mapping mode. In the clamp mode the fractional portion does not wrap around. At the edges the texture is clamped to the value at the edge. In the clamp mode the texel colors are replicated or smeared off and repeated for any value that is greater than 1 or less than 0.

Operation in the clamp mode needs to be identified to subsequent stages in the pipeline. In one embodiment an additional bit e.g. a clamp flag or clamp bit is sent down the pipeline to identify the clamp mode of texture mapping. The bit for each pixel can be transmitted as side band information in the manner described above. This information is used by the data fetch stage during its texture fetch in order to configure itself not to fetch wrap around adjacent texels of the edge of the texture to do interpolation. The clamp mode is typically is programmed by an application through a graphics API.

It should be noted that in another embodiment the raster stage can be configured to compute texture coordinates in accordance with a mirror mode where the texture coordinates are mirrored with different integer version of the texture coordinate value e.g. those s and t values that are outside the range zero to one . As with the clamp mode the mirror mode is identified to subsequent stages of the pipeline e.g. through the use of a flag or bit .

In this manner the raster stage performs parameter clamping wherein computed parameters are clamped to their valid range to save on the number of bits information that needs to be pushed down the pipeline. In this case the clamping involves discarding the integer portion of the computed texture coordinates and only sending the fractional portion within the range 0 1. This work is performed in the raster stage as opposed to other later stages in the pipeline. The clamping functionality only sends the necessary parameter data which minimizes the number of bits which need to be transmitted down the graphics pipeline and thereby minimizing power expenditure.

Process begins in step where the raster stage accesses a geometric primitive comprising its respective vertices of a polygon e.g. triangle . In step the geometric primitive is rasterized into a plurality of corresponding pixels. In step the raster stage processes each pixel of the triangle and computes texture coordinates to be used in subsequent stages of the pipeline. As described above the computed texture coordinates comprise both an integer portion and a fractional portion. In step the fractional portion is propagated downstream to the data fetch stage .

In step in accordance with instructions from an application executing on the computer system a determination is made as to whether a clamp mode or wrap mode will be implemented. In step in clamp mode the raster stage computes texture coordinates in accordance with a clamp texture mapping mode and propagates a clamping flag down the pipeline. As described above at the edges of the texture the texture color is clamped to the value at the edge. In step texture coordinates are fetched by the data fetch stage to implement clamp mode texture mapping e.g. as depicted in . In step in wrap mode texture coordinates are fetched by the data fetch stage to implement wrap mode texture mapping e.g. as depicted in .

As known by those skilled in the art mip mapping is a widely used type of LOD filtering. The LOD filtering is configured to prevent moire interference patterns aliasing and rendering artifacts by scaling and filtering a full resolution texture map into multiple lower resolution versions . For example the full resolution version contains all the surface details of an object. At close distances to the viewpoint the full resolution version renders in its original full detail. As the distances increase successively smaller resolution versions of the texture e.g. versions are used. By choosing the appropriate texture resolution and detail mip mapping ensures that pixels do not get lost at further distances. Instead properly averaged smaller versions of the original texture are used. At the furthest distances a single texel is used. Each of these stages is known as a mip map level e.g. level through level shown in . It should be noted that although shows five levels embodiments of the present invention can be implemented other numbers of versions e.g. etc. .

In one embodiment the raster stage implements LOD parameter clamping wherein a computed LOD parameter is clamped to a valid range in the raster stage of the graphics pipeline. The clamping functionality in this case comprises accessing a geometric primitive e.g. triangle comprising a plurality of vertices wherein each vertex has associated therewith a plurality of parameters including a level of detail LOD value. During rasterization of the primitive a respective LOD value for each pixel of the primitive is computed e.g. using interpolation . This LOD value is computed using a full precision function. Accordingly each LOD value of each pixel comprises an integer portion and a fractional portion.

The integer portion of the computed LOD value is used to select the correct mip map level corresponding to the primitive s distance from the viewpoint. The fractional portion of the computed LOD value is used to configure a blending operation performed on adjacent texels of adjacent mip map levels e.g. where the fractional portion is used to assign different weights to texels of different mip maps . This is shown in by the arrow indicating adjacent texels of different mip map levels used in a blending operation in accordance with an LOD fractional portion.

The raster stage is configured to clamp the LOD value to a maximum value if a computed LOD value is greater than the predetermined range e.g. clamped to the maximum value . Similarly the raster stage is also configured to clamp the LOD value to a minimum value if a computed LOD value is less than the predetermined range e.g. clamped to the minimum value . In other words where the computed LOD parameter indicates a texel pixel ratio for the primitive which is larger than the coarsest smallest mip map level e.g. version the LOD value can be clamped to this maximum value e.g. level and no higher LOD integer values need be computed stored or propagated down the pipeline. Where the computed LOD parameter indicates a texel pixel ratio which is smaller than the finest largest mip map level e.g. level the LOD integer value can be clamped to this minimum value and no lower LOD integer values e.g. negative LOD integer values need be computed stored or propagated. These clamped LOD parameter values are then propagated down the pipeline to the data fetch stage .

In one embodiment once the maximum or minimum value has been clamped the fractional portion can also be clamped. For example in a case where the maximum LOD parameter value has been greatly exceeded e.g. a parameter indicating a mip map level the lowest resolution version e.g. level is already being returned the fractional portion would be insignificant with respect to any blending interpolate. In such a case the fractional portion can also be clamped to its maximum value. Alternatively in one embodiment the fractional portion can merely be discarded e.g. as having no significant contribution to fragment color .

In one embodiment a four bit value is used to represent the integer portion of the LOD parameter and a four bit value is used to present the fractional portion of the LOD parameter.

Process begins in step where the raster stage accesses a geometric primitive comprising its respective vertices of a polygon e.g. triangle . In step the geometric primitive is rasterized into a plurality of corresponding pixels. In step the raster stage processes each pixel of the triangle and computes an LOD value to be used in subsequent stages of the pipeline. As described above the computed LOD value comprises both an integer portion and a fractional portion.

In step the integer portion and the fractional portion of the LOD parameter are clamped to a valid range. As described above when the computed LOD parameter exceeds the valid range the parameter is clamped to its maximum value. When the computed LOD parameter is less than the valid range the parameter is clamped to its minimum value. In step the clamped LOD parameter is propagated downstream to the data fetch stage of the pipeline.

In this manner as with the texture coordinates values LOD parameters are clamped to a valid range early in the rendering process by the raster stage to save in the number of bits that must be pushed down the pipeline thereby minimizing power expenditure.

The foregoing descriptions of specific embodiments of the present invention have been presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the invention to the precise forms disclosed and obviously many modifications and variations are possible in light of the above teaching. The embodiments were chosen and described in order to best explain the principles of the invention and its practical application to thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated. It is intended that the scope of the invention be defined by the claims appended hereto and their equivalents.

