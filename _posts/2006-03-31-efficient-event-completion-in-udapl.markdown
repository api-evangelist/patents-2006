---

title: Efficient event completion in UDAPL
abstract: A technique in accordance with one embodiment of the invention uses an adaptive algorithm to obtain UDAPL event messages. According to one aspect, a process repetitively performs the following steps as long as the process expects to receive at least one event message. By polling the event message queue at least once, the process determines whether the queue is empty. If the queue is empty, then the process blocks until specified criteria have been satisfied. Alternatively, if the queue is not empty, the process reads an event message from the queue. After the process has either read an event message from the event message queue or finished blocking, the foregoing steps are repeated if the process still expects to receive at least one more event message. According to one aspect, when the process blocks, the process blocks only until a specified number of event messages have arrived in the queue.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07577712&OS=07577712&RS=07577712
owner: Sun Microsystems, Inc.
number: 07577712
owner_city: Santa Clara
owner_country: US
publication_date: 20060331
---
Remote Direct Memory Access RDMA is a communications technique that allows data to be transmitted from the memory of one computer to the memory of another remote computer without the data passing through either computer s central processing unit CPU and without calling an operating system kernel. RDMA was developed largely in response to increasing demands for network speed. Generally speaking data can be transferred faster when the data does not have to pass through a CPU.

The InfiniBand computing architecture for example enables RDMA. InfiniBand has gradually been replacing the previously standard Peripheral Component Interconnect PCI bus architecture in certain servers and personal computers. While the PCI architecture sends data in parallel the InfiniBand architecture sends data in serial but concurrently carries multiple channels of data in a multiplexed signal.

In order to allow programmers to code their programs in such a way that their programs can reap the benefits of RDMA industry groups have collaborated and produced the User Direct Access Programming Library UDAPL . UDAPL is an Application Programming Interface API that defines methods that a program can invoke in order to perform RDMA operations. For example UDAPL defines a method that when invoked causes a computer to read from a remote memory region. For another example UDAPL defines a method that when invoked causes a computer to write to a remote memory region.

UDAPL operations are asynchronous. Much like the way a person might deposit a letter into a mailbox for delivery and then go on with life without waiting for a response to that letter a program that invokes a UDAPL method may go on performing other operations without waiting for any acknowledgement that the operations that should have been performed by that method actually were performed. However because programs often need some assurance that specified operations actually were performed prior to performing other operations UDAPL implements an event system.

Under the event system events are automatically generated in response to the completion of UDAPL operations. When an event is generated an event message is automatically inserted into an event dispatcher queue. A program interested in knowing whether a UDAPL operation completed is responsible for determining whether the corresponding event message was placed in the event dispatcher queue. The UDAPL API provides methods that a program can invoke in order to help make this determination.

One such method dat evd dequeue causes the invoking process to poll the event dispatcher queue in an attempt to discover whether the queue contains a specified event message. While the process is polling the event dispatcher queue other processes are precluded from using the CPU. If a process continuously invokes dat evd dequeue until a desired event message is found within the event dispatcher queue then other concurrently executing processes will be forced to wait until the desired event message is found before the CPU can perform any more of those other processes operations. This monopolization of the CPU may be unacceptable in many multiprocessing and or multi user scenarios.

Another method provided by UDAPL dat evd wait causes the invoking process to block until specified criteria passed as a parameter to the method are satisfied. When a process begins blocking the operating system may store that process in memory data to a hard disk drive. While the process is blocking the CPU may perform other process operations thus the blocked process does not monopolize the CPU. When the specified criteria are satisfied and the process ceases blocking the operating system may load the process data into volatile memory from the hard disk drive so that the CPU can continue operating on that data. This loading is part of what is called a context switch. Although the dat evd wait method avoids CPU monopolization the context switch that is sometimes performed when blocking ceases often requires a substantial amount of time to perform. As a result the performance of the process that was blocking can suffer. Some real time applications cannot tolerate significant quantities of such performance penalties.

Thus the use of either of these UDAPL event handling methods has an associated drawback. Previous approaches for determining whether a UDAPL event was completed tended to suffer either from CPU monopolization or performance penalties related to context switching.

A technique in accordance with one embodiment of the invention employs an adaptive algorithm that avoids CPU monopolization while also reducing the latency that results from extensive blocking. Typically for each UDAPL operation that a process has initiated the process expects to receive a separate corresponding event message as an acknowledgement that the UDAPL operation actually has completed. According to one embodiment of the invention a process continuously and repetitively performs the following steps as long as the process expects to receive at least one event message.

By polling the event message queue at least once the process determines whether the event message queue is empty. In response to determining that the event message queue is empty the process blocks until specified criteria some of which are described below have been satisfied. While the process is blocking the CPU can perform other processes operations. Alternatively in response to determining that the event message queue is not empty the process reads at least one event message from the event message queue. After the process has either read at least one event message from the event message queue or finished blocking as described above the foregoing steps are repeated if the process still expects to receive at least one more event message.

According to one embodiment of the invention when the process blocks the process blocks until and only until at least a specified number of event messages e.g. the total remaining number of event messages that the process still expects to receive have arrived in the event message queue. According to one embodiment of the invention after a process has finished blocking the process does not block again as long as at least one event message remains in the event message queue. Instead the process reads event messages from the event message queue until the event message queue is empty.

As a result of the foregoing embodiment of the invention processes do not monopolize the CPU by incessantly polling the event message queue until all expected messages have been received. Additionally processes do not block longer than necessary or a greater number of times than is necessary. By reducing the number of times that processes block fewer context switches are performed. Because fewer context switches are performed fewer performance penalties are incurred.

According to a technique described herein a process enters a loop of execution from which the process does not exit until the process no longer expects to receive any more event messages this condition occurs when the process has received a number of event messages equal to the number of corresponding operations that the process has initiated . While in the loop the process first determines whether the event message queue currently contains any messages. If the process determines that the event message queue contains at least one event message then the process reads an event message from the event message queue thereby removing the event message from the event message queue and the loop repeats without causing the process to block. Thus as long as at least one event message remains in the message queue the process continuously reads and removes event messages from the event message queue until no more event messages remain in the message queue.

Alternatively if the process determines that the event message queue is empty then the process blocks until the event message queue contains at least the number of event messages that the process still expects to receive. While the process is blocking the CPU can perform other processes operations thereby avoiding CPU monopolization. When the event message queue contains at least the number of event messages that the process still expects to receive the process ceases blocking and the loop repeats. This time when the loop repeats the process will be able to read all of the expected event messages from the event message queue as described above without blocking again. Because the process will typically not need to block more than once there are fewer opportunities for the operating system to perform a context switch that involves the process. Fewer context switches performed relative to the process equates to reduced latency and higher process performance.

In block a variable nready is set to 1. At any given time the value of the variable nready indicates a quantity of event messages that are assumed to be or actually are currently in the event message queue. Initially an assumption is made that at least one event message is contained in the event message queue.

In block a variable remaining dtos is set equal to the number of data transfer operations DTOs that the process has initiated. According to one embodiment of the invention the DTOs are UDAPL operations that the process has initiated by invoking certain methods of the UDAPL API e.g. dat cr accept dat ep create dat ep connect dat ep disconnect dat lmr create dat lmr free dat rmr create dat rmr free dat rmr bind dat evd post send dat evd post recv dat evd post rdma write dat evd post rdma read etc. . At any given time the value of the variable remaining dtos indicates a quantity of operations that the process has initiated but for which the process has not yet received acknowledgements of completion in the form of event messages corresponding to the operations.

In block a determination is made as to whether the value of remaining dtos is greater than zero. If the value of remaining dtos is greater than zero then control passes to block . Otherwise the adaptive technique described herein is completed the process does not expect to receive any more event messages and the process resumes performing other specified operations.

In block a determination is made as to whether the value of nready is greater than zero. If the value of nready is greater than zero then control passes to block . Otherwise control passes to block .

In block a variable status is assigned the value that is returned by the invocation of the UDAPL dat evd dequeue method. The dat evd dequeue method determines whether the event message queue contains at least one event message. If the event message queue contains at least one event message then the dat evd dequeue method reads an event message from the message queue thereby removing that event message from the message queue. If the dat evd dequeue method successfully read an event message from the message queue then the dat evd dequeue method returns a value DTO SUCCESS which may be defined as any unique specified value . Alternatively if the dat evd dequeue method was unable to read an event message from the message queue because the message queue was empty then the dat evd dequeue method returns a value QUEUE EMPTY which may be defined as any unique specified value .

In block a determination is made as to whether value of status is equal to QUEUE EMPTY. If the value of status is equal to QUEUE EMPTY then control passes to block . Otherwise control passes to block .

In block the variable status is assigned the value that is returned by the invocation of the UDAPL dat evd wait method. Two parameters are passed to the dat evd wait method in the invocation of the dat evd wait method. One parameter is the value of remaining dtos. The other parameter is a pointer to nready. The invocation of the dat evd wait method causes the process invoking the dat evd wait method the invoking process to begin blocking.

While the invoking process is blocking the operating system may perform a context switch thereby storing the invoking process in memory data to a hard disk drive so that the memory can be used to store other processes data temporarily. While the process invoking the dat evd wait method is blocking the CPU can perform operations on other processes data. Thus by blocking the invoking process refrains from monopolizing the CPU which would have resulted if the invoking process instead had invoked the dat evd dequeue method over and over without interruption until all of the expected event messages had been received and read.

According to one embodiment of the invention when the number of event messages in the event message queue becomes at least as great as the value of remaining dtos which was passed as a parameter to the dat evd wait method the dat evd wait method performs several actions. First the dat evd wait method assigns to the nready variable referred to by the pointer previously passed to dat evd wait as a parameter a value that indicates the number of event messages currently in the event message queue. Next the dat evd wait method causes the invoking process to cease blocking. If a context switch was performed earlier the operating system loads the invoking process data from the hard disk drive back into volatile memory so that the CPU can resume performing operations relative to the invoking process data. After performing the actions discussed above the dat evd wait method returns. Control passes to block .

Usually a process will not need to block more than once while performing the techniques described herein. Consequently the number of potential context switches that the operating system might perform is reduced. As a result processes employing the techniques described herein suffer fewer performance penalties.

In block a determination is made as to whether value of status is equal to DTO SUCCESS. If the value of status is equal to DTO SUCCESS then control passes to block . Otherwise control passes back to block in which the technique loops if the process expects to receive any additional event messages.

In block the value of nready is decremented by one. This is because the number of messages currently contained in the event message queue was reduced by one when the method dat evd dequeue successfully read an event message in block as evidenced by the method s return of DTO SUCCESS value rather than QUEUE EMPTY . Control passes to block .

In block the value of remaining dtos is decremented by one. This is because the number of messages that the process still expects to receive was reduced by one when the method dat evd dequeue successfully read an event message in block as evidenced by the method s return of DTO SUCCESS value rather than QUEUE EMPTY . Control passes back to block in which the technique loops if the process expects to receive any additional event messages.

Thus the above technique allows a process to receive UDAPL events without monopolizing the CPU and without incurring undue quantities of performance penalties related to context switching.

In an embodiment of the invention described above the dat evd dequeue method is invoked only once per each iteration of block . Thus under circumstances in which the event message queue is empty the process will only poll the event message queue once before blocking. This helps to prevent the process from monopolizing the CPU.

However in an alternative embodiment of the invention the dat evd dequeue method is invoked multiple times i.e. two or more to determine whether an event message has arrived in the event message queue before the process blocks. In such an alternative embodiment of the invention the process may attempt to dequeue an event message from the message queue a specified number of times before the process yields the CPU to other processes by blocking. Although such multiple attempts may allow the process to preclude other processes from using the CPU for a longer time interval this alternative embodiment of the invention may help to reduce the latency experienced by a time critical process even further.

Computer system may be coupled via bus to a display such as a cathode ray tube CRT for displaying information to a computer user. An input device including alphanumeric and other keys is coupled to bus for communicating information and command selections to processor . Another type of user input device is cursor control such as a mouse a trackball or cursor direction keys for communicating direction information and command selections to processor and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes a first axis e.g. x and a second axis e.g. y that allows the device to specify positions in a plane.

In computer system bus may be any mechanism and or medium that enables information signals data etc. to be exchanged between the various components. For example bus may be a set of conductors that carries electrical signals. Bus may also be a wireless medium that carries wireless signals between one or more of the components. Bus may also be a medium that enables signals to be capacitively exchanged between one or more of the components. Bus may further be a network connection that connects one or more of the components. Overall any mechanism and or medium that enables information signals data etc. to be exchanged between the various components may be used as bus .

Bus may also be a combination of these mechanisms media. For example processor may communicate with storage device wirelessly. In such a case the bus from the standpoint of processor and storage device would be a wireless medium such as an electromagnetic wave. Further processor may communicate with ROM capacitively. In this instance the bus would be the medium that enables this capacitive communication to take place. Further processor may communicate with main memory via a network connection. In this case the bus would be the network connection. Further processor may communicate with display via a set of conductors. In this instance the bus would be the set of conductors. Thus depending upon how the various components communicate with each other bus may take on different forms. Bus as shown in functionally represents all of the mechanisms and or media that enable information signals data etc. to be exchanged between the various components.

The invention is related to the use of computer system for implementing the techniques described herein. According to one embodiment of the invention those techniques are performed by computer system in response to processor executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory from another machine readable medium such as storage device . Execution of the sequences of instructions contained in main memory causes processor to perform the process steps described herein. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus embodiments of the invention are not limited to any specific combination of hardware circuitry and software.

The term machine readable medium as used herein refers to any medium that participates in providing data that causes a machine to operation in a specific fashion. In an embodiment implemented using computer system various machine readable media are involved for example in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example optical or magnetic disks such as storage device . Volatile media includes dynamic memory such as main memory . Transmission media includes coaxial cables copper wire and fiber optics including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves such as those generated during radio wave and infra red data communications.

Common forms of machine readable media include for example a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium a CD ROM any other optical medium punchcards papertape any other physical medium with patterns of holes a RAM a PROM and EPROM a FLASH EPROM any other memory chip or cartridge a carrier wave as described hereinafter or any other medium from which a computer can read.

Various forms of machine readable media may be involved in carrying one or more sequences of one or more instructions to processor for execution. For example the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system can receive the data on the telephone line and use an infra red transmitter to convert the data to an infra red signal. An infra red detector can receive the data carried in the infra red signal and appropriate circuitry can place the data on bus . Bus carries the data to main memory from which processor retrieves and executes the instructions. The instructions received by main memory may optionally be stored on storage device either before or after execution by processor .

Computer system also includes a communication interface coupled to bus . Communication interface provides a two way data communication coupling to a network link that is connected to a local network . For example communication interface may be an integrated services digital network ISDN card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example communication interface may be a local area network LAN card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation communication interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

Network link typically provides data communication through one or more networks to other data devices. For example network link may provide a connection through local network to a host computer or to data equipment operated by an Internet Service Provider ISP . ISP in turn provides data communication services through the worldwide packet data communication network now commonly referred to as the Internet . Local network and Internet both use electrical electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link and through communication interface which carry the digital data to and from computer system are exemplary forms of carrier waves transporting the information.

Computer system can send messages and receive data including program code through the network s network link and communication interface . In the Internet example a server might transmit a requested code for an application program through Internet ISP local network and communication interface .

Processor may execute the received code as the code is received and or stored in storage device or other non volatile storage for later execution. In this manner computer system may obtain application code in the form of a carrier wave.

In the foregoing specification embodiments of the invention have been described with reference to numerous specific details that may vary from implementation to implementation. Thus the sole and exclusive indicator of what is the invention and is intended by the applicants to be the invention is the set of claims that issue from this application in the specific form in which such claims issue including any subsequent correction. Any definitions expressly set forth herein for terms contained in such claims shall govern the meaning of such terms as used in the claims. Hence no limitation element property feature advantage or attribute that is not expressly recited in a claim should limit the scope of such claim in any way. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

