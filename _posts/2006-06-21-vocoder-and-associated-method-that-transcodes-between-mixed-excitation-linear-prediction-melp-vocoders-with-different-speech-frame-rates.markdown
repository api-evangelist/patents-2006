---

title: Vocoder and associated method that transcodes between mixed excitation linear prediction (MELP) vocoders with different speech frame rates
abstract: A vocoder and method transcodes Mixed Excitation Linear Prediction (MELP) encoded data for use at different speech frame rates. Input data is converted into MELP parameters such as used by a first MELP vocoder. These parameters are buffered and a time interpolation is performed on the parameters with quantization to predict spaced points. An encoding function is performed on the interpolated data as a block to produce a reduction in bit-rate as used by a second MELP vocoder at a different speech frame rate than the first MELP vocoder.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08589151&OS=08589151&RS=08589151
owner: Harris Corporation
number: 08589151
owner_city: Melbourne
owner_country: US
publication_date: 20060621
---
The present invention relates to communications more particularly the present invention relates to voice coders vocoders used in communications.

Voice coders also termed vocoders are circuits that reduce bandwidth occupied by voice signals such as by using speech compression technology and replace voice signals with electronically synthesized impulses. For example in some vocoders an electronic speech analyzer or synthesizer converts a speech waveform to several simultaneous analog signals. An electronic speech synthesizer can produce artificial sounds in accordance with analog control signals. A speech analyzer can convert analog waveforms to narrow band digital signals. Using some of this technology a vocoder can be used in conjunction with a key generator and modulator demodulator device to transmit digitally encrypted speech signals over a normal narrow band voice communication channel. As a result the bandwidth requirements for transmitting digitized speech signals are reduced.

A new military standard vocoder MIL STD 3005 algorithm is referred to as the Mixed Excitation Linear Prediction MELP which operates at 2.4 Kbps. When a vocoder is operated using this algorithm it has good voice quality under benign error channels. When the vocoder is subjected to a HF channel with typical power output of a ManPack Radio MPR however the vocoder speech quality is degraded. It has been found that a 600 bps vocoder provides a significant increase in secure voice availability relative to the 2.4 Kbps vocoder.

A need exists for a low rate speech vocoder with the same or better speech quality and intelligibility as compared to that of a typical 2.4 Kbps Linear Predictive Coding LPC10e based system. A MELP speech vocoder at 600 bps would take advantage of robust and lower bit rate waveforms than the current 2.4 Kbps LPC10e standard and also benefit from better speech quality of the MELP vocoder parametric model. Tactical ManPack Radios MPR typically require lower bit rate waveforms to ensure 24 hour connectivity using digital voice. Once HF users receive reliable good quality digital voice wide acceptance will provide for better security by all users. An HF user will also benefit from the inherent digital squelch of digital voice and the elimination of atmospheric noise in the receive audio.

Current 2.4 Kbps vocoders using the LPC10e standard have been widely used within encrypted voice systems on HF channels. A 2.4 Kbps system however allows for communication on narrow band HF channels with only limited success. A typical 3 kHz channel requires a relatively high signal to noise ratio SNR to allow reliable secure communications at the standard 2.4 Kbps bit rate. Even use of MIL STD 188 110B waveforms at 2400 bps would still require a 3 kHz SNR of more than 12 dB to provide a usable communication link over a typical fading channel.

While HF channels typically permit a 2400 bps channel using LPC10e to be relatively error free the voice quality is still marginal. Speech intelligibility and acceptability of these systems are limited to the amount of background noise level at the microphone. The intelligibility is further degraded by the low end frequency response of communications handsets such as the military H 250. The MELP speech model has an integrated noise pre processor that improves sensitivity in the vocoder to both background noise and low end frequency roll off. The 600 bps MELP vocoder would benefit from this type of noise pre processor and the improved low end frequency insensitivity of the MELP model.

In some systems vocoders are cascaded which degrades the speech intelligibility. A few cascades can reduce intelligibility below usable levels for example RF 6010 standards. Transcoding between cascades greatly reduces the intelligibility loss in which digital methods are used instead of analog. Transcoding between vocoders with different frame rates and technology has been found difficult however. There are also known systems that transcode between like vocoders to change bit rates. One prior art proposal has created transcoding between LPC10 and MELPe. A source code can also provide MELP transcoding between MELP1200 and 2400 systems.

A vocoder and associated method transcodes Mixed Excitation Linear Prediction MELP encoded data for use at different speech frame rates. Input data is converted into MELP parameters used by a first MELP vocoder. These parameters are buffered and a time interpolation is performed on the parameters with quantization to predict spaced points. An encoding function is performed on the interpolated data as a block to produce a reduction in bit rate as used by a second MELP vocoder at a different speech frame rate than the first MELP vocoder.

In yet another aspect the bit rate is transcoded with a MELP 2400 vocoder to bit rates used with a MELP 600 vocoder. The MELP parameters can be quantized for a block of voice data from unquantized MELP parameters of a plurality of successive frames within a block. An encoding function can be performed by obtaining unquantized MELP parameters and combining frames to form one MELP 600 BPS frame creating unquantized MELP parameters quantizing the MELP parameters of the MELP 600 BPS frame and encoding them into a serial data stream. The input data can be converted into MELP 2400 parameters. The MELP 2400 parameters can be buffered using one frame of delay. Twenty five millisecond spaced points can be predicted and in one aspect the bit rate is reduced by a factor of four.

In yet another aspect a vocoder and associated method transcodes Mixed Excitation Linear Prediction MELP encoded data by performing a decoding function on input data in accordance with parameters used by a second MELP vocoder at a different speech frame rate. The sampled speech parameters are interpolated and buffered and an encoding function on the interpolated parameters is performed to increase the bit rate. The interpolation can occur at 22.5 millisecond sampled speech parameters and buffering interpolated parameters can occur at about one frame. The bit rate can be increased by a factor of four.

The present invention will now be described more fully hereinafter with reference to the accompanying drawings in which preferred embodiments of the invention are shown. This invention may however be embodied in many different forms and should not be construed as limited to the embodiments set forth herein. Rather these embodiments are provided so that this disclosure will be thorough and complete and will fully convey the scope of the invention to those skilled in the art. Like numbers refer to like elements throughout.

As general background for purposes of understanding the present invention it should be understood that Linear Predictive Coding LPC is a speech analysis system and method that encodes speech at a low bit rate and provides accurate estimates of speech parameters for computation. LPC can analyze a speech signal by estimating the formants as a characteristic component of the quality of a speech sound. For example several resonant bands help determine the frenetic quality of a value. Their effects are removed from a speech signal and the intensity and frequency of the remaining buzz is estimated. Removing the formants can be termed inverse filtering and the remaining signal termed a residue. The numbers describing the formants and the residue can be stored or transmitted elsewhere.

LPC can synthesize a speech signal by reversing the process and using the residue to create a source signal using the formants to create a filter representing a tube and running the source through the filter resulting in speech. Speech signals vary with time and the process is accomplished on small portions of a speech signal called frames with usually 30 to 50 frames per second giving intelligible speech with good compression.

A difference equation can be used to determine formants from a speech signal to express each sample of the signal as a linear combination of previous samples using a linear predictor i.e. linear predictive coding LPC . The coefficients of a difference equation as prediction coefficients can characterize the formants such that the LPC system can estimate the coefficients by minimizing the mean square error between the predicted signal and the actual signal. Thus the computation of a matrix of coefficient values can be accomplished with a solution of a set of linear equations. The autocorrelation covariance or recursive lattice formulation techniques can be used to assure convergence to a solution.

There is a problem with tubes that have side branches however. For example for ordinary vowels a vocal tract is represented by a single tube but for nasal sounds there are side branches. Thus nasal sounds require more complicated algorithms. Because some consonants are produced by a turbulent air flow resulting in a hissy sound the LPC encoder typically must decide if a sound source is a buzz or hiss and estimate frequency and intensity and encode information such that a decoder can undo the steps. The LPC 10e algorithm uses one number to represent the frequency of the buzzer and the number 0 to represent hiss. It is also possible to use a code book as a table of typical residue signals in addition to the LPC 10e. An analyzer could compare residue to entries in a code book and choose an entry that has a close match and send the code for that entry. This could be termed code excited linear prediction CELP . The LPC 10e algorithm is described in federal standard 1015 and the CELP algorithm is described in federal standard 1016 the disclosures which are hereby incorporated by reference in their entirety.

The mixed excitation linear predictive MELP vocoder algorithm is the 2400 bps federal standard speech coder selected by the United States Department of Defense DOD digital voice processing consortion DDVPC . It is somewhat different than the traditional pitch excited LPC vocoders that use a periodic post train or white noise as an excitation foreign all pole synthesis filter in which vocoders produce intelligible speech at very low bit rates that sound mechanical buzzy. This typically is caused by the inability of a simple pulse train to reproduce voiced speech.

A MELP vocoder uses a mixed excitation model based on a traditional LPC parametric model but includes the additional features of mixed excitation periodic pulses pulse dispersion and adaptive spectral enhancement. Mixed excitation uses a multi band mixing model that simulates frequency dependant voicing strength with adaptive filtering based on a fixed filter bank to reduce buzz. With input speeches voice the MELP vocoder synthesizes speech using either periodic or aperiodic pulses. The pulse dispersion is implemented using fixed pulse dispersion filters based on a spectrally flattened triangle pulse that spreads the excitation energy with the pitch. An adaptive spectral enhancement filter based on the poles of the LPC vocal tract filter can enhance the formant structure in synthetic speech. The filter can improve the match between synthetic and natural bandpass waveforms and introduce a more natural quality to the speech output. The MELP coder can use Fourier Magnitude Coding of the prediction residual to improve speech quality and vector quantization techniques to encode the LPC and Fourier information.

In one accordance with non limiting examples of the present invention a vocoder transcodes the US DoD s military vocoder standard defined in MIL STD 3005 at 2400 bps to a fixed bit rate of 600 bps without performing MELPe 2400 analysis. This process is reversible such that MELPe 600 can be transcoded to MELPe 2400. Telephony operation can be improved when multiple rate bit rate changes are necessary when using a multi hop network. The typical analog rate change when cascading vocoders at different bit rates can quickly degrade the voice quality. The invention discussed here allows multiple rate changes 2400 600 2400 600 . . . without severely degrading the digital speech. It should understood that throughout this description MELP with the suffix e is synonymous with MELP without the e in order to prevent confusion.

The vocoder and associated method can improve the speech intelligibility and quality of a telephony system operating at bit rates of 2400 or 600 bps. The vocoder includes a coding process using the parametric mixed excitation linear prediction model of the vocal tract. The resulting 600 bps speech achieves very high Diagnostic Rhyme Test DRT a measure of speech intelligibility and Diagnostic Acceptability Measure DAM a measure of speech quality scores than vocoders at similar bit rates. The resulting 600 bps vocoder is used in a secure communication system allowing communication on high frequency HF radio channels under very poor signal to noise ratios and or under low transmit power conditions. The resulting MELP 600 bps vocoder results in a communication system that allows secure speech radio traffic to be transferred over more radio links more often throughout the day than the MELP 2400 based system. Backward compatibility can occur by transcoding MELP 600 to MELP 2400 for systems that run at higher rates or that do not support MELP 600.

In accordance with a non limiting example of the present invention a digital transcoder is operative at MELPe 2400 and MELPe 600 using transcoding as the process of encoding or decoding between different application formats or bit rates. It is not considered cascading vocoders. In accordance with one non limiting example of the present invention the vocoder and associated method converts between MELP 2400 MELP 600 data formats in real time with a four rate increase or reduction although other rates are possible. The transcoder can use an encoded bit stream. The process is lossy during the initial rate change only when multiple rate changes do not rapidly degrade speech quality after the first rate change. This allows MELPe 2400 only capable systems to operate with high frequency HF HF MELPe 600 capable systems.

The vocoder and method improves RF6010 multi hop HF VHF link speech quality. It can use a complete digital system with a vocoder analysis and synthesis running once per link independent of number of up down conversions rate changes . Speech distortion can be minimized to the first rate change and a minimal increase in speech distortion can occur with the number of rate changes. Network loading can decrease from 64K to 2.4K and use compressed speech over network. The F2 H requires transcoding SW and a 25 ms increase in audio delay during transcoding.

The system can have digital VHF F secure voice retransmission for F2 H and F2 F F2 V radios and would allow MELPe 600 operation into a US DoD MELPe based VOIP system. The system could provide US DoD NATO MELPe 2400 ineroperability with an MELPe 600 vocoder such as manufactured by Harris Corporation of Melbourne Fla. For purposes of illustration an example of speech with RF 6010 is shown below 

The vocoder and associated method uses an improved algorithm for an MELP 600 vocoder to send and receive data from a MIL STD NATO MELPe 2400 vocoder. An improved RF 6010 system could allow better speech quality using a transcoding base system MELP analysis and synthesis would be preformed only once over a multi hop network.

In accordance with one non limiting example of the present invention it is possible to transcode down from 2400 to 600 and convert input data into MELP 2400 parameters. There is a one frame delay with buffer parameters and the system and method can perform time interpolation of parameters with quantization to predict 25 ms spaced points . Thus it is possible to perform a MELP 600 analysis on interpolated data with a block of four. This results in a factor of four reduction and a bit rate that is now compatible with a MELP 600 vocoder such that MELP 2400 data is received and MELP 600 data is transmitted from a system.

It is also possible to transcode up from 600 to 2400 and perform MELPe 600 synthesis on input data. A vocoder would interpolate 22.5 ms sampled speech parameters and buffer interpolated parameters at one frame. The MELP 2400 analysis can be performed on the interpolated parameters. This results in a factor of four increase in bit rate that is now compatible with MIL STD NATO MELP 2400 to allow MELP 600 data to be received and MELP 2400 data to be transmitted.

The vocoder and associated method in accordance with the non limiting aspect of the invention can transcode bit rates between vocoders with different speech frame rates. The analysis window can be a different size and would not have to be locked between rate changes. A change in frame rate would not present additional distortion after the initial rate change. It is possible for the algorithm to have better quality digital voice on the RF 6010 cross net links. The AN PRC 117F does not support MELPe 600 but uses the algorithm to communicate with an AN PRC 150C running MELPe 600 over the air using an RF6010 system. The AN PRC 150C runs the transcoding and the AN PRC 150C has the ability to perform both transmit and receive transcoding using an algorithm in accordance with one non limiting aspect of the present invention.

An example of a communications system that can be used with the present invention is now set forth with regard to .

An example of a radio that could be used with such system and method is a Falcon III radio manufactured and sold by Harris Corporation of Melbourne Fla. It should be understood that different radios can be used including software defined radios that can be typically implemented with relatively standard processor and hardware components. One particular class of software radio is the Joint Tactical Radio JTR which includes relatively standard radio and processing hardware along with any appropriate waveform software modules to implement the communication waveforms a radio will use. JTR radios also use operating system software that conforms with the software communications architecture SCA specification see www.jtrs.saalt.mil which is hereby incorporated by reference in its entirety. The SCA is an open architecture framework that specifies how hardware and software components are to interoperate so that different manufacturers and developers can readily integrate the respective components into a single device.

The Joint Tactical Radio System JTRS Software Component Architecture SCA defines a set of interfaces and protocols often based on the Common Object Request Broker Architecture CORBA for implementing a Software Defined Radio SDR . In part JTRS and its SCA are used with a family of software re programmable radios. As such the SCA is a specific set of rules methods and design criteria for implementing software re programmable digital radios.

The JTRS SCA specification is published by the JTRS Joint Program Office JPO . The JTRS SCA has been structured to provide for portability of applications software between different JTRS SCA implementations leverage commercial standards to reduce development cost reduce development time of new waveforms through the ability to reuse design modules and build on evolving commercial frameworks and architectures.

The JTRS SCA is not a system specification as it is intended to be implementation independent but a set of rules that constrain the design of systems to achieve desired JTRS objectives. The software framework of the JTRS SCA defines the Operating Environment OE and specifies the services and interfaces that applications use from that environment. The SCA OE comprises a Core Framework CF a CORBA middleware and an Operating System OS based on the Portable Operating System Interface POSIX with associated board support packages. The JTRS SCA also provides a building block structure defined in the API Supplement for defining application programming interfaces APIs between application software components.

The JTRS SCA Core Framework CF is an architectural concept defining the essential core set of open software Interfaces and Profiles that provide for the deployment management interconnection and intercommunication of software application components in embedded distributed computing communication systems. Interfaces may be defined in the JTRS SCA Specification. However developers may implement some of them some may be implemented by non core applications i.e. waveforms etc. and some may be implemented by hardware device providers.

For purposes of description only a brief description of an example of a communications system that would benefit from the present invention is described relative to a non limiting example shown in . This high level block diagram of a communications system includes a base station segment and wireless message terminals that could be modified for use with the present invention. The base station segment includes a VHF radio and HF radio that communicate and transmit voice or data over a wireless link to a VHF net or HF net each which include a number of respective VHF radios and HF radios and personal computer workstations connected to the radios . Ad hoc communication networks are interoperative with the various components as illustrated. Thus it should be understood that the HF or VHF networks include HF and VHF net segments that are infrastructure less and operative as the ad hoc communications network. Although UHF radios and net segments are not illustrated these could be included.

The HF radio can include a demodulator circuit and appropriate convolutional encoder circuit block interleaver data randomizer circuit data and framing circuit modulation circuit matched filter circuit block or symbol equalizer circuit with an appropriate clamping device deinterleaver and decoder circuit modem and power adaptation circuit as non limiting examples. A vocoder circuit can incorporate the decode and encode functions and a conversion unit which could be a combination of the various circuits as described or a separate circuit. These and other circuits operate to perform any functions necessary for the present invention as well as other functions suggested by those skilled in the art. Other illustrated radios including all VHF mobile radios and transmitting and receiving stations can have similar functional circuits.

The base station segment includes a landline connection to a public switched telephone network PSTN which connects to a PABX . A satellite interface such as a satellite ground station connects to the PABX which connects to processors forming wireless gateways . These interconnect to the VHF radio or HF radio respectively. The processors are connected through a local area network to the PABX and e mail clients . The radios include appropriate signal generators and modulators.

An Ethernet TCP IP local area network could operate as a radio mail server. E mail messages could be sent over radio links and local air networks using STANAG 5066 as second generation protocols waveforms the disclosure which is hereby incorporated by reference in its entirety and of course preferably with the third generation interoperability standard STANAG 4538 the disclosure which is hereby incorporated by reference in its entirety. An interoperability standard FED STD 1052 the disclosure which is hereby incorporated by reference in its entirety could be used with legacy wireless devices. Examples of equipment that can be used in the present invention include different wireless gateway and radios manufactured by Harris Corporation of Melbourne Fla. This equipment could include RF800 5022 7210 5710 5285 and PRC 117 and 138 series equipment and devices as non limiting examples.

These systems can be operable with RF 5710A high frequency HF modems and with the NATO standard known as STANAG 4539 the disclosure which is hereby incorporated by reference in its entirety which provides for transmission of long distance HF radio circuits at rates up to 9 600 bps. In addition to modem technology those systems can use wireless email products that use a suite of data link protocols designed and perfected for stressed tactical channels such as the STANAG 4538 or STANAG 5066 the disclosures which are hereby incorporated by reference in their entirety. It is also possible to use a fixed non adaptive data rate as high as 19 200 bps with a radio set to ISB mode and an HF modem set to a fixed data rate. It is possible to use code combining techniques and ARQ.

As illustrated in the steps shown in MELP 2400 channel parameters with electronic counter countermeasures ECCOM are decoded Block . Prediction coefficients from line spectral frequencies LSF are generated Block . Perceptual inverse power spectrum weights are generated block . The current MELP 2400 parameters are pointed block . If the number of frames is greater than or equal to 2 block the update of interpolation values occurs block . The interpolation of new parameters includes pitch line spectral frequencies gain jitter bandpass voice unvoiced and voiced data and weights Block . If at the step for Block the answer is no then the steps for Blocks and are skipped. The number of frames has been determined Block and the MELP 600 encode process occurs Block . The MELP 600 algorithm such as disclosed in the 914 patent is preferably used. The previous input parameters are saved Block and the advanced state occurs Block and the return occurs Block .

Greater details of the transcoding up from MELP 600 to MELP 2400 are shown in as a non limiting example.

The MELPe 600 decode function occurs on data such as the process disclosed in the 914 patent Block . The current frame decode parameters are pointed at Block and the number of 22.5 millisecond frames are determined for this iteration Block .

This frame s interpolation values are obtained Block and the new parameters interpolated Block . A minimum line sequential frequency LSF is forced to minimum Block and the MELP 2400 encode performed Block . The encoded ECCM MELP 2400 bit stream is written Block and the frame count updated Block . If there are more 22.5 millisecond frames in this iteration Block the process begins again at Block . If not a comparison is made Block and the 25 millisecond frame counter updated Block . The return is made Block .

It should be understood that an MELP 2400 vocoder can use a Fourier magnitude coding of a prediction residual to improve speech quality and vector quantization techniques to encode the LPC Fourier information. An MELP 2400 vocoder can include 22.5 millisecond frame size and an 8 kHz sampling rate. An analyzer can have a high pass filter such as a fourth order Chebychev type II filter with a cut off frequency of about 60 Hz and a stopband rejection of about 30 dB. Butterworth filters can be used for bandpass voicing analysis. The analyzer can include linear prediction analysis and error protection with hamming codes. Any synthesizer could use mixed excitation generation with a sum of a filtered pulse and noise excitations. An inverse discrete Fourier transform of one pitch period in length and noise can be used and a uniform random number generator used. A pulse filter could have a sum of bandpass filter coefficients for voiced frequency bands and a noise filter could have a sum of bandpass filter coefficients for unvoiced frequency bands. An adaptive spectral enhancement filter could be used. There could also be linear prediction synthesis with a direct form filter and a pulse dispersion.

There is now described a 600 bps MELP vocoder algorithm that can take advantage of inherit inter frame redundancy of MELP parameters which could be used with the algorithm as described in accordance with non limiting examples of the present invention. Some data is presented showing the advantage in both diagnostic acceptability measure DAM and diagnostic rhyme test DTR with respect to the signal to noise ratio SNR on a typical HF channel when using the vocoder with a MIL STD 188 110B waveform. This type of vocoder can be used in the system and method of the present invention.

The 600 bps system uses a conventional MELP vocoder front end a block buffer for accumulating multiple frames of MELP parameters and individual block vector quantizers for MELP parameters. The low rate implementation of MELP uses a 25 ms frame length and the block buffer of four frames for block duration of 100 ms. This yields a total of sixty bits per block of duration 100 ms or 600 bits per second. Examples of the typical MELP parameters as coded are shown in Table 1.

Details of the individual parameter coding methods are covered below followed by a comparison of bit error performance of a Vector Quantized 600 bps LPC10e based vocoder contrasted against a MELP 600 bps vocoder in one non limiting example of the present invention. Results from a Diagnostic Rhyme Test DRT and a Diagnostic Acceptability Measure DAM for MELP 2400 and 600 at several different conditions are explained and compared with the results for LPC10e based systems under similar conditions. The DRT and DAM results represent testing performed by Harris Corporation and the National Security Agency NSA .

It should be understood there is an LPC Speech Model. LPC10e has become popular because it typically preserves much of the intelligibility information and because the parameters can be closely related to human speech production of the vocal tract. LPC10e can be defined to represent the speech spectrum in the time domain rather than in the frequency domain. An LPC10e analysis process or the transmit side produces predictor coefficients that model the human vocal tract filter as a linear combination of the previous speech samples. These predictor coefficients can be transformed into reflection coefficients to allow for better quantization interpolation and stability evaluation and correction. The synthesized output speech from LPC10e can be a gain scaled convolution of these predictor coefficients with either a canned glottal pulse repeated at the estimated pitch rate for voiced speech segments or convolution with random noise representing unvoiced speech.

The LPC10e speech model used two half frame voicing decisions an estimate of the current 22.5 ms frames pitch rate the RMS energy of the frame and the short time spectrum represented by a 10order prediction filter. A small portion of the more important bits of a frame can be coded with a simple hamming code to allow for some degree of tolerance to bit errors. During unvoiced frames more bits are free and used to protect more of the frame from channel errors.

The LPC10e model generates a high degree of intelligibility. The speech however can sound very synthetic and often contains buzzing speech. Vector quantizing of this model to lower rates would still contain the same synthetic sounding speech. The synthetic speech usually only degrades as the rate is reduced. A vocoder that is based on the MELP speech model may offer better sounding quality speech than one based on LPC10e. The vector quantization of the MELP model is possible.

There is also a MELP Speech model. MELP was developed by the U.S. government DoD Digital Voice Processing Consortium DDVPC as the next standard for narrow band secure voice coding. The new speech model represents an improvement in speech quality and intelligibility at the 2.4 Kbps data rate. The algorithm performs well in harsh acoustic noise such as HMMWV s helicopters and tanks. Typically the buzzy sounding speech of LPC10e model is reduced to an acceptable level. The MELP model represents a next generation of speech processing in bandwidth constrained channels.

The MELP model as defined in MIL STD 3005 is based on the traditional LPC10e parametric model but also includes five additional features. These are mixed excitation aperiodic pulses pulse dispersion adaptive spectral enhancement and Fourier magnitudes scaling of the voiced excitation.

The mixed excitation is implemented using a five band mixing model. The model can simulate frequency dependent voicing strengths using a fixed filter bank. The primary effect of this multi band mixed excitation is to reduce the buzz usually associated with LPC10e vocoders. Speech is often a composite of both voiced and unvoiced signals. MELP performs a better approximation of the composite signal than the Boolean voiced unvoiced decision of LPC10e.

The MELP vocoder can synthesize voiced speech using either periodic or aperiodic pulses. Aperiodic pulses are most often used during transition regions between voiced and unvoiced segments of the speech signal. This feature allows the synthesizer to reproduce erratic glottal pulses without introducing tonal noise.

Pulse dispersion can be implemented using a fixed pulse dispersion filter based on a spectrally flattened triangle pulse. The filter is implemented as a fixed finite impulse response FIR filter. The filter has the effect of spreading the excitation energy within a pitch period. The pulse dispersion filter aims to produce a better match between original and synthetic speech in regions without a formant by having the signal decay more slowly between pitch pulses. The filter reduces the harsh quality of the synthetic speech.

The adaptive spectral enhancement filter is based on the poles of the LPC vocal tract filter and is used to enhance the formant structure in the synthetic speech. The filter improves the match between synthetic and natural band pass waveforms and introduces a more natural quality to the output speech.

The first ten Fourier magnitudes are obtained by locating the peaks in the FFT of the LPC residual signal. The information embodied in these coefficients improves the accuracy of the speech production model at the perceptually important lower frequencies. The magnitudes are used to scale the voiced excitation to restore some of the energy lost in the 10order LPC process. This increases the perceived quality of the coded speech particularly for males and in the presence of background noise.

There is also MELP 2400 Parameter entropy. The entropy values can be indicative of the existing redundancy in the MELP vocoder speech model. MELP s entropy is shown in Table 2 below. The entropy in bits was measured using the TIMIT speech database of phonetically balanced sentences that was developed by the Massachusetts Institute of Technology MIT SRI International and Texas Instruments TI . TIMIT contains speech from 630 speakers from eight major dialects of American English each speaking ten phonetically rich sentences. The entropy of successive number of frames was also investigated to determine good choices of block length for block quantization at 600 bps. The block length chosen for each parameter is discussed in the following sections.

Vector quantization is the process of grouping source outputs together and encoding them as a single block. The block of source values can be viewed as a vector hence the name vector quantization. The input source vector is compared to a set of reference vectors called a codebook. The vector that minimizes some suitable distortion measure is selected as the quantized vector. The rate reduction occurs as the result of sending the codebook index instead of the quantized reference vector over the channel.

The vector quantization of speech parameters has been a widely studied topic in current research. At low rate of quantization efficient quantization of the parameters using as few bits as possible is essential. Using suitable codebook structure both the memory and computational complexity can be reduced. One attractive codebook structure is the use of a multi stage codebook. In addition the codebook structure can be selected to minimize the effects of the codebook index to bit errors. The codebooks can be designed using a generalized Lloyd algorithm to minimize average weighted mean squared error using the TIMIT speech database as training vectors. A generalized Lloyd algorithm consists of iteratively partitioning the training set into decisions regions for a given set of centroids. New centroids are then re optimized to minimize the distortion over a particular decision region. The generalized Lloyd algorithm could be as follows.

An initial set of codebook values Yand a set of training vectors X. Set k 0 D 0 are used and a threshold is selected 

The average distortion Dbetween the training vectors and the representative codebook value is computed 

k k 1. New codebook values Yare found that are the average value of the elements of each quantization regions V.

The aperiodic pulses are designed to remove the LPC synthesis artifacts of short isolated tones in the reconstructed speech. This occurs mainly in areas of marginally voiced speech when reconstructed speech is purely periodic. The aperiodic flag indicates a jittery voiced state is present in the frame of speech. When voicing is jittery the pulse positions of the excitation are randomized during synthesis based on a uniform distribution around the purely periodic mean position.

Investigation of the run length of the aperiodic state indicates that the run length is normally less than three frames across the TIMIT speech database and over several noise conditions tested. Further if a run of aperiodic voiced frames does occur it is unlikely that a second run will occur within the same block of four frames. It was decided not to send the Aperiodic bit over the channel since the effects on voice quality was not as significant as better quantizing the remaining MELP parameters.

The bandpass voicing BPV strengths control which of the five bands of excitation are voiced or unvoiced in the MELP model. The MELP standard sends the upper four bits individually while the least significant bit is encoded along with the pitch. Table 3 illustrates an example of the probability density function of the five bandpass voicing bits. These five bits can be easily quantized down to only two bits with typically little audible distortion. Further reduction can be obtained by taking advantage of the frame to frame redundancy of the voicing decisions. The current low rate coder can use a four bit codebook to quantize the most probable voicing transitions that occur over a four frame block. A rate reduction from four frames of five bit bandpass voicing strengths can be reduced to four bits. At four bits some audible differences are heard in the quantized speech. However the distortion caused by the bandpass voicing is not offensive.

MELP s energy parameter exhibits considerable frame to frame redundancy which can be exploited by various block quantization techniques. A sequence of energy values from successive frames can be grouped to form vectors of any dimension. In the MELP 600 bps model a vector length of four frames two gain values per frame can be used as a non limiting example. The energy codebook can be created using a K means vector quantization algorithm. The codebook was trained using training data scaled by multiple levels to prevent sensitivity to speech input level. During the codebook training process a new block of four energy values is created for every new frame so that energy transitions are represented in each of the four possible locations within the block. The resulting codebook is searched resulting in a codebook vector that minimizes mean squared error.

For MELP 2400 two individual gain values are transmitted every frame period. The first gain value is quantized to five bits using a 32 level uniform quantizer ranging from 10.0 to 77.0 dB. The second gain value is quantized to three bits using an adaptive algorithm. In the MELP 600 bps model the vector is quantized both of MELP s gain values across four frames. Using the 2048 element codebook the energy bits per frame are reduced from 8 bits per frame for MELP 2400 down to 2.909 bits per frame for MELP 600. Quantization values below 2.909 bits per frame for energy have been investigated but the quantization distortion becomes audible in the synthesized output speech and affected intelligibility at the onset and offset of words.

The excitation information is augmented by including Fourier coefficients of the LPC residual signal. These coefficients or magnitudes account for the spectral shape of the excitation not modeled by the LPC parameters. These Fourier magnitudes are estimated using a FFT on the LPC residual signal. The FFT is sampled at harmonics of the pitch frequency. In the current MIL STD 3005 the lower ten harmonics can be considered more important and are coded using an eight bit vector quantizer over the 22.5 ms frame.

The Fourier magnitude vector is quantized to one of two vectors. For unvoiced frames a spectrally flat vector is selected to represent the transmitted Fourier magnitude. For voiced frames a single vector is used to represent all voiced frames. The voiced frame vector can be selected to reduce some of the harshness remaining in the low rate vocoder. The reduction in rate for the remaining MELP parameters reduce the effect seen at the higher data rates to Fourier magnitudes. No bits are required to perform the above quantization.

The MELP model estimates the pitch of a frame using energy normalized correlation of 1 kHz low pass filtered speech. The MELP model further refines the pitch by interpolating fractional pitch values. The refined fractional pitch values are then checked for pitch errors resulting from multiples of the actual pitch value. It is this final pitch value that the MELP 600 vocoder uses to vector quantize.

MELP s final pitch value is first median filtered order 3 such that some of the transients are smoothed to allow the low rate representation of the pitch contour to sound more natural. Four successive frames of the smoothed pitch values are vector quantized using a codebook with 128 elements. The codebook can be trained using a k means method. The resulting codebook is searched resulting in the vector that minimizes mean squared error of voiced frames of pitch.

The LPC spectrum of MELP is converted to line spectral frequencies LSFs which is one of the more popular compact representations of the LPC spectrum. The LSF s are quantized with a four stage vector quantization algorithm. The first stage has seven bits while the remaining three stages use six bits each. The resulting quantized vector is the sum of the vectors from each of the four stages and the average vector. At each stage in the search process the VQ search locates the M best closest matches to the original using a perceptual weighted Euclidean distance. These M best vectors are used in the search for the next stage. The indices of the final best at each of the four stages determine the final quantized LSF.

The low rate quantization of the spectrum quantizes four frames of LSFs in sequence using a four stage vector quantization process. The first two stages of codebook use ten bits while the remaining two stages use nine bits each. The search for the best vector uses a similar M best technique with perceptual weighting as is used for the MIL STD 3005 vocoder. Four frames of spectra are quantized to only 38 bits.

The codebook generation process uses both the K Means and the generalized Lloyd technique. The K Means codebook is used as the input to the generalized Lloyd process. A sliding window can be used on a selective set of training speech to allow spectral transitions across the four frame block to be properly represented in the final codebook. The process of training the codebook can require significant diligence in selecting the correct balance of input speech content. The selection of training data can be created by repeatedly generating codebooks and logging vectors with above average distortion. This process can remove low probability transitions and some stationary frames that can be represented with transition frames without increasing the over all distortion to unacceptable levels.

The Diagnostic Acceptability Measure DAM and the Diagnostic Rhyme Test DRT are used to compare the performance of the MELP vocoder to the existing LPC based system. Both tests have been used extensively by the US government to quantify voice coder performance. The DAM requires the listeners to judge the detectability of a diversity of elementary and complex perceptual qualities of the signal itself and of the background environment. The DRT is a two choice intelligibility test based upon the principle that the intelligibility relevant information in speech is carried by a small number of distinctive features. The DRT was designed to measure how well information as to the state of six binary distinctive features voicing nasality sustension sibiliation graveness and compactness have been preserved by the communications system under test.

The DRT performance of both MELP based vocoders exceeds the intelligibility of the LPC vocoders for most test conditions. The 600 bps MELP DRT is within just 3.5 points of the higher bit rate MELP system. The rate reduction by vector quantization of MELP has not affected the intelligibility of the model noticeably. The DRT scores for HMMWV demonstrate that the noise pre processor of the MELP vocoders enables better intelligibility in the presence of acoustic noise.

The DAM performance of the MELP model demonstrates the strength of the new speech model. MELP s speech acceptability at 600 bps is more than 4.9 points better than LPC10e 2400 in the quiet test condition which is the most noticeable difference between both vocoders. Speaker recognition of MELP 2400 is much better than LPC10e 2400. MELP based vocoders have significantly less synthetic sounding voice with much less buzz. Audio of MELP is perceived to being brighter and having more low end and high end energy as compared to LPC10e.

Secure voice availability is directly related to the bit error rate performance of the waveform used to transfer the vocoder s data and the tolerance of the vocoder to bit errors. A 1 bit error rate causes both MELP and LPC based coders to degrade voice intelligibility and quality as seen in the example of table 5. The useful range therefore is below approximately a 3 bit error rate for MELP and 1 for LPC based vocoders.

The 1 bit error rate of the MIL STD 188 110B waveforms can be seen for both a Gaussian and CCIR Poor channel in the graphs shown in respectively. The curves indicate a gain of approximately seven dB can be achieved by using the 600 bps waveform over the 2400 bps standard. It is in this lower region in SNR that allows HF links to be functional for a longer portion of the day. In fact many 2400 bps links cannot function below a 1 bit error rate at any time during the day based on propagation and power levels. Typical ManPack Radios using 10 20 W power levels make the choice in vocoder rate even more mission critical.

The MELP vocoder in accordance with one non limiting example can run real time such as on a sixteen bit fixed point Texas Instrument s TMS320VC5416 digital signal processor. The low power hardware design can reside in the Harris RF 5800H PRC 150 ManPack Radio and can be responsible for running several voice coders and a variety of data related interfaces and protocols. The DSP hardware design could run the on chip core at 150 MHz zero wait state while the off chip accesses can be limited to 50 MHz two wait state in these non limiting examples. The data memory architecture can have 64K zero wait state on chip memory and 256K of two wait state external memory which is paged in 32K banks. For program memory the system can have an additional 64K zero wait state on chip memory and 256K of external memory that can be fully addressed by the DSP.

An example of the 2400 bps MELP source code could include Texas Instrument s 54X assembly language source code combined with a MELP 600 vocoder manufactured by Harris Corporation. This code in one non limiting example had been modified to run on the TMS320VC5416 architecture using a FAR CALLING run time environment which allows DSP programs to span more than 64K. The code has been integrated into a C calling environment using TI s C initialize mechanism to initialize MELP s variables and combined with a Harris proprietary DSP operating system.

Run time loading on the MELP 2400 target system allows for Analysis to run at 24.4 loaded the Noise Pre Processor is 12.44 loaded and Synthesis to run at 8.88 loaded. Very little load increase occurs as part of MELP 600 Synthesis since the process is no more than a table lookup. The additional cycles the for MELP 600 vocoder are contained in the vector quantization of the spectrum analysis.

The speech quality of the new MIL STD 3005 vocoder is better than the older FED STD 1015 vocoder. Vector quantization techniques can be used on the new standard vocoder combined with the use of the 600 bps waveform as is defined in U.S. MIL STD 188 110B. The results seem to indicate that a 5 7 dB improvement in HF performance can be possible on some fading channels. Furthermore the speech quality of the 600 bps vocoder is typically better than the existing 2400 bps LPC10e standard for several test conditions. Further on air testing will be required to validate the presented simulation results. If the on air tests confirm the results low rate coding of MELP could be used with the MIL STD 3005 for improved communication and extended availability to ManPack radios on difficult HF links.

Many modifications and other embodiments of the invention will come to the mind of one skilled in the art having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore it is understood that the invention is not to be limited to the specific embodiments disclosed and that modifications and embodiments are intended to be included within the scope of the appended claims.

