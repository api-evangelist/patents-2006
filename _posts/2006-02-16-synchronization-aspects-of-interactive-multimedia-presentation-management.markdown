---

title: Synchronization aspects of interactive multimedia presentation management
abstract: Playing an interactive multimedia presentation involves pre-rendering a media object at certain times based on a frame rate of the interactive content, a frame rate of the video content (which may include video, audio, data, or any combination thereof), and a play speed of the presentation. Certain actions taken include calculating a current elapsed play time representing an amount of the presentation's play duration that has passed. Based on the calculated time, a current interactive content presentation time is ascertained from an interactive content timeline. The interactive content timeline represents times at which the media object is presentable. A subsequent interactive content presentation time is selected from the interactive content timeline. The presentation state of the media object is predicted for the subsequent interactive content presentation time. The media object is pre-rendered within a time offset period before the subsequent interactive content presentation time occurs.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07721308&OS=07721308&RS=07721308
owner: Microsoft Corproation
number: 07721308
owner_city: Redmond
owner_country: US
publication_date: 20060216
---
This application claims the benefit of provisional application No. 60 695 944 filed Jul. 1 2005 which is incorporated by reference herein.

Multimedia players are devices that render combinations of video audio or data content multimedia presentations for consumption by users. Multimedia players such as DVD players currently do not provide for much if any user interactivity during play of video content video content play is generally interrupted to receive user inputs other than play speed adjustments. For example a user of a DVD player must generally stop the movie he is playing to return to a menu that includes options allowing him to select and receive features such as audio commentary actor biographies or games.

Interactive multimedia players are devices such devices may include hardware software firmware or any combination thereof that render combinations of interactive content concurrently with traditional video audio or data content interactive multimedia presentations . Although any type of device may be an interactive multimedia player devices such as optical media players for example DVD players computers and other electronic devices are particularly well positioned to enable the creation of and consumer demand for commercially valuable interactive multimedia presentations because they provide access to large amounts of relatively inexpensive portable data storage.

Interactive content is generally any user selectable visible or audible object presentable alone or concurrently with other video audio or data content. One kind of visible object is a graphical object such as a circle that may be used to identify and or follow certain things within video content people cars or buildings that appear in a movie for example. One kind of audible object is a click sound played to indicate that the user has selected a visible object such as the circle using a device such as a remote control or a mouse. Other examples of interactive content include but are not limited to menus captions and animations.

To enhance investment in interactive multimedia players and interactive multimedia presentations it is desirable to ensure accurate synchronization of the interactive content component of interactive multimedia presentations with the traditional video audio or data content components of such presentations. Accurate synchronization generally prioritizes predictable and glitch free play of the video audio or data content components. For example when a circle is presented around a car in a movie the movie should generally not pause to wait for the circle to be drawn and the circle should follow the car as it moves.

It will be appreciated that the claimed subject matter is not limited to implementations that solve any or all of the disadvantages of specific interactive multimedia presentation systems or aspects thereof.

In general an interactive multimedia presentation includes one or more of the following a play duration a video content component and an interactive content component. The video content component is referred to as a movie for exemplary purposes but may in fact be video audio data or any combination thereof. The video content component is arranged into a number of frames and or samples for rendering by a video content manager. The video frame rate is a periodic time interval within which a particular group of video audio or data samples is presentable.

The interactive content is arranged for rendering by an interactive content manager at an interactive content frame rate that may be different than the video frame rate. For exemplary purposes the interactive content component of the presentation is considered to be in the form of a media object having a presentation state. The media object is presentable at times within the play duration referred to as interactive content presentation times based on the interactive content frame rate. The interactive content presentation times may be conceptualized in the form of an interactive content timeline.

Methods systems apparatuses and articles of manufacture discussed herein for playing an interactive multimedia presentation involve rendering the media object at certain times based on the video frame rate and on the play speed so that the interactive content component and the video content component remain synchronized. Predicting times for pre rendering media objects is useful when the play speed of the presentation changes such as during trick play to ensure frame accurate rendering of the interactive content component and the video content component.

Certain actions taken during play of the presentation include calculating a current elapsed play time representing an amount of time of the play duration that has passed. Based on the current elapsed play time a current interactive content presentation time is then determined from the interactive content timeline. A subsequent interactive content presentation time which occurs at a different perhaps prior or perhaps later time than the current presentation time is selected from the interactive content timeline.

The presentation state of the media object for example whether it is on or off is predicted for the subsequent interactive content presentation time. The media object is then pre rendered in a time offset period before the subsequent interactive content presentation time occurs. It is generally desirable to pre render the media object one frame in advance of the subsequent interactive content presentation time. If media objects are pre rendered too far in advance there is no guarantee that the particular frames will be needed and instructions executed for mis predicted frames cannot be un executed. In addition pre rendering media objects too far in advance may limit the ability to respond to user input in a timely manner. For example when a user presses a virtual button a quick response is desired. Executing numerous predicted frames prior to responding to the button press may cause the user to experience a delayed response.

This Summary is provided to introduce a selection of concepts in a simplified form. The concepts are further described in the Detailed Description section. Elements or steps other than those described in this Summary are possible and no element or step is necessarily required. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended for use as an aid in determining the scope of the claimed subject matter.

Turning to the drawings where like numerals designate like components is a simplified functional block diagram of an interactive multimedia presentation system Presentation System . Presentation System includes an audio video content AVC manager an interactive content IC manager a presentation manager a timing signal management block and a mixer renderer . In general design choices dictate how specific functions of Presentation System are implemented. Such functions may be implemented using hardware software or firmware or combinations thereof.

In operation Presentation System handles interactive multimedia presentation content Presentation Content . Presentation Content includes a video content component video component and an interactive content component IC component . Video component and IC component are generally but need not be handled as separate data streams by AVC manager and IC manager respectively.

Presentation System also facilitates presentation of Presentation Content to a user not shown as played presentation . Played Presentation represents the visible and or audible information associated with Presentation Content that is produced by mixer renderer and receivable by the user via devices such as displays or speakers not shown . For discussion purposes it is assumed that Presentation Content and played presentation represent high definition DVD movie content in any format. It will be appreciated however that Presentation Content and Played Presentation may be any type of interactive multimedia presentation now known or later developed.

Video component represents the traditional video audio or data components of Presentation Content . For example a movie generally has one or more versions a version for mature audiences and a version for younger audiences for example one or more titles with one or more chapters not shown associated with each title titles are discussed further below in connection with presentation manger one or more audio tracks for example the movie may be played in one or more languages with or without subtitles and extra features such as director s commentary additional footage trailers and the like. It will be appreciated that distinctions between titles and chapters are purely logical distinctions. For example a single perceived media segment could be part of a single title chapter or could be made up of multiple titles chapters. It is up to the content authoring source to determine the applicable logical distinctions. It will also be appreciated that although video component is referred to as a movie video component may in fact be video audio data or any combination thereof.

The video audio or data that forms video component originates from one or more media sources for exemplary purposes two media sources are shown within A V manager . A media source is any device location or data from which video audio or data is derived or obtained. Examples of media sources include but are not limited to networks hard drives optical media alternate physical disks and data structures referencing storage locations of specific video audio or data.

Groups of samples of video audio or data from a particular media source are referred to as clips shown within video component AVC manager and playlist . Referring to AVC manager information associated with clips is received from one or more media sources and decoded at decoder blocks . Decoder blocks represent any devices techniques or steps used to retrieve renderable video audio or data content from information received from a media source . Decoder blocks may include encoder decoder pairs demultiplexers or decrypters for example. Although a one to one relationship between decoders and media sources is shown it will be appreciated that one decoder may serve multiple media sources and vice versa.

Audio video content data A V data is data associated with video component that has been prepared for rendering by AVC manager and transmitted to mixer renderer . Frames of A V data generally include for each active clip a rendering of a portion of the clip. The exact portion or amount of the clip rendered in a particular frame may be based on several factors such as the characteristics of the video audio or data content of the clip or the formats techniques or rates used to encode or decode the clip.

IC component includes media objects which are user selectable visible or audible objects optionally presentable concurrently with video component along with any instructions shown as applications and discussed further below for presenting the visible or audible objects. Media objects may be static or animated. Examples of media objects include among other things video samples or clips audio samples or clips graphics text and combinations thereof.

Media objects originate from one or more sources not shown . A source is any device location or data from which media objects are derived or obtained. Examples of sources for media objects include but are not limited to networks hard drives optical media alternate physical disks and data structures referencing storage locations of specific media objects. Examples of formats of media objects include but are not limited to portable network graphics PNG joint photographic experts group JPEG moving picture experts group MPEG multiple image network graphics MNG audio video interleave AVI extensible markup language XML hypertext markup language HTML and extensible HTML XHTML .

Applications provide the mechanism by which Presentation System presents media objects to a user. Applications represent any signal processing method or stored instruction s that electronically control predetermined operations on data. It is assumed for discussion purposes that IC component includes three applications which are discussed further below in connection with . The first application presents a copyright notice prior to the movie the second application presents concurrently with visual aspects of the movie certain media objects that provide a menu having multiple user selectable items and the third application presents one or more media objects that provide graphic overlays such as circles that may be used to identify and or follow one or items appearing in the movie a person a car a building or a product for example .

Interactive content data IC data is data associated with IC component that has been prepared for rendering by IC manager and transmitted to mixer renderer . Each application has an associated queue not shown which holds one or more work items not shown associated with rendering the application.

Presentation manager which is configured for communication with both AVC manager and IC manager facilitates handling of Presentation Content and presentation of played presentation to the user. Presentation manager has access to a playlist . Playlist includes among other things a time ordered sequence of clips and applications including media objects that are presentable to a user. The clips and applications media objects may be arranged to form one or more titles . For exemplary purposes one title is discussed herein. Playlist may be implemented using an extensible markup language XML document or another data structure.

Presentation manager uses playlist to ascertain a presentation timeline for title . Conceptually presentation timeline indicates the times within title when specific clips and applications are presentable to a user. A sample presentation timeline which illustrates exemplary relationships between presentation of clips and applications is shown and discussed in connection with . In certain circumstances it is also useful to use playlist and or presentation timeline to ascertain a video content timeline video timeline and an interactive content timeline IC timeline .

Presentation manager provides information including but not limited to information about presentation timeline to AVC manager and IC manager . Based on input from presentation manger AVC manager prepares A V data for rendering and IC manager prepares IC data for rendering.

Timing signal management block produces various timing signals which are used to control the timing for preparation and production of A V data and IC data by AVC manager and IC manager respectively. In particular timing signals are used to achieve frame level synchronization of A V data and IC data . Details of timing signal management block and timing signals are discussed further below in connection with .

Mixer renderer renders A V data in a video plane not shown and renders IC data in a graphics plane not shown . The graphics plane is generally but not necessarily overlayed onto the video plane to produce played presentation for the user.

With continuing reference to is a graphical illustration of a sample presentation timeline for title within playlist . Time is shown on horizontal axis . Information about video component clips are illustrated and IC component applications which present media objects are illustrated is shown on vertical axis . Two clips are shown a first video clip video clip and a second video clip video clip . For discussion purposes as mentioned above in connection with it is assumed that a first application is responsible for presenting one or more media objects for example images and or text that comprise copyright notice . A second application is responsible for presenting certain media objects that provide user selectable items for example buttons with associated text or graphics of menu . A third application is responsible for presenting one or more media objects that provide graphic overlay . Menu is displayed concurrently with video clip and video clip and graphic overlay is displayable concurrently with video clip and menu .

The particular amount of time along horizontal axis in which title is presentable to the user is referred to as play duration of title . Specific times within play duration are referred to as title times. Four title times TTs are shown on presentation timeline TT TT TT and TT . Because a title may be played once or may be played more than once in a looping fashion for example play duration is determined based on one iteration of title . Play duration may be determined with respect to any desired reference including but not limited to a predetermined play speed for example normal or 1 play speed a predetermined frame rate or a predetermined timing signal status. Play speeds frame rates and timing signals are discussed further below in connection with . It will be appreciated that implementation specific factors such as encoding techniques display techniques and specific rules regarding play sequences and timing relationships among clips and media objects for each title may impact upon exact values of a title s play duration and title times therein. The terms play duration and title times are intended to encompass all such implementation specific details. Although title times at within which content associated with IC component is presentable are generally predetermined it will be appreciated that actions taken when the user interacts with such content may only be determined based on user input while Played Presentation is playing. For example the user may select activate or deactivate certain applications media objects and or additional content associated therewith during play of Played Presentation .

Other times and or durations within play duration are also defined and discussed herein. Video presentation intervals are defined by beginning and ending times of play duration between which particular content associated with video component is playable. For example video clip has a presentation interval between title times TT and TT and video clip has a presentation interval between title times TT and TT . Application presentation intervals application play durations page presentation intervals and page durations are also defined and discussed below in connection with .

With continuing reference to two types of time intervals are present within play duration . A first type of time interval is one in which video component is not scheduled for presentation. Time interval the time preceding presentation of the movie when copyright notice is displayed is an example of the first type of time interval. Although the application that presents copyright notice is scheduled for presentation during time interval it will be appreciated that it is not necessary for an application to be scheduled for presentation during the first type of time interval.

A second type of time interval is one in which video component is scheduled for presentation. Time interval and time interval are examples of the second type of time interval. Sometimes more than one video may be scheduled for presentation during the second type of time interval. Often but not always interactive content is presentable during the second type of time interval. For example in time interval menu and graphic overlay are scheduled for presentation concurrently with video clip . In time interval menu is scheduled for concurrent presentation with video clip and video clip .

With continuing reference to is a functional block diagram of a single application . Application is generally representative of applications responsible for presenting media objects and . Application includes instructions discussed further below . Application has associated therewith a resource package data structure discussed further below an application play duration and one or more application presentation intervals .

Application play duration is a particular amount of time with reference to an amount a part or all of play duration within which media objects associated with application are presentable to and or selectable by a recipient of played presentation . In the context of for example application responsible for copyright notice has an application play duration composed of the amount of time between TT and TT . The application responsible for menu has an application play duration composed of the amount of time between TT and TT . The application responsible for graphical overlay has an application play duration composed of the amount of time between TT and ends at TT .

The intervals defined by beginning and ending title times obtained when an application play duration associated with a particular application is conceptualized on presentation timeline are referred to as application presentation intervals . For example the application responsible for copyright notice has an application presentation interval beginning at TT and ending at TT the application responsible for menu has an application presentation interval beginning at TT and TT and the application responsible for graphic overlay has an application presentation interval beginning at TT and TT .

Referring again to in some cases application may have more than one page. A page is a logical grouping of one or more media objects that are contemporaneously presentable within a particular application play duration and or application presentation interval . Media objects associated with a particular page however may be presented concurrently serially or a combination thereof. As shown an initial page has associated initial media object s and subsequent pages have associated media object s . Each page in turn has its own page duration. As shown initial page has page duration and subsequent page s has page duration . A page duration is the particular amount of time with reference to an amount a part or all of application play duration in which media objects associated with a particular page are presentable to and or selectable by a user.

The intervals defined by beginning and ending title times obtained when a page play duration associated with a particular page is conceptualized on the presentation timeline are referred to as page presentation intervals . Page presentation intervals are sub intervals of application presentation intervals . Specific media object presentation intervals may also be defined within page presentation intervals .

The number of applications and pages associated with a given title and the media objects associated with each application or page are generally logical distinctions that are matters of design choice. Multiple pages may be used when it is desirable to manage for example limit the number or amount of resources associated with an application that are loaded into memory during execution of the application. Resources for an application include the media objects used by the application as well as instructions for rendering the media objects. For example when an application with multiple pages is presentable it may be possible to only load into memory only those resources associated with a currently presentable page of the application.

Resource package data structure is used to facilitate loading of application resources into memory prior to execution of the application. Resource package data structure references memory locations where resources for that application are located. Resource package data structure may be stored in any desirable location together with or separate from the resources it references. For example resource package data structure may be disposed on an optical medium such a high definition DVD in an area separate from video component . Alternatively resource package data structure may be embedded into video component . In a further alternative the resource package data structure may be remotely located. One example of a remote location is a networked server. Topics relating to handling the transition of resources for application execution and between applications are not discussed in detail herein.

Referring again to application itself instructions when executed perform tasks related to rendering of media objects associated with application based on user input. One type of user input or a result thereof is a user event. User events are actions or occurrences initiated by a recipient of played presentation that relate to IC component . User events are generally but not necessarily asynchronous. Examples of user events include but are not limited to user interaction with media objects within played presentation such as selection of a button within menu or selection of the circle associated with graphical overlay . Such interactions may occur using any type of user input device now known or later developed including a keyboard a remote control a mouse a stylus or a voice command. It will be appreciated that application may respond to events other than user events but such events are not specifically discussed herein.

In one implementation instructions are computer executable instructions encoded in computer readable media discussed further below in connection with . In the examples set forth herein instructions are implemented using either script or markup elements . Although either script or markup elements may be used alone in general the combination of script and markup elements enables the creation of a comprehensive set of interactive capabilities for the high definition DVD movie.

Script includes instructions written in a non declarative programming language such as an imperative programming language. An imperative programming language describes computation in terms of a sequence of commands to be performed by a processor. In most cases where script is used the script is used to respond to user events. Script is useful in other contexts however such as handling issues that are not readily or efficiently implemented using markup elements alone. Examples of such contexts include system events and resource management for example accessing cached or persistently stored resources . In one implementation script is ECMAScript as defined by ECMA International in the ECMA 262 specification. Common scripting programming languages falling under ECMA 262 include JavaScript and JScript. In some settings it may be desirable to implement using a subset of ECMAScript 262 such as ECMA 327 along with a host environment and a set of application programming interfaces.

Markup elements and represent instructions written in a declarative programming language such as Extensible Markup Language XML . In XML elements are logical units of information defined using start tags and end tags within XML documents. XML documents are data objects that are made up of storage units called entities also called containers which contain either parsed or unparsed data. Parsed data is made up of characters some of which form character data and some of which form markup. Markup encodes a description of the document s storage layout and logical structure. There is one root element in an XML document no part of which appears in the content of any other element. For all other elements the start tags and end tags are within the content of other elements nested within each other.

An XML schema is a definition of the syntax es of a class of XML documents. One type of XML schema is a general purpose schema. Some general purpose schemas are defined by the World Wide Web Consortium W3C . Another type of XML schema is a special purpose schema. In the high definition DVD context for example one or more special purpose XML schemas have been promulgated by the DVD Forum for use with XML documents in compliance with the DVD Specifications for High Definition Video. It will be appreciated that other schemas for high definition DVD movies as well as schemas for other interactive multimedia presentations are possible.

At a high level an XML schema includes 1 a global element declaration which associates an element name with an element type and 2 a type definition which defines attributes sub elements and character data for elements of that type. Attributes of an element specify particular properties of the element using a name value pair with one attribute specifying a single element property.

Content elements which may include user event elements are used to identify particular media object elements presentable to a user by application . Media object elements in turn generally specify locations where data defining particular media objects is disposed. Such locations may be for example locations in persistent local or remote storage including locations on optical media or on wired or wireless public or private networks such as on the Internet privately managed networks or the World Wide Web. Locations specified by media object elements may also be references to locations such as references to resource package data structure . In this manner locations of media objects may be specified indirectly.

Timing elements are used to specify the times at or the time intervals during which particular content elements are presentable to a user by a particular application . Examples of timing elements include par timing or seq elements within a time container of an XML document.

Style elements are generally used to specify the appearance of particular content elements presentable to a user by a particular application.

User event elements represent content elements timing elements or style elements that are used to define or respond to user events.

Markup elements and have attributes that are usable to specify certain properties of their associated media object elements media objects . In one implementation these attributes properties represent values of one or more clocks or timing signals discussed further below in connection with . Using attributes of markup elements that have properties representing times or time durations is one way that synchronization between IC component and video component is achieved while a user receives played presentation .

A sample XML document containing markup elements is set forth below script is not shown . The sample XML document includes style and timing elements for performing a crop animation on a content element which references a media object element called id. The location of data defining media object associated with the id media object element is not shown.

The sample XML document begins with a root element called xml. Following the root element several namespace xmlns fields refer to locations on the World Wide Web where various schemas defining the syntax for the sample XML document and containers therein can be found. In the context of an XML document for use with a high definition DVD movie for example the namespace fields may refer to websites associated with the DVD Forum.

One content element referred to as id is defined within a container described by tags labeled body. Style elements elements under the label styling in the example associated with content element id are defined within a container described by tags labeled head. Timing elements elements under the label timing are also defined within the container described by tags labeled head. 

With continuing reference to is a simplified functional block diagram illustrating various components of timing signal management block and timing signals in more detail.

Timing signal management block is responsible for the handling of clocks and or timing signals that are used to determine specific times or time durations within Presentation System . As shown a continuous timing signal is produced at a predetermined rate by a clock source . Clock source may be a clock associated with a processing system such as a general purpose computer or a special purpose electronic device. Timing signal produced by clock source generally changes continually as a real world clock would within one second of real time clock source produces at a predetermined rate one second worth of timing signals . Timing signal is input to IC frame rate calculator A V frame rate calculator time reference calculator and time reference calculator .

IC frame rate calculator produces a timing signal based on timing signal . Timing signal is referred to as an IC frame rate which represents the rate at which frames of IC data are produced by IC manager . One exemplary value of the IC frame rate is 30 frames per second. IC frame rate calculator may reduce or increase the rate of timing signal to produce timing signal .

Frames of IC data generally include for each valid application and or page thereof a rendering of each media object associated with the valid application and or page in accordance with relevant user events. For exemplary purposes a valid application is one that has an application presentation interval within which the current title time of play duration falls based on presentation timeline . It will be appreciated that an application may have more than one application presentation interval. It will also be appreciated that no specific distinctions are made herein about an application s state based on user input or resource availability.

A V frame rate calculator also produces a timing signal timing signal based on timing signal . Timing signal is referred to as an A V frame rate which represents the rate at which frames of A V data are produced by AVC manager . The A V frame rate may be the same as or different from IC frame rate . One exemplary value of the A V frame rate is 24 frames per second. A V frame rate calculator may reduce or increase the rate of timing signal to produce timing signal .

A clock source produces timing signal which governs the rate at which information associated with clips is produced from media source s . Clock source may be the same clock as clock or based on the same clock as clock source . Alternatively clocks and may be altogether different and or have different sources. Clock source adjusts the rate of timing signal based on a play speed input . Play speed input represents user input received that affects the play speed of played presentation . Play speed is affected for example when a user jumps from one part of the movie to another referred to as trick play or when the user pauses slow forwards fast forwards slow reverses or fast reverses the movie. Trick play may be achieved by making selections from menu shown in or in other manners.

Time references represent the amounts of time that have elapsed within particular presentation intervals associated with active clips . For purposes of discussion herein an active clip is one that has a presentation interval within which the current title time of play duration falls based on presentation timeline . Time references are referred to as elapsed clip play time s . Time reference calculator receives time references and produces a media time reference . Media time reference represents the total amount of play duration that has elapsed based on one or more time references . In general when two or more clips are playing concurrently only one time reference is used to produce media time reference . The particular clip used to determine media time reference and how media time reference is determined based on multiple clips is a matter of implementation preference.

Time reference calculator receives timing signal media time reference and play speed input and produces a title time reference . Title time reference represents the total amount of time that has elapsed within play duration based on one or more of the inputs to time reference calculator . An exemplary method for calculating title time is shown and described in connection with .

Time reference calculator receives timing signal and title time reference and produces application time reference s and page time reference s . A single application time reference represents an amount of elapsed time of a particular application play duration shown and discussed in connection with with reference to continuous timing signal . Application time reference is determined when title time reference indicates that the current title time falls within application presentation interval of the particular application. Application time reference re sets for example becomes inactive or starts over at the completion of application presentation interval . Application time reference may also re set in other circumstances such as in response to user events or when trick play occurs.

Page time reference represents an amount of elapsed time of a single page play duration also shown and discussed in connection with with reference to continuous timing signal . Page time reference for a particular page of an application is determined when title time reference indicates that the current title time falls within an applicable page presentation interval . Page presentation intervals are sub intervals of application presentation intervals . Page time reference s may re set at the completion of the applicable page presentation interval s . Page time reference may also re set in other circumstances such as in response to user events or when trick play occurs. It will be appreciated that media object presentation intervals which may be sub intervals of application presentation intervals and or page presentation intervals are also definable.

Table 1 illustrates exemplary occurrences during play of played presentation by Presentation System and the effects of such occurrences on application time reference page time reference title time reference and media time reference .

The movie begins playing when the timing signal has a value of zero. When the timing signal has a value of 10 the application becomes valid and activates. Application time as well as page time associated with page one of the application assumes a value of zero. Pages two and three are inactive. Title time and media time both have values of 10.

Page two of the application loads at timing signal value . The application time and page one time have values of 5 while the title time and the media time have values of 15.

Page three of the application loads when the timing signal has a value of 20. The application time has a value of 10 page two time has a value of 5 and page one time is inactive. The title time and the media time have values of 20.

The movie pauses at timing signal value 22. The application time has a value of 12 page three time has a value of two and pages one and two are inactive. The title time and media time have values of 22. The movie resumes at timing signal value 24. Then the application time has a value of 14 page three time has a value of four and the title time and media time have values of 22.

At timing signal value 27 a new clip starts. The application time has a value of 17 page three time has a value of 7 the title time has a value of 25 and the media time is re set to zero.

A user de activates the application at timing signal value 32. The application time has a value of 22 the page time has a value of 12 the title time has a value of 30 and the media time has a value of 5.

At timing signal value 39 the user jumps backwards to another portion of the same clip. The application is assumed to be valid at the jumped to location and re activates shortly thereafter. The application time has a value of 0 page one time has a value of zero the other pages are inactive the title time has a value of 27 and the media time has a value of 2.

At timing signal value 46 the user changes the play speed of the movie fast forwarding at two times the normal speed. Fast forwarding continues until timing signal value 53. As shown the application and page times continue to change at a contstant pace with the continuous timing signal unaffected by the change in play speed of the movie while the title and media times change in proportion to the play speed of the movie. It should be noted that when a particular page of the application is loaded is tied to title time and or media time see discussion of application presentation interval s and page presentation interval s in connection with .

At timing signal value 48 a new title begins and title time and media time are re set to values of zero. With respect to the initial title this occurs when the title time has a value of 62 and the media time has a value of 36. Re setting not shown of application time and page time follows re setting of title time and media time .

Having access to various timelines clock sources timing signals and timing signal references enhances the ability of Presentation System to achieve frame level synchronization of IC data and A V data within played presentation and to maintain such frame level synchronization during periods of user interactivity.

With continuing reference to is a flowchart of one method for enhancing the ability of an interactive multimedia presentation system such as Presentation System to synchronously present interactive and video components of an interactive multimedia presentation such as IC component and video component of Presentation Content played presentation .

The method involves predicting and pre rendering a media object such as media object prior to the time at which the media object is scheduled for presentation. It will be appreciated that any number of media objects may be pre rendered but for exemplary purposes one media object is discussed.

The media object has a presentation state which represents one or more properties that are used to indicate whether and or how the media object is presentable within the presentation. Examples of the properties represented by the presentation state of the media object include states of various clocks or timing signals or states of various user gestures with respect to the media object.

The method is discussed in the context of Presentation System . It will be appreciated that any number of media objects may be pre rendered but for exemplary purposes one media object is discussed. Video component and IC component are presented to a user as A V data and IC data respectively within an amount of time represented by play duration . A V data is arranged for rendering by AVC manager which arranges one or more clips into a plurality of video frames at a rate based on A V frame rate . Video frames include samples of video audio data or any combination thereof and the video frame rate is a periodic time interval within which a particular group of video audio or data samples is presentable.

An exemplary video timeline with reference to A V frame rate is shown in . Various frame number presentation times are indicated on video timeline . Frame number presentation times represent times within play duration at which individual numbered frames of A V data are presentable. As shown frame number presentation times occur at a rate based on A V frame rate which also defines the duration of periodic video time intervals between frame number presentation times . The remainder of is discussed further below.

Media object is arranged for rendering by IC manager which presents the media object in accordance with the presentation state in a plurality of interactive content frames at a rate based on IC frame rate . IC frame rate is decoupled from A V frame rate .

The method begins at block and continues at block where a video frame rate an interactive content frame rate and a play speed of the presentation are ascertained.

For exemplary purposes A V frame rate is assumed to be 24 frames per second note that it is not necessary for frame rate to be the same as the frame rate at which a particular clip was recorded IC frame rate is assumed to be 30 frames per second and the play speed is assumed to be normal or 1 .

At block an interactive content IC timeline is ascertained. An exemplary IC timeline is shown in . Various IC presentation times are indicated on IC timeline . IC presentation times represent times within play duration at which the media object is presentable. As shown IC presentation times occur at a rate based on IC frame rate which also defines the duration of periodic interactive content time intervals between IC presentation times . For discussion purposes IC frame rate is assumed to be 30 frames per second. The remainder of is discussed further below.

A brief description of whether and or how the media object is presentable in the context of Presentation System follows. In general the media object is presentable when title time reference falls within an applicable application presentation interval and or page presentation interval of an application with which the media object is associated. Specific media object presentation intervals may also be defined. It will be appreciated however that a media object is not always rendered when it is presentable because specific user input may dictate whether and or when the media object is rendered.

An instruction such as instruction is generally associated with the application media object . Instruction represents one or more declarative language data structures such as XML markup elements or attributes thereof used alone or in combination with script to establish conditions under which the media object is presentable. Markup elements within content containers timing containers or style containers may be used to establish the conditions under which the media object is presentable.

In one implementation elements and attributes thereof can refer to timing signal and or timing signal directly or indirectly to establish times at or time durations within which the media object is presentable. For example timing signal may be referred to indirectly via clock source IC frame rate calculator A V frame rate calculator application time or page time . Likewise timing signal may be referred to indirectly via clock source elapsed clip play time s time reference calculator media time reference time reference calculator or title time reference for example.

Expressions involving logical references to clocks timing signals time reference calculators and or time references may also be used to define times conditions at which a particular media object is presentable. For example Boolean operands such as AND OR and NOT along with other operands or types thereof may be used to define such expressions or conditions. It will be appreciated however that presentation states of media objects are definable with reference to items other than timing signals clocks or time references.

Referring again to the steps illustrated by blocks through are performed. At block a current elapsed play time is calculated based on the video frame rate and on the play speed. Next at block a current interactive content presentation time is ascertained based on the current elapsed play time. At block a subsequent interactive content presentation time is selected. The subsequent interactive content presentation time is different from the current interactive content presentation time. The presentation state of the media object is predicted at the subsequent interactive content presentation time at block . At block based on the predicted presentation state the media object is pre rendered at a pre rendering time. Finally the pre rendered media object is arranged for presentation at the subsequent interactive content presentation time as indicated at block .

In the context of Presentation System referring to the timelines shown in a current elapsed play time of play duration is ascertained with reference to video timeline . Current elapsed play time may be the current value of title time for example. A current IC presentation time is ascertained with reference to video timeline and IC timeline IC presentation time that corresponds to current elapsed play time represents current IC presentation time . If there is no IC presentation time on IC timeline that corresponds exactly to title time on video timeline another IC presentation time may be deemed to be current IC presentation time . In one example the IC presentation time closest to title time is deemed to be IC presentation time . Alternatively IC presentation time may be selected using other criteria.

A subsequent IC presentation time is also ascertained with reference to IC timeline . In one implementation subsequent IC presentation time is the IC presentation time that corresponds to next presentable frame number presentation time on video timeline . Next presentable frame number presentation time represents the frame number presentation time associated with the next frame number after the frame number associated with current elapsed play time title time that is presentable to a user. It will be appreciated however that the next presentable frame number may be the next consecutive frame number based on playlist or may be a frame number one or more frame number presentation times away from the frame number associated with current elapsed play time . In one example during normal play speed subsequent IC presentation time is selected by adding an amount based on IC frame rate to current IC presentation time .

Likewise subsequent IC presentation time may not be the next consecutive IC presentation time with respect to current IC presentation time . One reason for these differences is because IC frame rate may be different than A V frame rate . Another reason is because user input may have affected the play speed and or direction of the presentation. A method for predicting subsequent IC presentation time is discussed below in connection with .

To predict the presentation state of media object at subsequent IC presentation time the presentation state may be determined from available information. Alternatively if the presentation state is not prospectively predictable with certainty the presentation state may be assumed based on one or more previous presentation states or the presentation state may be set or re set to a predetermined value based on conditions existing within Presentation System or other relevant conditions such as received user inputs.

During execution of a particular application a document object model DOM tree not shown associated with the application maintains the context for the state of the markup elements and or associated media objects affected thereby and a script host not shown associated with the application maintains the context for the script s variables functions and other states. As execution of application instructions progresses and user input is received the properties of any affected elements media objects are recorded and may be used to trigger behavior of media objects within played presentation .

At pre rendering time the media object is pre rendered and arranged for presentation by IC manager . Pre rendering time is offset from subsequent IC presentation time by an amount represented by time offset . Time offset is determined in a manner that preserves the appearance of simultaneous presentation of A V data at frame number presentation time and media object at predicted IC presentation time . For example time offset may be determined by taking the inverse of IC frame rate or A V frame rate .

Rendering pre rendering involves performing work items not shown resulting from execution of instructions that have been placed in queue s not shown associated with individual applications media objects. IC data resulting from performance of work items is transmitted to renderer mixer . Mixer renderer renders IC data in the graphics plane to produce the interactive portion of played presentation for the user.

Pre rendering media object a short time for example one IC frame and or video frame in advance is useful because whether or not a media object is affected by user events at a particular time is not generally prospectively ascertainable in an interactive environment. If the media object is pre rendered too many frames in advance there is no guarantee that the pre rendered frames will be needed and instructions executed for mis predicted frames cannot be un executed. Also pre rendering media objects too far in advance may limit the ability to respond to user events in a timely manner. When a user presses a button displayed via a media object a quick response is desired. Executing numerous predicted frames prior to responding to the user s button press may cause the user to experience a delayed response.

Receiving user input that affects the play speed of the movie such as trick play pausing slow forwarding fast forwarding slow reversing or fast reversing can exacerbate the problem of achieving frame by frame synchronization of interactive content and video content. During play of a presentation at normal speed video frames are generally pre rendered by AVC manager . Pre rendering involves retrieving and preparing for rendering certain portions of active clips from media source s prior to the time at which such portions are scheduled for presentation based on presentation timeline . After certain play speed changes occur such as trick play a user may experience a short delay before video content is presented. This delay represents among other things the time taken to locate and decode the first appropriate frame of video component . If however the first frame of IC component is not determined until after the first appropriate frame of video component is fully decoded then the presentation of IC component may be delayed with respect to the video component and the user may notice the loss of synchronicity.

The method begins at block and continues at block which illustrates the step of selecting the subsequent IC presentation time shown and discussed in connection with block of .

At block a predicted frame number presentation time is ascertained. The predicted frame number presentation time is then used to select the subsequent IC presentation time at block .

In the context of Presentation System referring to next presentable frame number time may be ascertained. One way to ascertain next presentable frame number time is to predict an amount of elapsed time of play duration in addition to current elapsed play time title time that has passed based on the play speed and A V frame rate .

In one implementation the predicted amount of elapsed time is calculated by estimating how many predicted frame number presentation times on video timeline have passed since presentation of video content at current elapsed play time title time . For example the predicted amount of elapsed time may be calculated by adding a multiplier value to current elapsed play time . The multiplier value is obtained by multiplying a play speed factor which may be a positive or a negative number depending on the direction of the play speed change by a frame rate factor. The play speed factor is obtained by dividing a value representing the play speed by A V frame rate . The frame rate factor is obtained by dividing A V frame rate by IC frame rate .

Then using one or more techniques discussed in connection with the predicted amount of elapsed time is used to locate the particular IC presentation time that will serve as selected subsequent IC presentation time .

Often at various play speeds patterns can be observed between the predicted amount of elapsed time and frame number presentation times corresponding thereto and corresponding IC presentation times .

For example frame number presentation times on a video timeline associated with a presentation progressing at normal play speed having an A V frame rate of 24 frames per second can be represented as a sequence of discrete values 0.04716 seconds 0.0833 seconds 0.71250 seconds 0.716666 seconds and so on. Predicted amounts of elapsed time that is title times however correspond to 0.03333 seconds 0.06666 seconds 0.8000 seconds 0.13333 seconds under the same conditions. Thus predicted amounts of elapsed time need not correspond exactly to frame number presentation times . To realize improvements in prediction adjusted predicted elapsed times shown in Table 2 below may be used in place of predicted amounts of elapsed time . Such adjustments may be accomplished by rounding predicted elapsed times up or down to the nearest discrete frame number presentation time . Similar adjustments may be made with respect to corresponding IC presentation times .

Table 2 illustrates certain exemplary patterns usable to predict adjusted predicted elapsed times APET in the case where a particular presentation has a normal play speed an A V frame rate of 24 frames per second an IC frame rate ICFR of 30 frames per second and a current IC presentation time that starts at zero and is incremented at a rate corresponding to the inverse of the IC frame rate. Patterns for adjusted predicted elapsed times APET IC presentation times ICPT frame number presentation times FNPT and predicted amounts of elapsed time PET are shown.

Recognizing patterns on video and or IC timelines may reduce the need to perform calculations of IC presentation times at each frame number presentation time . The patterns can be represented in predetermined tables or other data structures which can be used to look up IC presentation times subsequent IC presentation time based on particular frame number presentation times . Using predetermined data structures or tables in this manner rendering of certain frames and other adjustments may be skipped enabling better synchronization. In addition multiple video and or IC content timelines may be processed concurrently in an instance where more than one video is playing for example .

The processes illustrated in may be implemented in one or more general multi purpose or single purpose processors such as processor discussed below in connection with . Unless specifically stated the methods described herein are not constrained to a particular order or sequence. In addition some of the described method or elements thereof can occur or be performed concurrently.

A processor is responsive to computer readable media and to computer programs . Processor which may be a real or a virtual processor controls functions of an electronic device by executing computer executable instructions.

Computer readable media represent any number and combination of local or remote devices in any form now known or later developed capable of recording or storing computer readable data. In particular computer readable media may be or may include a semiconductor memory such as a read only memory ROM any type of programmable ROM PROM a random access memory RAM or a flash memory for example a magnetic storage device such as a floppy disk drive a hard disk drive a magnetic drum a magnetic tape or a magneto optical disk an optical storage device such as any type of compact disk or digital versatile disk a bubble memory a cache memory a core memory a holographic memory a memory stick a paper tape a punch card or any combination thereof. Computer readable media may also include transmission media and data associated therewith. Examples of transmission media data include but are not limited to data embodied in any form of wireline or wireless transmission such as packetized or non packetized data carried by a modulated carrier signal.

Computer programs represent any signal processing methods or stored instructions that electronically control predetermined operations on data. In general computer programs are computer executable instructions implemented as software components according to well known practices for component based software development and encoded in computer readable media such as computer readable media . Computer programs may be combined or distributed in various ways.

With continued reference to is a block diagram of an exemplary configuration of an operating environment in which all or part of Presentation System may be implemented or used. Operating environment is generally indicative of a wide variety of general purpose or special purpose computing environments. Operating environment is only one example of a suitable operating environment and is not intended to suggest any limitation as to the scope of use or functionality of the system s and methods described herein. For example operating environment may be a type of computer such as a personal computer a workstation a server a portable device a laptop a tablet or any other type of electronic device such as an optical media player or another type of media player now known or later developed or any aspect thereof. Operating environment may also be a distributed computing network or a Web service for example. A specific example of operating environment is an environment such as a DVD player or an operating system associated therewith which facilitates playing high definition DVD movies.

As shown operating environment includes or accesses components of computing unit including processor computer readable media and computer programs . Storage includes additional or different computer readable media associated specifically with operating environment such as an optical disc which is handled by optical disc drive . One or more internal buses which are well known and widely available elements may be used to carry data addresses control signals and other information within to or from computing environment or elements thereof.

Input interface s provide input to computing environment . Input may be collected using any type of now known or later developed interface such as a user interface. User interfaces may be touch input devices such as remote controls displays mice pens styluses trackballs keyboards microphones scanning devices and all types of devices that are used to input data.

Output interface s provide output from computing environment . Examples of output interface s include displays printers speakers drives such as optical disc drive and other disc drives and the like.

External communication interface s are available to enhance the ability of computing environment to receive information from or to transmit information to another entity via a communication medium such as a channel signal a data signal or a computer readable medium. External communication interface s may be or may include elements such as cable modems data terminal equipment media players data storage devices personal digital assistants or any other device or component combination thereof along with associated network support devices and or software or interfaces.

On client side one or more clients which may be implemented in hardware software firmware or any combination thereof are responsive to client data stores . Client data stores may be computer readable media employed to store information local to clients . On server side one or more servers are responsive to server data stores . Like client data stores server data stores may be computer readable media employed to store information local to servers .

Various aspects of an interactive multimedia presentation system that is used to present interactive content to a user synchronously with audio video content have been described. An interactive multimedia presentation has been generally described as having a play duration a variable play speed a video component and an IC component. It will be understood however that all of the foregoing components need not be used nor must the components when used be present concurrently. Functions components described in the context of Presentation System as being computer programs are not limited to implementation by any specific embodiments of computer programs. Rather functions are processes that convey or transform data and may generally be implemented by or executed in hardware software firmware or any combination thereof.

Although the subject matter herein has been described in language specific to structural features and or methodological acts it is also to be understood that the subject matter defined in the claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

It will further be understood that when one element is indicated as being responsive to another element the elements may be directly or indirectly coupled. Connections depicted herein may be logical or physical in practice to achieve a coupling or communicative interface between elements. Connections may be implemented among other ways as inter process communications among software processes or inter machine communications among networked computers.

The word exemplary is used herein to mean serving as an example instance or illustration. Any implementation or aspect thereof described herein as exemplary is not necessarily to be constructed as preferred or advantageous over other implementations or aspects thereof.

As it is understood that embodiments other than the specific embodiments described above may be devised without departing from the spirit and scope of the appended claims it is intended that the scope of the subject matter herein will be governed by the following claims.

